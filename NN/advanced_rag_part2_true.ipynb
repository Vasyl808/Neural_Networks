{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUCaGdAj9-9F"
      },
      "source": [
        "# Advanced RAG on HuggingFace documentation using LangChain\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKv51c_h9-9H"
      },
      "source": [
        "This notebook demonstrates how you can build an advanced RAG (Retrieval Augmented Generation) for answering a user's question about a specific knowledge base (here, the HuggingFace documentation), using LangChain.\n",
        "\n",
        "RAG systems are complex, with many moving parts: here a RAG diagram, where we noted in blue all possibilities for system enhancement:\n",
        "\n",
        "<img src=\"https://huggingface.co/datasets/huggingface/cookbook-images/resolve/main/RAG_workflow.png\" height=\"700\">\n",
        "\n",
        "> ğŸ’¡ As you can see, there are many steps to tune in this architecture: tuning the system properly will yield significant performance gains.\n",
        "\n",
        "In this notebook, we will take a look into many of these blue notes to see how to tune your RAG system and get the best performance.\n",
        "\n",
        "__Let's dig into the model building!__ First, we install the required model dependancies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NSX0p0rV9-9I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50d6cded-24ff-440b-9b0e-188ca94e518d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m297.6/297.6 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m817.7/817.7 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m171.5/171.5 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m70.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m291.3/291.3 kB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m115.2/115.2 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m647.5/647.5 kB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for annoy (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q torch transformers transformers accelerate bitsandbytes langchain sentence-transformers faiss-gpu openpyxl pacmap"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8KdqqTrbdID",
        "outputId": "01cbd2a4-1a92-48b0-a9e7-6c2952c7e94e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHZlCPPecMtI",
        "outputId": "e1c3850f-7e52-4397-a2de-8e922bcdb923"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.19.0-py3-none-any.whl (542 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Collecting huggingface-hub>=0.21.2 (from datasets)\n",
            "  Downloading huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m388.9/388.9 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, dill, multiprocess, huggingface-hub, datasets\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.20.3\n",
            "    Uninstalling huggingface-hub-0.20.3:\n",
            "      Successfully uninstalled huggingface-hub-0.20.3\n",
            "Successfully installed datasets-2.19.0 dill-0.3.8 huggingface-hub-0.22.2 multiprocess-0.70.16 xxhash-3.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8_Uyukt39-9J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66cbf3ba-f1b5-43bf-ddd7-6b659c00b4f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cannot find .env file\n"
          ]
        }
      ],
      "source": [
        "%reload_ext dotenv\n",
        "%dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "eoujYMwW9-9J"
      },
      "outputs": [],
      "source": [
        "from tqdm.notebook import tqdm\n",
        "import pandas as pd\n",
        "from typing import Optional, List, Tuple\n",
        "from datasets import Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pd.set_option(\n",
        "    \"display.max_colwidth\", None\n",
        ")  # this will be helpful when visualizing retriever outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kr6rN10U9-9J"
      },
      "source": [
        "### Load your knowledge base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "qZLVIEVW9-9J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237,
          "referenced_widgets": [
            "2956df5a5ef346d8b00183c8c8e613e8",
            "211e246543704c3fa34ca2fcf079a543",
            "44ba550273f646bbb3ac77c4bdd6a53c",
            "a4d62a370aa041e89a8e99f5151db55b",
            "272df92d04944724b223123388d21d41",
            "32de49a189034e288801c60cf75092b4",
            "f2dcf3e5aca74b679472e7c3e33d8336",
            "7287810c20b5479baa850d372946c472",
            "90765904443a4778b5d5077093c1bb36",
            "b434c8e91f914cbc85e6b90e0c8bfc9c",
            "56ed646918894840b56fe8739dae35f6",
            "6760cf877e514c0cb439258fc360182f",
            "7d5a2d1a727e40768d18eecf5dd2d720",
            "d4fa71c5a73f49c6b3e2a42f6fbc3e7d",
            "5a462a5d2963484ba6ae08f20791c2b8",
            "b672ad621eeb448cbbb038646d06aee8",
            "a5fd2d7ea2cb4edca35c2ed6d8e25388",
            "18e4fb7c01db400db8706f15aa596e85",
            "7241e4afcbc8477d82929cd37d3b1909",
            "524e4d1fc823479d8cacd2ffe835edeb",
            "5009c54c8f5c43db9bcd3c739bb42794",
            "51a2ee4a161843e2b900619a8d25ba16",
            "9175eaa7c9074cf6ad18a6fd3ab5414c",
            "4634fd9ed537423fa40197de02fc85ad",
            "c875b42ce80b4e95a3c416bf0ba60d3f",
            "cb094a58200b415d810814731f45a217",
            "002cc319f0a4440bbf065dc4e586e4f8",
            "a1f2f36cf9c242598a8d8aad3489bb5c",
            "cc7b79a6d59d4735a5beaf94dbc14b6e",
            "f747c9c27f054bc1a51b98ba63f24878",
            "db26bed459bb4810929ba91a8a1888a3",
            "2e2e811f45144bf8b89cd128ae51eb3a",
            "95ff6e1ca6db446689aabbb271324d30"
          ]
        },
        "outputId": "63f7d775-c6dc-4114-c27c-608ed91c6322"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/21.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2956df5a5ef346d8b00183c8c8e613e8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/22.0M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6760cf877e514c0cb439258fc360182f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/2647 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9175eaa7c9074cf6ad18a6fd3ab5414c"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import datasets\n",
        "\n",
        "ds = datasets.load_dataset(\"m-ric/huggingface_doc\", split=\"train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "836Q7vF49-9K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "a855d3969d364c6883baa4ea25c9415b",
            "0374af1f2f2141dcbde6dc1ec62f8e04",
            "d635c50fe95241b3aa8d89d628eeb819",
            "6a495551e2d7494093e4b488a00520a5",
            "88a30f9f33f1481f9c30f36987f7fc2f",
            "fbc1a418773042d09d18b21e0649d35d",
            "5113b8d55f514315ad7bdc94ca9aa160",
            "5fba4a72a9104ef08f28c796100340f4",
            "130fe463d7d24d2baf6f8381a1735aaf",
            "e1198effa1fd4391ae7dc3e33ce06f0a",
            "caa40c25ed824e34afea3274f478cb72"
          ]
        },
        "outputId": "1539a52a-1ebf-4dcf-db7f-ae626df2c20a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2647 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a855d3969d364c6883baa4ea25c9415b"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from langchain.docstore.document import Document as LangchainDocument\n",
        "\n",
        "RAW_KNOWLEDGE_BASE = [\n",
        "    LangchainDocument(page_content=doc[\"text\"], metadata={\"source\": doc[\"source\"]})\n",
        "    for doc in tqdm(ds)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\""
      ],
      "metadata": {
        "id": "f54exG56Iopf"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ragatouille"
      ],
      "metadata": {
        "id": "hGmrY80gfXXS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05f81424-ec7a-431f-d700-ad6510ef08d5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ragatouille\n",
            "  Downloading ragatouille-0.0.8.post2-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m752.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colbert-ai==0.2.19 (from ragatouille)\n",
            "  Downloading colbert-ai-0.2.19.tar.gz (86 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.7/86.7 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting faiss-cpu<2.0.0,>=1.7.4 (from ragatouille)\n",
            "  Downloading faiss_cpu-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fast-pytorch-kmeans==0.2.0.1 (from ragatouille)\n",
            "  Downloading fast_pytorch_kmeans-0.2.0.1-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: langchain<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from ragatouille) (0.1.16)\n",
            "Requirement already satisfied: langchain_core<0.2.0,>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from ragatouille) (0.1.45)\n",
            "Collecting llama-index>=0.7 (from ragatouille)\n",
            "  Downloading llama_index-0.10.30-py3-none-any.whl (6.9 kB)\n",
            "Collecting onnx<2.0.0,>=1.15.0 (from ragatouille)\n",
            "  Downloading onnx-1.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sentence-transformers<3.0.0,>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from ragatouille) (2.7.0)\n",
            "Requirement already satisfied: srsly==2.4.8 in /usr/local/lib/python3.10/dist-packages (from ragatouille) (2.4.8)\n",
            "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from ragatouille) (2.2.1+cu121)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.36.2 in /usr/local/lib/python3.10/dist-packages (from ragatouille) (4.40.0)\n",
            "Collecting voyager<3.0.0,>=2.0.2 (from ragatouille)\n",
            "  Downloading voyager-2.0.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.2 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bitarray (from colbert-ai==0.2.19->ragatouille)\n",
            "  Downloading bitarray-2.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m288.3/288.3 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from colbert-ai==0.2.19->ragatouille) (2.19.0)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (from colbert-ai==0.2.19->ragatouille) (2.2.5)\n",
            "Collecting git-python (from colbert-ai==0.2.19->ragatouille)\n",
            "  Downloading git_python-1.0.3-py2.py3-none-any.whl (1.9 kB)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (from colbert-ai==0.2.19->ragatouille) (1.0.1)\n",
            "Collecting ninja (from colbert-ai==0.2.19->ragatouille)\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from colbert-ai==0.2.19->ragatouille) (1.11.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from colbert-ai==0.2.19->ragatouille) (4.66.2)\n",
            "Collecting ujson (from colbert-ai==0.2.19->ragatouille)\n",
            "  Downloading ujson-5.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m53.2/53.2 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fast-pytorch-kmeans==0.2.0.1->ragatouille) (1.25.2)\n",
            "Collecting pynvml (from fast-pytorch-kmeans==0.2.0.1->ragatouille)\n",
            "  Downloading pynvml-11.5.0-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: catalogue<2.1.0,>=2.0.3 in /usr/local/lib/python3.10/dist-packages (from srsly==2.4.8->ragatouille) (2.0.10)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.0->ragatouille) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.0->ragatouille) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.0->ragatouille) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.0->ragatouille) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.0->ragatouille) (0.6.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.0->ragatouille) (1.33)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.32 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.0->ragatouille) (0.0.34)\n",
            "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.0->ragatouille) (0.0.1)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.0->ragatouille) (0.1.49)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.0->ragatouille) (2.7.0)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.0->ragatouille) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.0->ragatouille) (8.2.3)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain_core<0.2.0,>=0.1.4->ragatouille) (23.2)\n",
            "Collecting llama-index-agent-openai<0.3.0,>=0.1.4 (from llama-index>=0.7->ragatouille)\n",
            "  Downloading llama_index_agent_openai-0.2.3-py3-none-any.whl (13 kB)\n",
            "Collecting llama-index-cli<0.2.0,>=0.1.2 (from llama-index>=0.7->ragatouille)\n",
            "  Downloading llama_index_cli-0.1.12-py3-none-any.whl (26 kB)\n",
            "Collecting llama-index-core<0.11.0,>=0.10.30 (from llama-index>=0.7->ragatouille)\n",
            "  Downloading llama_index_core-0.10.30-py3-none-any.whl (15.4 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m15.4/15.4 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama-index-embeddings-openai<0.2.0,>=0.1.5 (from llama-index>=0.7->ragatouille)\n",
            "  Downloading llama_index_embeddings_openai-0.1.8-py3-none-any.whl (6.0 kB)\n",
            "Collecting llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2 (from llama-index>=0.7->ragatouille)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.1.5-py3-none-any.whl (6.7 kB)\n",
            "Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama-index>=0.7->ragatouille)\n",
            "  Downloading llama_index_legacy-0.9.48-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama-index-llms-openai<0.2.0,>=0.1.13 (from llama-index>=0.7->ragatouille)\n",
            "  Downloading llama_index_llms_openai-0.1.16-py3-none-any.whl (10 kB)\n",
            "Collecting llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 (from llama-index>=0.7->ragatouille)\n",
            "  Downloading llama_index_multi_modal_llms_openai-0.1.5-py3-none-any.whl (5.8 kB)\n",
            "Collecting llama-index-program-openai<0.2.0,>=0.1.3 (from llama-index>=0.7->ragatouille)\n",
            "  Downloading llama_index_program_openai-0.1.5-py3-none-any.whl (4.1 kB)\n",
            "Collecting llama-index-question-gen-openai<0.2.0,>=0.1.2 (from llama-index>=0.7->ragatouille)\n",
            "  Downloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl (2.9 kB)\n",
            "Collecting llama-index-readers-file<0.2.0,>=0.1.4 (from llama-index>=0.7->ragatouille)\n",
            "  Downloading llama_index_readers_file-0.1.19-py3-none-any.whl (36 kB)\n",
            "Collecting llama-index-readers-llama-parse<0.2.0,>=0.1.2 (from llama-index>=0.7->ragatouille)\n",
            "  Downloading llama_index_readers_llama_parse-0.1.4-py3-none-any.whl (2.5 kB)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx<2.0.0,>=1.15.0->ragatouille) (3.20.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers<3.0.0,>=2.2.2->ragatouille) (1.2.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers<3.0.0,>=2.2.2->ragatouille) (0.22.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers<3.0.0,>=2.2.2->ragatouille) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->ragatouille) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->ragatouille) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->ragatouille) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->ragatouille) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->ragatouille) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->ragatouille) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->ragatouille) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->ragatouille) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->ragatouille) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->ragatouille) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->ragatouille) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->ragatouille) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->ragatouille) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->ragatouille) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->ragatouille) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->ragatouille) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->ragatouille) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->ragatouille) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13->ragatouille) (12.4.127)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.36.2->ragatouille) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.36.2->ragatouille) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.36.2->ragatouille) (0.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.0->ragatouille) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.0->ragatouille) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.0->ragatouille) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.0->ragatouille) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.0->ragatouille) (1.9.4)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.0->ragatouille) (3.21.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.0->ragatouille) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain<0.2.0,>=0.1.0->ragatouille) (2.4)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain<0.2.0,>=0.1.0->ragatouille) (3.10.1)\n",
            "Collecting openai>=1.14.0 (from llama-index-agent-openai<0.3.0,>=0.1.4->llama-index>=0.7->ragatouille)\n",
            "  Downloading openai-1.23.2-py3-none-any.whl (311 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting deprecated>=1.2.9.3 (from llama-index-core<0.11.0,>=0.10.30->llama-index>=0.7->ragatouille)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.11.0,>=0.10.30->llama-index>=0.7->ragatouille)\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Collecting httpx (from llama-index-core<0.11.0,>=0.10.30->llama-index>=0.7->ragatouille)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llamaindex-py-client<0.2.0,>=0.1.18 (from llama-index-core<0.11.0,>=0.10.30->llama-index>=0.7->ragatouille)\n",
            "  Downloading llamaindex_py_client-0.1.18-py3-none-any.whl (136 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m136.1/136.1 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.30->llama-index>=0.7->ragatouille) (1.6.0)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.30->llama-index>=0.7->ragatouille) (3.8.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.30->llama-index>=0.7->ragatouille) (2.0.3)\n",
            "Collecting tiktoken>=0.3.3 (from llama-index-core<0.11.0,>=0.10.30->llama-index>=0.7->ragatouille)\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.30->llama-index>=0.7->ragatouille) (1.14.1)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index>=0.7->ragatouille) (4.12.3)\n",
            "Collecting pypdf<5.0.0,>=4.0.1 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index>=0.7->ragatouille)\n",
            "  Downloading pypdf-4.2.0-py3-none-any.whl (290 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m290.4/290.4 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index>=0.7->ragatouille)\n",
            "  Downloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
            "Collecting llama-parse<0.5.0,>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index>=0.7->ragatouille)\n",
            "  Downloading llama_parse-0.4.1-py3-none-any.whl (7.3 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.2.0,>=0.1.0->ragatouille) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.2.0,>=0.1.0->ragatouille) (2.18.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain<0.2.0,>=0.1.0->ragatouille) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain<0.2.0,>=0.1.0->ragatouille) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain<0.2.0,>=0.1.0->ragatouille) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain<0.2.0,>=0.1.0->ragatouille) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain<0.2.0,>=0.1.0->ragatouille) (3.0.3)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->colbert-ai==0.2.19->ragatouille) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->colbert-ai==0.2.19->ragatouille) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->colbert-ai==0.2.19->ragatouille) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->colbert-ai==0.2.19->ragatouille) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->colbert-ai==0.2.19->ragatouille) (0.70.16)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask->colbert-ai==0.2.19->ragatouille) (3.0.2)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask->colbert-ai==0.2.19->ragatouille) (2.2.0)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask->colbert-ai==0.2.19->ragatouille) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13->ragatouille) (2.1.5)\n",
            "Collecting gitpython (from git-python->colbert-ai==0.2.19->ragatouille)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers<3.0.0,>=2.2.2->ragatouille) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers<3.0.0,>=2.2.2->ragatouille) (3.4.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13->ragatouille) (1.3.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index>=0.7->ragatouille) (2.5)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.30->llama-index>=0.7->ragatouille) (3.7.1)\n",
            "Collecting httpcore==1.* (from httpx->llama-index-core<0.11.0,>=0.10.30->llama-index>=0.7->ragatouille)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.30->llama-index>=0.7->ragatouille) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.30->llama-index>=0.7->ragatouille)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.3.0,>=0.1.4->llama-index>=0.7->ragatouille) (1.7.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.0->ragatouille) (1.0.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython->git-python->colbert-ai==0.2.19->ragatouille)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.30->llama-index>=0.7->ragatouille) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.30->llama-index>=0.7->ragatouille) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.30->llama-index>=0.7->ragatouille) (2024.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.30->llama-index>=0.7->ragatouille) (1.2.1)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython->git-python->colbert-ai==0.2.19->ragatouille)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.30->llama-index>=0.7->ragatouille) (1.16.0)\n",
            "Building wheels for collected packages: colbert-ai\n",
            "  Building wheel for colbert-ai (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for colbert-ai: filename=colbert_ai-0.2.19-py3-none-any.whl size=114762 sha256=04dff1a1d019b772c86f0d95a603fd253fdcba57479aefb9b1335d64ba502739\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/b9/63/d4fc276c73c42ef7fc1065a26cf87e5a1cf56ef6498cbfbe5d\n",
            "Successfully built colbert-ai\n",
            "Installing collected packages: striprtf, ninja, dirtyjson, bitarray, voyager, ujson, smmap, pypdf, pynvml, onnx, h11, faiss-cpu, deprecated, tiktoken, httpcore, gitdb, httpx, gitpython, openai, llamaindex-py-client, git-python, fast-pytorch-kmeans, llama-index-legacy, llama-index-core, colbert-ai, llama-parse, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-program-openai, llama-index-question-gen-openai, llama-index, ragatouille\n",
            "Successfully installed bitarray-2.9.2 colbert-ai-0.2.19 deprecated-1.2.14 dirtyjson-1.0.8 faiss-cpu-1.8.0 fast-pytorch-kmeans-0.2.0.1 git-python-1.0.3 gitdb-4.0.11 gitpython-3.1.43 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 llama-index-0.10.30 llama-index-agent-openai-0.2.3 llama-index-cli-0.1.12 llama-index-core-0.10.30 llama-index-embeddings-openai-0.1.8 llama-index-indices-managed-llama-cloud-0.1.5 llama-index-legacy-0.9.48 llama-index-llms-openai-0.1.16 llama-index-multi-modal-llms-openai-0.1.5 llama-index-program-openai-0.1.5 llama-index-question-gen-openai-0.1.3 llama-index-readers-file-0.1.19 llama-index-readers-llama-parse-0.1.4 llama-parse-0.4.1 llamaindex-py-client-0.1.18 ninja-1.11.1.1 onnx-1.16.0 openai-1.23.2 pynvml-11.5.0 pypdf-4.2.0 ragatouille-0.0.8.post2 smmap-5.0.1 striprtf-0.0.26 tiktoken-0.6.0 ujson-5.9.0 voyager-2.0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_LxjD5h9-9K"
      },
      "source": [
        "# 1. Retriever - embeddings ğŸ—‚ï¸\n",
        "The __retriever acts like an internal search engine__: given the user query, it returns a few relevant snippets from your knowledge base.\n",
        "\n",
        "These snippets will then be fed to the Reader Model to help it generate its answer.\n",
        "\n",
        "So __our objective here is, given a user question, to find the most snippets from our knowledge base to answer that question.__\n",
        "\n",
        "This is a wide objective, it leaves open some questions. How many snippets should we retrieve? This parameter will be named `top_k`.\n",
        "\n",
        "How long should these snippets be? This is called the `chunk size`. There's no one-size-fits-all answers, but here are a few elements:\n",
        "- ğŸ”€ Your `chunk size` is allowed to vary from one snippet to the other.\n",
        "- Since there will always be some noise in your retrieval, increasing the `top_k` increases the chance to get relevant elements in your retrieved snippets. ğŸ¯ Shooting more arrows increases your probability to hit your target.\n",
        "- Meanwhile, the summed length of your retrieved documents should not be too high: for instance, for most current models 16k tokens will probably drown your Reader model in information due to [Lost-in-the-middle phenomenon](https://huggingface.co/papers/2307.03172). ğŸ¯ Give your reader model only the most relevant insights, not a huge pile of books!\n",
        "\n",
        "\n",
        "> In this notebook, we use Langchain library since __it offers a huge variety of options for vector databases and allows us to keep document metadata throughout the processing__."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uS6Mv8O9-9L"
      },
      "source": [
        "### 1.1 Split the documents into chunks\n",
        "\n",
        "- In this part, __we split the documents from our knowledge base into smaller chunks__ which will be the snippets on which the reader LLM will base its answer.\n",
        "- The goal is to prepare a collection of **semantically relevant snippets**. So their size should be adapted to precise ideas: too small will truncate ideas, too large will dilute them.\n",
        "\n",
        "ğŸ’¡ _Many options exist for text splitting: splitting on words, on sentence boundaries, recursive chunking that processes documents in a tree-like way to preserve structure information... To learn more about chunking, I recommend you read [this great notebook](https://github.com/FullStackRetrieval-com/RetrievalTutorials/blob/main/5_Levels_Of_Text_Splitting.ipynb) by Greg Kamradt._\n",
        "\n",
        "\n",
        "- **Recursive chunking** breaks down the text into smaller parts step by step using a given list of separators sorted from the most important to the least important separator. If the first split doesn't give the right size or shape chunks, the method repeats itself on the new chunks using a different separator. For instance with the list of separators `[\"\\n\\n\", \"\\n\", \".\", \"\"]`:\n",
        "    - The method will first break down the document wherever there is a double line break `\"\\n\\n\"`.\n",
        "    - Resulting documents will be split again on simple line breaks `\"\\n\"`, then on sentence ends `\".\"`.\n",
        "    - And finally, if some chunks are still too big, they will be split whenever they overflow the maximum size.\n",
        "\n",
        "- With this method, the global structure is well preserved, at the expense of getting slight variations in chunk size.\n",
        "\n",
        "> [This space](https://huggingface.co/spaces/A-Roucher/chunk_visualizer) lets you visualize how different splitting options affect the chunks you get.\n",
        "\n",
        "ğŸ”¬ Let's experiment a bit with chunk sizes, beginning with an arbitrary size, and see how splits work. We use Langchain's implementation of recursive chunking with `RecursiveCharacterTextSplitter`.\n",
        "- Parameter `chunk_size` controls the length of individual chunks: this length is counted by default as the number of characters in the chunk.\n",
        "- Parameter `chunk_overlap` lets adjacent chunks get a bit of overlap on each other. This reduces the probability that an idea could be cut in half by the split between two adjacent chunks. We ~arbitrarily set this to 1/10th of the chunk size, you could try different values!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PblZwLDhv40T",
        "outputId": "7a8294b1-c97e-4201-bd99-e07c903db34d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.1.3-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.42 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (0.1.45)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (1.23.2)\n",
            "Requirement already satisfied: tiktoken<1,>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (0.6.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.42->langchain_openai) (6.0.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.42->langchain_openai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.42->langchain_openai) (0.1.49)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.42->langchain_openai) (23.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.42->langchain_openai) (2.7.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.42->langchain_openai) (8.2.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (0.27.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (4.11.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.5.2->langchain_openai) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.5.2->langchain_openai) (2.31.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.10.0->langchain_openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.10.0->langchain_openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain_openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain_openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain_openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.42->langchain_openai) (2.4)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.42->langchain_openai) (3.10.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.42->langchain_openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.42->langchain_openai) (2.18.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain_openai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain_openai) (2.0.7)\n",
            "Installing collected packages: langchain_openai\n",
            "Successfully installed langchain_openai-0.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install semchunk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKReWCz8LAhV",
        "outputId": "0ec8b206-baa9-46e9-dbb1-17338b30e3bb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting semchunk\n",
            "  Downloading semchunk-0.2.3-py3-none-any.whl (6.6 kB)\n",
            "Installing collected packages: semchunk\n",
            "Successfully installed semchunk-0.2.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NOxcYVcLoxy",
        "outputId": "5a115a70-a42e-4791-a68e-c461eb51d789"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.6.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install semantic-text-splitter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZmRTgI5SJhY",
        "outputId": "da3ded4c-1f53-44d2-caab-d5abfcfddf6e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting semantic-text-splitter\n",
            "  Downloading semantic_text_splitter-0.11.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: semantic-text-splitter\n",
            "Successfully installed semantic-text-splitter-0.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "M4m6TwDJ9-9L"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# We use a hierarchical list of separators specifically tailored for splitting Markdown documents\n",
        "# This list is taken from LangChain's MarkdownTextSplitter class.\n",
        "MARKDOWN_SEPARATORS = [\n",
        "    \"\\n#{1,6} \",\n",
        "    \"```\\n\",\n",
        "    \"\\n\\\\*\\\\*\\\\*+\\n\",\n",
        "    \"\\n---+\\n\",\n",
        "    \"\\n___+\\n\",\n",
        "    \"\\n\\n\",\n",
        "    \"\\n\",\n",
        "    \" \",\n",
        "    \"\",\n",
        "]\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,  # the maximum number of characters in a chunk: we selected this value arbitrarily\n",
        "    chunk_overlap=100,  # the number of characters to overlap between chunks\n",
        "    add_start_index=True,  # If `True`, includes chunk's start index in metadata\n",
        "    strip_whitespace=True,  # If `True`, strips whitespace from the start and end of every document\n",
        "    separators=MARKDOWN_SEPARATORS,\n",
        ")\n",
        "\n",
        "docs_processed = []\n",
        "for doc in RAW_KNOWLEDGE_BASE:\n",
        "    docs_processed += text_splitter.split_documents([doc])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5jJUMgb9-9M"
      },
      "source": [
        "We also have to keep in mind that when embedding documents, we will use an embedding model that has accepts a certain maximum sequence length `max_seq_length`.\n",
        "\n",
        "So we should make sure that our chunk sizes are below this limit, because any longer chunk will be truncated before processing, thus losing relevancy."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try out different embedding model"
      ],
      "metadata": {
        "id": "r66IHoAAdp_f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#EMBEDDING_MODEL_NAME = \"sentence-transformers/bert-base-nli-stsb-mean-tokens\""
      ],
      "metadata": {
        "id": "a1GS28HadQiC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##EMBEDDING_MODEL_NAME = \"Mihaiii/gte-micro\""
      ],
      "metadata": {
        "id": "ZA2jAG5TXHgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "1c52eccde31740f98a2dc73e86b670ec",
            "0b12653c943c4d48acf9307e22f4def2",
            "0ff5c7ad45924098bad422f510e6d66f",
            "c4521b0aaa5f4b008a187b8bb9f28ae9",
            "fd3b329f856742a4bfffd0a5a58399ee",
            "921d40fe580b4622a9f3e85de24ebac6",
            "761f034edae544e1b8667abe2b706bc1",
            "ad8178beb87d4720963cc257a3af76c5",
            "cca998bbac2b430ab55ba3607bd97ddf",
            "85082cad860e45c79a3b09901633fe85",
            "ecb7daff99e141da8e629095e603b30e",
            "5d35d0bec01a441b9d7300d905473eed",
            "9215d86a38e64358b57daf0990c54360",
            "4a85071f674f44a19fe7c02e6ae37eb6",
            "3fac0f7cac0f4a959499bb06484a51eb",
            "6810fa5182724cc19fdb5f124704c3f8",
            "9666cbe1994443b0aa75ce9951fb1ca0",
            "c57bcc92bc2e4faa840f5de267794d0b",
            "893a89883e674cbc85668589602712c0",
            "536e6e8f5d7b46f78e595a431a99f85e",
            "5b1d5bc73e70426f99bd3c0078ce5278",
            "922a870d16954612ab89a28acb1f59f3",
            "8fb9641e2904464a9b35962da4b5bb54",
            "6d078c09092f4f7db19f5c898f7cce39",
            "9c50416d4a0d4d2ead41f213826cb58f",
            "1922ebb985f444fda4a0f1e9ed01e6f6",
            "43f2893792ba497690d1773682385af7",
            "0289e78f6c49470a9e8bf67dd867e172",
            "5318a330754e4c49a6736a9e640f10fb",
            "97d0264b273549eb9fe1c50cbb166582",
            "ba7f9b2f0ccd4ccdb6de19bcba0e8e6e",
            "6095bceaede048a0825a200a60f8b14c",
            "bdc400452f454baabc25b783ed643493",
            "4e378194502d4a1987952f1c961df757",
            "3ababca1d1e84029b5a3dd40c93bbc53",
            "aae39aec90cd426bbf1be9b82d3eea4d",
            "af1163d0fe4a4aa3bdd4fb9a97046950",
            "8661178767ff40c9af81814329bbcc55",
            "76084feac7864b338c4580896805c7a1",
            "b87a4b3d3af94bc5ae3438431ae3d57d",
            "673e55d54c71465f8e04f2d48f396eaa",
            "834ba3c05d8c4a47986535b3bde8dc91",
            "5c97da952d464f8f9297b25dffc56850",
            "5183c17098c54e32857a712e66e39bee",
            "599008141b7949c2b973ed3912d133d5",
            "f2f1c4330ceb42f7ae3dc2fb5e0e6efe",
            "dfdac4ff89764e029f3a10955abd753c",
            "579bbca0ddee4ebfb597a8259212c50f",
            "ca415ae913e4404785add23ee7356972",
            "fad9772949b946c6965fe5f6b64c822d",
            "2583be50cff1449894a9a0ea241b8fb0",
            "3c16b8b586a1438db9b571571e2c4f11",
            "a97a470947ab4f399239dee50132ae2b",
            "5c43a33c27534eda8e6c199d3ac9f2c6",
            "938145e87a4941af94afd87e619f1ad2",
            "051262e7b15c459580ae5eb9765764c3",
            "b0179244d5904679ba73497a3da77845",
            "c28679ef7b02493e81f623b14d09f0f2",
            "0d08cedf90534dfa83407906119c505d",
            "c69845eec7ac4b7997f16017d75c20d5",
            "84fb0aca383c4b098974179757894b62",
            "f3c93912ab7945a4aec1209bd3ce442d",
            "2fa604dad6fe453ca34972fb16c8ff06",
            "1d664576d98e4f6c9aec3aece8e197bd",
            "7bbeee11c9ab4fe799a667fdb9467110",
            "063056e902db4514bec9c8d37293016b",
            "dc63b09dafbf444c9f3af08ac0c7d8b4",
            "098d27ee2dce4f58aa5e3db7617efce4",
            "68d650508812484cadc4ed02c32710e8",
            "253c31ec02b640fc85bdf2339ebb211b",
            "1a20a65d8998429f839b39120cad62cd",
            "25408a3dd1eb44649f9ec8f81a3ad4a4",
            "eac8b023304043b39e0fa1dcf0e0508c",
            "6ef2ae3251384974b0a6a94c5c9c8162",
            "c83f0e97952a4e0fb674d00557aea39a",
            "19c0eef7a0f94422addb535444e6584c",
            "d694f1f4984b4c8386c6a5867b33dafd",
            "43d1f9c5b9144247aa66920fe71c5bc3",
            "0ab16a67dd3143798203378fa8449c6e",
            "1a6d21c92d3b4d949b0782d29dc7eb64",
            "0eca988963174b12be493a6de78c02cf",
            "0060493798be456f8d2c2ea9a9c81e16",
            "fb0cdc2583504f8d925b9f49fee22f12",
            "34b002fd67b94cbc9b0dda0b2bf14e19",
            "1b659bedc78d4dc881df9bd65822ae73",
            "3043a09751d2436e954cf4711c5798ab",
            "0ad450fa1e464e04a656aaf991f9086f",
            "42630f1dbfa344cdafa93fc7271bf823",
            "ebe2e7a8254e435dbe70a49cd6548097",
            "5850fa89e70b4ca29fdac93dace604a1",
            "2977d8a4e4f242e4aa8eca54de251131",
            "6f153358a883430c936aed4f7ff086fb",
            "ee9632f8313d4bc98f028af47c5a1dea",
            "1f08b4b1c273433c9539b4eb0d057b20",
            "07f6f3f0ee104308b7cf4748c87fd2a1",
            "fb8b2bdd65a9445abe1ce7ee63f18ca8",
            "aa4545a9771340d882b98be9a561ffbb",
            "bc353ce69f2b438191fcc2c06c36eec2",
            "87f88f8cbc144a43bc5674bbb2f4e7ef",
            "4ff43bb3a2394870a0e14c117e49be09",
            "15aa3e341aef4cd996048e762c39b314",
            "97ed49e9b6304d758c288e610cb425f5",
            "750e807876484cc681060602bd1415eb",
            "5ad5d0bffda64009915f56a098ae0e68",
            "eb1a5663b21d4a60bee1d78e5a01b6d6",
            "3fd7711b603f42508c2918b3ae14bf95",
            "6c5c0616dd3a4ce3beead52965072731",
            "5b57ad2e7f574a809df423d027c4eeb9",
            "36a5d5847e8c42428357188f02e08041",
            "2e4a148990b6497c9830335610825574",
            "314223aab91d4577a76aead5d148c8f9",
            "6c6b20ca047c427185d9aa04b19de467",
            "0b2ccef1413147b69b4d05b99c66e691",
            "a5804c8122264d93840c413dd5eff35e",
            "3423ba9792774a4cb88c01ae17a17452",
            "66c89e30c8174259a796d5cd3e40e612",
            "6efa18c33f194e9fa43561d0a647ca2c",
            "00d4ab26ba62489e9e3059a83071e0b1",
            "5b6efbb15fd94dd7a070db7791b43264",
            "fafacb4028b542aba11886ca03528b8f",
            "c0d5da340bda49b6879137e7b7ba3ca3",
            "a602afe293414f4a98ed4bca4cbeaa18",
            "c34d2b27247045518ee1a52d4a213d35",
            "2a83b9d66b9f46c39a46e5115debdff3",
            "a4ddffa6c6e54ac1b781120299ededcf",
            "d00bebd6886b4ed59ff0b1b7cc0672af",
            "cab9b7ed1d6f4db2ae3e3a617b08589a",
            "b02168cb7dd84d5d92c4c16dc6b4fa7e",
            "bc7dfe551aca46c894e778c1dfaa8737",
            "2c0c53cc3da645d9ae6ad78021358b9e",
            "9c8f1a4b7a2f4627a0b8a6941a9e4e3b",
            "bd0cf4e8ff984f718db37137e70a0634"
          ],
          "base_uri": "https://localhost:8080/",
          "height": 853
        },
        "id": "B4hoki349-9M",
        "outputId": "838bd8b5-130e-4d3f-d644-24fbda55273f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1c52eccde31740f98a2dc73e86b670ec"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/171 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5d35d0bec01a441b9d7300d905473eed"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/14.7k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8fb9641e2904464a9b35962da4b5bb54"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4e378194502d4a1987952f1c961df757"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/594 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "599008141b7949c2b973ed3912d133d5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/69.6M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "051262e7b15c459580ae5eb9765764c3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.46k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dc63b09dafbf444c9f3af08ac0c7d8b4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "43d1f9c5b9144247aa66920fe71c5bc3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/712k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ebe2e7a8254e435dbe70a49cd6548097"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/695 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4ff43bb3a2394870a0e14c117e49be09"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "1_Pooling/config.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "314223aab91d4577a76aead5d148c8f9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model's maximum sequence length: 512\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/31085 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a602afe293414f4a98ed4bca4cbeaa18"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# To get the value of the max sequence_length, we will query the underlying `SentenceTransformer` object used in the RecursiveCharacterTextSplitter.\n",
        "print(\n",
        "    f\"Model's maximum sequence length: {SentenceTransformer('Mihaiii/gte-micro').max_seq_length}\"\n",
        ")\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Mihaiii/gte-micro\")\n",
        "lengths = [len(tokenizer.encode(doc.page_content)) for doc in tqdm(docs_processed)]\n",
        "\n",
        "# Plot the distrubution of document lengths, counted as the number of tokens\n",
        "fig = pd.Series(lengths).hist()\n",
        "plt.title(\"Distribution of document lengths in the knowledge base (in count of tokens)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3teXczl9-9M"
      },
      "source": [
        "ğŸ‘€ As you can see, __the chunk lengths are not aligned with our limit of 512 tokens__, and some documents are above the limit, thus some part of them will be lost in truncation!\n",
        " - So we should change the `RecursiveCharacterTextSplitter` class to count length in number of tokens instead of number of characters.\n",
        " - Then we can choose a specific chunk size, here we would choose a lower threshold than 512:\n",
        "    - smaller documents could allow the split to focus more on specific ideas.\n",
        "    - But too small chunks would split sentences in half, thus losing meaning again: the proper tuning is a matter of balance."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Try out different embedding model\n",
        "\n",
        "Ğ¯ Ğ²Ğ¸ĞºĞ¾Ñ€Ğ¸ÑÑ‚Ğ°Ğ² 2 Ñ–Ğ½ÑˆÑ– Ğ¼Ğ¾Ğ´ĞµĞ»Ñ–"
      ],
      "metadata": {
        "id": "TIsNnGRtPOlR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#EMBEDDING_MODEL_NAME = \"Mihaiii/gte-micro\""
      ],
      "metadata": {
        "id": "R6Kz5JAVdTFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "61aa1a3d641c40759488931c1fa99ea1",
            "32cc0f5af1f247d6b1b1ec6483dc7f14",
            "8962e85fcceb4692860f9fea1036b545",
            "bbf4422e26c7455bbf42c58fe57240c4",
            "9e79cbb5835f495d8bb385d77fa5c4fd",
            "446b11c33f7e490293340ee6a4a2dbfb",
            "87faaef4e0e54c31b568e91b42ced923",
            "364641c148704883bb3c9f7be30c8c10",
            "7e62eec9dce54917a33bae11b58c3e83",
            "e0428c644b4748db954fa3266b071803",
            "cb669d9803dd4766a9bddf7488ba46cb",
            "48f421954105463eb083577cc299b97b",
            "a24015f113a84b36afa1f8716bc1fd01",
            "dec8d95a7d8a4ff189ca322ec7e76f36",
            "02855e587eec4cbdb22a6a0a987498bf",
            "01f915bcbd314c51891dbe16f4977952",
            "26a1b26787b14f1c97fa032a07574065",
            "929ab19e75ac44ad8f194b5b6df6bcd8",
            "b1fe3e880aa64b3c9a77bf27e7a25dc6",
            "0182c114510c4b4eababe3cdbac2a6f6",
            "59abc074158046138e049cdcff2cc693",
            "bfa7a54b06c947d095ca3d6f20304d93"
          ],
          "base_uri": "https://localhost:8080/",
          "height": 516
        },
        "id": "9hvIL2jO9-9M",
        "outputId": "29673476-13f4-4325-9630-8cc03db8c572"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2647 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "61aa1a3d641c40759488931c1fa99ea1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/17995 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "48f421954105463eb083577cc299b97b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "EMBEDDING_MODEL_NAME = \"Mihaiii/gte-micro\"\n",
        "\n",
        "\n",
        "def split_documents(\n",
        "    chunk_size: int,\n",
        "    knowledge_base: List[LangchainDocument],\n",
        "    tokenizer_name: Optional[str] = EMBEDDING_MODEL_NAME,\n",
        ") -> List[LangchainDocument]:\n",
        "    \"\"\"\n",
        "    Split documents into chunks of maximum size `chunk_size` tokens and return a list of documents.\n",
        "    \"\"\"\n",
        "    text_splitter = RecursiveCharacterTextSplitter.from_huggingface_tokenizer(\n",
        "        AutoTokenizer.from_pretrained(tokenizer_name),\n",
        "        chunk_size=chunk_size,\n",
        "        chunk_overlap=int(chunk_size / 10),\n",
        "        add_start_index=True,\n",
        "        strip_whitespace=True,\n",
        "        separators=MARKDOWN_SEPARATORS,\n",
        "    )\n",
        "\n",
        "    docs_processed = []\n",
        "    for doc in tqdm(knowledge_base):\n",
        "        docs_processed += text_splitter.split_documents([doc])\n",
        "\n",
        "    # Remove duplicates\n",
        "    unique_texts = {}\n",
        "    docs_processed_unique = []\n",
        "    for doc in docs_processed:\n",
        "        if doc.page_content not in unique_texts:\n",
        "            unique_texts[doc.page_content] = True\n",
        "            docs_processed_unique.append(doc)\n",
        "\n",
        "    return docs_processed_unique\n",
        "\n",
        "\n",
        "docs_processed = split_documents(\n",
        "    512,  # We choose a chunk size adapted to our model\n",
        "    RAW_KNOWLEDGE_BASE,\n",
        "    tokenizer_name=EMBEDDING_MODEL_NAME,\n",
        ")\n",
        "\n",
        "# Let's visualize the chunk sizes we would have in tokens from a common model\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(EMBEDDING_MODEL_NAME)\n",
        "lengths = [len(tokenizer.encode(doc.page_content)) for doc in tqdm(docs_processed)]\n",
        "fig = pd.Series(lengths).hist()\n",
        "plt.title(\"Distribution of document lengths in the knowledge base (in count of tokens)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Tune the chunking method - **2 points total**\n",
        "    1. Size of the chunks - 1 point\n",
        "    2. Method: split on different separators, use [semantic chunking](https://python.langchain.com/docs/modules/data_connection/document_transformers/semantic-chunker) - 1 point\n"
      ],
      "metadata": {
        "id": "WdfT89LPikUb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. Size of the chunks - 1 point"
      ],
      "metadata": {
        "id": "s0_bEXrEsJFc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "EMBEDDING_MODEL_NAME = \"thenlper/gte-small\"\n",
        "\n",
        "\n",
        "def split_documents(\n",
        "    chunk_size: int,\n",
        "    knowledge_base: List[LangchainDocument],\n",
        "    tokenizer_name: Optional[str] = EMBEDDING_MODEL_NAME,\n",
        ") -> List[LangchainDocument]:\n",
        "    \"\"\"\n",
        "    Split documents into chunks of maximum size `chunk_size` tokens and return a list of documents.\n",
        "    \"\"\"\n",
        "    text_splitter = RecursiveCharacterTextSplitter.from_huggingface_tokenizer(\n",
        "        AutoTokenizer.from_pretrained(tokenizer_name),\n",
        "        chunk_size=chunk_size,\n",
        "        chunk_overlap=int(chunk_size / 10),\n",
        "        add_start_index=True,\n",
        "        strip_whitespace=True,\n",
        "        separators=MARKDOWN_SEPARATORS,\n",
        "    )\n",
        "\n",
        "    docs_processed = []\n",
        "    for doc in knowledge_base:\n",
        "        docs_processed += text_splitter.split_documents([doc])\n",
        "\n",
        "    # Remove duplicates\n",
        "    unique_texts = {}\n",
        "    docs_processed_unique = []\n",
        "    for doc in docs_processed:\n",
        "        if doc.page_content not in unique_texts:\n",
        "            unique_texts[doc.page_content] = True\n",
        "            docs_processed_unique.append(doc)\n",
        "\n",
        "    return docs_processed_unique\n",
        "\n",
        "\n",
        "docs_processed = split_documents(\n",
        "    348,  # Chunck size change to 348\n",
        "    RAW_KNOWLEDGE_BASE,\n",
        "    tokenizer_name=EMBEDDING_MODEL_NAME,\n",
        ")\n",
        "\n",
        "# Let's visualize the chunk sizes we would have in tokens from a common model\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(EMBEDDING_MODEL_NAME)\n",
        "lengths = [len(tokenizer.encode(doc.page_content)) for doc in tqdm(docs_processed)]\n",
        "fig = pd.Series(lengths).hist()\n",
        "plt.title(\"Distribution of document lengths in the knowledge base (in count of tokens)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612,
          "referenced_widgets": [
            "ee8e030c5fe04bb6952ecfcbe90efcfa",
            "311b84ae2cfe4140ab40a4797ade8220",
            "0759d15312bf4f20ae6fee0e9c584525",
            "d20a0fa248794d38a46cf315ddcc493f",
            "4228cdc1d59243bb889c665c9d96b45b",
            "2d609fd4abfe438d8a59885c7df6ea85",
            "47e41defed02436c8d9afaf573e50848",
            "abea490afe434d75843f9ac9415c15a6",
            "04e17b21a41b41bd94d886d46fdc3e2c",
            "5b372dc78baa4458b19a141a310bc8ef",
            "a1700e6effd6479295406beec87d8a00",
            "c92b9016f36c40e7b814110f7c2e3b6e",
            "25431821d2da4757ab6d65a04143e7fe",
            "a55e19415bb94990a7964f30be904435",
            "427992f15c11455ab4ab8ffd4ff89492",
            "c73a05b066db45c29a818254f65639c2",
            "aafdd95536e143febe03a5b8c8701e97",
            "50d6e665396242259ac9c9654d7fc0ca",
            "d448855908a64d48aa82a2ca8bf85cc0",
            "4a6f4649c07e410bb4906c31d1362788",
            "950dad6c3ad44418963980327bff066b",
            "533ed8b74a7542cda670de9d86ff07b2",
            "6cb4b64dc835485594341b1039826e1e",
            "dca089a74a14403e96c99686a19cfd7f",
            "0e3d3a4759da41b2b36df2acb2e49b03",
            "859b6a6997de436b84d9b58c33fbc6de",
            "7c72d9b92c8348d2baff4de26d5b804c",
            "6e0aa61044f94ff3a95ba555fe785fb6",
            "9579b0d7de6e4c4fb1f93345279796b4",
            "8479f2ef66df4db19c02f6b9930b4858",
            "1ee79477267741e59fe8abd47a0495ea",
            "65d7aa6e746048fd8786c3d68fe774dc",
            "e357128b85ca4f75889f5bb494064368",
            "be99578799654f108ffb7541acdbfd6a",
            "3f3c485bd9654653b841e01bdc9bfaa4",
            "c2002c07fe9e4cf786f477a32b3255cb",
            "d7a7d808b47944f9a3435659de139d67",
            "1839d749bc344a83b126a726cc579735",
            "82d4471a2e774b11a49ccc2fedfdf501",
            "ff239f4e8af3409993ca547597172526",
            "51b3a5b1f5b749f09e9b262290289989",
            "44a9a259896a40f09c5ad9b5d106d2e6",
            "83d8d0336c2a4e14a196373b028cca31",
            "b8394bfac17e48bf8b8228f8ea119a8a",
            "e9ba3a55e8e8470cadae4ab8f568879b",
            "fb4bc8387c504fdc853744ccd72c8574",
            "19d0de43169f4dec812a3c2cc16117a9",
            "107c93980ef04b0fac47a6bc66438ceb",
            "01a384c0be5d4efda260ecc050cdb3ce",
            "1753e8f2f7fc46d29b5df827b2bb8884",
            "46f9657990dc49aea5f39685b2a4e40f",
            "848aa6d089fc4b55a829954f8b35d603",
            "b9f0af68016e421da38f607f4e8df39a",
            "c2b35bef5fab4086b3e3e1e8445f4796",
            "125423eae7ba44eaaca227df46b8f3fe"
          ]
        },
        "id": "U03gx1cAivyb",
        "outputId": "a682969d-f48d-448e-c873-50ec4ed0983b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/394 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ee8e030c5fe04bb6952ecfcbe90efcfa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c92b9016f36c40e7b814110f7c2e3b6e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/712k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6cb4b64dc835485594341b1039826e1e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "be99578799654f108ffb7541acdbfd6a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/26298 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e9ba3a55e8e8470cadae4ab8f568879b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wc3riwX39-9M"
      },
      "source": [
        "â¡ï¸ Now the chunk length distribution looks better!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.Method: split on different separators, use semantic chunking - 1 point"
      ],
      "metadata": {
        "id": "7xHPyqTJbIcH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from transformers import AutoTokenizer\n",
        "import semchunk\n",
        "import tiktoken\n",
        "from semantic_text_splitter import TextSplitter\n",
        "from tokenizers import Tokenizer\n",
        "from langchain.docstore.document import Document\n",
        "\n",
        "\n",
        "EMBEDDING_MODEL_NAME = \"thenlper/gte-small\"\n",
        "\n",
        "\n",
        "def split_documents(\n",
        "    knowledge_base: List[LangchainDocument],\n",
        "    tokenizer_name: Optional[str] = EMBEDDING_MODEL_NAME,\n",
        ") -> List[LangchainDocument]:\n",
        "    tokenizer = Tokenizer.from_pretrained(EMBEDDING_MODEL_NAME)\n",
        "    splitter = TextSplitter.from_huggingface_tokenizer(tokenizer)\n",
        "\n",
        "    docs_processed = []\n",
        "    for doc in tqdm(knowledge_base):\n",
        "        page_content = doc.page_content\n",
        "        curr = splitter.chunks(page_content, chunk_capacity=(200, 1000))\n",
        "        for i in curr:\n",
        "            docs_processed.append(Document(page_content=str(i), metadata=doc.metadata))\n",
        "\n",
        "    # Remove duplicates\n",
        "    unique_texts = {}\n",
        "    docs_processed_unique = []\n",
        "    for doc in docs_processed:\n",
        "        if doc.page_content not in unique_texts:\n",
        "            unique_texts[doc.page_content] = True\n",
        "            docs_processed_unique.append(doc)\n",
        "\n",
        "    return docs_processed_unique\n",
        "\n",
        "\n",
        "docs_processed = split_documents(\n",
        "    RAW_KNOWLEDGE_BASE,\n",
        "    tokenizer_name=EMBEDDING_MODEL_NAME,\n",
        ")\n",
        "\n",
        "# Let's visualize the chunk sizes we would have in tokens from a common model\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(EMBEDDING_MODEL_NAME)\n",
        "lengths = [len(tokenizer.encode(doc.page_content)) for doc in tqdm(docs_processed)]\n",
        "fig = pd.Series(lengths).hist()\n",
        "plt.title(\"Distribution of document lengths in the knowledge base (in count of tokens)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 644,
          "referenced_widgets": [
            "0355b562bbb640dd82a8a0fd0c8d8e1b",
            "3a5ca67cadfa4f488ea872ab43732539",
            "ca3a454d9cb9428a9cbfaf3fc7fccb69",
            "b82bd1b565b94de59ecbecf353365cf0",
            "6cfbaebd5ced44489ff622844bef13ae",
            "c43b980e9fa1468facd6aad00a0067a7",
            "0b3b3ebed04e4dcb871209046ceecadb",
            "f31f3e2131f14f7c99b4c19edcb0c8aa",
            "5cda11bb426840c980d10113d2655710",
            "f3306f3ead164f748b49ba66a3d5c161",
            "742714df22764075ae1aea1319733cd3",
            "7e638a86a4e94430ab9538feb16a99cd",
            "e316a9c6feef495c88a433f5c9fa559b",
            "c39621038fdf4bda8b3b7f944aa1f7ca",
            "5efaadf9602c487cab5dd1bbbd79782d",
            "278be15e6ad14a73a5ff27b0856a3c3a",
            "2f06b66eae2f4b6595cf54bbeb65258c",
            "71eafa7e4b3643d2810da017d1238252",
            "53d3d3ecff4f4a938de01420755a44b1",
            "949efc00a02b43218ed7ee8646dea83f",
            "dbaad1850f1646c984bdbc49259a3c0c",
            "fb80a54ce0164b1a813f16a1831f919e",
            "b1ca34935f6f4d868d2937545ad6a205",
            "d3bfbe39ba2946d388ee5b829bb90b39",
            "5fa0641a56064148982ed03b4367d493",
            "7fb70101db2e4442b45f541163fd9359",
            "338e3bbd708649528b58098e91967121",
            "d12a206c14d049fc902886845ebbbac8",
            "10d451a0d8a5438c93afd408b4d6c205",
            "a18a3bbabc084461bef5c6c1a12710a3",
            "7e4b218e9d294ff193cbbce325b88a19",
            "ea0e081ad93747aab02985fe7d73d000",
            "61188de0c66f4cb79113b3edfaf54b43",
            "a718bcb76c3b4aa5a97b7ed23d27633c",
            "8dbe2de7bb2b4cd28b27103ee10bf0fe",
            "dafd2f65eaf2492cbb8924941a89a1e9",
            "f30ed2bb43db40b6be79fbe1784a22b2",
            "dc3945c69bb248e0a69d83d13c56733e",
            "8e96ebc627d7431aa50c93ac97816c72",
            "0bfa169fbd3d4941806b55b91a8deb83",
            "57178a3ae7bb4ab491f2c659c44cdeac",
            "95808613a46d4708b49a0050fb76a853",
            "d12cc4f77ad94379b75a3d3aeccc1e38",
            "0131cf1e4491432c906287b921f870da",
            "013e9f99578042c99092b1a4a73b9a4d",
            "5996a751ec8a4946901f63cb3c8408a5",
            "4faeb43ad56f4f5b9448f11dc89008ba",
            "300cac470c754aed865c31792bbaea84",
            "98cfcbb4585142008056286f98de426b",
            "b3623ce01aaf4adf899d907f6abf5098",
            "4bd5be4212bf42dc9fb60e7fedae4ed4",
            "a3e73804ad134994ab770230dfc80dd3",
            "deeeb5da0c634e2bbdccb3952efb7d56",
            "13da19098dce427f938e77832af7c1c1",
            "605b162479f24735ab4f32d317d88f87",
            "65044b2026b04f0ca921d0db379bd6ab",
            "ecbb5cb58cb244399fd23a4fe0f23f4a",
            "946b0d4ab5494b2bb399599f3aeed2ea",
            "53e7c07c73a445b3af8ba7b1700ea65e",
            "686a5d216c5e494db23f710fafa9ae66",
            "2533e146572445b9a07161dbad04629e",
            "b0772679a9b146ed98b37221e2a73168",
            "815f966f6e554cc3933463c066c06c36",
            "141a024723684d5aa3e877b92f5c0e65",
            "ed0057ac3d0c48d4a5789f568f55b3fb",
            "b520990dd7a8423abc70f92bfa8f07c5"
          ]
        },
        "id": "YSKjEk7lLW2O",
        "outputId": "bb5aa940-9df1-4a00-d07e-ed58950c5cf6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/712k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0355b562bbb640dd82a8a0fd0c8d8e1b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2647 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7e638a86a4e94430ab9538feb16a99cd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/394 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b1ca34935f6f4d868d2937545ad6a205"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a718bcb76c3b4aa5a97b7ed23d27633c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "013e9f99578042c99092b1a4a73b9a4d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2628 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "65044b2026b04f0ca921d0db379bd6ab"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1ho-UKM9-9M"
      },
      "source": [
        "### 1.2 Building the vector database\n",
        "\n",
        "We want to compute the embeddings for all the chunks of our knowledge base: to learn more on sentence embeddings, we recommend reading [this guide](https://osanseviero.github.io/hackerllama/blog/posts/sentence_embeddings/).\n",
        "\n",
        "#### How does retrieval work ?\n",
        "\n",
        "Once the chunks are all embedded, we store them into a vector database. When the user types in a query, it gets embedded by the same model previously used, and a similarity search returns the closest documents from the vector database.\n",
        "\n",
        "The technical challenge is thus, given a query vector, to quickly find the nearest neighbours of this vector in the vector database. To do this, we need to choose two things: a distance, and a search algorithm to find the nearest neighbors quickly within a database of thousands of records.\n",
        "\n",
        "##### Nearest Neighbor search algorithm\n",
        "\n",
        "There are plentiful choices for the nearest neighbor search algorithm: we go with Facebook's [FAISS](https://github.com/facebookresearch/faiss), since FAISS is performant enough for most use cases, and it is well known thus widely implemented.\n",
        "\n",
        "##### Distances\n",
        "\n",
        "Regarding distances, you can find a good guide [here](https://osanseviero.github.io/hackerllama/blog/posts/sentence_embeddings/#distance-between-embeddings). In short:\n",
        "\n",
        "- **Cosine similarity** computes similarity between two vectors as the cosinus of their relative angle: it allows us to compare vector directions are regardless of their magnitude. Using it requires to normalize all vectors, to rescale them into unit norm.\n",
        "- **Dot product** takes into account magnitude, with the sometimes undesirable effect that increasing a vector's length will make it more similar to all others.\n",
        "- **Euclidean distance** is the distance between the ends of vectors.\n",
        "\n",
        "You can try [this small exercise](https://developers.google.com/machine-learning/clustering/similarity/check-your-understanding) to check your understanding of these concepts. But once vectors are normalized, [the choice of a specific distance does not matter much](https://platform.openai.com/docs/guides/embeddings/which-distance-function-should-i-use).\n",
        "\n",
        "Our particular model works well with cosine similarity, so choose this distance, and we set it up both in the Embedding model, and in the `distance_strategy` argument of our FAISS index. With cosine similarity, we have to normalize our embeddings.\n",
        "\n",
        "ğŸš¨ğŸ‘‡ The cell below takes a few minutes to run on A10G!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Try different indexing algorithm used"
      ],
      "metadata": {
        "id": "UYrDNhNxPUD6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ğ¯ Ğ²Ğ¸ĞºĞ¾Ñ€Ğ¸ÑÑ‚Ğ°Ğ² Annoy Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼"
      ],
      "metadata": {
        "id": "rlkeTB7GPl0n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "dalledM99-9M"
      },
      "outputs": [],
      "source": [
        "from langchain.vectorstores import FAISS\n",
        "from langchain.vectorstores import Annoy\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores.utils import DistanceStrategy\n",
        "\n",
        "embedding_model = HuggingFaceEmbeddings(\n",
        "    model_name=EMBEDDING_MODEL_NAME,\n",
        "    multi_process=True,\n",
        "    model_kwargs={\"device\": \"cuda\"},\n",
        "    encode_kwargs={\"normalize_embeddings\": True},  # set True for cosine similarity\n",
        ")\n",
        "\n",
        "#Annoy\n",
        "KNOWLEDGE_VECTOR_DATABASE = Annoy.from_documents(\n",
        "    docs_processed, embedding_model, distance_strategy=DistanceStrategy.COSINE\n",
        ")\n",
        "\n",
        "#KNOWLEDGE_VECTOR_DATABASE = FAISS.from_documents(\n",
        "#    docs_processed, embedding_model, distance_strategy=DistanceStrategy.COSINE\n",
        "#)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zM-wfiJ9-9N"
      },
      "source": [
        "ğŸ‘€ To visualize the search for the closest documents, let's project our embeddings from 384 dimensions down to 2 dimensions using PaCMAP.\n",
        "\n",
        "ğŸ’¡ _We chose PaCMAP rather than other techniques such as t-SNE or UMAP, since [it is efficient (preserves local and global structure), robust to initialization parameters and fast](https://www.nature.com/articles/s42003-022-03628-x#Abs1)._"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "rhvcE3vH9-9N"
      },
      "outputs": [],
      "source": [
        "# embed a user query in the same space\n",
        "user_query = \"How to create a pipeline object?\"\n",
        "query_vector = embedding_model.embed_query(user_query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "l8nz5FYC9-9N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d83e38f2-59ef-494e-d74b-7bee6b409667"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pacmap/pacmap.py:828: UserWarning: Warning: random state is set to 1\n",
            "  warnings.warn(f'Warning: random state is set to {_RANDOM_STATE}')\n"
          ]
        }
      ],
      "source": [
        "import pacmap\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "\n",
        "embedding_projector = pacmap.PaCMAP(\n",
        "    n_components=2, n_neighbors=None, MN_ratio=0.5, FP_ratio=2.0, random_state=1\n",
        ")\n",
        "\n",
        "embeddings_2d = [\n",
        "    list(KNOWLEDGE_VECTOR_DATABASE.index.reconstruct_n(idx, 1)[0])\n",
        "    for idx in range(len(docs_processed))\n",
        "] + [query_vector]\n",
        "\n",
        "# fit the data (The index of transformed data corresponds to the index of the original data)\n",
        "documents_projected = embedding_projector.fit_transform(\n",
        "    np.array(embeddings_2d), init=\"pca\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "7Cl9Fw2A9-9N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "outputId": "c290ddf4-e143-4caa-a6f6-701c412214d1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"6ccbbf3b-57b6-4b5c-a614-3a152e9969fe\" class=\"plotly-graph-div\" style=\"height:700px; width:1000px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"6ccbbf3b-57b6-4b5c-a614-3a152e9969fe\")) {                    Plotly.newPlot(                        \"6ccbbf3b-57b6-4b5c-a614-3a152e9969fe\",                        [{\"customdata\":[[\"Create an Endpoint\\n\\nAfter your first login, you will be directed to the [Endpoint creation page](htt...\"],[\"Access and read Logs\\n\\nHugging Face Endpoints provides access to the logs of your Endpoints through t...\"],[\"Hugging Face Inference Endpoints documentation\\n\\n## Setup\\n\\n```bash\\npip install hf-doc-builder==0.4.0 ...\"],[\"Pricing\\n\\n\\u003cdiv class=\\\"flex md:justify-start mb-2 text-gray-400 items-center\\\"\\u003e\\n  \\u003ca href=\\\"https:\\u002f\\u002fui.e...\"],[\"Supported Transformers & Diffusers Tasks\\n\\nInference Endpoints offers out-of-the-box support for Mach...\"],[\"Access and view Metrics\\n\\nHugging Face Endpoints provides access to the metrics and analytics of your...\"],[\"# FAQs \\n\\n\\n\\n### Q: In which regions are Inference Endpoints available?\\n\\nA: Inference Endpoints are cu...\"],[\"Help & Support \\n\\nWe have a variety of Inference Endpoints blog posts to help you at https:\\u002f\\u002fhuggingf...\"],[\"Pause and Resume your Endpoint\\n\\nYou can `pause` & `resume` endpoints to save cost and configurations...\"],[\"API Reference (Swagger)\\n\\nğŸ¤— Inference Endpoints can be used through the [UI](https:\\u002f\\u002fui.endpoints.hug...\"],[\"Use a custom Container Image\\n\\n\\nInference Endpoints not only allows you to [customize your inference ...\"],[\"Autoscaling\\n\\nAutoscaling allows you to dynamically adjust the number of endpoint replicas running yo...\"],[\"Create a Private Endpoint with AWS PrivateLink\\n\\nSecurity and secure inference are key principles of ...\"],[\"Security & Compliance\\n\\nğŸ¤— Inference Endpoints is built with security and secure inference at its core...\"],[\"Send Requests to Endpoints\\n\\nYou can send requests to Inference Endpoints using the UI leveraging the...\"],[\"Change Organization or Account\\n\\nInference Endpoints uses your [Hugging Face](https:\\u002f\\u002fhuggingface.co\\u002f...\"],[\"Update your Endpoint\\n\\nYou can update `running` Endpoints to change some of the configurations. Howev...\"],[\"Advanced Setup (Instance Types, Auto Scaling, Versioning)\\n\\nWe have seen how fast and easy it is to d...\"],[\"Inference Endpoints Version\\n\\nHugging Face Inference Endpoints comes with a default serving container...\"],[\"Serialization & Deserialization for Requests\\n\\nHugging Face Inference Endpount comes with a default s...\"],[\"ğŸ¤— Inference Endpoints\\n\\nğŸ¤— Inference Endpoints offers a secure production solution to easily deploy an...\"],[\"Access ğŸ¤— Inference Endpoints\\n\\nTo access the [Inference Endpoints web application](https:\\u002f\\u002fui.endpoin...\"],[\"Add custom Dependencies\\n\\nInference Endpointsâ€™ base image includes all required libraries to run infe...\"],[\"Create custom Inference Handler\\n\\nHugging Face Endpoints supports all of the Transformers and Sentenc...\"]],\"hovertemplate\":\"source=hf-endpoints-documentation\\u003cbr\\u003esymbol=circle\\u003cbr\\u003ex=%{x}\\u003cbr\\u003ey=%{y}\\u003cbr\\u003esize_col=%{marker.size}\\u003cbr\\u003eextract=%{customdata[0]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"hf-endpoints-documentation, circle\",\"marker\":{\"color\":\"#EF553B\",\"size\":[4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4],\"sizemode\":\"area\",\"sizeref\":0.25,\"symbol\":\"circle\",\"line\":{\"color\":\"DarkSlateGrey\",\"width\":0},\"opacity\":1},\"mode\":\"markers\",\"name\":\"hf-endpoints-documentation, circle\",\"showlegend\":true,\"x\":[0.46987572,0.43920732,0.22869056,-0.29434606,-1.3185724,0.25984287,-0.0064875516,-0.32980302,0.29589024,0.14934824,-0.24806666,-0.21995728,0.48437765,0.22231871,-0.044456203,0.91357577,0.3387757,-0.1478624,-0.3124512,-0.11591694,-0.50684005,-0.045829017,-0.20490266,-0.46922466],\"xaxis\":\"x\",\"y\":[6.934607,6.7795606,5.739535,7.1090503,6.8153114,6.870977,7.277345,7.1285467,7.051492,7.178121,7.301917,7.025986,7.008412,7.090668,7.120307,6.723217,7.158332,7.322722,7.3506446,7.1685905,7.177489,7.0543747,7.1380396,7.1061215],\"yaxis\":\"y\",\"type\":\"scattergl\"},{\"customdata\":[[\"Choosing a metric for your task\\n\\n**So you've trained your model and want to see how well itâ€™s doing ...\"],[\"--\\ntitle: poseval\\nemoji: ğŸ¤— \\ncolorFrom: blue\\ncolorTo: red\\nsdk: gradio\\nsdk_version: 3.19.1\\napp_file: a...\"],[\"--\\ntitle: MAPE\\nemoji: ğŸ¤— \\ncolorFrom: blue\\ncolorTo: red\\nsdk: gradio\\nsdk_version: 3.19.1\\napp_file: app....\"],[\"--\\ntitle: ROUGE\\nemoji: ğŸ¤— \\ncolorFrom: blue\\ncolorTo: red\\nsdk: gradio\\nsdk_version: 3.19.1\\napp_file: app...\"],[\"--\\ntitle: Word Length\\nemoji: ğŸ¤—\\ncolorFrom: green\\ncolorTo: purple\\nsdk: gradio\\nsdk_version: 3.0.2\\napp_f...\"],[\"Working with Keras and Tensorflow\\n\\n\\n\\nEvaluate can be easily intergrated into your Keras and Tensorfl...\"],[\"--\\ntitle: CharCut\\nemoji: ğŸ”¤\\ncolorFrom: blue\\ncolorTo: red\\nsdk: gradio\\nsdk_version: 3.19.1\\napp_file: ap...\"],[\"--\\ntitle: IndicGLUE\\nemoji: ğŸ¤— \\ncolorFrom: blue\\ncolorTo: red\\nsdk: gradio\\nsdk_version: 3.19.1\\napp_file:...\"],[\"--\\ntitle: Google BLEU\\nemoji: ğŸ¤— \\ncolorFrom: blue\\ncolorTo: red\\nsdk: gradio\\nsdk_version: 3.19.1\\napp_fil...\"],[\"--\\ntitle: \\nemoji: ğŸ¤— \\ncolorFrom: blue\\ncolorTo: red\\nsdk: gradio\\nsdk_version: 3.19.1\\napp_file: app.py\\np...\"],[\"--\\ntitle: Mean IoU\\nemoji: ğŸ¤— \\ncolorFrom: blue\\ncolorTo: red\\nsdk: gradio\\nsdk_version: 3.19.1\\napp_file: ...\"],[\"--\\ntitle: SuperGLUE\\nemoji: ğŸ¤— \\ncolorFrom: blue\\ncolorTo: red\\nsdk: gradio\\nsdk_version: 3.19.1\\napp_file:...\"],[\"ğŸ¤— Transformers\\n\\nTo run the ğŸ¤— Transformers examples make sure you have installed the following librar...\"],[\"!---\\nCopyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"--\\ntitle: Spearman Correlation Coefficient Metric \\nemoji: ğŸ¤— \\ncolorFrom: blue\\ncolorTo: red\\nsdk: gradi...\"],[\"--\\ntitle: TREC Eval\\nemoji: ğŸ¤— \\ncolorFrom: blue\\ncolorTo: red\\nsdk: gradio\\nsdk_version: 3.19.1\\napp_file:...\"],[\"A quick tour\\n\\nğŸ¤— Evaluate provides access to a wide range of evaluation tools. It covers a range of m...\"],[\"Using the `evaluator` with custom pipelines\\n\\nThe evaluator is designed to work with `transformer` pi...\"],[\"--\\ntitle: Matthews Correlation Coefficient\\nemoji: ğŸ¤— \\ncolorFrom: blue\\ncolorTo: red\\nsdk: gradio\\nsdk_ve...\"],[\"Evaluator\\n\\nThe evaluator classes for automatic evaluation.\\n\\n## Evaluator classes\\n\\nThe main entry poi...\"],[\"Using the `evaluator`\\n\\nThe `Evaluator` classes allow to evaluate a  triplet of model, dataset, and m...\"],[\"--\\ntitle: Exact Match\\nemoji: ğŸ¤— \\ncolorFrom: blue\\ncolorTo: red\\nsdk: gradio\\nsdk_version: 3.19.1\\napp_fil...\"],[\"--\\ntitle: Wilcoxon\\nemoji: ğŸ¤— \\ncolorFrom: blue\\ncolorTo: green\\nsdk: gradio\\nsdk_version: 3.0.2\\napp_file:...\"],[\"--\\ntitle: SQuAD v2\\nemoji: ğŸ¤— \\ncolorFrom: blue\\ncolorTo: red\\nsdk: gradio\\nsdk_version: 3.19.1\\napp_file: ...\"],[\"--\\ntitle: BLEU\\nemoji: ğŸ¤— \\ncolorFrom: blue\\ncolorTo: red\\nsdk: gradio\\nsdk_version: 3.19.1\\napp_file: app....\"],[\"--\\ntitle: Pearson Correlation Coefficient \\nemoji: ğŸ¤— \\ncolorFrom: blue\\ncolorTo: red\\nsdk: gradio\\nsdk_ve...\"],[\"--\\ntitle: Code Eval\\nemoji: ğŸ¤— \\ncolorFrom: blue\\ncolorTo: red\\nsdk: gradio\\nsdk_version: 3.19.1\\napp_file:...\"],[\"p align=\\\"center\\\"\\u003e\\n    \\u003cbr\\u003e\\n    \\u003cimg src=\\\"https:\\u002f\\u002fhuggingface.co\\u002fdatasets\\u002fevaluate\\u002fmedia\\u002fresolve\\u002fmain...\"],[\"Types of Evaluations in ğŸ¤— Evaluate\\n\\nThe goal of the ğŸ¤— Evaluate library is to support different types...\"],[\"--\\ntitle: WER\\nemoji: ğŸ¤— \\ncolorFrom: blue\\ncolorTo: red\\nsdk: gradio\\nsdk_version: 3.19.1\\napp_file: app.p...\"],[\"--\\ntitle: chrF\\nemoji: ğŸ¤— \\ncolorFrom: blue\\ncolorTo: red\\nsdk: gradio\\nsdk_version: 3.19.1\\napp_file: app....\"],[\"--\\ntitle: Regard\\nemoji: ğŸ¤—\\ncolorFrom: green\\ncolorTo: purple\\nsdk: gradio\\nsdk_version: 3.0.2\\napp_file: ...\"],[\"--\\ntitle: Honest\\nemoji: ğŸ¤—\\ncolorFrom: blue\\ncolorTo: green\\nsdk: gradio\\nsdk_version: 3.0.2\\napp_file: ap...\"],[\"--\\ntitle: SQuAD\\nemoji: ğŸ¤— \\ncolorFrom: blue\\ncolorTo: red\\nsdk: gradio\\nsdk_version: 3.19.1\\napp_file: app...\"],[\"--\\ntitle: Recall\\nemoji: ğŸ¤— \\ncolorFrom: blue\\ncolorTo: red\\nsdk: gradio\\nsdk_version: 3.19.1\\napp_file: ap...\"],[\"--\\ntitle: BERT Score\\nemoji: ğŸ¤— \\ncolorFrom: blue\\ncolorTo: red\\nsdk: gradio\\nsdk_version: 3.19.1\\napp_file...\"],[\"--\\ntitle: Competition MATH\\nemoji: ğŸ¤— \\ncolorFrom: blue\\ncolorTo: red\\nsdk: gradio\\nsdk_version: 3.19.1\\nap...\"],[\"--\\ntitle: MSE\\nemoji: ğŸ¤— \\ncolorFrom: blue\\ncolorTo: red\\nsdk: gradio\\nsdk_version: 3.19.1\\napp_file: app.p...\"],[\"--\\ntitle: WikiSplit\\nemoji: ğŸ¤— \\ncolorFrom: blue\\ncolorTo: red\\nsdk: gradio\\nsdk_version: 3.19.1\\napp_file:...\"],[\"--\\ntitle: r_squared\\nemoji: ğŸ¤— \\ncolorFrom: blue\\ncolorTo: red\\nsdk: gradio\\nsdk_version: 3.0.2\\napp_file: ...\"],[\"--\\ntitle: Precision\\nemoji: ğŸ¤— \\ncolorFrom: blue\\ncolorTo: red\\nsdk: gradio\\nsdk_version: 3.19.1\\napp_file:...\"],[\"--\\ntitle: XTREME-S\\nemoji: ğŸ¤— \\ncolorFrom: blue\\ncolorTo: red\\nsdk: gradio\\nsdk_version: 3.19.1\\napp_file: ...\"],[\"--\\ntitle: CER\\nemoji: ğŸ¤— \\ncolorFrom: blue\\ncolorTo: red\\nsdk: gradio\\nsdk_version: 3.19.1\\napp_file: app.p...\"],[\"--\\ntitle: {{ cookiecutter.module_name }}\\ndatasets:\\n- {{ cookiecutter.dataset_name }} \\ntags:\\n- evalua...\"],[\"--\\ntitle: McNemar\\nemoji: ğŸ¤— \\ncolorFrom: blue\\ncolorTo: green\\nsdk: gradio\\nsdk_version: 3.0.2\\napp_file: ...\"],[\"--\\ntitle: F1\\nemoji: ğŸ¤— \\ncolorFrom: blue\\ncolorTo: red\\nsdk: gradio\\nsdk_version: 3.19.1\\napp_file: app.py...\"],[\"Considerations for model evaluation\\n\\nDeveloping an ML model is rarely a one-shot deal: it often invo...\"],[\"--\\ntitle: Mahalanobis Distance\\nemoji: ğŸ¤— \\ncolorFrom: blue\\ncolorTo: red\\nsdk: gradio\\nsdk_version: 3.19....\"],[\"--\\ntitle: MAUVE\\nemoji: ğŸ¤—\\ncolorFrom: blue\\ncolorTo: red\\nsdk: gradio\\nsdk_version: 3.19.1\\napp_file: app....\"],[\"--\\ntitle: BLEURT\\nemoji: ğŸ¤— \\ncolorFrom: blue\\ncolorTo: red\\nsdk: gradio\\nsdk_version: 3.19.1\\napp_file: ap...\"],[\"--\\ntitle: Label Distribution\\nemoji: ğŸ¤—\\ncolorFrom: green\\ncolorTo: purple\\nsdk: gradio\\nsdk_version: 3.0....\"],[\"--\\ntitle: XNLI\\nemoji: ğŸ¤— \\ncolorFrom: blue\\ncolorTo: red\\nsdk: gradio\\nsdk_version: 3.19.1\\napp_file: app....\"],[\"--\\ntitle: Text Duplicates\\nemoji: ğŸ¤—\\ncolorFrom: green\\ncolorTo: purple\\nsdk: gradio\\nsdk_version: 3.0.2\\na...\"],[\"Creating an EvaluationSuite\\n\\nIt can be useful to evaluate models on a variety of different tasks to ...\"],[\"--\\ntitle: MAE\\nemoji: ğŸ¤— \\ncolorFrom: blue\\ncolorTo: red\\nsdk: gradio\\nsdk_version: 3.19.1\\napp_file: app.p...\"],[\"--\\ntitle: GLUE\\nemoji: ğŸ¤— \\ncolorFrom: blue\\ncolorTo: red\\nsdk: gradio\\nsdk_version: 3.19.1\\napp_file: app....\"],[\"Scikit-Learn\\n\\nTo run the scikit-learn examples make sure you have installed the following library:\\n\\n...\"],[\"Logging methods\\n\\nğŸ¤— Evaluate strives to be transparent and explicit about how it works, but this can ...\"],[\"Installation\\n\\nBefore you start, you will need to setup your environment and install the appropriate ...\"],[\"--\\ntitle: Word Count\\nemoji: ğŸ¤—\\ncolorFrom: green\\ncolorTo: purple\\nsdk: gradio\\nsdk_version: 3.0.2\\napp_fi...\"],[\"--\\ntitle: seqeval\\nemoji: ğŸ¤— \\ncolorFrom: blue\\ncolorTo: red\\nsdk: gradio\\nsdk_version: 3.19.1\\napp_file: a...\"],[\"p align=\\\"center\\\"\\u003e\\n    \\u003cbr\\u003e\\n    \\u003cimg src=\\\"https:\\u002f\\u002fhuggingface.co\\u002fdatasets\\u002fevaluate\\u002fmedia\\u002fresolve\\u002fmain...\"],[\"--\\ntitle: SARI\\nemoji: ğŸ¤— \\ncolorFrom: blue\\ncolorTo: red\\nsdk: gradio\\nsdk_version: 3.19.1\\napp_file: app....\"],[\"--\\ntitle: METEOR\\nemoji: ğŸ¤— \\ncolorFrom: blue\\ncolorTo: red\\nsdk: gradio\\nsdk_version: 3.19.1\\napp_file: ap...\"],[\"--\\ntitle: CharacTER\\nemoji: ğŸ”¤\\ncolorFrom: orange\\ncolorTo: red\\nsdk: gradio\\nsdk_version: 3.19.1\\napp_file...\"],[\"!---\\nCopyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"--\\ntitle: MASE\\nemoji: ğŸ¤— \\ncolorFrom: blue\\ncolorTo: red\\nsdk: gradio\\nsdk_version: 3.19.1\\napp_file: app....\"],[\"--\\ntitle: sMAPE\\nemoji: ğŸ¤— \\ncolorFrom: blue\\ncolorTo: red\\nsdk: gradio\\nsdk_version: 3.19.1\\napp_file: app...\"],[\"Saving methods\\n\\nMethods for saving evaluations results:\\n\\n## Save\\n\\n[[autodoc]] evaluate.save...\"],[\"--\\ntitle: Exact Match \\nemoji: ğŸ¤— \\ncolorFrom: blue\\ncolorTo: green\\nsdk: gradio\\nsdk_version: 3.0.2\\napp_f...\"],[\"--\\ntitle: Perplexity\\nemoji: ğŸ¤—\\ncolorFrom: green\\ncolorTo: purple\\nsdk: gradio\\nsdk_version: 3.0.2\\napp_fi...\"],[\"--\\ntitle: Accuracy\\nemoji: ğŸ¤— \\ncolorFrom: blue\\ncolorTo: red\\nsdk: gradio\\nsdk_version: 3.19.1\\napp_file: ...\"],[\"--\\ntitle: RL Reliability\\nemoji: ğŸ¤— \\ncolorFrom: blue\\ncolorTo: red\\nsdk: gradio\\nsdk_version: 3.19.1\\napp_...\"],[\"--\\ntitle: \\nemoji: ğŸ¤— \\ncolorFrom: blue\\ncolorTo: red\\nsdk: gradio\\nsdk_version: 3.19.1\\napp_file: app.py\\np...\"],[\"--\\ntitle: CUAD\\nemoji: ğŸ¤— \\ncolorFrom: blue\\ncolorTo: red\\nsdk: gradio\\nsdk_version: 3.19.1\\napp_file: app....\"],[\"Visualization methods\\n\\nMethods for visualizing evaluations results:\\n\\n## Radar Plot\\n\\n[[autodoc]] eval...\"],[\"--\\ntitle: TER\\nemoji: ğŸ¤— \\ncolorFrom: blue\\ncolorTo: red\\nsdk: gradio\\nsdk_version: 3.19.1\\napp_file: app.p...\"],[\"--\\ntitle: Toxicity\\nemoji: ğŸ¤—\\ncolorFrom: blue\\ncolorTo: red\\nsdk: gradio\\nsdk_version: 3.0.2\\napp_file: ap...\"],[\"Hub methods\\n\\nMethods for using the Hugging Face Hub:\\n\\n## Push to hub \\n\\n[[autodoc]] evaluate.push_to_...\"],[\"--\\ntitle: COMET\\nemoji: ğŸ¤— \\ncolorFrom: blue\\ncolorTo: red\\nsdk: gradio\\nsdk_version: 3.19.1\\napp_file: app...\"],[\"--\\ntitle: Brier Score\\nemoji: ğŸ¤— \\ncolorFrom: blue\\ncolorTo: red\\nsdk: gradio\\nsdk_version: 3.19.1\\napp_fil...\"],[\"--\\ntitle: Perplexity\\nemoji: ğŸ¤—\\ncolorFrom: blue\\ncolorTo: red\\nsdk: gradio\\nsdk_version: 3.19.1\\napp_file:...\"],[\"Loading methods\\n\\nMethods for listing and loading evaluation modules:\\n\\n## List\\n\\n[[autodoc]] evaluate....\"],[\"Creating and sharing a new evaluation\\n\\n## Setup\\n\\nBefore you can create a new metric make sure you ha...\"],[\"Main classes\\n\\n## EvaluationModuleInfo\\n\\nThe base class `EvaluationModuleInfo` implements a the logic ...\"],[\"--\\ntitle: SacreBLEU\\nemoji: ğŸ¤— \\ncolorFrom: blue\\ncolorTo: red\\nsdk: gradio\\nsdk_version: 3.19.1\\napp_file:...\"],[\"--\\ntitle: ROC AUC\\nemoji: ğŸ¤— \\ncolorFrom: blue\\ncolorTo: red\\nsdk: gradio\\nsdk_version: 3.19.1\\napp_file: a...\"],[\"--\\ntitle: NIST_MT\\nemoji: ğŸ¤— \\ncolorFrom: purple\\ncolorTo: red\\nsdk: gradio\\nsdk_version: 3.19.1\\napp_file:...\"]],\"hovertemplate\":\"source=evaluate\\u003cbr\\u003esymbol=circle\\u003cbr\\u003ex=%{x}\\u003cbr\\u003ey=%{y}\\u003cbr\\u003esize_col=%{marker.size}\\u003cbr\\u003eextract=%{customdata[0]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"evaluate, circle\",\"marker\":{\"color\":\"#00cc96\",\"size\":[4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4],\"sizemode\":\"area\",\"sizeref\":0.25,\"symbol\":\"circle\",\"line\":{\"color\":\"DarkSlateGrey\",\"width\":0},\"opacity\":1},\"mode\":\"markers\",\"name\":\"evaluate, circle\",\"showlegend\":true,\"x\":[6.512675,7.8962693,8.210207,7.6843114,7.752611,6.2848,7.616019,7.6841354,7.659993,7.722692,8.177224,7.6178465,6.376671,-1.5199528,8.044554,7.794563,6.323699,6.23391,7.9762626,6.105928,6.248461,7.818758,7.8664503,7.5747046,7.6444697,8.033986,7.777018,6.356927,6.356835,7.5824504,7.820073,7.7359133,7.684819,7.5347047,8.112892,7.4006925,7.870682,8.192933,7.758686,7.903247,8.183573,7.584746,7.6376524,16.754795,7.7738214,8.157694,6.3703623,7.961742,7.306236,7.614333,8.102746,7.675564,7.8806324,6.3391447,8.247155,7.619283,6.4247136,-1.1353388,-1.3239696,7.8567905,7.732827,6.3680587,7.546625,7.599953,7.622267,-3.1509125,8.436136,8.2360935,-1.1419615,7.905869,7.29384,8.200654,8.070858,7.7315087,7.7113485,5.845971,7.672054,7.7834034,-0.5247914,7.6175933,7.9673796,7.204136,-0.88594633,6.3448777,6.071518,7.6855307,7.9850626,7.6642814],\"xaxis\":\"x\",\"y\":[-9.005419,-10.938225,-10.460284,-11.395876,-10.820879,-8.790275,-11.390711,-11.3642435,-11.5032835,-11.124502,-10.380999,-11.257618,-8.904195,1.1516225,-10.260129,-11.103933,-8.869756,-8.680484,-10.251989,-8.53205,-8.777986,-11.109197,-10.647072,-10.55909,-11.342761,-10.255787,-10.869248,-8.906498,-8.897659,-10.716233,-10.937204,-11.051434,-11.315324,-10.523555,-10.57982,-10.653568,-11.014246,-10.252504,-11.141077,-10.318653,-10.54733,-10.960652,-10.5640545,1.1054564,-10.872189,-10.525969,-8.946399,-10.493802,-11.37206,-11.216446,-10.58457,-11.081703,-10.75659,-8.93322,-10.354113,-11.065679,-8.782087,2.5703957,2.7018166,-11.040771,-11.018954,-8.889195,-10.633778,-11.16053,-11.438034,1.0476902,-10.495503,-10.416261,2.5648913,-10.841535,-10.587397,-10.58433,-10.766556,-11.20508,-11.123534,-8.198194,-11.138519,-10.997362,4.773422,-11.329955,-10.744056,-10.385449,2.4088173,-8.870232,-8.470346,-11.2243805,-10.499245,-11.38784],\"yaxis\":\"y\",\"type\":\"scattergl\"},{\"customdata\":[[\"ä¸»è¦ç‰¹ç‚¹\\n\\nè®©æˆ‘ä»¬æ¥ä»‹ç»ä¸€ä¸‹ Gradio æœ€å—æ¬¢è¿çš„ä¸€äº›åŠŸèƒ½ï¼è¿™é‡Œæ˜¯ Gradio çš„ä¸»è¦ç‰¹ç‚¹ï¼š\\n\\n1. [æ·»åŠ ç¤ºä¾‹è¾“å…¥](#example-inputs)\\n2. [ä¼ é€’è‡ªå®šä¹‰é”™è¯¯æ¶ˆæ¯](#erro...\"],[\"Gradio Demo: blocks_random_slider\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\n\\nimport gradio as gr\\n\\n\\ndef...\"],[\"State in Blocks\\n\\nWe covered [State in Interfaces](https:\\u002f\\u002fgradio.app\\u002finterface-state), this guide ta...\"],[\"å¦‚ä½•ä½¿ç”¨åœ°å›¾ç»„ä»¶ç»˜åˆ¶å›¾è¡¨\\n\\nRelated spaces:\\nTags: PLOTS, MAPS\\n\\n## ç®€ä»‹\\n\\næœ¬æŒ‡å—ä»‹ç»å¦‚ä½•ä½¿ç”¨ Gradio çš„ `Plot` ç»„ä»¶åœ¨åœ°å›¾ä¸Šç»˜åˆ¶åœ°ç†æ•°æ®ã€‚Gradi...\"],[\"Gradio Demo: examples_component\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\n# Downloading files from the...\"],[\"Gradio Demo: number_component\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr \\n\\nwith gr....\"],[\"Gradio Demo: map_airbnb\\n### Display an interactive map of AirBnB locations with Plotly. Data is host...\"],[\"Gradio Demo: question-answering\\n\\n\\n```\\n!pip install -q gradio torch transformers\\n```\\n\\n\\n```\\nimport gra...\"],[\"`@gradio\\u002fbutton`\\n\\n```html\\n\\u003cscript\\u003e\\n\\timport { Button } from \\\"@gradio\\u002fbutton\\\";\\n\\u003c\\u002fscript\\u003e\\n\\n\\u003cbutton type...\"],[\"Gradio Demo: sales_projections\\n\\n\\n```\\n!pip install -q gradio pandas numpy matplotlib\\n```\\n\\n\\n```\\nimport...\"],[\"Gradio and W&B Integration\\n\\nRelated spaces: https:\\u002f\\u002fhuggingface.co\\u002fspaces\\u002fakhaliq\\u002fJoJoGAN\\nTags: WAND...\"],[\"Gradio Demo: duplicatebutton_component\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr \\n...\"],[\"Gradio Demo: upload_button_component_events\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as...\"],[\"@gradio\\u002fimageeditor\\n\\n## 0.2.0\\n\\n### Features\\n\\n- [#6809](https:\\u002f\\u002fgithub.com\\u002fgradio-app\\u002fgradio\\u002fpull\\u002f680...\"],[\"Gradio Demo: chatinterface_system_prompt\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr...\"],[\"Gradio Demo: streaming_wav2vec\\n\\n\\n```\\n!pip install -q gradio torch transformers \\n```\\n\\n\\n```\\nfrom trans...\"],[\"component-styles\\n\\n## Textbox\\n\\n| name        | type                                 | description    ...\"],[\"Gradio Demo: blocks_webcam\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport numpy as np\\n\\nimport gradio...\"],[\"Gradio Demo: on_listener_live\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\n\\nwith gr.B...\"],[\"ä¸»é¢˜ Theming\\n\\nTags: THEMES\\n\\n## ä»‹ç»\\n\\nGradio å…·æœ‰å†…ç½®çš„ä¸»é¢˜å¼•æ“ï¼Œå¯è®©æ‚¨è‡ªå®šä¹‰åº”ç”¨çš„å¤–è§‚å’Œæ„Ÿè§‰ã€‚æ‚¨å¯ä»¥é€‰æ‹©å„ç§ä¸»é¢˜ï¼Œæˆ–è€…åˆ›å»ºè‡ªå·±çš„ä¸»é¢˜ã€‚è¦è¿™æ ·åšï¼Œè¯·å°† `theme=...\"],[\"his demo shows how you can build an interactive dashboard with gradio. Click on a python library on ...\"],[\"gradio\\n\\n## 4.11.0\\n\\n### Features\\n\\n- [#6842](https:\\u002f\\u002fgithub.com\\u002fgradio-app\\u002fgradio\\u002fpull\\u002f6842) [`846d52d...\"],[\"@gradio\\u002fstatustracker\\n\\n## 0.4.3\\n\\n### Features\\n\\n- [#6814](https:\\u002f\\u002fgithub.com\\u002fgradio-app\\u002fgradio\\u002fpull\\u002f6...\"],[\"create-svelte\\n\\nEverything you need to build a Svelte project, powered by [`create-svelte`](https:\\u002f\\u002fg...\"],[\"imple image classification in Pytorch with Gradio's Image input and Label output....\"],[\"`@gradio\\u002fatoms`\\n\\n```html\\n\\u003cscript lang=\\\"ts\\\"\\u003e\\n\\timport { Block, BlockTitle, BlockLabel, IconButton, Emp...\"],[\"his text generation demo works like autocomplete. There's only one textbox and it's used for both th...\"],[\"Gradio Demo: sound_alert\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\n# Downloading files from the demo r...\"],[\"Gradio Demo: theme_extended_step_2\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\nimpor...\"],[\"å®æ—¶è¯­éŸ³è¯†åˆ«\\n\\nRelated spaces: https:\\u002f\\u002fhuggingface.co\\u002fspaces\\u002fabidlabs\\u002fstreaming-asr-paused, https:\\u002f\\u002fhugging...\"],[\"Gradio Demo: sine_curve\\n\\n\\n```\\n!pip install -q gradio plotly\\n```\\n\\n\\n```\\nimport math\\nimport gradio as g...\"],[\"his text generation demo takes in input text and returns generated text. It uses the Transformers li...\"],[\"Gradio Demo: color_generator\\n\\n\\n```\\n!pip install -q gradio opencv-python numpy\\n```\\n\\n\\n```\\nimport gradi...\"],[\"@gradio\\u002fclient\\n\\n## 0.9.3\\n\\n### Features\\n\\n- [#6814](https:\\u002f\\u002fgithub.com\\u002fgradio-app\\u002fgradio\\u002fpull\\u002f6814) [`...\"],[\"@gradio\\u002flabel\\n\\n## 0.2.6\\n\\n### Patch Changes\\n\\n- Updated dependencies [[`828fb9e`](https:\\u002f\\u002fgithub.com\\u002fg...\"],[\"Case Study: A Component to Display PDFs\\n\\nLet's work through an example of building a custom gradio c...\"],[\"Gradio Demo: stream_audio_out\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\n# Downloading files from the d...\"],[\"gradio-ui\\n\\nThis folder contains all of the Gradio UI and component source code.\\n\\n- [set up](#setup)\\n...\"],[\"Gradio Demo: gallery_component\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr \\n\\nwith gr...\"],[\"Gradio Demo: blocks_scroll\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\n\\n\\ndemo = gr.B...\"],[\"website\\n\\n## 0.20.3\\n\\n### Patch Changes\\n\\n- Updated dependencies []:\\n  - @gradio\\u002fcode@0.3.3\\n\\n## 0.20.2\\n...\"],[\"Gradio Demo: live_dashboard\\n### This demo shows how you can build a live interactive dashboard with ...\"],[\"Image Classification in TensorFlow and Keras\\n\\nRelated spaces: https:\\u002f\\u002fhuggingface.co\\u002fspaces\\u002fabidlabs...\"],[\"Gradio Demo: queue_full_e2e_test\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\nimport ...\"],[\"Gradio Demo: blocks_simple_squares\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\n\\ndemo...\"],[\"Gradio Demo: blocks_static\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\n\\ndemo = gr.Bl...\"],[\"Gradio Demo: main_note\\n\\n\\n```\\n!pip install -q gradio scipy numpy matplotlib\\n```\\n\\n\\n```\\n# Downloading f...\"],[\"@gradio\\u002fatoms\\n\\n## 0.4.1\\n\\n### Fixes\\n\\n- [#6766](https:\\u002f\\u002fgithub.com\\u002fgradio-app\\u002fgradio\\u002fpull\\u002f6766) [`7326...\"],[\"demo for predicting the depth of an image and generating a 3D model of it....\"],[\"Gradio Demo: video_component\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\n# Downloading files from the de...\"],[\"TensorFlow å’Œ Keras ä¸­çš„å›¾åƒåˆ†ç±»\\n\\nç›¸å…³ç©ºé—´ï¼šhttps:\\u002f\\u002fhuggingface.co\\u002fspaces\\u002fabidlabs\\u002fkeras-image-classifier\\næ ‡ç­¾ï¼šVIS...\"],[\"his demo identifies if two speakers are the same person using Gradio's Audio and HTML components....\"],[\"Gradio Demo: image_classifier_interface_load\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\n# Downloading f...\"],[\"@gradio\\u002fimage\\n\\n## 0.5.3\\n\\n### Fixes\\n\\n- [#6766](https:\\u002f\\u002fgithub.com\\u002fgradio-app\\u002fgradio\\u002fpull\\u002f6766) [`7326...\"],[\"Gradio Demo: latex\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\n\\nwith gr.Blocks() as ...\"],[\"Gradio Demo: video_identity\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\n# Downloading files from the dem...\"],[\"@gradio\\u002ffallback\\n\\n## 0.2.6\\n\\n### Patch Changes\\n\\n- Updated dependencies [[`828fb9e`](https:\\u002f\\u002fgithub.co...\"],[\"ğŸš€ Creating Discord Bots from Gradio Apps ğŸš€\\n\\nTags: NLP, TEXT, CHAT\\n\\nWe're excited to announce that Gr...\"],[\"Gradio Demo: blocks_essay\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\n\\ncountries_cit...\"],[\"Gradio Demo: generate_tone\\n\\n\\n```\\n!pip install -q gradio numpy\\n```\\n\\n\\n```\\nimport numpy as np\\nimport gr...\"],[\"`@gradio\\u002fform`\\n\\n```html\\n\\u003cscript\\u003e\\n\\timport { Form } from \\\"@gradio\\u002fform\\\";\\n\\u003c\\u002fscript\\u003e\\n```\\n\\nForm\\n```javasc...\"],[\"Gradio Demo: hello_world_3\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\n\\ndef greet(na...\"],[\"Gradio Components: The Key Concepts\\n\\nIn this section, we discuss a few important concepts when it co...\"],[\"Real Time Speech Recognition\\n\\nTags: ASR, SPEECH, STREAMING\\n\\n## Introduction\\n\\nAutomatic speech recogn...\"],[\"Gradio Demo: unified_demo_text_generation\\n\\n\\n```\\n!pip install -q gradio torch transformers\\n```\\n\\n\\n```\\n...\"],[\"Gradio Demo: calculator_blocks_cached\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\n\\n\\n...\"],[\"Gradio Demo: image-simple\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\n# Downloading files from the demo ...\"],[\"`@gradio\\u002fimageeditor`...\"],[\"Gradio Demo: chatbot_multimodal\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\n# Downloading files from the...\"],[\"Gradio Demo: dataframe_block-ui-test\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\n\\nwi...\"],[\"Gradio Demo: on_listener_test\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\n\\nwith gr.B...\"],[\"The Backend ğŸ\\n\\nThis guide will cover everything you need to know to implement your custom component'...\"],[\"Gradio Demo: blocks_flag\\n\\n\\n```\\n!pip install -q gradio numpy\\n```\\n\\n\\n```\\nimport numpy as np\\nimport grad...\"],[\"Gradio Demo: concurrency_without_queue\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\ni...\"],[\"Gradio Demo: dashboard\\n### This demo shows how you can build an interactive dashboard with gradio. C...\"],[\"@gradio\\u002fslider\\n\\n## 0.2.6\\n\\n### Patch Changes\\n\\n- Updated dependencies [[`828fb9e`](https:\\u002f\\u002fgithub.com\\u002f...\"],[\"@gradio\\u002fmodel3d\\n\\n## 0.4.11\\n\\n### Patch Changes\\n\\n- Updated dependencies [[`828fb9e`](https:\\u002f\\u002fgithub.co...\"],[\"mport { Meta } from \\\"@storybook\\u002fblocks\\\";\\n\\n\\u003cMeta title=\\\"Introduction\\\" \\u002f\\u003e\\n\\n\\u003cstyle\\u003e\\n\\t{`\\n    img {\\n     ...\"],[\"simple demo showcasing the upload button used with its `upload` event trigger....\"],[\"`@gradio\\u002fhighlightedtext`\\n\\n```html\\n\\u003cscript\\u003e\\n    import { BaseStaticHighlightedText, BaseInteractiveH...\"],[\"Gradio Demo: image_component_events\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\n\\nwit...\"],[\"Gradio Demo: reverse_audio\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\n# Downloading files from the demo...\"],[\"Gradio Demo: blocks_page_load\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\n\\n\\ndef prin...\"],[\"Gradio & LLM Agents ğŸ¤\\n\\nLarge Language Models (LLMs) are very impressive but they can be made even mo...\"],[\"his simple demo takes advantage of Gradio's HighlightedText, JSON and HTML outputs to create a clear...\"],[\"`@gradio\\u002fvideo`\\n\\n```javascript\\n\\u003cscript\\u003e\\n\\timport { BaseInteractiveVideo, BaseStaticVideo, BasePlayer ...\"],[\"utomatic speech recognition English. Record from your microphone and the app will transcribe the aud...\"],[\"Gradio Demo: longest_word\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\n\\n\\ndef longest_...\"],[\"`@gradio\\u002fcolorpicker`\\n\\n```html\\n\\u003cscript\\u003e\\n    import { BaseColorPicker, BaseExample } from \\\"@gradio\\u002fco...\"],[\"Gradio Demo: annotatedimage_component\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\nim...\"],[\"Running a Gradio App on your Web Server with Nginx\\n\\nTags: DEPLOYMENT, WEB SERVER, NGINX\\n\\n## Introduc...\"],[\"@gradio\\u002fupload\\n\\n## 0.5.6\\n\\n### Fixes\\n\\n- [#6766](https:\\u002f\\u002fgithub.com\\u002fgradio-app\\u002fgradio\\u002fpull\\u002f6766) [`732...\"],[\"Getting Started with the Gradio Python client\\n\\nTags: CLIENT, API, SPACES\\n\\nThe Gradio Python client m...\"],[\"Frequently Asked Questions\\n\\n## What do I need to install before using Custom Components?\\nBefore usin...\"],[\"Create Your Own Friends with a GAN\\n\\nRelated spaces: https:\\u002f\\u002fhuggingface.co\\u002fspaces\\u002fNimaBoscarino\\u002fcryp...\"],[\"Gradio Demo: blocks_component_shortcut\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\n\\n...\"],[\"Gradio Demo: progress_component\\n\\n\\n```\\n!pip install -q gradio tqdm\\n```\\n\\n\\n```\\nimport gradio as gr\\nimpo...\"],[\"Gradio Demo: calculator\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\n# Downloading files from the demo re...\"],[\"Gradio Demo: cancel_events\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport time\\nimport gradio as gr\\n\\n...\"],[\"Gradio Demo: live_with_vars\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\n\\ndemo = gr.I...\"],[\"ååº”å¼ç•Œé¢ (Reactive Interfaces)\\n\\næœ¬æŒ‡å—ä»‹ç»äº†å¦‚ä½•ä½¿ Gradio ç•Œé¢è‡ªåŠ¨åˆ·æ–°æˆ–è¿ç»­æµå¼ä¼ è¾“æ•°æ®ã€‚\\n\\n## å®æ—¶ç•Œé¢ (Live Interfaces)\\n\\næ‚¨å¯ä»¥é€šè¿‡åœ¨ç•Œé¢ä¸­...\"],[\"Gradio Demo: gpt2_xl\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\n\\ntitle = \\\"gpt2-xl\\\"\\n...\"],[\"Gradio Demo: uploadbutton_component\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\n\\ndef...\"],[\"Vision Transformers å›¾åƒåˆ†ç±»\\n\\nç›¸å…³ç©ºé—´ï¼šhttps:\\u002f\\u002fhuggingface.co\\u002fspaces\\u002fabidlabs\\u002fvision-transformer\\næ ‡ç­¾ï¼šVISION, ...\"],[\"Gradio Demo: blocks_speech_text_sentiment\\n\\n\\n```\\n!pip install -q gradio torch transformers\\n```\\n\\n\\n```\\n...\"],[\"Gradio Demo: spectogram\\n\\n\\n```\\n!pip install -q gradio scipy numpy matplotlib\\n```\\n\\n\\n```\\nimport matplot...\"],[\"Gradio Demo: clustering\\n### This demo built with Blocks generates 9 plots based on the input.\\n      ...\"],[\"@gradio\\u002fhtml\\n\\n## 0.1.6\\n\\n### Patch Changes\\n\\n- Updated dependencies [[`828fb9e`](https:\\u002f\\u002fgithub.com\\u002fgr...\"],[\"`@gradio\\u002fgallery`\\n\\n```html\\n\\u003cscript\\u003e\\n\\timport { BaseGallery } from \\\"@gradio\\u002fgallery\\\";\\n\\u003c\\u002fscript\\u003e\\n```\\n\\nB...\"],[\"å‘½åå®ä½“è¯†åˆ« ï¼ˆNamed-Entity Recognitionï¼‰\\n\\nç›¸å…³ç©ºé—´ï¼šhttps:\\u002f\\u002fhuggingface.co\\u002fspaces\\u002frajistics\\u002fbiobert_ner_demoï¼Œhtt...\"],[\"Blocks and Event Listeners\\n\\nWe briefly descirbed the Blocks class in the [Quickstart](\\u002fmain\\u002fguides\\u002fq...\"],[\"Gradio Demo: no_input\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\nimport random\\n\\nsen...\"],[\"Gradio Demo: hello_world_2\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\n\\ndef greet(na...\"],[\"Gradio Demo: blocks_plug\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\n\\n\\ndef change_ta...\"],[\"PyTorch å›¾åƒåˆ†ç±»\\n\\nRelated spaces: https:\\u002f\\u002fhuggingface.co\\u002fspaces\\u002fabidlabs\\u002fpytorch-image-classifier, https...\"],[\"Gradio Demo: video_subtitle\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\n# Downloading files from the dem...\"],[\"@gradio\\u002fstate\\n\\n## 0.1.0\\n\\n### Features\\n\\n- [#5498](https:\\u002f\\u002fgithub.com\\u002fgradio-app\\u002fgradio\\u002fpull\\u002f5498) [`2...\"],[\"åˆ†äº«æ‚¨çš„åº”ç”¨\\n\\nå¦‚ä½•åˆ†äº«æ‚¨çš„ Gradio åº”ç”¨ï¼š\\n\\n1. [ä½¿ç”¨ share å‚æ•°åˆ†äº«æ¼”ç¤º](#sharing-demos)\\n2. [åœ¨ HF Spaces ä¸Šæ‰˜ç®¡](#hosting-on-hf-...\"],[\"Gradio Demo: english_translator\\n\\n\\n```\\n!pip install -q gradio transformers torch\\n```\\n\\n\\n```\\nimport gra...\"],[\"@gradio\\u002frow\\n\\n## 0.1.1\\n\\n### Features\\n\\n- [#6399](https:\\u002f\\u002fgithub.com\\u002fgradio-app\\u002fgradio\\u002fpull\\u002f6399) [`053...\"],[\"Gradio Demo: image_editor\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\n# Downloading files from the demo ...\"],[\"åˆ†å—çŠ¶æ€ (State in Blocks)\\n\\næˆ‘ä»¬å·²ç»ä»‹ç»äº†[æ¥å£çŠ¶æ€](https:\\u002f\\u002fgradio.app\\u002finterface-state)ï¼Œè¿™ç¯‡æŒ‡å—å°†ä»‹ç»åˆ†å—çŠ¶æ€ï¼Œå®ƒçš„å·¥ä½œåŸç†å¤§è‡´ç›¸åŒã€‚\\n\\n#...\"],[\"ote: This is a simplified version of the code needed to create the Stable Diffusion demo. See full c...\"],[\"Gradio Demo: matrix_transpose\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport numpy as np\\n\\nimport gra...\"],[\"Gradio Demo: blocks_textbox_max_lines\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\n\\n\\n...\"],[\"ecreate the viral AnimeGAN image transformation demo....\"],[\"Gradio Demo: calculator_list_and_dict\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\n\\nw...\"],[\"åŒºå—å’Œäº‹ä»¶ç›‘å¬å™¨ (Blocks and Event Listeners)\\n\\næˆ‘ä»¬åœ¨[å¿«é€Ÿå…¥é—¨](https:\\u002f\\u002fgradio.app\\u002fquickstart\\u002f#blocks-more-flexibil...\"],[\"Gradio Demo: checkbox_component\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr \\n\\nwith g...\"],[\"@gradio\\u002ficons\\n\\n## 0.3.2\\n\\n### Features\\n\\n- [#6399](https:\\u002f\\u002fgithub.com\\u002fgradio-app\\u002fgradio\\u002fpull\\u002f6399) [`0...\"],[\"Gradio Demo: audio_component_events\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\n\\nwit...\"],[\"Gradio Demo: chatinterface_random_response\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport random\\nimp...\"],[\"Gradio Demo: colorpicker_component\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr \\n\\nwit...\"],[\"Gradio Demo: blocks_update\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\n\\nwith gr.Bloc...\"],[\"Getting Started with the Gradio JavaScript client\\n\\nTags: CLIENT, API, SPACES\\n\\nThe Gradio JavaScript ...\"],[\"æ›´å¤šç¤ºä¾‹ (More on Examples)\\n\\næœ¬æŒ‡å—ä»‹ç»äº†æœ‰å…³ç¤ºä¾‹çš„æ›´å¤šå†…å®¹ï¼šä»ç›®å½•ä¸­åŠ è½½ç¤ºä¾‹ï¼Œæä¾›éƒ¨åˆ†ç¤ºä¾‹å’Œç¼“å­˜ã€‚å¦‚æœä½ å¯¹ç¤ºä¾‹è¿˜ä¸ç†Ÿæ‚‰ï¼Œè¯·æŸ¥çœ‹ [å…³é”®ç‰¹æ€§](..\\u002fkey-features\\u002f#e...\"],[\"ä» Supabase æ•°æ®åˆ›å»ºä»ªè¡¨ç›˜\\n\\nTags: TABULAR, DASHBOARD, PLOTS\\n\\n[Supabase](https:\\u002f\\u002fsupabase.com\\u002f) æ˜¯ä¸€ä¸ªåŸºäºäº‘çš„å¼€æºåç«¯ï¼Œæ...\"],[\"Gradio Demo: model3d_component\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr \\n\\nwith gr...\"],[\"@gradio\\u002fmarkdown\\n\\n## 0.6.0\\n\\n### Features\\n\\n- [#6842](https:\\u002f\\u002fgithub.com\\u002fgradio-app\\u002fgradio\\u002fpull\\u002f6842) ...\"],[\"Gradio Demo: video_identity_2\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\n\\ndef video...\"],[\"`gradio_client`: Use a Gradio app as an API -- in 3 lines of Python\\n\\nThis directory contains the sou...\"],[\"Gradio Demo: image_classification\\n### Simple image classification in Pytorch with Gradio's Image inp...\"],[\"Gradio Demo: label_component\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr \\n\\nwith gr.B...\"],[\"è‡ªå®šä¹‰çš„ JS å’Œ CSS\\n\\næœ¬æŒ‡å—ä»‹ç»äº†å¦‚ä½•æ›´çµæ´»åœ°ä¸º Blocks æ·»åŠ æ ·å¼ï¼Œå¹¶æ·»åŠ  JavaScript ä»£ç åˆ°äº‹ä»¶ç›‘å¬å™¨ä¸­ã€‚\\n\\n**è­¦å‘Š**ï¼šåœ¨è‡ªå®šä¹‰çš„ JS å’Œ CSS ä¸­ä½¿ç”¨æŸ¥è¯¢é€‰æ‹©å™¨ä¸èƒ½...\"],[\"Gradio Demo: bokeh_plot\\n\\n\\n```\\n!pip install -q gradio bokeh\\u003e=3.0 xyzservices\\n```\\n\\n\\n```\\nimport gradio ...\"],[\"# JavaScript Client Library\\n\\nA javascript (and typescript) client to call Gradio APIs.\\n\\n## Installat...\"],[\"iles in this directory are used in:\\n\\n- tests for the gradio library\\n- example inputs in the view API...\"],[\"How to Use the 3D Model Component\\n\\nRelated spaces: https:\\u002f\\u002fhuggingface.co\\u002fspaces\\u002fgradio\\u002fModel3D, htt...\"],[\"@gradio\\u002fdataset\\n\\n## 0.1.13\\n\\n### Patch Changes\\n\\n- Updated dependencies [[`828fb9e`](https:\\u002f\\u002fgithub.co...\"],[\"Gradio Demo: blocks_kinematics\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport pandas as pd\\nimport nu...\"],[\"Gradio Demo: blocks_neural_instrument_coding\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\n# Downloading f...\"],[\"Gradio Demo: image_classifier\\n\\n\\n```\\n!pip install -q gradio numpy tensorflow\\n```\\n\\n\\n```\\n# Downloading ...\"],[\"Using Gradio Blocks Like Functions\\n\\nTags: TRANSLATION, HUB, SPACES\\n\\n**Prerequisite**: This Guide bui...\"],[\"Gradio Demo: animeganv2\\n### Recreate the viral AnimeGAN image transformation demo.\\n        \\n\\n\\n```\\n!p...\"],[\"Gradio Demo: image_segmentation\\n### Simple image segmentation using gradio's AnnotatedImage componen...\"],[\"Gradio Demo: stable-diffusion\\n### Note: This is a simplified version of the code needed to create th...\"],[\"`@gradio\\u002fstatustracker`\\n\\n```html\\n\\u003cscript\\u003e\\n    import {StatusTracker, Toast, Loader} from `@gradio\\u002fst...\"],[\"@gradio\\u002fsimpletextbox\\n\\n## 0.1.6\\n\\n### Patch Changes\\n\\n- Updated dependencies [[`828fb9e`](https:\\u002f\\u002fgith...\"],[\"Gradio Demo: chatbot_consecutive\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\nimport ...\"],[\"Gradio Demo: file_explorer\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\nfrom pathlib ...\"],[\"è¿è¡Œåå°ä»»åŠ¡\\n\\nRelated spaces: https:\\u002f\\u002fhuggingface.co\\u002fspaces\\u002ffreddyaboulton\\u002fgradio-google-forms\\nTags: TASKS...\"],[\"Gradio Demo: file_component\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr \\n\\nwith gr.Bl...\"],[\"Gradio Demo: blocks_group\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\n\\ndef greet(nam...\"],[\"é€šè¿‡è‡ªåŠ¨é‡è½½å®ç°æ›´å¿«çš„å¼€å‘\\n\\n**å…ˆå†³æ¡ä»¶**ï¼šæœ¬æŒ‡å—è¦æ±‚æ‚¨äº†è§£å—çš„çŸ¥è¯†ã€‚è¯·ç¡®ä¿[å…ˆé˜…è¯»å—æŒ‡å—](https:\\u002f\\u002fgradio.app\\u002fquickstart\\u002f#blocks-more-flexibil...\"],[\"Gradio Demo: sentiment_analysis\\n### This sentiment analaysis demo takes in input text and returns it...\"],[\"Gradio Demo: image_mod\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\n# Downloading files from the demo rep...\"],[\"Gradio Demo: hello_blocks\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\n\\ndef greet(nam...\"],[\"Installing Gradio in a Virtual Environment\\n\\nTags: INSTALLATION\\n\\nIn this guide, we will describe step...\"],[\"Gradio Demo: score_tracker\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\n\\nscores = []\\n...\"],[\"`@gradio\\u002ffile`\\n\\n```html\\n\\u003cscript\\u003e\\n\\timport { BaseFile, BaseFileUpload, FilePreview, BaseExample } from...\"],[\"Gradio Demo: scatterplot_component\\n\\n\\n```\\n!pip install -q gradio vega_datasets\\n```\\n\\n\\n```\\nimport gradi...\"],[\"Gradio Demo: xgboost-income-prediction-with-explainability\\n### This demo takes in 12 inputs from the...\"],[\"his demo built with Blocks generates 9 plots based on the input....\"],[\"Gradio & LLM Agents ğŸ¤\\n\\néå¸¸å¼ºå¤§çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ï¼Œå¦‚æœæˆ‘ä»¬èƒ½èµ‹äºˆå®ƒä»¬å®Œæˆä¸“é—¨ä»»åŠ¡çš„æŠ€èƒ½ï¼Œå®ƒä»¬å°†å˜å¾—æ›´åŠ å¼ºå¤§ã€‚\\n\\n[gradio_tools](https:\\u002f\\u002fgithub...\"],[\"Gradio Demo: barplot_component\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\nimport pa...\"],[\"Gradio Demo: blocks_hello\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\n\\ndef welcome(n...\"],[\"his is a fake GAN that shows how to create a text-to-image interface for image generation. Check out...\"],[\"Gradio Demo: loginbutton_component\\n\\n\\n```\\n!pip install -q gradio gradio[oauth]\\n```\\n\\n\\n```\\nimport gradi...\"],[\"@gradio\\u002fgallery\\n\\n## 0.4.14\\n\\n### Patch Changes\\n\\n- Updated dependencies [[`828fb9e`](https:\\u002f\\u002fgithub.co...\"],[\"åœ¨ Web æœåŠ¡å™¨ä¸Šä½¿ç”¨ Nginx è¿è¡Œ Gradio åº”ç”¨\\n\\næ ‡ç­¾ï¼šéƒ¨ç½²ï¼ŒWeb æœåŠ¡å™¨ï¼ŒNginx\\n\\n## ä»‹ç»\\n\\nGradio æ˜¯ä¸€ä¸ª Python åº“ï¼Œå…è®¸æ‚¨å¿«é€Ÿåˆ›å»ºå¯å®šåˆ¶çš„ Web åº”ç”¨ç¨‹...\"],[\"@gradio\\u002fhighlightedtext\\n\\n## 0.4.6\\n\\n### Patch Changes\\n\\n- Updated dependencies [[`828fb9e`](https:\\u002f\\u002fgi...\"],[\"Gradio Demo: stream_frames\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\nimport numpy ...\"],[\"@gradio\\u002futils\\n\\n## 0.2.0\\n\\n### Features\\n\\n- [#5498](https:\\u002f\\u002fgithub.com\\u002fgradio-app\\u002fgradio\\u002fpull\\u002f5498) [`2...\"],[\"ä» Google Sheets åˆ›å»ºå®æ—¶ä»ªè¡¨ç›˜\\n\\nTags: TABULAR, DASHBOARD, PLOTS\\n[Google Sheets](https:\\u002f\\u002fwww.google.com\\u002fshee...\"],[\"@gradio\\u002fradio\\n\\n## 0.3.7\\n\\n### Patch Changes\\n\\n- Updated dependencies [[`828fb9e`](https:\\u002f\\u002fgithub.com\\u002fg...\"],[\"Gradio Demo: markdown_example\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\n\\ncss = (\\n ...\"],[\"gradio_client\\n\\n## 0.7.3\\n\\n### Fixes\\n\\n- [#6693](https:\\u002f\\u002fgithub.com\\u002fgradio-app\\u002fgradio\\u002fpull\\u002f6693) [`34f9...\"],[\"Gradio Demo: blocks_form\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\n\\nwith gr.Blocks...\"],[\"Gradio Demo: tictactoe\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\n\\nwith gr.Blocks()...\"],[\"Gradio Demo: fake_gan_2\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\n# Downloading files from the demo re...\"],[\"simple dashboard ranking spaces by number of likes....\"],[\"@gradio\\u002fjson\\n\\n## 0.1.6\\n\\n### Patch Changes\\n\\n- Updated dependencies [[`828fb9e`](https:\\u002f\\u002fgithub.com\\u002fgr...\"],[\"`gradio\\u002fmodel3d`\\n\\n```html\\n\\u003cscript\\u003e\\n    import {BaseModel3D, BaseModel3DUpload, BaseExample } from `@...\"],[\"@gradio\\u002ftheme\\n\\n## 0.2.0\\n\\n### Features\\n\\n- [#5498](https:\\u002f\\u002fgithub.com\\u002fgradio-app\\u002fgradio\\u002fpull\\u002f5498) [`2...\"],[\"Gradio Demo: automatic-speech-recognition\\n### Automatic speech recognition English. Record from your...\"],[\"Gradio Demo: event_trigger\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\n# Downloading files from the demo...\"],[\"`@gradio\\u002fbutton`\\n\\n```html\\n\\u003cscript\\u003e\\n\\timport { BaseChatBot } from \\\"@gradio\\u002fchatbot\\\";\\n\\u003c\\u002fscript\\u003e\\n```\\n\\n\\nB...\"],[\"div align=\\\"center\\\"\\u003e\\n\\n[\\u003cimg src=\\\"readme_files\\u002fgradio.svg\\\" alt=\\\"gradio\\\" width=400\\u003e](https:\\u002f\\u002fgradio.app...\"],[\"Gradio Demo: theme_new_step_3\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nfrom __future__ import annotat...\"],[\"Gradio Demo: dataframe_datatype\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\nimport p...\"],[\"Gradio Demo: Echocardiogram-Segmentation\\n\\n\\n```\\n!pip install -q gradio -f https:\\u002f\\u002fdownload.pytorch.or...\"],[\"`@gradio\\u002fbutton`\\n\\n```javascript\\n\\u003cscript\\u003e\\n\\timport { BaseButton } from \\\"@gradio\\u002fbutton\\\";\\n\\timport { cre...\"],[\"Gradio Demo: reverse_audio_2\\n\\n\\n```\\n!pip install -q gradio numpy\\n```\\n\\n\\n```\\nimport gradio as gr\\nimport...\"],[\"Gradio Demo: model3d_component_events\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\n\\nw...\"],[\"Gradio Demo: sentence_builder\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\n\\n\\ndef sent...\"],[\"@gradio\\u002faudio\\n\\n## 0.6.3\\n\\n### Fixes\\n\\n- [#6766](https:\\u002f\\u002fgithub.com\\u002fgradio-app\\u002fgradio\\u002fpull\\u002f6766) [`7326...\"],[\"Gradio Demo: waveform\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\nimport random\\n\\n\\nCO...\"],[\"Gradio Demo: hello_login\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\nimport argparse...\"],[\"@gradio\\u002ffileexplorer\\n\\n## 0.3.13\\n\\n### Patch Changes\\n\\n- Updated dependencies [[`828fb9e`](https:\\u002f\\u002fgith...\"],[\"Using Gradio and Comet\\n\\nTags: COMET, SPACES\\nContributed by the Comet team\\n\\n## Introduction\\n\\nIn this ...\"],[\"`@gradio\\u002fmarkdown`\\n\\n```html\\n\\u003cscript\\u003e\\n    import { BaseMarkdown, MarkdownCode, BaseExample } from `@g...\"],[\"Gradio Demo: calculator_live\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\n\\ndef calcul...\"],[\"Named-Entity Recognition\\n\\nRelated spaces: https:\\u002f\\u002fhuggingface.co\\u002fspaces\\u002frajistics\\u002fbiobert_ner_demo, ...\"],[\"Gradio Demo: fraud_detector\\n\\n\\n```\\n!pip install -q gradio pandas\\n```\\n\\n\\n```\\n# Downloading files from t...\"],[\"!-- DO NOT EDIT THIS FILE DIRECTLY. INSTEAD EDIT THE `readme_template.md` OR `guides\\u002f1)getting_start...\"],[\"Building a FastAPI App with the Gradio Python Client\\n\\nTags: CLIENT, API, WEB APP\\n\\nIn this blog post,...\"],[\"Developing Faster with Auto-Reloading\\n\\n**Prerequisite**: This Guide requires you to know about Block...\"],[\"Running Background Tasks\\n\\nRelated spaces: https:\\u002f\\u002fhuggingface.co\\u002fspaces\\u002ffreddyaboulton\\u002fgradio-google...\"],[\"How to Use the Plot Component for Maps\\n\\nTags: PLOTS, MAPS\\n\\n## Introduction\\n\\nThis guide explains how ...\"],[\"Gradio Demo: blocks_style\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\n\\nwith gr.Block...\"],[\"Using Flagging\\n\\nRelated spaces: https:\\u002f\\u002fhuggingface.co\\u002fspaces\\u002fgradio\\u002fcalculator-flagging-crowdsource...\"],[\"his demo shows how you can build a live interactive dashboard with gradio.\\nThe current time is refre...\"],[\"Gradio Demo: plot_component\\n\\n\\n```\\n!pip install -q gradio matplotlib numpy\\n```\\n\\n\\n```\\nimport gradio as...\"],[\"Gradio Demo: request_ip_headers\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\n\\n\\ndef pr...\"],[\"è¿æ¥åˆ°æ•°æ®åº“\\n\\nç›¸å…³ç©ºé—´ï¼šhttps:\\u002f\\u002fhuggingface.co\\u002fspaces\\u002fgradio\\u002fchicago-bike-share-dashboard\\næ ‡ç­¾ï¼šTABULAR, PLOTS\\n\\n##...\"],[\"Gradio Demo: chatinterface_streaming_echo\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport time\\nimport...\"],[\"Gradio Demo: hangman\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\n\\nsecret_word = \\\"gra...\"],[\"The 4 Kinds of Gradio Interfaces\\n\\nSo far, we've always assumed that in order to build an Gradio demo...\"],[\"`@gradio\\u002fdataframe`\\n\\n```html\\n\\u003cscript\\u003e\\n    import { BaseDataFrame, BaseExample } from \\\"@gradio\\u002fdatafr...\"],[\"Gradio Demo: line_plot\\n\\n\\n```\\n!pip install -q gradio vega_datasets pandas\\n```\\n\\n\\n```\\nimport gradio as ...\"],[\"Contributing to Gradio\\n\\n![GitHub issues by-label](https:\\u002f\\u002fimg.shields.io\\u002fgithub\\u002fissues\\u002fgradio-app\\u002fgr...\"],[\"Gradio Demo: leaderboard\\n### A simple dashboard ranking spaces by number of likes.\\n        \\n\\n\\n```\\n!p...\"],[\"Gradio ç•Œé¢çš„ 4 ç§ç±»å‹\\n\\nåˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬ä¸€ç›´å‡è®¾æ„å»º Gradio æ¼”ç¤ºéœ€è¦åŒæ—¶å…·å¤‡è¾“å…¥å’Œè¾“å‡ºã€‚ä½†å¯¹äºæœºå™¨å­¦ä¹ æ¼”ç¤ºæ¥è¯´ï¼Œå¹¶ä¸æ€»æ˜¯å¦‚æ­¤ï¼šä¾‹å¦‚ï¼Œ*æ— æ¡ä»¶å›¾åƒç”Ÿæˆæ¨¡å‹*ä¸éœ€è¦ä»»ä½•è¾“å…¥ï¼Œä½†ä¼šç”Ÿæˆä¸€...\"],[\"Gradio Demo: calculator_blocks\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\n\\n\\ndef cal...\"],[\"@gradio\\u002fdataframe\\n\\n## 0.4.3\\n\\n### Patch Changes\\n\\n- Updated dependencies [[`846d52d`](https:\\u002f\\u002fgithub.c...\"],[\"Gradio Demo: rows_and_columns\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\n# Downloading files from the d...\"],[\"Gradio Demo: lineplot_component\\n\\n\\n```\\n!pip install -q gradio vega_datasets\\n```\\n\\n\\n```\\nimport gradio a...\"],[\"@gradio\\u002fbox\\n\\n## 0.1.6\\n\\n### Patch Changes\\n\\n- Updated dependencies [[`73268ee`](https:\\u002f\\u002fgithub.com\\u002fgra...\"],[\"Gradio Demo: webcam\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\n\\nimport gradio as gr\\n\\n\\ndef snap(image, v...\"],[\"Gradio Demo: theme_new_step_2\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nfrom __future__ import annotat...\"],[\"Gradio å’Œ ONNX åœ¨ Hugging Face ä¸Š\\n\\nRelated spaces: https:\\u002f\\u002fhuggingface.co\\u002fspaces\\u002fonnx\\u002fEfficientNet-Lite...\"],[\"Gradio Demo: slider_release\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\n\\n\\ndef identi...\"],[\"How to add support for more languages\\n\\nWe would love to support more languages for Gradio ğŸŒ\\n\\nTo add ...\"],[\"Setting Up a Demo for Maximum Performance\\n\\nTags: CONCURRENCY, LATENCY, PERFORMANCE\\n\\nLet's say that y...\"],[\"Gradio Demo: blocks_outputs\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\n\\n\\ndef make_m...\"],[\"Gradio Demo: slider_component\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr \\n\\nwith gr....\"],[\"`@gradio\\u002fradio`\\n\\n```html\\n\\u003cscript\\u003e\\n    import { BaseRadio, BaseExample } from \\\"@gradio\\u002fradio\\\"; \\n\\u003c\\u002fscr...\"],[\"Gradio Demo: clearbutton_component\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\n\\n\\nwit...\"],[\"`@gradio\\u002fhtml`\\n\\n```javascript\\nimport { BaseHTML } from \\\"@gradio\\u002fhtml\\\";\\n```\\n\\nBaseHTML\\n```javascript\\n\\t...\"],[\"Gradio Demo: hello_world\\n### The simplest possible Gradio demo. It wraps a 'Hello {name}!' function ...\"],[\"Gradio Demo: ner_pipeline\\n\\n\\n```\\n!pip install -q gradio torch transformers\\n```\\n\\n\\n```\\nfrom transformer...\"],[\"æ¥å£çŠ¶æ€ (Interface State)\\n\\næœ¬æŒ‡å—ä»‹ç»äº† Gradio ä¸­å¦‚ä½•å¤„ç†çŠ¶æ€ã€‚äº†è§£å…¨å±€çŠ¶æ€å’Œä¼šè¯çŠ¶æ€çš„åŒºåˆ«ï¼Œä»¥åŠå¦‚ä½•åŒæ—¶ä½¿ç”¨å®ƒä»¬ã€‚\\n\\n## å…¨å±€çŠ¶æ€ (Global State)\\n\\næ‚¨çš„...\"],[\"ä½¿ç”¨ Hugging Face é›†æˆ\\n\\nç›¸å…³ç©ºé—´ï¼šhttps:\\u002f\\u002fhuggingface.co\\u002fspaces\\u002fgradio\\u002fhelsinki_translation_en_es\\næ ‡ç­¾ï¼šHUBï¼ŒSPAC...\"],[\"Gradio Demo: chatbot_dialogpt\\n\\n\\n```\\n!pip install -q gradio torch transformers\\n```\\n\\n\\n```\\nimport gradi...\"],[\"Gradio Demo: blocks_joined\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\n# Downloading files from the demo...\"],[\"Gradio Demo: zip_to_json\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nfrom zipfile import ZipFile\\n\\nimport...\"],[\"@gradio\\u002fgroup\\n\\n## 0.1.0\\n\\n### Features\\n\\n- [#5498](https:\\u002f\\u002fgithub.com\\u002fgradio-app\\u002fgradio\\u002fpull\\u002f5498) [`2...\"],[\"Gradio Demo: titanic_survival\\n\\n\\n```\\n!pip install -q gradio scikit-learn numpy pandas\\n```\\n\\n\\n```\\n# Dow...\"],[\"`@gradio\\u002fuploadbutton`\\n\\n```html\\n\\u003cscript\\u003e\\n    import { BaseUploadButton } from \\\"@gradio\\u002fuploadbutton\\\"...\"],[\"Gradio Demo: translation\\n### This translation demo takes in the text, source and target languages, a...\"],[\"Using Hugging Face Integrations\\n\\nRelated spaces: https:\\u002f\\u002fhuggingface.co\\u002fspaces\\u002fgradio\\u002fen2es\\nTags: HU...\"],[\"ä½¿ç”¨ Gradio å—åƒå‡½æ•°ä¸€æ ·\\n\\nTags: TRANSLATION, HUB, SPACES\\n\\n**å…ˆå†³æ¡ä»¶**: æœ¬æŒ‡å—æ˜¯åœ¨å—ä»‹ç»çš„åŸºç¡€ä¸Šæ„å»ºçš„ã€‚è¯·ç¡®ä¿[å…ˆé˜…è¯»è¯¥æŒ‡å—](https:\\u002f\\u002fgrad...\"],[\"Gradio Demo: unispeech-speaker-verification\\n\\n\\n```\\n!pip install -q gradio git+https:\\u002f\\u002fgithub.com\\u002fhugg...\"],[\"Gradio Demo: white_noise_vid_not_playable\\n\\n\\n```\\n!pip install -q gradio opencv-python\\n```\\n\\n\\n```\\nimpor...\"],[\"Gradio Demo: logoutbutton_component\\n\\n\\n```\\n!pip install -q gradio gradio[oauth]\\n```\\n\\n\\n```\\nimport grad...\"],[\"Gradio Demo: chicago-bikeshare-dashboard\\n\\n\\n```\\n!pip install -q gradio psycopg2 matplotlib SQLAlchemy...\"],[\"Gradio Demo: textbox_component\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr \\n\\nwith gr...\"],[\"ä½¿ç”¨æ ‡è®°\\n\\nç›¸å…³ç©ºé—´ï¼šhttps:\\u002f\\u002fhuggingface.co\\u002fspaces\\u002fgradio\\u002fcalculator-flagging-crowdsourced, https:\\u002f\\u002fhuggingfac...\"],[\"Image Classification in PyTorch\\n\\nRelated spaces: https:\\u002f\\u002fhuggingface.co\\u002fspaces\\u002fabidlabs\\u002fpytorch-imag...\"],[\"Theming\\n\\nTags: THEMES\\n\\n## Introduction\\n\\nGradio features a built-in theming engine that lets you cust...\"],[\"@gradio\\u002ftabs\\n\\n## 0.1.0\\n\\n### Features\\n\\n- [#5498](https:\\u002f\\u002fgithub.com\\u002fgradio-app\\u002fgradio\\u002fpull\\u002f5498) [`28...\"],[\"å¦‚ä½•åˆ›å»ºä¸€ä¸ªæ–°ç»„ä»¶\\n\\n## ç®€ä»‹\\n\\næœ¬æŒ‡å—æ—¨åœ¨è¯´æ˜å¦‚ä½•æ·»åŠ ä¸€ä¸ªæ–°ç»„ä»¶ï¼Œä½ å¯ä»¥åœ¨ Gradio åº”ç”¨ç¨‹åºä¸­ä½¿ç”¨è¯¥ç»„ä»¶ã€‚è¯¥æŒ‡å—å°†é€šè¿‡ä»£ç ç‰‡æ®µé€æ­¥å±•ç¤ºå¦‚ä½•æ·»åŠ [ColorPicker](https:\\u002f\\u002fgr...\"],[\"Gradio Demo: concurrency_with_queue\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\nimpo...\"],[\"Gradio Demo: blocks_essay_simple\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\n\\n\\ndef c...\"],[\"@gradio\\u002fform\\n\\n## 0.1.6\\n\\n### Patch Changes\\n\\n- Updated dependencies [[`73268ee`](https:\\u002f\\u002fgithub.com\\u002fgr...\"],[\"Gradio Demo: blocks_chained_events\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\nimpor...\"],[\"Gradio Demo: dataframe_component\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\n\\nwith g...\"],[\"Gradio-Lite: Serverless Gradio Running Entirely in Your Browser\\n\\nTags: SERVERLESS, BROWSER, PYODIDE\\n...\"],[\"æ§åˆ¶å¸ƒå±€ (Controlling Layout)\\n\\né»˜è®¤æƒ…å†µä¸‹ï¼Œå—ä¸­çš„ç»„ä»¶æ˜¯å‚ç›´æ’åˆ—çš„ã€‚è®©æˆ‘ä»¬çœ‹çœ‹å¦‚ä½•é‡æ–°æ’åˆ—ç»„ä»¶ã€‚åœ¨å¹•åï¼Œè¿™ç§å¸ƒå±€ç»“æ„ä½¿ç”¨äº†[Web å¼€å‘çš„ flexbox æ¨¡å‹](https:\\u002f...\"],[\"Gradio Demo: blocks_kitchen_sink\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\nimport ...\"],[\"isplay an interactive map of AirBnB locations with Plotly. Data is hosted on HuggingFace Datasets....\"],[\"ä½¿ç”¨ Gradio å’Œ Comet\\n\\nTags: COMET, SPACES\\nç”± Comet å›¢é˜Ÿè´¡çŒ®\\n\\n## ä»‹ç»\\n\\nåœ¨è¿™ä¸ªæŒ‡å—ä¸­ï¼Œæˆ‘ä»¬å°†å±•ç¤ºæ‚¨å¯ä»¥å¦‚ä½•ä½¿ç”¨ Gradio å’Œ Cometã€‚æˆ‘ä»¬å°†ä»‹ç»...\"],[\"@gradio\\u002fcolumn\\n\\n## 0.1.0\\n\\n### Features\\n\\n- [#5498](https:\\u002f\\u002fgithub.com\\u002fgradio-app\\u002fgradio\\u002fpull\\u002f5498) [`...\"],[\"Gradio Demo: asr\\n\\n\\n```\\n!pip install -q gradio torch torchaudio transformers\\n```\\n\\n\\n```\\nimport gradio ...\"],[\"he simplest possible Gradio demo. It wraps a 'Hello {name}!' function in an Interface that accepts a...\"],[\"his  demo converts text to speech in 14 languages....\"],[\"Contributing a Guide\\n\\nWant to help teach Gradio? Consider contributing a Guide! ğŸ¤—\\n\\nBroadly speaking,...\"],[\"Gradio Demo: blocks_xray\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\nimport time\\n\\ndi...\"],[\"Gradio Demo: fake_gan\\n### This is a fake GAN that shows how to create a text-to-image interface for ...\"],[\"å¦‚ä½•ä½¿ç”¨ 3D æ¨¡å‹ç»„ä»¶\\n\\nç›¸å…³ç©ºé—´ï¼šhttps:\\u002f\\u002fhuggingface.co\\u002fspaces\\u002fdawood\\u002fModel3D, https:\\u002f\\u002fhuggingface.co\\u002fspaces\\u002fradam...\"],[\"@gradio\\u002faccordion\\n\\n## 0.2.6\\n\\n### Patch Changes\\n\\n- Updated dependencies [[`828fb9e`](https:\\u002f\\u002fgithub.c...\"],[\"Gradio Demo: highlightedtext_component\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\n\\n...\"],[\"Gradio Demo: on_listener_decorator\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\n\\nwith...\"],[\"Gradio Demo: zip_files\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\n# Downloading files from the demo rep...\"],[\"his demo uses a fake model to showcase iterative output. The Image output will update every time a g...\"],[\"Gradio Demo: color_picker\\n\\n\\n```\\n!pip install -q gradio Pillow\\n```\\n\\n\\n```\\n# Downloading files from the...\"],[\"Gradio Demo: tax_calculator\\n### Calculate taxes using Textbox, Radio, and Dataframe components\\n     ...\"],[\"Customizing your demo with CSS and Javascript\\n\\nGradio allows you to customize your demo in several w...\"],[\"The `Interface` class\\n\\nAs mentioned in the [Quickstart](\\u002fmain\\u002fguides\\u002fquickstart), the `gr.Interface`...\"],[\"Gradio Demo: variable_outputs\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\n\\nmax_textb...\"],[\"Security Policy\\n\\n## Reporting a Vulnerability\\n\\nIf you discover a security vulnerability, we would be...\"],[\"Configuring Your Custom Component\\n\\nThe custom components workflow focuses on [convention over config...\"],[\"Gradio Demo: blocks_gpt\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\n\\napi = gr.load(\\\"...\"],[\"imple image segmentation using gradio's AnnotatedImage component....\"],[\"Gradio Demo: save_file_no_output\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport random\\nimport string...\"],[\"@gradio\\u002fcolorpicker\\n\\n## 0.2.6\\n\\n### Patch Changes\\n\\n- Updated dependencies [[`828fb9e`](https:\\u002f\\u002fgithub...\"],[\"Gradio Demo: code_component\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\n\\nwith gr.Blo...\"],[\"Gradio Demo: fake_diffusion\\n### This demo uses a fake model to showcase iterative output. The Image ...\"],[\"Gradio Demo: altair_plot\\n\\n\\n```\\n!pip install -q gradio altair vega_datasets\\n```\\n\\n\\n```\\nimport altair a...\"],[\"Gradio Demo: native_plots\\n\\n\\n```\\n!pip install -q gradio vega_datasets\\n```\\n\\n\\n```\\n# Downloading files f...\"],[\"Gradio Demo: same-person-or-different\\n### This demo identifies if two speakers are the same person u...\"],[\"How to Create a Custom Chatbot with Gradio Blocks\\n\\nTags: NLP, TEXT, CHAT\\nRelated spaces: https:\\u002f\\u002fhug...\"],[\"Gradio Demo: video_component_events\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\n\\nwit...\"],[\"Gradio Demo: bar_plot\\n\\n\\n```\\n!pip install -q gradio pandas\\n```\\n\\n\\n```\\nimport gradio as gr\\nimport panda...\"],[\"Gradio Demo: progress_simple\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\nimport time...\"],[\"@gradio\\u002fuploadbutton\\n\\n## 0.3.4\\n\\n### Patch Changes\\n\\n- Updated dependencies [[`828fb9e`](https:\\u002f\\u002fgithu...\"],[\"The Frontend ğŸŒâ­ï¸\\n\\nThis guide will cover everything you need to know to implement your custom compone...\"],[\"@gradio\\u002fsimpledropdown\\n\\n## 0.1.6\\n\\n### Patch Changes\\n\\n- Updated dependencies [[`828fb9e`](https:\\u002f\\u002fgit...\"],[\"Test Coverage\\n\\nJust a little reference docs to understand what is tested\\u002f needs testing. Perhaps tem...\"],[\"@gradio\\u002fcode\\n\\n## 0.3.3\\n\\n### Patch Changes\\n\\n- Updated dependencies [[`828fb9e`](https:\\u002f\\u002fgithub.com\\u002fgr...\"],[\"Gradio Demo: text_analysis\\n### This simple demo takes advantage of Gradio's HighlightedText, JSON an...\"],[\"Gradio Demo: diff_texts\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nfrom difflib import Differ\\n\\nimport g...\"],[\"Gradio Demo: code\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\n# Downloading files from the demo repo\\nimp...\"],[\"Reactive Interfaces\\n\\nFinally, we cover how to get Gradio demos to refresh automatically or continuou...\"],[\"`@gradio\\u002ftheme`\\n\\ncss for gradio...\"],[\"Gradio Demo: chatbot_simple\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\nimport rando...\"],[\"his sentiment analaysis demo takes in input text and returns its classification for either positive,...\"],[\"Gradio Demo: count_generator\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\nimport time...\"],[\"Creating a Real-Time Dashboard from Google Sheets\\n\\nTags: TABULAR, DASHBOARD, PLOTS\\n\\n[Google Sheets](...\"],[\"@gradio\\u002fnumber\\n\\n## 0.3.6\\n\\n### Patch Changes\\n\\n- Updated dependencies [[`828fb9e`](https:\\u002f\\u002fgithub.com\\u002f...\"],[\"@gradio\\u002fplot\\n\\n## 0.2.6\\n\\n### Patch Changes\\n\\n- Updated dependencies [[`828fb9e`](https:\\u002f\\u002fgithub.com\\u002fgr...\"],[\"Gradio Demo: chatbot_component\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\n\\nwith gr....\"],[\"Gradio Demo: interface_random_slider\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\n\\n\\nd...\"],[\"his demo identifies musical instruments from an audio file. It uses Gradio's Audio and Label compone...\"],[\"Gradio Demo: blocks_js_load\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\n\\ndef welcome...\"],[\"Gradio Demo: image_mod_default_image\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\n# Downloading files fro...\"],[\"Gradio Demo: on_listener_basic\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\n\\nwith gr....\"],[\"Gradio Demo: reversible_flow\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\n\\ndef increa...\"],[\"@gradio\\u002fcheckboxgroup\\n\\n## 0.3.7\\n\\n### Patch Changes\\n\\n- Updated dependencies [[`828fb9e`](https:\\u002f\\u002fgith...\"],[\"Gradio Demo: digit_classifier\\n\\n\\n```\\n!pip install -q gradio tensorflow\\n```\\n\\n\\n```\\nfrom urllib.request ...\"],[\"@gradio\\u002fwasm\\n\\n## 0.4.0\\n\\n### Features\\n\\n- [#6398](https:\\u002f\\u002fgithub.com\\u002fgradio-app\\u002fgradio\\u002fpull\\u002f6398) [`67...\"],[\"@gradio\\u002fcheckbox\\n\\n## 0.2.6\\n\\n### Patch Changes\\n\\n- Updated dependencies [[`828fb9e`](https:\\u002f\\u002fgithub.co...\"],[\"Gradio Demo: input_output\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\n\\n\\ndef image_mo...\"],[\"Key Features\\n\\nLet's go through some of the key features of Gradio. This guide is intended to be a hi...\"],[\"Gradio Demo: file_explorer_component\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr \\n\\nw...\"],[\"Gradio Demo: timeseries-forecasting-with-prophet\\n### A simple dashboard showing pypi stats for pytho...\"],[\"Custom Components in 5 minutes\\n\\nGradio 4.0 introduces Custom Components -- the ability for developer...\"],[\"Test Strategy\\n\\nVery brief, mildly aspirational test strategy document. This isn't where we are but i...\"],[\"Gradio Demo: audio_debugger\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\n# Downloading files from the dem...\"],[\"`@gradio\\u002fupload`\\n\\n```html\\n\\u003cscript\\u003e\\n    import { Upload, ModifyUpload, normalise_file, get_fetchable_...\"],[\"Gradio Demo: hello_blocks_decorator\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\n\\n\\nwi...\"],[\"Connecting to a Database\\n\\nRelated spaces: https:\\u002f\\u002fhuggingface.co\\u002fspaces\\u002fgradio\\u002fchicago-bikeshare-das...\"],[\"Gradio Demo: image_classifier_2\\n\\n\\n```\\n!pip install -q gradio pillow torch torchvision\\n```\\n\\n\\n```\\n# Do...\"],[\"Gradio Demo: scatter_plot\\n\\n\\n```\\n!pip install -q gradio vega_datasets pandas\\n```\\n\\n\\n```\\nimport gradio ...\"],[\"ä½¿ç”¨Gradio Pythonå®¢æˆ·ç«¯æ„å»ºFastAPIåº”ç”¨\\n\\nTags: CLIENT, API, WEB APP\\n\\nåœ¨æœ¬åšå®¢æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬å°†æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ `gradio_client` [Python...\"],[\"Gradio Demo: theme_extended_step_3\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\nimpor...\"],[\"@gradio\\u002ftabitem\\n\\n## 0.1.0\\n\\n### Features\\n\\n- [#5498](https:\\u002f\\u002fgithub.com\\u002fgradio-app\\u002fgradio\\u002fpull\\u002f5498) [...\"],[\"ä» BigQuery æ•°æ®åˆ›å»ºå®æ—¶ä»ªè¡¨ç›˜\\n\\nTags: è¡¨æ ¼ , ä»ªè¡¨ç›˜ , ç»˜å›¾\\n\\n[Google BigQuery](https:\\u002f\\u002fcloud.google.com\\u002fbigquery) æ˜¯ä¸€ä¸ªåŸº...\"],[\"Gradio Demo: progress\\n\\n\\n```\\n!pip install -q gradio tqdm datasets\\n```\\n\\n\\n```\\nimport gradio as gr\\nimpor...\"],[\"Gradio Demo: theme_new_step_1\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\nfrom gradi...\"],[\"Interface State\\n\\nSo far, we've assumed that your demos are *stateless*: that they do not persist inf...\"],[\"Gradio Demo: tabbed_interface_lite\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\n\\nhell...\"],[\"Gradio Demo: theme_extended_step_1\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\nimpor...\"],[\"ä½¿ç”¨ GAN åˆ›å»ºæ‚¨è‡ªå·±çš„æœ‹å‹\\n\\nspaces\\u002fNimaBoscarino\\u002fcryptopunks, https:\\u002f\\u002fhuggingface.co\\u002fspaces\\u002fnateraw\\u002fcryptopunks...\"],[\"Gradio Demo: blocks_flipper\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport numpy as np\\nimport gradio...\"],[\"@gradio\\u002fannotatedimage\\n\\n## 0.3.13\\n\\n### Patch Changes\\n\\n- Updated dependencies [[`828fb9e`](https:\\u002f\\u002fgi...\"],[\"Gradio Demo: stt_or_tts\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\n\\ntts_examples = ...\"],[\"Gradio and W&B Integration\\n\\nç›¸å…³ç©ºé—´ï¼šhttps:\\u002f\\u002fhuggingface.co\\u002fspaces\\u002fakhaliq\\u002fJoJoGAN\\næ ‡ç­¾ï¼šWANDB, SPACES\\nç”± Gr...\"],[\"Gradio Demo: dataset\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\n# Downloading files from the demo repo\\n...\"],[\"`@gradio\\u002fdropdown`\\n\\n```html\\n\\u003cscript\\u003e\\n    import {BaseDropdown, BaseMultiselect, BaseExample } from \\\"...\"],[\"Gradio Demo: fake_diffusion_with_gif\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\n# Downloading files fro...\"],[\"Gradio Demo: theme_soft\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\nimport time\\n\\nwit...\"],[\"Gradio Demo: radio_component\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr \\n\\nwith gr.B...\"],[\"Gradio Demo: image_selections\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\nimport num...\"],[\"ä½¿ç”¨ Gradio Python å®¢æˆ·ç«¯å…¥é—¨\\n\\nTags: CLIENT, API, SPACES\\n\\nGradio Python å®¢æˆ·ç«¯ä½¿å¾—å°†ä»»ä½• Gradio åº”ç”¨ç¨‹åºä½œä¸º API ä½¿ç”¨å˜å¾—éå¸¸å®¹æ˜“...\"],[\"Gradio Demo: markdown_component\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\n\\nwith gr...\"],[\"Gradio Demo: gpt2_xl_unified\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\n\\ncomponent ...\"],[\"How to Create a Chatbot with Gradio\\n\\nTags: NLP, TEXT, CHAT\\n\\n## Introduction\\n\\nChatbots are a popular ...\"],[\"Create a Dashboard from Supabase Data\\n\\nTags: TABULAR, DASHBOARD, PLOTS\\n\\n[Supabase](https:\\u002f\\u002fsupabase....\"],[\"Gradio Demo: hello_world_4\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\n\\ndef greet(na...\"],[\"Gradio Demo: fake_gan_no_input\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport time\\n\\nimport gradio as...\"],[\"gradio_test\\n\\n## 0.3.3\\n\\n### Patch Changes\\n\\n- Updated dependencies [[`828fb9e`](https:\\u002f\\u002fgithub.com\\u002fgra...\"],[\"@gradio\\u002fpreview\\n\\n## 0.6.0\\n\\n### Features\\n\\n- [#6738](https:\\u002f\\u002fgithub.com\\u002fgradio-app\\u002fgradio\\u002fpull\\u002f6738) [...\"],[\"Gradio Demo: blocks_js_methods\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\n\\nblocks =...\"],[\"Gradio Demo: theme_extended_step_4\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\nimpor...\"],[\"@gradio\\u002ftextbox\\n\\n## 0.4.7\\n\\n### Patch Changes\\n\\n- Updated dependencies [[`828fb9e`](https:\\u002f\\u002fgithub.com...\"],[\"Gradio Demo: dataset_component\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\n\\nwith gr....\"],[\"Gradio Demo: blocks_layout\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\n\\n\\ndemo = gr.B...\"],[\"@gradio\\u002fapp\\n\\n## 1.17.0\\n\\n### Features\\n\\n- [#6831](https:\\u002f\\u002fgithub.com\\u002fgradio-app\\u002fgradio\\u002fpull\\u002f6831) [`f3...\"],[\"Gradio Demo: kitchen_sink\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\n# Downloading files from the demo ...\"],[\"`@gradio\\u002futils`\\n\\nGeneral functions for handling events in Gradio Svelte components\\n\\n\\n```javascript\\ne...\"],[\"Gradio Demo: audio_component\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\n\\nwith gr.Bl...\"],[\"Gradio Demo: musical_instrument_identification\\n### This demo identifies musical instruments from an ...\"],[\"Gradio Demo: change_vs_input\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\n# Downloading files from the de...\"],[\"@gradio\\u002fchatbot\\n\\n## 0.5.5\\n\\n### Patch Changes\\n\\n- Updated dependencies [[`846d52d`](https:\\u002f\\u002fgithub.com...\"],[\"@gradio\\u002fbutton\\n\\n## 0.2.13\\n\\n### Patch Changes\\n\\n- Updated dependencies [[`828fb9e`](https:\\u002f\\u002fgithub.com...\"],[\"Gradio Demo: dataframe_colorful\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport pandas as pd \\nimport ...\"],[\"How to Style the Gradio Dataframe\\n\\nTags: DATAFRAME, STYLE, COLOR\\n\\n## Introduction\\n\\nData visualizatio...\"],[\"Image Classification with Vision Transformers\\n\\nRelated spaces: https:\\u002f\\u002fhuggingface.co\\u002fspaces\\u002fabidlab...\"],[\"Gradio Demo: text_generation\\n### This text generation demo takes in input text and returns generated...\"],[\"Gradio Demo: diffusers_with_batching\\n\\n\\n```\\n!pip install -q gradio torch transformers diffusers\\n```\\n\\n...\"],[\"Gradio Demo: depth_estimation\\n### A demo for predicting the depth of an image and generating a 3D mo...\"],[\"Using Gradio for Tabular Data Science Workflows\\n\\nRelated spaces: https:\\u002f\\u002fhuggingface.co\\u002fspaces\\u002fsciki...\"],[\"Controlling Layout\\n\\nBy default, Components in Blocks are arranged vertically. Let's take a look at h...\"],[\"Build a Custom Multimodal Chatbot - Part 1\\n\\nThis is the first in a two part series where we build a ...\"],[\"Creating a Real-Time Dashboard from BigQuery Data\\n\\nTags: TABULAR, DASHBOARD, PLOTS\\n\\n[Google BigQuery...\"],[\"Gradio Demo: sepia_filter\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport numpy as np\\nimport gradio a...\"],[\"`@gradio\\u002fimage`\\n\\n```html\\n\\u003cscript\\u003e\\n\\timport { BaseImageUploader, BaseStaticImage, Webcam, BaseExample ...\"],[\"`@gradio\\u002faudio`\\n\\n```html\\n\\u003cscript\\u003e\\n\\timport { BaseStaticAudio, BaseInteractiveAudio, BasePlayer, BaseE...\"],[\"Gradio Demo: blocks_multiple_event_triggers\\n\\n\\n```\\n!pip install -q gradio plotly pypistats\\n```\\n\\n\\n```\\n...\"],[\"!-- DO NOT EDIT THIS FILE DIRECTLY. INSTEAD EDIT THE `readme_template.md` OR `guides\\u002f1)getting_start...\"],[\"More on Examples\\n\\nIn the [previous Guide](\\u002fmain\\u002fguides\\u002fthe-interface-class), we discussed how to pro...\"],[\"Backend Testing Guidelines\\n\\n- All the tests should test Backend functionalities. Frontend functional...\"],[\"Gradio and ONNX on Hugging Face\\n\\nRelated spaces: https:\\u002f\\u002fhuggingface.co\\u002fspaces\\u002fonnx\\u002fEfficientNet-Lit...\"],[\"# ä½¿ç”¨ Gradio è¿›è¡Œè¡¨æ ¼æ•°æ®ç§‘å­¦å·¥ä½œæµ\\n\\nRelated spaces: https:\\u002f\\u002fhuggingface.co\\u002fspaces\\u002fscikit-learn\\u002fgradio-skops-int...\"],[\"his translation demo takes in the text, source and target languages, and returns the translation. It...\"],[\"Gradio Demo: model3D\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\n# Downloading files from the demo repo\\n...\"],[\"@gradio\\u002flite\\n\\n## 0.4.4\\n\\n## 0.4.4-beta.0\\n\\n### Features\\n\\n- [#6147](https:\\u002f\\u002fgithub.com\\u002fgradio-app\\u002fgradi...\"],[\"@gradio\\u002fvideo\\n\\n## 0.2.3\\n\\n### Fixes\\n\\n- [#6766](https:\\u002f\\u002fgithub.com\\u002fgradio-app\\u002fgradio\\u002fpull\\u002f6766) [`7326...\"],[\"Gradio Demo: outbreak_forecast\\n### Generate a plot based on 5 inputs.\\n        \\n\\n\\n```\\n!pip install -q...\"],[\"@gradio\\u002ffile\\n\\n## 0.4.3\\n\\n### Patch Changes\\n\\n- Updated dependencies [[`828fb9e`](https:\\u002f\\u002fgithub.com\\u002fgr...\"],[\"Gradio Demo: blocks_flashcards\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport random\\n\\nimport gradio ...\"],[\"`@gradio\\u002fjson`\\n\\n```html\\n\\u003cscript\\u003e\\n\\timport { BaseJSON } from \\\"@gradio\\u002fjson\\\";\\n\\u003c\\u002fscript\\u003e\\n```\\n\\nBaseJSON\\n`...\"],[\"ä½¿ç”¨Gradio JavaScriptå®¢æˆ·ç«¯å¿«é€Ÿå…¥é—¨\\n\\nTags: CLIENT, API, SPACES\\n\\nGradio JavaScriptå®¢æˆ·ç«¯ä½¿å¾—ä½¿ç”¨ä»»ä½•Gradioåº”ç”¨ä½œä¸ºAPIéå¸¸ç®€å•ã€‚ä¾‹...\"],[\"@gradio\\u002ftootils\\n\\n## 0.1.7\\n\\n### Patch Changes\\n\\n- Updated dependencies [[`828fb9e`](https:\\u002f\\u002fgithub.com...\"],[\"Quickstart\\n\\nGradio is an open-source Python package that allows you to quickly **build** a demo or w...\"],[\"å¦‚ä½•åˆ›å»ºä¸€ä¸ªèŠå¤©æœºå™¨äºº\\n\\nTags: NLP, TEXT, CHAT\\nRelated spaces: https:\\u002f\\u002fhuggingface.co\\u002fspaces\\u002fgradio\\u002fchatbot_stre...\"],[\"Gradio Demo: chatbot_streaming\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\nimport ra...\"],[\"Gradio Demo: upload_button\\n### A simple demo showcasing the upload button used with its `upload` eve...\"],[\"Gradio Demo: button_component\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\n\\nwith gr.B...\"],[\"Gradio Demo: image_component\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr \\n\\nwith gr.B...\"],[\"`@gradio\\u002fcheckbox`\\n\\n```html\\n\\u003cscript\\u003e\\n    import { BaseCheckbox } from \\\"@gradio\\u002fcheckbox\\\";\\n\\u003c\\u002fscript\\u003e\\n...\"],[\"Gradio Demo: dropdown_component\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr \\n\\nwith g...\"],[\"Gradio Demo: filter_records\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\n\\n\\ndef filter...\"],[\"@gradio\\u002fdropdown\\n\\n## 0.4.3\\n\\n### Patch Changes\\n\\n- Updated dependencies [[`828fb9e`](https:\\u002f\\u002fgithub.co...\"],[\"Gradio Demo: autocomplete\\n### This text generation demo works like autocomplete. There's only one te...\"],[\"Gradio Demo: generate_english_german\\n\\n\\n```\\n!pip install -q gradio transformers torch\\n```\\n\\n\\n```\\nimpor...\"],[\"Gradio Demo: gallery_component_events\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr \\n\\n...\"],[\"Gradio Demo: theme_builder\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\n\\ndemo = gr.th...\"],[\"Gradio Demo: blocks_inputs\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\n# Downloading files from the demo...\"],[\"Gradio Demo: html_component\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr \\n\\nwith gr.Bl...\"],[\"Gradio Demo: checkboxgroup_component\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr \\n\\nw...\"],[\"Gradio Demo: state_component\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr \\n\\nwith gr.B...\"],[\"`@gradio\\u002ftextbox`\\n\\n```html\\n\\u003cscript\\u003e\\n    import { BaseTextbox, BaseExample } from \\\"@gradio\\u002ftextbox\\\";\\n...\"],[\"Gradio Demo: clear_components\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\n# Downloading files from the d...\"],[\"å¿«é€Ÿå¼€å§‹\\n\\n**å…ˆå†³æ¡ä»¶**ï¼šGradio éœ€è¦ Python 3.8 æˆ–æ›´é«˜ç‰ˆæœ¬ï¼Œå°±æ˜¯è¿™æ ·ï¼\\n\\n## Gradio æ˜¯åšä»€ä¹ˆçš„ï¼Ÿ\\n\\nä¸ä»–äººåˆ†äº«æ‚¨çš„æœºå™¨å­¦ä¹ æ¨¡å‹ã€API æˆ–æ•°æ®ç§‘å­¦æµç¨‹çš„*æœ€ä½³æ–¹å¼ä¹‹ä¸€...\"],[\"@gradio\\u002fstorybook\\n\\n## 0.2.0\\n\\n### Features\\n\\n- [#6451](https:\\u002f\\u002fgithub.com\\u002fgradio-app\\u002fgradio\\u002fpull\\u002f6451)...\"],[\"Sharing Your App\\n\\nHow to share your Gradio app:\\n\\n1. [Sharing demos with the share parameter](#sharin...\"],[\"`@gradio\\u002ftooltip`\\n\\n```javascript\\nimport { Tooltip } from \\\"@gradio\\u002ftooltip\\\";\\n```\\n\\n```javascript\\n\\texpo...\"],[\"enerate a plot based on 5 inputs....\"],[\"Gradio Demo: stock_forecast\\n\\n\\n```\\n!pip install -q gradio numpy matplotlib\\n```\\n\\n\\n```\\nimport matplotli...\"],[\"simple dashboard showing pypi stats for python libraries. Updates on load, and has no buttons!...\"],[\"Gradio Demo: neon-tts-plugin-coqui\\n### This  demo converts text to speech in 14 languages.\\n        \\n...\"],[\"@gradio\\u002ftooltip\\n\\n## 0.1.0\\n\\n## 0.1.0-beta.2\\n\\n### Features\\n\\n- [#6136](https:\\u002f\\u002fgithub.com\\u002fgradio-app\\u002fgr...\"],[\"`@gradio\\u002fcode`\\n\\n```html\\n\\u003cscript\\u003e\\n    import { BaseCode, BaseCopy, BaseDownload, BaseWidget, BaseExam...\"],[\"Gradio Demo: gif_maker\\n\\n\\n```\\n!pip install -q gradio opencv-python\\n```\\n\\n\\n```\\nimport cv2\\nimport gradio...\"],[\"Gradio Demo: file_explorer_component_events\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\n# Downloading fi...\"],[\"Gradio Demo: stream_audio\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\nimport numpy a...\"],[\"Gradio Demo: gallery_selections\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr\\nimport n...\"],[\"Gradio Demo: stream_asr\\n\\n\\n```\\n!pip install -q gradio torch torchaudio transformers\\n```\\n\\n\\n```\\nimport ...\"],[\"his demo takes in 12 inputs from the user in dropdowns and sliders and predicts income. It also has ...\"],[\"`@gradio\\u002flabel`\\n\\n```html\\n\\u003cscript\\u003e\\n\\timport { BaseLabel } from \\\"@gradio\\u002flabel\\\";\\n\\u003c\\u002fscript\\u003e\\n```\\n\\nBaseLab...\"],[\"alculate taxes using Textbox, Radio, and Dataframe components...\"],[\"Gradio Demo: json_component\\n\\n\\n```\\n!pip install -q gradio \\n```\\n\\n\\n```\\nimport gradio as gr \\n\\nwith gr.Bl...\"]],\"hovertemplate\":\"source=gradio\\u003cbr\\u003esymbol=circle\\u003cbr\\u003ex=%{x}\\u003cbr\\u003ey=%{y}\\u003cbr\\u003esize_col=%{marker.size}\\u003cbr\\u003eextract=%{customdata[0]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"gradio, circle\",\"marker\":{\"color\":\"#ab63fa\",\"size\":[4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4],\"sizemode\":\"area\",\"sizeref\":0.25,\"symbol\":\"circle\",\"line\":{\"color\":\"DarkSlateGrey\",\"width\":0},\"opacity\":1},\"mode\":\"markers\",\"name\":\"gradio, circle\",\"showlegend\":true,\"x\":[15.630309,18.376587,16.593658,15.5498,16.72783,18.479046,15.959671,17.903502,22.233566,16.068132,16.331161,18.793941,17.878923,16.992376,19.843237,17.516775,16.368605,17.604378,18.696125,16.296923,15.961598,16.971786,16.960556,-1.9256018,15.740896,22.239637,-5.0730815,17.387016,18.619139,15.532094,16.131418,-5.07021,16.761778,16.844465,16.96882,17.34057,17.396872,17.246494,16.870104,19.086702,16.989275,16.02199,15.529623,18.51416,18.607693,18.69462,17.295498,16.980206,-4.4237957,17.58146,15.242721,17.2186,16.403194,16.981258,18.1325,17.32745,16.973347,20.139236,18.37845,17.359703,22.24463,19.268087,17.317318,17.70537,17.99463,18.410173,16.756298,16.965143,20.135763,17.161102,19.209265,17.228937,17.31989,18.90093,15.928883,16.970062,16.968136,17.148943,17.977158,22.249289,17.694817,17.417656,19.19088,17.54549,16.925945,22.232264,-6.5137053,18.331028,22.248096,16.68945,17.117712,16.975225,16.609495,17.412502,-3.8473485,18.792847,18.418125,18.21316,17.489012,18.915237,15.557792,18.084991,17.70671,15.262249,17.831278,17.025536,16.063864,16.970873,22.2445,15.656171,17.158173,18.832619,19.259388,18.903582,14.980731,17.419159,17.074713,15.637314,17.913513,17.007343,16.727877,15.608097,-13.637689,17.37009,18.920292,-4.3920107,18.32427,15.617576,18.879917,17.012672,17.496885,19.896318,18.663774,18.78041,16.580572,16.033545,15.609587,18.231085,16.994974,17.607248,16.38387,15.804576,18.431616,16.742474,15.885549,16.986246,17.097624,16.414078,16.966526,16.409685,17.283512,15.8569975,17.864368,16.286993,16.20656,16.636765,22.238682,16.968601,20.121115,17.797136,15.683527,18.362093,18.89598,15.718678,17.868065,16.701061,19.283834,17.439684,18.591228,22.245611,16.349798,16.21762,-4.8337607,16.014252,16.320696,19.27286,-13.102135,18.841955,16.97663,15.821454,16.97126,17.22472,17.04182,15.637656,16.965405,17.08919,16.551243,18.955814,18.456406,16.565485,2.7417269,16.974993,22.248997,17.090475,17.478193,17.707361,22.243982,16.988022,18.429222,16.457777,16.205553,22.197296,17.481146,17.547457,18.122234,16.996069,17.194836,19.288992,16.97351,16.708313,22.250273,18.457165,-6.697643,17.075584,16.96919,16.477676,17.04166,16.247395,15.769302,18.762753,16.533165,15.931917,16.373772,17.985237,15.526336,19.95573,18.930277,16.679243,22.251848,16.004318,17.342861,15.99629,15.414033,18.356525,16.968649,16.843143,16.534634,16.971674,17.476324,18.6662,15.399399,18.510519,17.506006,16.627296,18.77823,18.395708,22.244928,19.015972,22.247597,19.414051,17.94126,15.610896,-2.2753363,20.13885,16.822428,17.764135,17.06381,16.908068,22.234884,18.069756,-1.6072551,15.789811,17.436234,17.056112,18.82112,15.873203,18.701324,15.783069,15.485103,17.310934,17.034689,15.908273,19.05779,18.697666,16.978102,18.569845,16.84881,17.13108,15.9062195,17.984863,3.0597544,15.715286,17.043669,17.601986,19.07121,-5.768868,16.849882,17.849556,16.477417,15.963937,16.97066,18.770658,19.213463,17.57858,-4.792385,16.897821,17.794304,17.379301,17.190979,18.756353,16.98891,17.394585,18.575409,16.183836,17.186838,16.98056,18.63877,16.839964,15.965992,16.14494,17.478252,20.095018,17.61941,16.09152,18.758337,16.970297,17.297804,16.973978,1.3951446,16.969294,17.874973,18.225319,18.044796,16.627876,17.141245,20.088358,17.425982,18.320698,15.766018,16.968803,16.956966,20.067589,18.27352,17.4321,19.019363,16.630322,19.202366,18.568136,16.967949,15.965583,16.997509,16.971619,18.52436,16.892979,17.94257,15.941984,17.288876,16.950626,17.454615,22.238586,19.28674,15.744689,15.793384,16.077612,16.090403,18.675005,17.032633,15.542576,18.049448,18.605297,16.547573,18.642014,18.578747,14.818881,18.095016,16.972347,18.16022,15.602587,17.317528,22.246117,16.647026,18.6932,18.659872,16.720875,15.822663,18.761385,18.20455,20.082506,15.753095,19.191786,16.72658,16.975332,16.999128,18.931187,18.623764,16.982328,17.288208,18.9627,16.997814,17.358988,22.201685,17.83466,17.21912,17.284237,16.968622,16.975473,16.313173,15.994767,15.582627,17.87957,16.782423,16.260195,15.92667,16.91231,19.791382,15.702501,16.743172,22.24532,22.224598,16.490078,16.545017,16.566473,16.898035,16.074265,15.743599,-5.4382405,16.80467,17.018103,16.99289,15.958152,16.972889,18.04408,22.24385,15.74055,16.963013,16.979015,15.665664,20.118341,17.707354,18.7034,18.20945,22.241243,18.768847,17.301895,16.984282,17.84543,17.947088,17.25868,18.624548,18.635681,18.756023,18.980835,18.611113,22.25102,16.357529,15.851362,17.017376,16.649672,22.248955,-4.6724834,15.930627,-0.60101753,17.734488,17.054707,22.247452,16.938152,17.806753,17.403656,17.11111,17.617895,-4.8118644,22.252972,-4.4473147,18.406395],\"xaxis\":\"x\",\"y\":[0.65228516,-2.0739062,0.54115915,0.2619107,-3.3530128,-2.6898234,-0.15654904,0.076397404,8.091456,-1.5017453,-0.016344003,-2.7101703,-2.9944637,3.2887113,-0.20991457,-0.6257794,2.0573726,-2.381017,-1.5459979,0.864516,-0.70965135,3.2870405,4.4040284,3.4427814,-2.4930868,8.097562,-2.1661286,-1.9840702,-0.52697396,0.77474105,-1.3877776,-2.101364,-2.340777,1.7977124,5.0626836,1.3988917,-1.5816534,1.4937805,-3.3249862,-1.8855028,4.1434107,-1.144131,-2.4632993,-1.2783207,-1.7597888,-2.0626876,-1.6860429,3.772046,-2.7791119,-3.0348718,-0.748902,-0.7300153,-3.2044673,4.2732286,-1.6785326,-2.934945,5.108921,0.36935076,-1.1315157,-1.6546772,8.109136,-1.0027658,1.2096769,-0.7194388,-0.3849051,-1.869581,-3.3295805,2.2057238,0.30961126,-1.8132931,-1.6374202,1.4381313,-2.2733054,-0.9724139,-1.1130046,5.100124,4.738511,1.3995291,-1.6713988,8.108564,-3.0183802,-1.8822224,-1.7090915,0.015768763,-0.42356896,8.085444,-0.88097155,-0.89073163,8.107849,-2.5278704,0.74680024,4.3408613,0.8461976,1.5331775,-3.5885286,-1.9689205,-2.2974403,-1.7794605,-1.85637,-1.4227419,0.6471568,-1.137793,-2.977389,0.09856885,-0.46075752,-1.7362517,-1.5653208,5.117017,8.102266,0.5654079,0.6238717,-0.7833491,-1.1299224,-1.7423846,0.036250543,-2.899636,3.074322,0.6510654,0.03717298,3.2920256,-3.2853224,0.65485245,-6.339723,-1.827925,-1.6106926,-2.9605937,-1.6960126,0.7011067,-2.782745,3.1342497,-2.3597116,-0.009654739,-2.503259,-1.8492328,1.2662371,1.0083236,-0.07044968,-2.9656398,3.6802807,-2.6551445,0.85304624,-2.6060839,-2.4928162,0.9999676,-1.5836699,1.4333918,1.5953213,-1.8373365,4.8891068,-1.6055194,-1.7467296,-2.7086625,-0.23095444,-2.634815,-2.1598067,-2.6571493,8.094117,4.9894924,0.21195363,-2.8982747,0.4826165,-2.8556454,-1.9240986,0.6248112,-0.3986162,-3.4012413,-1.308775,-0.5599473,-1.005559,8.103609,-1.8897209,-1.8425524,-2.4358425,0.66543055,-1.9019953,-1.4000537,-4.2305098,-2.6730666,4.8135524,0.6553367,5.099826,-2.450915,3.3294022,0.2949356,5.015667,1.5841682,1.3479348,-1.7553961,-1.5684546,-3.134436,5.283203,5.167172,8.1064825,1.7227522,-0.28296363,-2.9603312,8.099912,1.3752049,-0.5184646,-1.7639912,-2.5611558,8.042184,-1.6415421,-2.9194863,-0.32158065,3.4450257,-1.9384562,-1.2287413,4.986006,0.040456954,8.109649,-1.5877771,6.0118785,-1.8368535,1.2722653,0.7355065,0.40396932,0.08376003,-0.7578092,-1.9249,0.29561862,-0.6730054,-1.8608415,-0.3701843,0.46426573,0.09818518,-1.6309488,0.28122216,8.111005,-1.6299145,1.2353029,-0.4123186,0.7683407,-1.5922976,4.7560396,-3.2744918,-1.9724224,5.1054792,-2.6278791,-0.365004,0.4498376,-1.7818493,0.21917836,0.8920023,-1.9594603,-2.7259238,8.103369,-2.3341742,8.107102,-1.1427205,-0.22141011,0.7521673,5.0052395,0.30113083,-3.207379,-2.8092952,2.9971247,-1.5510167,8.089452,-0.14582376,5.7276845,0.7162768,-0.88661706,-2.616393,-2.7601893,-0.7775388,-2.508757,0.621547,-2.4113007,0.7490263,3.3339086,0.8393979,-1.1066105,-1.0740889,5.156188,-1.3754636,-2.1063478,0.9917051,1.0064169,-0.08714931,5.3844333,0.51298636,3.295323,-0.669061,-0.7303963,-1.6043699,0.49281633,-2.0206532,-2.8969846,-1.4717782,5.071753,-1.8183842,-1.4502381,-3.010772,-2.4876652,-2.515558,-1.7241441,1.0578408,0.5542096,-1.6676903,1.8345478,1.5215105,-1.5540367,-2.1923804,-2.9495246,4.704882,-2.3588614,-2.7786772,-1.521605,-1.7560358,-1.177893,0.33314896,-2.9347072,-1.698992,-1.409105,4.774639,1.506387,5.1116343,5.8059554,5.09599,-0.29406664,-0.6905483,-1.761242,0.28168917,1.273284,0.24399546,-0.24259053,-1.5396055,-0.6001143,5.106373,4.74749,0.2261996,-1.6641574,-1.623688,-1.7446295,-3.3753135,-1.5735979,-1.4778156,4.9610295,-2.4930062,2.2615094,5.0572968,-2.2567613,0.5038693,-2.9987543,-1.4117454,1.5199649,1.4125881,-1.9039336,8.093943,-1.3180251,-0.33801565,-2.5853431,-1.5872185,0.8886919,-0.55375767,3.238556,0.40685284,-1.8556381,-0.5062925,0.4782765,-0.93256485,-0.6723061,0.3402315,-2.2212489,4.755668,-0.714494,0.47947052,-3.1133373,8.106254,-2.8809333,-0.51583236,-2.6737306,-2.4198987,0.7983221,-2.421498,-1.7547535,0.28318334,-0.55961895,-1.1851957,-2.794935,4.9263244,3.673268,-1.5078629,-0.4562122,4.5816236,-2.1205432,-1.820513,3.4134612,-2.9856014,8.045205,-2.2963097,-1.371315,-2.7457776,4.961354,5.076356,-1.9244667,-1.3154526,-2.3861578,-0.113662794,-2.6543708,-2.4784942,-0.8620847,1.5062957,0.49445295,-0.14021802,-2.59259,8.102293,8.077884,-1.2275351,1.1691269,0.5494689,1.6207442,-0.4434983,0.18543705,4.729728,-2.775789,3.4026186,3.9049296,-1.657207,5.1638575,-1.7381983,8.102439,0.7749204,4.5905194,0.4179344,0.6726597,0.2312925,-2.8526108,-2.7575152,-2.7739272,8.100215,-2.70494,-1.923082,4.182859,-0.07788355,-0.123437226,-3.0994864,-1.148889,-2.0335217,-2.3425183,-2.5160663,-2.678417,8.11082,-1.9747047,0.6166873,3.2405741,0.5168875,8.108167,-2.4004614,-1.6707343,2.7207723,-0.5954735,3.4604633,8.107693,-2.639363,-3.0258098,-1.7038416,-2.4994617,-0.6588183,-2.2970982,8.11191,-2.0940423,-2.7242892],\"yaxis\":\"y\",\"type\":\"scattergl\"},{\"customdata\":[[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!---\\nCopyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"!--Copyright 2021 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!---\\nCopyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"Author: [@vasudevgupta7](https:\\u002f\\u002fgithub.com\\u002fthevasudevgupta\\u002f)\\n\\n## Intro\\n\\nIn this project, we fine-tu...\"],[\"!---\\nCopyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2021 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"*TEMPLATE**\\n=====================================\\n\\n*search & replace the following keywords, e.g.:*\\n...\"],[\"!---\\nCopyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!---\\nCopyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2021 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"### Fine-tuning BERT on SQuAD1.0 with relative position embeddings\\n\\nThe following examples show how ...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2021 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2021 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"Performer fine-tuning\\n\\nExample authors: @TevenLeScao, @Patrickvonplaten\\n\\nPaper authors: Krzysztof Ch...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"End-to-End finetuning of RAG (including DPR retriever) for Question Answering.\\n\\nThis finetuning scri...\"],[\"!--Copyright 2021 NVIDIA Corporation and The HuggingFace Team. All rights reserved.\\n\\nLicensed under ...\"],[\"!--Copyright 2021 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2021 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2021 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!---\\nCopyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!---\\nCopyright 2021 The Google Flax Team Authors and HuggingFace Team. All rights reserved.\\n\\nLicense...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!---\\nCopyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2021 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team and The OpenBMB Team. All rights reserved.\\n\\nLicensed under th...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!---\\nCopyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"CodeParrot ğŸ¦œ\\n\\u003cp align=\\\"center\\\"\\u003e\\n    \\u003cimg src=\\\"https:\\u002f\\u002fhuggingface.co\\u002fdatasets\\u002flvwerra\\u002frepo-images\\u002fra...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!---\\nCopyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 NVIDIA and The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache L...\"],[\"!---\\nCopyright 2021 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!---\\nCopyright 2021 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"!--Copyright 2021 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2021 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"# Contributor Covenant Code of Conduct\\n\\n## Our Pledge\\n\\nWe as members, contributors, and leaders pled...\"],[\"!---\\nCopyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!---\\nCopyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!---\\nCopyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"## Motivation\\nWithout processing, english-\\u003e romanian mbart-large-en-ro gets BLEU score 26.8 on the W...\"],[\"!---\\nCopyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!---\\nCopyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"Movement Pruning: Adaptive Sparsity by Fine-Tuning\\n\\nAuthor: @VictorSanh\\n\\n*Magnitude pruning is a wid...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\nLicensed under the Apache License, Vers...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 Mistral AI and The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apac...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2021 NVIDIA Corporation and The HuggingFace Team. All rights reserved.\\n\\nLicensed under ...\"],[\"Summarization (Seq2Seq model) training examples\\n\\nThe following example showcases how to finetune a s...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!---\\nCopyright 2021 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"!---\\nCopyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"!--Copyright 2021 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!---\\nCopyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"!--Copyright 2023 The Intel Labs Team Authors, The Microsoft Research Team Authors and HuggingFace I...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!---\\nCopyright 2021 NVIDIA Corporation. All rights reserved.\\nLicensed under the Apache License, Vers...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!---\\nCopyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!---\\nCopyright 2021 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!---\\nCopyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!---\\nCopyright 2020 The HuggingFace Team. All rights reserved.\\nLicensed under the Apache License, Ve...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!---\\nCopyright 2022 The Microsoft Inc. and The HuggingFace Inc. Team. All rights reserved.\\n\\nLicensed...\"],[\"!---\\nCopyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!---\\nCopyright 2021 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!---\\nCopyright 2021 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"!---\\nCopyright 2021 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2021 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!---\\nCopyright 2021 The HuggingFace Team. All rights reserved.\\nLicensed under the Apache License, Ve...\"],[\"# ğŸ”¥ Model cards now live inside each huggingface.co model repo ğŸ”¥\\n\\n\\nFor consistency, ease of use and ...\"],[\"!---\\nCopyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!---\\nCopyright 2021 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!---\\nCopyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2021 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!---\\nCopyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2021 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"Awesome projects built with Transformers\\n\\nThis page lists awesome projects built on top of Transform...\"],[\"!---\\nCopyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!---\\nCopyright 2021 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2021 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2021 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"Token classification\\n\\n## PyTorch version, no Trainer\\n\\nFine-tuning (m)LUKE for token classification t...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2021 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2021 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!---\\nCopyright 2021 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2021 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"## Translating the Transformers documentation into your language\\n\\nAs part of our mission to democrat...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!---\\nCopyright 2021 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"Zero-shot classifier distillation\\n\\nAuthor: @joeddav \\n\\nThis script provides a way to improve the spee...\"],[\"!--Copyright 2023 Mistral AI and The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apac...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 IBM and HuggingFace Inc. team. All rights reserved.\\n\\nLicensed under the Apache Lic...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!---\\nCopyright 2021 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"!---\\nCopyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"!--Copyright 2021 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"DeeBERT: Early Exiting for *BERT\\n\\nThis is the code base for the paper [DeeBERT: Dynamic Early Exitin...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"Fine-Tuning week of XLSR-Wav2Vec2 on 60 languages ğŸŒ\\n\\nWelcome to the fine-tuning week! The goal of th...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"Flax\\u002fJAX community week ğŸ¤—\\n\\nWelcome to the Flax\\u002fJAX community week! The goal of this week is to make ...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"Text Summarization with Pretrained Encoders\\n\\nThis folder contains part of the code necessary to repr...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The Intel Team Authors and HuggingFace Inc. team. All rights reserved.\\n\\nLicensed u...\"],[\"# Adversarial evaluation of model performances\\n\\nHere is an example on evaluating a model using adver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2021 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"Distil*\\n\\nAuthor: @VictorSanh\\n\\nThis folder contains the original code used to train Distil* as well a...\"],[\"How to propose a Flax\\u002fJAX + Transformers project \\n\\nGreat that you've opened this document! \\nWhile we...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2021 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2021 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2021 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"Image Captioning (vision-encoder-text-decoder model) training example\\n\\nThe following example showcas...\"],[\"!---\\nCopyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"Simple VQGAN CLIP\\n\\nAuthor: @ErwannMillon \\n\\nThis is a very simple VQGAN-CLIP implementation that was ...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!---\\nCopyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"!--Copyright 2021 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2021 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!---\\nCopyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"Wav2Vec2 Contrastive Loss PreTraining examples\\n\\nThe following example showcases how to pretrain a wa...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!---\\nCopyright 2021 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"LXMERT DEMO\\n\\n1. make a virtualenv: ``virtualenv venv`` and activate ``source venv\\u002fbin\\u002factivate``\\n2. ...\"],[\"!---\\nCopyright 2021 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"Robust Speech Challenge ğŸ¤—\\n\\nWelcome to the robust speech recognition challenge ğŸ™ï¸ !\\n\\nThe goal of this...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!---\\nCopyright 2021 The HuggingFace Team. All rights reserved.\\nLicensed under the Apache License, Ve...\"],[\"Testing mixed int8 quantization\\n\\n![HFxbitsandbytes.png](https:\\u002f\\u002fcdn-uploads.huggingface.co\\u002fproductio...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2021 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"Plug and Play Language Models: a Simple Approach to Controlled Text Generation\\n\\nAuthors: [Sumanth Da...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!---\\nCopyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!---\\nCopyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"!---\\nCopyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!---\\nCopyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!---\\nCopyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2021 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2021 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!---\\nCopyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"Self-training\\n\\nThis is an implementation of the self-training algorithm (without task augmentation) ...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"Security Policy\\n\\n## Reporting a Vulnerability\\n\\nğŸ¤— We have our bug bounty program set up with HackerOn...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2021 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2021 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2021 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2021 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!---\\nCopyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!---\\nCopyright 2021 The HuggingFace Team. All rights reserved.\\nLicensed under the Apache License, Ve...\"],[\"Patience-based Early Exit\\n\\nPatience-based Early Exit (PABEE) is a plug-and-play inference method for...\"],[\"Long Form Question Answering\\n\\nAuthor: @yjernite\\n\\nThis folder contains the code for the Long Form Que...\"],[\"!--Copyright 2021 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace and Baidu Team. All rights reserved.\\n\\nLicensed under the Apache Li...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!---\\nCopyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"!---\\nCopyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to...\"],[\"!--Copyright 2021 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"# Sequence to Sequence Training and Evaluation\\n\\nThis directory contains examples for finetuning and ...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!---\\nCopyright 2021 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"p align=\\\"center\\\"\\u003e \\u003cimg src=\\\"http:\\u002f\\u002fsayef.tech:8082\\u002fuploads\\u002fFSNER-LOGO-2.png\\\" alt=\\\"FSNER LOGO\\\"\\u003e \\u003c\\u002fp\\u003e\\n...\"],[\"!--âš ï¸ Note that this file is in Markdown but contains specific syntax for our doc-builder (similar t...\"],[\"\\u003c!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ve...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2021 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!---\\nCopyright 2021 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"!--Copyright 2021 NVIDIA Corporation and The HuggingFace Team. All rights reserved.\\n\\nLicensed under ...\"],[\"!---\\nCopyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"!---\\nCopyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"ere is how to convert a GPT2 model generated outside of `transformers`\\n\\n* [Megatron-LM](https:\\u002f\\u002fgith...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"# MM-IMDb\\n\\nBased on the script [`run_mmimdb.py`](https:\\u002f\\u002fgithub.com\\u002fhuggingface\\u002ftransformers\\u002fblob\\u002fma...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!---\\nCopyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"Intro\\n\\nAuthors: @patrickvonplaten and @lhoestq\\n\\nAimed at tackling the knowledge-intensive NLP tasks ...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2021 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"# Information Gain Filtration(IGF)\\n\\nAuthors @Tuko @mraunak\\n\\nThis folder contains the code how to imp...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!---\\nCopyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"## Saved Pseudo-Labels\\nThese are the generations of various large models on various large **training...\"],[\"!---\\nCopyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"urrently the following model proposals are available:\\n\\n- \\u003cs\\u003e[BigBird (Google)](.\\u002fADD_BIG_BIRD.md)\\u003c\\u002fs...\"],[\"!--Copyright 2021 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2021 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2021 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!---\\nCopyright 2021 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"VisualBERT Demo\\n\\nThis demo shows usage of VisualBERT VQA model and is adapted from LXMERT demo prese...\"],[\"!--Copyright 2021 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!---\\nCopyright 2021 The Google Flax Team Authors and HuggingFace Team. All rights reserved.\\n\\nLicense...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"Testing new Hugging Face Deep Learning Container.\\n\\nThis document explains the testing strategy for r...\"],[\"!--Copyright 2021 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!---\\nCopyright 2020 The HuggingFace Team. All rights reserved.\\nLicensed under the Apache License, Ve...\"],[\"!---\\nCopyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2021 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"Training a masked language model end-to-end from scratch on TPUs\\n\\nIn this example, we're going to de...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team and Microsoft. All rights reserved.\\n\\nLicensed under the MIT L...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!---\\nCopyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2021 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!---\\nCopyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2021 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!---\\nCopyright 2021 The Google Flax Team Authors and HuggingFace Team. All rights reserved.\\n\\nLicense...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!---\\nCopyright 2021 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\nLicensed under the Apache License, Vers...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2021 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"*NOTE**: This example is outdated and is not longer actively maintained. Please \\nfollow the new inst...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"ow to add BigBird to ğŸ¤— Transformers?\\n=====================================\\n\\nMentor: [Patrick](https:...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"Examples\\nIn this folder we showcase some examples to use code models for downstream tasks.\\n\\n## Compl...\"],[\"!--Copyright 2021 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"# Token classification\\n\\nBased on the scripts [`run_ner.py`](https:\\u002f\\u002fgithub.com\\u002fhuggingface\\u002ftransform...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"]],\"hovertemplate\":\"source=transformers\\u003cbr\\u003esymbol=circle\\u003cbr\\u003ex=%{x}\\u003cbr\\u003ey=%{y}\\u003cbr\\u003esize_col=%{marker.size}\\u003cbr\\u003eextract=%{customdata[0]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"transformers, circle\",\"marker\":{\"color\":\"#FFA15A\",\"size\":[4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4],\"sizemode\":\"area\",\"sizeref\":0.25,\"symbol\":\"circle\",\"line\":{\"color\":\"DarkSlateGrey\",\"width\":0},\"opacity\":1},\"mode\":\"markers\",\"name\":\"transformers, circle\",\"showlegend\":true,\"x\":[-4.229134,-6.0267353,-11.627033,-10.481632,-3.0824184,-0.9111973,-10.296753,-10.344702,-7.898052,-8.907179,-11.233556,-7.275426,-3.1508887,-4.6094136,-10.572497,-7.3779907,-5.2620173,-7.82849,-5.933611,-7.678776,-7.0634475,-9.667253,-7.431927,-2.8973591,-7.445752,-7.783742,-8.12446,-10.725961,-7.6354413,-10.669131,-7.0390687,-10.651983,-9.771788,-4.928741,-6.458426,-10.470329,-7.687667,-4.431734,-10.562832,-4.9453607,-7.818889,-10.584124,-4.729474,-10.276549,-7.9966893,-6.541163,-10.991122,-7.3392906,-7.347984,-8.00915,-10.369019,-7.6678843,-11.704294,-7.765947,-10.392329,-7.712748,-5.792218,-6.280736,-10.655283,-11.323524,-6.2816863,-8.89932,-2.879892,-4.2686777,-11.542268,-6.517937,-10.733301,-11.636001,-3.0922506,-5.232946,-4.2435966,-4.0322533,-6.1581826,-10.544891,-7.973329,-10.73378,-6.7351017,-4.4917088,-10.731602,-11.6282625,-11.051401,-9.838126,-9.504563,-6.913109,1.511725,-6.8650894,-9.03125,-11.601348,-3.8547564,-3.392289,7.1221447,-3.3872652,-8.519271,-3.2789736,-6.8434157,-8.398482,-4.752236,-10.272918,-5.801762,-7.010173,-7.138363,-6.2303715,-6.4687643,-11.718859,-7.808856,-7.122807,-6.0191727,-3.184582,-11.596092,-3.2674851,-11.122476,-7.2356367,-7.212821,-7.861945,-7.9482794,-3.961041,-6.4383373,0.9215589,-5.4111495,-6.340844,-6.2632036,-7.608675,-8.081163,-5.9300256,-3.3940792,-7.138598,-4.354767,-11.662658,-7.4316645,-3.1941066,-7.190311,-4.384361,-7.0461135,-11.441384,-7.9922285,-7.940364,-10.583443,-12.579673,-10.051871,-6.433221,-7.5260487,-7.711472,-7.9509106,6.6526704,-5.888426,0.11150639,-2.7837334,-8.354151,-4.151758,-5.8624496,-9.9429455,-7.5323205,-8.312895,-7.6118965,-8.649444,-5.525458,-5.671812,-9.956801,-7.968515,-10.648113,-8.849571,-9.043727,-3.5338733,-4.707617,-4.5462604,-5.438101,-7.8543706,-8.200526,-11.666637,-10.5763855,-6.840248,-7.9274416,-8.413636,-7.8888955,-5.168095,-5.9394255,-7.9590254,-7.7295527,-3.361408,-10.6234045,-4.3724732,-3.1490533,-10.205498,-10.59315,-7.6793346,-7.8032393,-7.1390886,-10.526518,-7.4628415,-11.406217,-8.124559,-3.8482432,-8.152398,-7.219857,-7.732832,-8.262478,-6.325978,-4.87336,-7.6572366,-4.2384505,-11.233513,-6.7944083,-6.2958817,-6.835026,-8.096929,-6.491872,-7.0084643,-8.044416,-7.385613,-4.6555576,-7.3786364,-7.0268383,-8.200501,-10.473302,-6.075029,-10.438828,-10.109237,-11.272378,-6.1811943,-6.429524,-4.03261,-4.9243975,-8.929978,-7.4795794,-7.5256023,-6.112567,-4.1130276,-6.474462,-7.246946,-10.465399,-7.5181866,-6.8876224,-10.746123,-3.8411846,-11.128993,-6.950833,-10.537912,-4.9881773,-11.216869,6.297322,-6.465552,-4.747642,-9.820021,-8.2044525,-11.612638,-6.708132,-4.258625,-7.4729605,-10.600087,-7.277939,-10.0145,-7.9266515,-6.2467275,-4.656436,-11.537007,-6.6096277,-8.204151,-7.9688463,-2.507698,-10.588826,-10.553236,-4.823139,-10.80812,-5.74301,-7.373273,-7.447604,-3.0927844,-8.319621,-7.9994884,-2.709265,-11.790411,-5.478585,-10.000986,-5.3715606,-8.287803,-5.9540186,-3.826751,-6.748057,-7.364877,-10.65956,-1.4864582,-7.4491224,-7.4958954,-7.445864,-7.1598496,-3.82856,-3.4411523,-10.3541565,-9.027615,-10.439202,-6.0933976,-5.662213,-7.3261275,-3.188756,-1.4369837,-5.92844,-6.319309,-7.7653346,-10.437933,-5.0315566,-10.474881,-5.367667,-4.6478295,-3.0302134,-3.551809,-7.4094033,-8.395363,-11.399901,-7.853296,-5.0041795,-4.5116396,-4.329159,-1.2669048,-4.4223785,-7.0339,-7.8671002,-10.720952,1.2069002,-10.562558,-6.151361,-10.169299,-3.1190372,-7.967316,-7.8299136,-11.716494,-5.3139377,-4.2606897,-11.648663,-8.13468,-10.595506,-7.966172,-2.9902816,-11.580194,-4.8414783,-6.0887027,-7.529399,-10.534401,-10.677069,-7.4327097,-7.786653,-4.6915393,-8.174858,-11.462961,-11.575403,-3.7641084,-10.137014,-2.1687887,-7.7350974,-10.547775,-11.244992,-6.3020625,-11.792337,-4.912506,-7.584118,-6.67828,-3.9084404,-5.1217456,-4.7179985,-5.9426622,-8.111301,-4.3298464,-10.596767,-4.6272364,-7.5608554,-7.3720202,-5.4300914,-7.4483757,-6.2580457,-6.492219,-5.1088943,-7.921481,-4.775631,-8.431075,-7.845077,-7.109907,-11.756486,-6.4817495,-8.215751,-7.0914855,-10.611035,-3.0468678,-7.3069086,-6.5399556,-7.377173,-4.3848577,-8.495871,-7.6163936,-7.7881155,-8.330388,-6.7182207,-3.9101164,-6.1625304,-7.5823436,-4.5723805,-11.734844,-1.5677532,-10.516566,-7.982042,-4.8401265,-10.063713,-8.020045,-9.66286,-7.5908957,-4.827005,-5.8793063,-8.21562,-8.01033,-5.0613313,-1.9139254,-11.451223,-10.56135,-10.400874,-11.146153,-10.366189,-6.474537,-4.3049355,-1.3496888,-7.917046,-4.5717573,-6.165073,-10.686089,-11.524078,-4.8585362,-5.892316,-7.5098567,-4.399165,-4.5176997,-4.1673017,-10.270758,-10.549043,-11.719586,-7.945793,-7.9847794,-3.4145567,-6.6471496,-11.802098,-8.6344595,-10.684495,-8.351007,-11.421324,-11.40666,-4.404672,-4.5540123,-11.48807,-11.6883135,-6.6254287,-7.988546,-7.5641174,-7.7448907,-7.8422375,-10.464368,-3.7546477,-6.7201724,-10.998354,-6.0198884,-6.10086,-6.636552,-10.551491,-11.475123,-7.5817585,-7.8466067,-2.1639528,-3.0370085,-4.487603,-5.400576,-5.387519,-7.50599,-7.74974,-10.680635,-11.093296,-11.1904545,-5.3526897,-7.998603,-6.2947903,-7.43407,-7.708594,-6.1196575,-3.069385,-11.017531,-8.548829,-4.4861026],\"xaxis\":\"x\",\"y\":[3.707328,5.027157,-1.2077293,0.7465466,0.8123795,4.990824,1.3845154,0.8308714,4.7954884,2.8466632,-0.5949911,6.5376525,1.330344,3.594732,3.3019054,5.52184,3.9473827,5.197289,4.855339,-1.5069481,6.860789,0.9168525,6.010463,4.7799816,3.254019,-1.0184805,5.3816643,0.28451353,-0.5667149,0.7987983,4.4067874,0.92622465,3.0472903,2.9738083,6.2611303,0.8554473,-1.2273318,4.038247,1.634088,2.9122577,5.174067,1.8311098,5.857775,1.820545,-1.5457354,4.3093877,1.3285284,6.9460263,3.4995575,-1.6150653,0.20676053,-0.80360067,-0.6476965,4.14507,1.0231228,-1.5420705,3.5796583,4.5121455,1.3038658,-0.6261453,5.1059003,2.7332916,0.64855915,4.0117407,-0.7473325,4.281008,0.21053581,-1.1467239,0.7171354,5.2995415,4.008111,4.0671515,6.6240683,3.2701519,5.0171275,0.10305258,2.5874677,2.707195,1.1212454,-1.2604622,-0.27572933,0.79479015,0.16994058,4.636934,5.8184266,5.763959,2.828778,-1.2740282,4.111328,1.3926755,-9.456866,1.5559543,4.1471567,2.1582088,3.609544,2.8780208,1.4527423,1.0014986,4.8238177,0.18154949,3.9716458,5.184341,4.3631573,-0.6707173,5.5248437,4.01279,6.174784,2.4679897,-1.1299396,1.1889089,-0.5181287,-0.34488237,3.347384,-0.9977148,5.5048766,2.4891882,6.0254354,2.200628,5.737346,4.9007597,1.9221478,4.1557574,5.4138765,3.5908718,0.20974985,4.8042746,2.8385823,-0.82529134,7.187687,0.8645337,5.068704,4.1989045,6.059042,-0.7904418,5.4138184,5.204915,0.73598176,1.7378149,8.002309,5.1946235,-1.2064838,-1.327286,-1.6193556,-10.478104,4.5970793,5.255663,4.757,5.2961936,4.0589304,3.719649,0.99436605,5.417895,4.5072246,5.7760925,5.4363513,4.573394,5.583386,0.63347906,3.9141808,1.264822,2.566982,0.94356424,2.0544732,2.5706267,2.7819152,2.5489528,5.570792,4.642147,-0.7131838,1.1145847,5.563393,5.5388174,4.458805,-0.87593865,3.5301514,2.6459877,5.6571946,3.520298,2.1238086,0.8937102,4.518895,0.577219,0.40308908,1.0951403,5.6444016,-1.43392,5.346468,2.9740813,-1.0108758,-0.812503,5.2240744,2.053542,5.6572113,5.787751,-1.5464749,-1.3536624,5.427475,6.4286995,5.9626555,3.7595878,-0.57202595,6.0005765,4.931512,0.24192867,6.45525,2.5689323,-0.9644493,-1.4499253,6.750728,4.518762,6.53953,6.0042653,5.2135196,0.51402485,1.3180243,3.0895185,0.27857795,-0.5889927,5.424267,3.9373078,3.4825778,3.4884665,2.723217,5.5284467,4.886041,4.9739685,2.335692,5.3108773,4.566755,0.8845347,-1.3769999,5.0501575,0.7241366,5.1504126,-0.4094314,5.8167257,1.1697028,2.3922615,-0.5683825,-8.978902,4.469961,3.766596,7.717041,4.605661,-1.4497347,4.6153817,4.9171,6.3076367,3.224435,-1.0892801,3.300593,-1.5336833,5.690721,2.9182434,-1.4813055,2.1393447,5.174413,3.6378694,3.1011167,3.3730369,2.6816068,3.0212357,1.284062,4.9503694,3.2684999,6.66488,0.78776395,6.0981536,5.586856,4.8107305,-0.685515,4.0427322,0.7234143,5.8590198,4.5412936,5.1768765,3.0812154,2.750013,-1.0570507,1.8052434,2.841823,5.529439,6.397046,-1.1941911,5.3388104,2.7014015,2.75999,0.7397623,6.5458727,0.26188403,6.2616024,1.3174541,5.2880297,-7.112567,1.1387514,5.0854287,1.3506415,5.135492,3.4781744,3.0951407,0.13118434,3.937547,5.034226,4.8572664,1.8706858,-0.82709837,5.126271,-0.74406147,5.6861496,6.105782,2.8368692,2.7902453,7.594219,3.8981729,-0.58161706,5.575572,0.7986852,5.926653,0.7324933,5.609268,0.55474985,-6.883768,-1.662524,5.7170515,-0.7317577,3.0481434,4.1057262,-0.5718474,-1.3903062,1.956344,5.3747287,1.1990217,-0.79351795,2.5093358,4.3107247,7.2487736,1.0310774,1.310471,6.9661746,-1.5075399,3.9278543,5.2927566,-0.91032743,-1.2067219,2.2333302,8.048536,2.9905307,-1.4666438,2.5504334,0.1743531,5.49028,-1.8568637,3.494887,-1.4174422,6.098166,4.336978,2.5836635,2.251747,2.3669844,5.382624,1.8576275,0.8037108,2.2674813,6.6590347,6.1043015,4.1604943,4.016442,4.9432673,2.6199322,3.1221013,5.534677,4.296265,2.4312468,-1.6707826,4.812485,-0.626182,2.6067288,5.5205913,6.696615,0.9735988,3.4972498,3.1137764,5.0541778,-1.0445049,2.8636484,5.253858,7.068501,4.6710587,4.2829833,5.979141,4.3382945,4.315801,-0.49917915,3.4896312,-0.5177533,3.1695564,0.5004486,-1.2701772,1.832796,8.014394,5.3825655,0.90505165,-0.97370666,3.0149856,3.9307094,4.671842,-0.8266247,3.3730462,2.8258855,-0.8076726,3.1339118,0.051788125,-0.46373916,1.6977242,5.250249,4.100943,7.5560427,-1.713121,1.4365699,5.1740985,0.99909055,-0.89268094,3.1664212,1.8604784,3.223971,3.3972428,3.7176974,4.012078,0.2975802,0.9536453,-0.68470347,5.1615963,5.3561053,2.36228,5.3466067,-2.0232391,3.619136,0.99174684,5.5290523,-0.76154065,-0.7297181,2.5626261,3.0171359,-0.84968066,-0.64859015,5.4169393,5.565225,5.873595,-1.597177,4.717152,3.2216966,1.9596958,5.3023725,-0.5629247,4.179472,5.200595,5.658357,3.308257,-0.7329644,-1.3375703,5.557588,2.4691737,3.0755098,3.6669497,6.116779,5.3400264,6.972288,-0.95911366,2.072897,-0.35278916,-0.5040652,2.635646,5.5188303,5.5003977,-0.6490371,5.625147,6.416688,5.7831097,-0.5127585,5.5294127,3.009002],\"yaxis\":\"y\",\"type\":\"scattergl\"},{\"customdata\":[[\"Git over SSH\\n\\nYou can access and write data in repositories on huggingface.co using SSH (Secure Shel...\"],[\"Using Flair at Hugging Face\\n\\n[Flair](https:\\u002f\\u002fgithub.com\\u002fflairNLP\\u002fflair) is a very simple framework f...\"],[\"Widget Examples\\n\\nNote that each widget example can also optionally describe the corresponding model ...\"],[\"Configure the Dataset Viewer\\n\\nThe Dataset Viewer supports many [data files formats](.\\u002fdatasets-addin...\"],[\"Adding a Sign-In with HF button to your Space\\n\\nYou can enable a built-in sign-in flow in your Space ...\"],[\"User access tokens\\n\\n## What are User Access Tokens?\\n\\nUser Access Tokens are the preferred way to aut...\"],[\"ZenML on Spaces\\n\\n[ZenML](https:\\u002f\\u002fgithub.com\\u002fzenml-io\\u002fzenml) is an extensible, open-source MLOps fram...\"],[\"Using Spaces for Organization Cards\\n\\nOrganization cards are a way to describe your organization to o...\"],[\"Repository Settings \\n\\n## Private repositories\\n\\nYou can choose a repository's visibility when you cre...\"],[\"--\\n# Example metadata to be added to a dataset card.  \\n# Full dataset card template at https:\\u002f\\u002fgithu...\"],[\"Repository limitations and recommendations\\n\\nThere are some limitations to be aware of when dealing w...\"],[\"Dask\\n\\n[Dask](https:\\u002f\\u002fgithub.com\\u002fdask\\u002fdask) is a parallel and distributed computing library that scal...\"],[\"Access control in organizations\\n\\n\\u003cTip\\u003e\\n\\nYou can set up [Single Sign-On (SSO)](.\\u002fsecurity-sso) to be ...\"],[\"Billing\\n\\nAt Hugging Face, we build a collaboration platform for the ML community (i.e., the Hub), an...\"],[\"Streamlit Spaces\\n\\n**Streamlit** gives users freedom to build a full-featured web app with Python in ...\"],[\"Next Steps\\n\\nThese next sections highlight features and additional information that you may find usef...\"],[\"Run with Docker\\n\\nYou can use Docker to run most Spaces locally.\\nTo view instructions to download and...\"],[\"Advanced Topics\\n\\n## Contents\\n\\n- [Using OpenCV in Spaces](.\\u002fspaces-using-opencv)\\n- [More ways to crea...\"],[\"Using spaCy at Hugging Face\\n\\n`spaCy` is a popular library for advanced Natural Language Processing u...\"],[\"Audit Logs\\n\\n\\u003cTip warning={true}\\u003e\\nThis feature is part of the \\u003ca href=\\\"https:\\u002f\\u002fhuggingface.co\\u002fenterpr...\"],[\"Spaces Overview\\n\\nHugging Face Spaces make it easy for you to create and deploy ML-powered demos in m...\"],[\"Search\\n\\nYou can now easily search anything on the Hub with **Full-text search**. We index model card...\"],[\"[paddlenlp-banner](https:\\u002f\\u002fhuggingface.co\\u002fdatasets\\u002fhuggingface\\u002fdocumentation-images\\u002fresolve\\u002fmain\\u002fhub...\"],[\"Reference\\n\\n## Deep Learning Container\\n\\nBelow you can find a version table of currently available Hug...\"],[\"Pandas\\n\\n[Pandas](https:\\u002f\\u002fgithub.com\\u002fpandas-dev\\u002fpandas) is a widely used Python data analysis toolkit...\"],[\"Datasets without language challenge\\n\\nRelated to https:\\u002f\\u002fgithub.com\\u002fhuggingface\\u002fhub-docs\\u002fissues\\u002f986.\\n...\"],[\"Advanced Topics\\n\\n## Contents\\n\\n- [Integrate your library with the Hub](.\\u002fmodels-adding-libraries)\\n- [...\"],[\"Storage Regions on the Hub\\n\\nRegions let you decide where your org's models and datasets will be stor...\"],[\"Managing Spaces with Github Actions\\n\\nYou can keep your app in sync with your GitHub repository with ...\"],[\"Webhook guide: Setup an automatic metadata quality review for models and datasets \\n\\n\\u003cTip\\u003e\\n\\nWebhooks ...\"],[\"ğŸŸ§ Label Studio on Spaces\\n\\n[Label Studio](https:\\u002f\\u002flabelstud.io) is an [open-source data labeling\\nplat...\"],[\"Webhooks\\n\\n\\u003cTip\\u003e\\n\\nWebhooks are now publicly available!\\n\\n\\u003c\\u002fTip\\u003e\\n\\nWebhooks are a foundation for MLOps-r...\"],[\"Dataset viewer\\n\\nThe dataset page includes a table with the contents of the dataset, arranged by page...\"],[\"The Model Hub\\n\\n## What is the Model Hub?\\n\\nThe Model Hub is where the members of the Hugging Face com...\"],[\"Signing commits with GPG\\n\\n`git` has an authentication layer to control who can push commits to a rep...\"],[\"Spaces Changelog\\n\\n## [2023-07-28] - Upstream Streamlit frontend for `\\u003e=1.23.0`\\n\\n- Streamlit SDK uses...\"],[\"Licenses\\n\\nYou are able to add a license to any repo that you create on the Hugging Face Hub to let o...\"],[\"Hugging Face Hub documentation\\n\\nThe Hugging Face Hub is a platform with over 350k models, 75k datase...\"],[\"Using ESPnet at Hugging Face\\n\\n`espnet` is an end-to-end toolkit for speech processing, including aut...\"],[\"Model Card components\\n\\n**Model Card Components** are special elements that you can inject directly i...\"],[\"Annotated Model Card Template\\n\\n\\n## Template\\n\\n[modelcard_template.md file](https:\\u002f\\u002fgithub.com\\u002fhugging...\"],[\"Organizations\\n\\nThe Hugging Face Hub offers **Organizations**, which can be used to group accounts an...\"],[\"Using ğŸ¤— Datasets\\n\\nOnce you've found an interesting dataset on the Hugging Face Hub, you can load the...\"],[\"Appendix\\n\\n## Appendix A: User Study\\n_Full text responses to key questions_\\n\\n### How would you define...\"],[\"Notifications\\n\\nNotifications allow you to know when new activities (Pull Requests or discussions) ha...\"],[\"How to configure SAML SSO with Azure\\n\\nIn this guide, we will use Azure as the SSO provider and with ...\"],[\"Gradio Spaces\\n\\n**Gradio** provides an easy and intuitive interface for running a model from a list o...\"],[\"Cookie limitations in Spaces\\n\\nIn Hugging Face Spaces, applications have certain limitations when usi...\"],[\"Argilla on Spaces\\n\\n**Argilla** is an open-source, data labelling tool, for highly efficient human-in...\"],[\"Using Stable-Baselines3 at Hugging Face\\n\\n`stable-baselines3` is a set of reliable implementations of...\"],[\"File names and splits\\n\\nTo host and share your dataset, create a dataset repository on the Hugging Fa...\"],[\"Integrate your library with the Hub\\n\\nThe Hugging Face Hub aims to facilitate sharing machine learnin...\"],[\"Aim on Spaces\\n\\n**Aim** is an easy-to-use & supercharged open-source experiment tracker. Aim logs you...\"],[\"# Model `license:other` challenge\\n\\nRelated to https:\\u002f\\u002fgithub.com\\u002fhuggingface\\u002fhub-docs\\u002fissues\\u002f985.\\n\\n#...\"],[\"ChatUI on Spaces\\n\\n**Hugging Chat** is an open-source interface enabling everyone to try open-source ...\"],[\"Model Cards\\n\\n\\u003cTip\\u003e\\n\\n[New! Try our experimental Model Card Creator App](https:\\u002f\\u002fhuggingface.co\\u002fspaces...\"],[\"Uploading datasets\\n\\nThe [Hub](https:\\u002f\\u002fhuggingface.co\\u002fdatasets) is home to an extensive collection of...\"],[\"WebDataset\\n\\n[WebDataset](https:\\u002f\\u002fgithub.com\\u002fwebdataset\\u002fwebdataset) is a library to write I\\u002fO pipelin...\"],[\"Pull requests and Discussions\\n\\nHub Pull requests and Discussions allow users to do community contrib...\"],[\"Using fastai at Hugging Face\\n\\n`fastai` is an open-source Deep Learning library that leverages PyTorc...\"],[\"Using SpeechBrain at Hugging Face\\n\\n`speechbrain` is an open-source and all-in-one conversational too...\"],[\"Model Card Guidebook \\n\\nModel cards are an important documentation and transparency framework for mac...\"],[\"Models Frequently Asked Questions\\n\\n## How can I see what dataset was used to train the model?\\n\\nIt's ...\"],[\"Using OpenCLIP at Hugging Face\\n\\n[OpenCLIP](https:\\u002f\\u002fgithub.com\\u002fmlfoundations\\u002fopen_clip) is an open-so...\"],[\"Libraries\\n\\nThe Datasets Hub has support for several libraries in the Open Source ecosystem.\\nThanks t...\"],[\"Using Stanza at Hugging Face\\n\\n`stanza` is a collection of accurate and efficient tools for the lingu...\"],[\"Panel on Spaces\\n\\n[Panel](https:\\u002f\\u002fpanel.holoviz.org\\u002f) is an open-source Python library that lets you ...\"],[\"User Studies\\n## Model Card Audiences and Use Cases\\n\\nDuring our investigation into the landscape of m...\"],[\"Docker Spaces Examples\\n\\nWe gathered some example demos in the [Spaces Examples](https:\\u002f\\u002fhuggingface....\"],[\"Datasets\\n\\nThe Hugging Face Hub is home to a growing collection of datasets that span a variety of do...\"],[\"Using GPU Spaces\\n\\nYou can upgrade your Space to use a GPU accelerator using the _Settings_ button in...\"],[\"How to Add a Space to ArXiv\\n\\nDemos on Hugging Face Spaces allow a wide audience to try out state-of-...\"],[\"Datasets Overview\\n\\n## Datasets on the Hub\\n\\nThe Hugging Face Hub hosts a [large number of community-c...\"],[\"Using AllenNLP at Hugging Face\\n\\n`allennlp` is a NLP library for developing state-of-the-art models o...\"],[\"Webhook guide: Setup an automatic system to re-train a model when a dataset changes\\n\\n\\u003cTip\\u003e\\n\\nWebhooks...\"],[\"Downloading models\\n\\n## Integrated libraries\\n\\nIf a model on the Hub is tied to a [supported library](...\"],[\"Getting Started with Repositories\\n\\nThis beginner-friendly guide will help you get the basic skills y...\"],[\"Embed your Space in another website\\n\\nOnce your Space is up and running you might wish to embed it in...\"],[\"Tabby on Spaces\\n\\n[Tabby](https:\\u002f\\u002ftabby.tabbyml.com) is an open-source, self-hosted AI coding assista...\"],[\"Data files Configuration\\n\\nThere are no constraints on how to structure dataset repositories.\\n\\nHoweve...\"],[\"Single Sign-On (SSO)\\n\\n\\u003cTip warning={true}\\u003e\\nThis feature is part of the \\u003ca href=\\\"https:\\u002f\\u002fhuggingface....\"],[\"Models\\n\\nThe Hugging Face Hub hosts many models for a [variety of machine learning tasks](https:\\u002f\\u002fhug...\"],[\"Using Asteroid at Hugging Face\\n\\n`asteroid` is a Pytorch toolkit for audio source separation. It enab...\"],[\"Models Download Stats\\n\\n## How are download stats generated for models?\\n\\nCounting the number of downl...\"],[\"Using RL-Baselines3-Zoo at Hugging Face\\n\\n`rl-baselines3-zoo` is a training framework for Reinforceme...\"],[\"Using OpenCV in Spaces\\n\\nIn order to use OpenCV in your Gradio or Streamlit Spaces, you'll need to ma...\"],[\"Uploading models\\n\\nTo upload models to the Hub, you'll need to create an account at [Hugging Face](ht...\"],[\"Digital Object Identifier (DOI)\\n\\nThe Hugging Face Hub offers the possibility to generate DOI for you...\"],[\"Secrets Scanning\\n\\nIt is important to manage [your secrets (env variables) properly](.\\u002fspaces-overvie...\"],[\"Downloading datasets\\n\\n## Integrated libraries\\n\\nIf a dataset on the Hub is tied to a [supported libra...\"],[\"Handling Spaces Dependencies\\n\\n## Default dependencies\\n\\nThe default Spaces environment comes with sev...\"],[\"Inference API\\n\\nPlease refer to [Inference API Documentation](https:\\u002f\\u002fhuggingface.co\\u002fdocs\\u002fapi-inferen...\"],[\"Enterprise Hub\\n\\nEnterprise Hub adds advanced capabilities to organizations, enabling safe, compliant...\"],[\"How to configure SAML SSO with Okta\\n\\nIn this guide, we will use Okta as the SSO provider and with th...\"],[\"Using ğŸ§¨ `diffusers` at Hugging Face\\n\\nDiffusers is the go-to library for state-of-the-art pretrained ...\"],[\"Security\\n\\nThe Hugging Face Hub offers several security features to ensure that your code and data ar...\"],[\"Using SpanMarker at Hugging Face\\n\\n[SpanMarker](https:\\u002f\\u002fgithub.com\\u002ftomaarsen\\u002fSpanMarkerNER) is a fram...\"],[\"Disk usage on Spaces\\n\\nEvery Space comes with a small amount of disk storage. This disk space is ephe...\"],[\"Hugging Face on Amazon SageMaker\\n\\n![cover](https:\\u002f\\u002fhuggingface.co\\u002fdatasets\\u002fhuggingface\\u002fdocumentation...\"],[\"Hub API Endpoints\\n\\nWe have open endpoints that you can use to retrieve information from the Hub as w...\"],[\"Displaying carbon emissions for your model\\n\\n## Why is it beneficial to calculate the carbon emission...\"],[\"Train and deploy Hugging Face on Amazon SageMaker\\n\\nThe get started guide will show you how to quickl...\"],[\"Dataset Cards\\n\\n## What are Dataset Cards?\\n\\nEach dataset may be documented by the `README.md` file in...\"],[\"Using sample-factory at Hugging Face\\n\\n[`sample-factory`](https:\\u002f\\u002fgithub.com\\u002falex-petrenko\\u002fsample-fac...\"],[\"hub-docs\\n\\nThis repository regroups documentation and information that is hosted on the Hugging Face ...\"],[\"Datasets Download Stats\\n\\n## How are download stats generated for datasets?\\n\\nThe Hub provides downloa...\"],[\"Using TensorBoard\\n\\nTensorBoard provides tooling for tracking and visualizing metrics as well as visu...\"],[\"Organizations, Security, and the Hub API\\n\\n## Contents\\n\\n- [Organizations](.\\u002forganizations)\\n  - [Manag...\"],[\"Using timm at Hugging Face\\n\\n`timm`, also known as [pytorch-image-models](https:\\u002f\\u002fgithub.com\\u002frwightma...\"],[\"Image Dataset\\n\\nThis guide will show you how to configure your dataset repository with image files. Y...\"],[\"Deploy models to Amazon SageMaker\\n\\nDeploying a ğŸ¤— Transformers models in SageMaker for inference is a...\"],[\"Single Sign-On (SSO)\\n\\nThe Hugging Face Hub gives you the ability to implement mandatory Single Sign-...\"],[\"Spaces Configuration Reference\\n\\nSpaces are configured through the `YAML` block at the top of the **R...\"],[\"Spaces Settings\\n\\nYou can configure your Space's appearance and other settings inside the `YAML` bloc...\"],[\"Your First Docker Space: Text Generation with T5\\n\\nIn the following sections, you'll learn the basics...\"],[\"Using Sentence Transformers at Hugging Face\\n\\n`sentence-transformers` is a library that provides easy...\"],[\"How to configure OIDC SSO with Okta\\n\\nIn this guide, we will use Okta as the SSO provider and with th...\"],[\"Repositories\\n\\nModels, Spaces, and Datasets are hosted on the Hugging Face Hub as [Git repositories](...\"],[\"Malware Scanning\\n\\nWe run every file of your repositories through a [malware scanner](https:\\u002f\\u002fwww.cla...\"],[\"Managing Spaces with CircleCI Workflows\\n\\nYou can keep your app in sync with your GitHub repository w...\"],[\"Docker Spaces\\n\\nSpaces accommodate custom [Docker containers](https:\\u002f\\u002fdocs.docker.com\\u002fget-started\\u002f) f...\"],[\"Webhook guide: build a Discussion bot based on BLOOM\\n\\n\\u003cTip\\u003e\\n\\nWebhooks are now publicly available!\\n\\n\\u003c...\"],[\"Sign in with Hugging Face\\n\\nYou can use the HF OAuth \\u002f OpenID connect flow to create a **\\\"Sign in wit...\"],[\"Using `Transformers.js` at Hugging Face\\n\\nTransformers.js is a JavaScript library for running ğŸ¤— Trans...\"],[\"Using SetFit with Hugging Face\\n\\nSetFit is an efficient and prompt-free framework for few-shot fine-t...\"],[\"Spaces\\n\\n[Hugging Face Spaces](https:\\u002f\\u002fhuggingface.co\\u002fspaces) offer a simple way to host ML demo apps...\"],[\"Using Adapter Transformers at Hugging Face\\n\\n`adapter-transformers` is a library that extends ğŸ¤— `tran...\"],[\"Using PEFT at Hugging Face\\n\\nğŸ¤— [Parameter-Efficient Fine-Tuning (PEFT)](https:\\u002f\\u002fhuggingface.co\\u002fdocs\\u002fp...\"],[\"Organization cards\\n\\nYou can create an organization card to help users learn more about what your org...\"],[\"Libraries\\n\\nThe Hub has support for dozens of libraries in the Open Source ecosystem. Thanks to the `...\"],[\"Gated models\\n\\nTo give more control over how models are used, the Hub allows model authors to enable ...\"],[\"Gated datasets\\n\\nTo give more control over how datasets are used, the Hub allows datasets authors to ...\"],[\"Custom Python Spaces\\n\\n\\u003cTip\\u003e\\n\\nSpaces now support arbitrary Dockerfiles so you can host any Python app...\"],[\"Paper Pages\\n\\nPaper pages allow people to find artifacts related to a paper such as models, datasets ...\"],[\"DuckDB\\n\\n[DuckDB](https:\\u002f\\u002fgithub.com\\u002fduckdb\\u002fduckdb) is an in-process SQL [OLAP](https:\\u002f\\u002fen.wikipedia....\"],[\"More ways to create Spaces\\n\\n## Duplicating a Space\\n\\nYou can duplicate a Space by clicking the three ...\"],[\"Shiny on Spaces\\n\\n[Shiny](https:\\u002f\\u002fshiny.posit.co\\u002f) is an open-source framework for building simple, b...\"],[\"Using ML-Agents at Hugging Face\\n\\n`ml-agents` is an open-source toolkit that enables games and simula...\"],[\"--\\n# Example metadata to be added to a model card.  \\n# Full model card template at https:\\u002f\\u002fgithub.co...\"],[\"Using ğŸ¤— `transformers` at Hugging Face\\n\\nğŸ¤— `transformers` is a library maintained by Hugging Face and...\"],[\"THE LANDSCAPE OF ML DOCUMENTATION TOOLS\\nThe development of the model cards framework in 2018 was ins...\"],[\"Using Keras at Hugging Face\\n\\n`keras` is an open-source machine learning library that uses a consiste...\"],[\"Widgets\\n\\n## What's a widget?\\n\\nMany model repos have a widget that allows anyone to run inferences di...\"],[\"No-license models challenge\\n\\n## Context\\n\\nThe Hugging Face Hub hosts hundreds of thousands of public ...\"],[\"Manual Configuration\\n\\nThis guide will show you how to configure a custom structure for your dataset ...\"],[\"Static HTML Spaces\\n\\nSpaces also accommodate custom HTML for your app instead of using Streamlit or G...\"],[\"Tasks\\n\\n## What's a task?\\n\\nTasks, or pipeline types, describe the \\\"shape\\\" of each model's API (inputs...\"],[\"Collections\\n\\nUse Collections to group repositories from the Hub (Models, Datasets, Spaces and Papers...\"],[\"Run training on Amazon SageMaker\\n\\n\\u003ciframe width=\\\"700\\\" height=\\\"394\\\" src=\\\"https:\\u002f\\u002fwww.youtube.com\\u002fembe...\"],[\"Managing organizations\\n\\n## Creating an organization\\n\\nVisit the [New Organization](https:\\u002f\\u002fhf.co\\u002forga...\"],[\"Pickle Scanning\\n\\nPickle is a widely used serialization format in ML. Most notably, it is the default...\"],[\"Moderation\\n\\n\\u003cTip\\u003e\\n\\nCheck out the [Code of Conduct](https:\\u002f\\u002fhuggingface.co\\u002fcode-of-conduct) and the [...\"],[\"Livebook on Spaces\\n\\n**Livebook** is an open-source tool for writing interactive code notebooks in [E...\"]],\"hovertemplate\":\"source=hub-docs\\u003cbr\\u003esymbol=circle\\u003cbr\\u003ex=%{x}\\u003cbr\\u003ey=%{y}\\u003cbr\\u003esize_col=%{marker.size}\\u003cbr\\u003eextract=%{customdata[0]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"hub-docs, circle\",\"marker\":{\"color\":\"#19d3f3\",\"size\":[4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4],\"sizemode\":\"area\",\"sizeref\":0.25,\"symbol\":\"circle\",\"line\":{\"color\":\"DarkSlateGrey\",\"width\":0},\"opacity\":1},\"mode\":\"markers\",\"name\":\"hub-docs, circle\",\"showlegend\":true,\"x\":[1.6235605,-2.9876049,-5.614876,1.534848,2.5322707,1.1298436,2.9841478,1.6290185,1.4849886,0.545377,1.8450611,2.0226011,1.5039519,0.08242349,3.4228473,1.3049319,3.155075,3.4287605,-2.1829832,1.302328,3.2617664,0.44052932,-1.8655133,-1.2297945,2.06287,0.026123265,0.0129058,1.3866204,2.8280141,0.62462926,3.374085,1.6762801,1.2141124,-0.4189396,1.9606012,3.343767,0.21906047,-0.7120723,-6.9949627,-0.21201466,-0.34180477,1.3616863,1.5947766,-0.53385615,1.533475,1.2765992,16.19628,3.2846286,3.3244476,-2.6808584,1.4475527,-0.32034037,3.274123,-0.08363651,2.8632882,-0.38568434,1.5007508,1.8467156,1.2140096,-1.6823909,-7.156987,-0.5209855,-0.23409611,-1.2864026,1.6402683,-3.6920106,3.2901485,-0.46603787,3.356083,1.5090272,2.9925928,2.9753582,1.4154812,-2.2887976,0.77998257,-0.32745218,1.205116,3.2628102,3.117878,1.3900293,1.6051235,-0.37926683,-0.4418094,-0.05936884,-2.7641702,16.768923,0.017300954,-0.07825511,1.00198,1.7839226,3.2316334,-0.78634447,1.5283664,1.4582374,-14.363555,1.2409699,-3.7090268,2.724329,-1.4219469,1.2875944,-1.7553822,-1.2455388,0.7687424,-2.7146292,0.28309783,1.4904083,-2.222325,1.6560699,-2.1716523,1.2694114,-1.2930276,1.4370522,3.2686944,3.3191268,3.340502,-4.067463,1.7274834,1.375437,1.1149626,2.9741328,3.4166708,1.4320841,1.2609261,-4.189639,-7.1006975,3.362054,-4.789105,-6.309409,1.0804098,-0.2466266,0.5158649,1.157647,3.4919395,0.43920255,2.2151048,3.3865693,3.3945293,-2.8292634,-0.09556707,-4.367669,-0.755748,-1.7478852,-2.5392737,-0.022877906,1.4546902,3.385585,-0.51012915,1.0521457,-1.2030104,1.2433044,-1.5426947,1.2597421,3.1834683],\"xaxis\":\"x\",\"y\":[5.936774,5.6604004,6.8669724,2.137891,5.9207354,5.9587674,5.5895977,5.3195586,5.4841285,4.3776164,5.3148413,2.8189611,6.170923,6.5038195,5.8088217,5.2344394,5.8708167,5.7919164,5.496575,6.001193,5.8498755,5.0170712,5.670492,7.5738373,2.594622,4.2651343,5.2502666,5.2488017,5.7788363,4.8337708,5.828895,5.0812006,2.72009,5.206409,5.6584973,5.7813,5.563324,4.935431,-0.7026186,5.092057,5.165076,6.144876,3.2619863,5.101891,5.34868,6.6655426,-0.5002276,5.873276,5.804369,-5.5949674,2.338385,4.8298826,5.7654467,5.15948,5.867735,5.176868,3.2936182,2.99016,4.910513,4.9067287,-0.7801138,5.149676,5.313579,5.1904507,3.1227076,5.7085876,5.8182487,5.2102585,5.8631396,3.3326523,6.0695376,5.798986,3.5657468,5.59866,4.606101,5.197107,5.131304,5.861645,5.790299,2.214598,6.4035153,5.3582993,5.55299,4.542951,-6.082734,-1.3292598,5.453258,5.372685,5.1732974,3.140767,5.8501883,6.862218,6.027281,6.607568,-6.4766817,6.1980867,5.5950856,5.6929307,7.5821123,4.9707084,4.205312,7.599687,4.4729934,-5.6989927,4.283579,3.196732,3.2621007,5.816037,3.701729,2.3258142,7.645804,6.3384256,5.8127494,5.866688,5.8956785,4.7261305,6.353024,5.336196,5.646091,5.7144074,5.890262,5.03098,6.410961,3.517007,3.6272223,5.849019,3.4002726,1.8593413,5.4966655,4.9668727,5.3026986,4.409609,5.886729,5.490929,2.9112008,5.874456,5.813102,-5.684418,5.056381,3.7456133,5.149374,4.6679277,5.6620545,5.2109265,2.0499525,5.885077,5.894732,5.018605,7.663485,5.887631,2.742183,5.5407734,5.7479296],\"yaxis\":\"y\",\"type\":\"scattergl\"},{\"customdata\":[[\"SE-ResNet\\n\\n**SE ResNet** is a variant of a [ResNet](https:\\u002f\\u002fwww.paperswithcode.com\\u002fmethod\\u002fresnet) th...\"],[\"Res2Net\\n\\n**Res2Net** is an image model that employs a variation on bottleneck residual blocks, [Res2...\"],[\"# Ensemble Adversarial Inception ResNet v2\\n\\n**Inception-ResNet-v2** is a convolutional neural archit...\"],[\"TResNet\\n\\nA **TResNet** is a variant on a [ResNet](https:\\u002f\\u002fpaperswithcode.com\\u002fmethod\\u002fresnet) that aim...\"],[\"SE-ResNet\\n\\n**SE ResNet** is a variant of a [ResNet](https:\\u002f\\u002fwww.paperswithcode.com\\u002fmethod\\u002fresnet) th...\"],[\"CSP-ResNeXt\\n\\n**CSPResNeXt** is a convolutional neural network where we apply the Cross Stage Partial...\"],[\"RexNet\\n\\n**Rank Expansion Networks** (ReXNets) follow a set of new design principles for designing bo...\"],[\"RegNetY\\n\\n**RegNetY** is a convolutional network design space with simple, regular models with parame...\"],[\"Feature Extraction\\n\\nAll of the models in `timm` have consistent mechanisms for obtaining various typ...\"],[\"Wide ResNet\\n\\n**Wide Residual Networks** are a variant on [ResNets](https:\\u002f\\u002fpaperswithcode.com\\u002fmethod...\"],[\"Res2NeXt\\n\\n**Res2NeXt** is an image model that employs a variation on [ResNeXt](https:\\u002f\\u002fpaperswithcod...\"],[\"RegNetY\\n\\n**RegNetY** is a convolutional network design space with simple, regular models with parame...\"],[\"Archived Changes\\n\\n### Nov 22, 2021\\n* A number of updated weights anew new model defs\\n  * `eca_halone...\"],[\"(Tensorflow) EfficientNet CondConv\\n\\n**EfficientNet** is a convolutional neural network architecture ...\"],[\"SWSL ResNeXt\\n\\nA **ResNeXt** repeats a [building block](https:\\u002f\\u002fpaperswithcode.com\\u002fmethod\\u002fresnext-blo...\"],[\"Model Summaries\\n\\nThe model architectures included come from a wide variety of sources. Sources, incl...\"],[\"(Tensorflow) MobileNet v3\\n\\n**MobileNetV3** is a convolutional neural network that is designed for mo...\"],[\"Sharing and Loading Models From the Hugging Face Hub\\n\\nThe `timm` library has a built-in integration ...\"],[\"Big Transfer (BiT)\\n\\n**Big Transfer (BiT)** is a type of pretraining recipe that pre-trains  on a lar...\"],[\"MobileNet v2\\n\\n**MobileNetV2** is a convolutional neural network architecture that seeks to perform w...\"],[\"EfficientNet (Knapsack Pruned)\\n\\n**EfficientNet** is a convolutional neural network architecture and ...\"],[\"(Tensorflow) Inception v3\\n\\n**Inception v3** is a convolutional neural network architecture from the ...\"],[\"DenseNet\\n\\n**DenseNet** is a type of convolutional neural network that utilises dense connections bet...\"],[\"Training Examples\\n\\n## EfficientNet-B2 with RandAugment - 80.4 top-1, 95.1 top-5\\nThese params are for...\"],[\"MnasNet\\n\\n**MnasNet** is a type of convolutional neural network optimized for mobile devices that is ...\"],[\"SK-ResNet\\n\\n**SK ResNet** is a variant of a [ResNet](https:\\u002f\\u002fwww.paperswithcode.com\\u002fmethod\\u002fresnet) th...\"],[\"Inception v4\\n\\n**Inception-v4** is a convolutional neural network architecture that builds on previou...\"],[\"CSP-ResNeXt\\n\\n**CSPResNeXt** is a convolutional neural network where we apply the Cross Stage Partial...\"],[\"MnasNet\\n\\n**MnasNet** is a type of convolutional neural network optimized for mobile devices that is ...\"],[\"NASNet\\n\\n**NASNet** is a type of convolutional neural network discovered through neural architecture ...\"],[\"SelecSLS\\n\\n**SelecSLS** uses novel selective long and short range skip connections to improve the inf...\"],[\"MixNet\\n\\n**MixNet** is a type of convolutional neural network discovered via AutoML that utilises [Mi...\"],[\"DenseNet\\n\\n**DenseNet** is a type of convolutional neural network that utilises dense connections bet...\"],[\"SK-ResNeXt\\n\\n**SK ResNeXt** is a variant of a [ResNeXt](https:\\u002f\\u002fwww.paperswithcode.com\\u002fmethod\\u002fresnext...\"],[\"Recent Changes\\n\\n### Aug 29, 2022\\n* MaxVit window size scales with img_size by default. Add new RelPo...\"],[\"Hugging Face Timm Docs\\n\\n## Getting Started\\n\\n```\\npip install git+https:\\u002f\\u002fgithub.com\\u002fhuggingface\\u002fdoc-b...\"],[\"ResNeSt\\n\\nA **ResNeSt** is a variant on a [ResNet](https:\\u002f\\u002fpaperswithcode.com\\u002fmethod\\u002fresnet), which i...\"],[\"FBNet\\n\\n**FBNet** is a type of convolutional neural architectures discovered through [DNAS](https:\\u002f\\u002fp...\"],[\"HRNet\\n\\n**HRNet**, or **High-Resolution Net**, is a general purpose convolutional neural network for ...\"],[\"Learning Rate Schedulers\\n\\nThis page contains the API reference documentation for learning rate sched...\"],[\"MobileNet v3\\n\\n**MobileNetV3** is a convolutional neural network that is designed for mobile phone CP...\"],[\"ResNet\\n\\n**Residual Networks**, or **ResNets**, learn residual functions with reference to the layer ...\"],[\"SK-ResNet\\n\\n**SK ResNet** is a variant of a [ResNet](https:\\u002f\\u002fwww.paperswithcode.com\\u002fmethod\\u002fresnet) th...\"],[\"SelecSLS\\n\\n**SelecSLS** uses novel selective long and short range skip connections to improve the inf...\"],[\"PNASNet\\n\\n**Progressive Neural Architecture Search**, or **PNAS**, is a method for learning the struc...\"],[\"(Tensorflow) EfficientNet CondConv\\n\\n**EfficientNet** is a convolutional neural network architecture ...\"],[\"ECA-ResNet\\n\\nAn **ECA ResNet** is a variant on a [ResNet](https:\\u002f\\u002fpaperswithcode.com\\u002fmethod\\u002fresnet) t...\"],[\"Validation and Benchmark Results\\n\\nThis folder contains validation and benchmark results for the mode...\"],[\"Results\\n\\nCSV files containing an ImageNet-1K and out-of-distribution (OOD) test set validation resul...\"],[\"Inception v3\\n\\n**Inception v3** is a convolutional neural network architecture from the Inception fam...\"],[\"CSP-DarkNet\\n\\n**CSPDarknet53** is a convolutional neural network and backbone for object detection th...\"],[\"SPNASNet\\n\\n**Single-Path NAS** is a novel differentiable NAS method for designing hardware-efficient ...\"],[\"Wide ResNet\\n\\n**Wide Residual Networks** are a variant on [ResNets](https:\\u002f\\u002fpaperswithcode.com\\u002fmethod...\"],[\"SSL ResNeXT\\n\\nA **ResNeXt** repeats a [building block](https:\\u002f\\u002fpaperswithcode.com\\u002fmethod\\u002fresnext-bloc...\"],[\"RegNetX\\n\\n**RegNetX** is a convolutional network design space with simple, regular models with parame...\"],[\"Installation\\n\\nBefore you start, you'll need to setup your environment and install the appropriate pa...\"],[\"(Tensorflow) MobileNet v3\\n\\n**MobileNetV3** is a convolutional neural network that is designed for mo...\"],[\"Big Transfer (BiT)\\n\\n**Big Transfer (BiT)** is a type of pretraining recipe that pre-trains  on a lar...\"],[\"Instagram ResNeXt WSL\\n\\nA **ResNeXt** repeats a [building block](https:\\u002f\\u002fpaperswithcode.com\\u002fmethod\\u002fre...\"],[\"(Gluon) Xception\\n\\n**Xception** is a convolutional neural network architecture that relies solely on ...\"],[\"This guideline is very much a work-in-progress.*\\n\\nContributions to `timm` for code, documentation, t...\"],[\"Deep Layer Aggregation\\n\\nExtending  â€œshallowâ€ skip connections, **Dense Layer Aggregation (DLA)** inc...\"],[\"Data\\n\\n[[autodoc]] timm.data.create_dataset\\n\\n[[autodoc]] timm.data.create_loader\\n\\n[[autodoc]] timm.da...\"],[\"CSP-ResNet\\n\\n**CSPResNet** is a convolutional neural network where we apply the Cross Stage Partial N...\"],[\"Inception v3\\n\\n**Inception v3** is a convolutional neural network architecture from the Inception fam...\"],[\"Getting Started\\n\\n## Welcome\\n\\nWelcome to the `timm` documentation, a lean set of docs that covers the...\"],[\"Model Summaries\\n\\nThe model architectures included come from a wide variety of sources. Sources, incl...\"],[\"Deep Layer Aggregation\\n\\nExtending  â€œshallowâ€ skip connections, **Dense Layer Aggregation (DLA)** inc...\"],[\"Feature Extraction\\n\\nAll of the models in `timm` have consistent mechanisms for obtaining various typ...\"],[\"(Gluon) ResNet\\n\\n**Residual Networks**, or **ResNets**, learn residual functions with reference to th...\"],[\"Adversarial Inception v3\\n\\n**Inception v3** is a convolutional neural network architecture from the I...\"],[\"ResNet-D\\n\\n**ResNet-D** is a modification on the [ResNet](https:\\u002f\\u002fpaperswithcode.com\\u002fmethod\\u002fresnet) a...\"],[\"(Tensorflow) EfficientNet Lite\\n\\n**EfficientNet** is a convolutional neural network architecture and ...\"],[\"CSP-DarkNet\\n\\n**CSPDarknet53** is a convolutional neural network and backbone for object detection th...\"],[\"EfficientNet\\n\\n**EfficientNet** is a convolutional neural network architecture and scaling method tha...\"],[\"timm\\n\\n\\u003cimg class=\\\"float-left !m-0 !border-0 !dark:border-0 !shadow-none !max-w-lg w-[150px]\\\" src=\\\"ht...\"],[\"Scripts\\nA train, validation, inference, and checkpoint cleaning script included in the github root f...\"],[\"(Legacy) SE-ResNeXt\\n\\n**SE ResNeXt** is a variant of a [ResNeXt](https:\\u002f\\u002fwww.paperswithcode.com\\u002fmetho...\"],[\"RexNet\\n\\n**Rank Expansion Networks** (ReXNets) follow a set of new design principles for designing bo...\"],[\"MixNet\\n\\n**MixNet** is a type of convolutional neural network discovered via AutoML that utilises [Mi...\"],[\"(Gluon) SE-ResNeXt\\n\\n**SE ResNeXt** is a variant of a [ResNext](https:\\u002f\\u002fwww.paperswithcode.com\\u002fmethod...\"],[\"RegNetX\\n\\n**RegNetX** is a convolutional network design space with simple, regular models with parame...\"],[\"(Tensorflow) EfficientNet\\n\\n**EfficientNet** is a convolutional neural network architecture and scali...\"],[\"(Legacy) SE-ResNet\\n\\n**SE ResNet** is a variant of a [ResNet](https:\\u002f\\u002fwww.paperswithcode.com\\u002fmethod\\u002fr...\"],[\"Inception ResNet v2\\n\\n**Inception-ResNet-v2** is a convolutional neural architecture that builds on t...\"],[\"(Gluon) Inception v3\\n\\n**Inception v3** is a convolutional neural network architecture from the Incep...\"],[\"(Legacy) SENet\\n\\nA **SENet** is a convolutional neural network architecture that employs [squeeze-and...\"],[\"Quickstart\\n\\nThis quickstart is intended for developers who are ready to dive into the code and see a...\"],[\"Optimization\\n\\nThis page contains the API reference documentation for learning rate optimizers includ...\"],[\"SE-ResNeXt\\n\\n**SE ResNeXt** is a variant of a [ResNext](https:\\u002f\\u002fwww.paperswithcode.com\\u002fmethod\\u002fresneXt...\"],[\"SWSL ResNet\\n\\n**Residual Networks**, or **ResNets**, learn residual functions with reference to the l...\"],[\"FBNet\\n\\n**FBNet** is a type of convolutional neural architectures discovered through [DNAS](https:\\u002f\\u002fp...\"],[\"Dual Path Network (DPN)\\n\\nA **Dual Path Network (DPN)** is a convolutional neural network which prese...\"],[\"(Tensorflow) MixNet\\n\\n**MixNet** is a type of convolutional neural network discovered via AutoML that...\"],[\"Inception ResNet v2\\n\\n**Inception-ResNet-v2** is a convolutional neural architecture that builds on t...\"],[\"(Gluon) SE-ResNeXt\\n\\n**SE ResNeXt** is a variant of a [ResNext](https:\\u002f\\u002fwww.paperswithcode.com\\u002fmethod...\"],[\"(Tensorflow) Inception v3\\n\\n**Inception v3** is a convolutional neural network architecture from the ...\"],[\"SK-ResNeXt\\n\\n**SK ResNeXt** is a variant of a [ResNeXt](https:\\u002f\\u002fwww.paperswithcode.com\\u002fmethod\\u002fresnext...\"],[\"HRNet\\n\\n**HRNet**, or **High-Resolution Net**, is a general purpose convolutional neural network for ...\"],[\"(Legacy) SE-ResNeXt\\n\\n**SE ResNeXt** is a variant of a [ResNeXt](https:\\u002f\\u002fwww.paperswithcode.com\\u002fmetho...\"],[\"SE-ResNeXt\\n\\n**SE ResNeXt** is a variant of a [ResNext](https:\\u002f\\u002fwww.paperswithcode.com\\u002fmethod\\u002fresneXt...\"],[\"(Legacy) SE-ResNet\\n\\n**SE ResNet** is a variant of a [ResNet](https:\\u002f\\u002fwww.paperswithcode.com\\u002fmethod\\u002fr...\"],[\"EfficientNet\\n\\n**EfficientNet** is a convolutional neural network architecture and scaling method tha...\"],[\"Res2NeXt\\n\\n**Res2NeXt** is an image model that employs a variation on [ResNeXt](https:\\u002f\\u002fpaperswithcod...\"],[\"ECA-ResNet\\n\\nAn **ECA ResNet** is a variant on a [ResNet](https:\\u002f\\u002fpaperswithcode.com\\u002fmethod\\u002fresnet) t...\"],[\"Instagram ResNeXt WSL\\n\\nA **ResNeXt** repeats a [building block](https:\\u002f\\u002fpaperswithcode.com\\u002fmethod\\u002fre...\"],[\"Res2Net\\n\\n**Res2Net** is an image model that employs a variation on bottleneck residual blocks, [Res2...\"],[\"Scripts\\n\\nA train, validation, inference, and checkpoint cleaning script included in the github root ...\"],[\"ResNeSt\\n\\nA **ResNeSt** is a variant on a [ResNet](https:\\u002f\\u002fpaperswithcode.com\\u002fmethod\\u002fresnet), which i...\"],[\"ResNet\\n\\n**Residual Networks**, or **ResNets**, learn residual functions with reference to the layer ...\"],[\"NASNet\\n\\n**NASNet** is a type of convolutional neural network discovered through neural architecture ...\"],[\"(Gluon) Inception v3\\n\\n**Inception v3** is a convolutional neural network architecture from the Incep...\"],[\"(Gluon) SENet\\n\\nA **SENet** is a convolutional neural network architecture that employs [squeeze-and-...\"],[\"Vision Transformer (ViT)\\n\\nThe **Vision Transformer** is a model for image classification that employ...\"],[\"ResNet-D\\n\\n**ResNet-D** is a modification on the [ResNet](https:\\u002f\\u002fpaperswithcode.com\\u002fmethod\\u002fresnet) a...\"],[\"PNASNet\\n\\n**Progressive Neural Architecture Search**, or **PNAS**, is a method for learning the struc...\"],[\"AdvProp (EfficientNet)\\n\\n**AdvProp** is an adversarial training scheme which treats adversarial examp...\"],[\"MobileNet v2\\n\\n**MobileNetV2** is a convolutional neural network architecture that seeks to perform w...\"],[\"TResNet\\n\\nA **TResNet** is a variant on a [ResNet](https:\\u002f\\u002fpaperswithcode.com\\u002fmethod\\u002fresnet) that aim...\"],[\"ESE-VoVNet\\n\\n**VoVNet** is a convolutional neural network that seeks to make [DenseNet](https:\\u002f\\u002fpaper...\"],[\"CSP-ResNet\\n\\n**CSPResNet** is a convolutional neural network where we apply the Cross Stage Partial N...\"],[\"AdvProp (EfficientNet)\\n\\n**AdvProp** is an adversarial training scheme which treats adversarial examp...\"],[\"(Legacy) SENet\\n\\nA **SENet** is a convolutional neural network architecture that employs [squeeze-and...\"],[\"(Gluon) SENet\\n\\nA **SENet** is a convolutional neural network architecture that employs [squeeze-and-...\"],[\"SWSL ResNeXt\\n\\nA **ResNeXt** repeats a [building block](https:\\u002f\\u002fpaperswithcode.com\\u002fmethod\\u002fresnext-blo...\"],[\"ResNeXt\\n\\nA **ResNeXt** repeats a [building block](https:\\u002f\\u002fpaperswithcode.com\\u002fmethod\\u002fresnext-block) t...\"],[\"PyTorch Image Models\\n- [What's New](#whats-new)\\n- [Introduction](#introduction)\\n- [Models](#models)\\n...\"],[\"ResNeXt\\n\\nA **ResNeXt** repeats a [building block](https:\\u002f\\u002fpaperswithcode.com\\u002fmethod\\u002fresnext-block) t...\"],[\"Xception\\n\\n**Xception** is a convolutional neural network architecture that relies solely on [depthwi...\"],[\"Dual Path Network (DPN)\\n\\nA **Dual Path Network (DPN)** is a convolutional neural network which prese...\"],[\"(Gluon) ResNeXt\\n\\nA **ResNeXt** repeats a [building block](https:\\u002f\\u002fpaperswithcode.com\\u002fmethod\\u002fresnext-...\"],[\"# Ensemble Adversarial Inception ResNet v2\\n\\n**Inception-ResNet-v2** is a convolutional neural archit...\"],[\"(Gluon) ResNeXt\\n\\nA **ResNeXt** repeats a [building block](https:\\u002f\\u002fpaperswithcode.com\\u002fmethod\\u002fresnext-...\"],[\"SSL ResNet\\n\\n**Residual Networks**, or **ResNets**, learn residual functions with reference to the la...\"],[\"Xception\\n\\n**Xception** is a convolutional neural network architecture that relies solely on [depthwi...\"],[\"(Gluon) ResNet\\n\\n**Residual Networks**, or **ResNets**, learn residual functions with reference to th...\"],[\"(Tensorflow) EfficientNet Lite\\n\\n**EfficientNet** is a convolutional neural network architecture and ...\"],[\"Models\\n\\n[[autodoc]] timm.create_model\\n\\n[[autodoc]] timm.list_models...\"],[\"SPNASNet\\n\\n**Single-Path NAS** is a novel differentiable NAS method for designing hardware-efficient ...\"],[\"MobileNet v3\\n\\n**MobileNetV3** is a convolutional neural network that is designed for mobile phone CP...\"],[\"EfficientNet (Knapsack Pruned)\\n\\n**EfficientNet** is a convolutional neural network architecture and ...\"],[\"Inception v4\\n\\n**Inception-v4** is a convolutional neural network architecture that builds on previou...\"],[\"Noisy Student (EfficientNet)\\n\\n**Noisy Student Training** is a semi-supervised learning approach. It ...\"],[\"Noisy Student (EfficientNet)\\n\\n**Noisy Student Training** is a semi-supervised learning approach. It ...\"],[\"(Tensorflow) MixNet\\n\\n**MixNet** is a type of convolutional neural network discovered via AutoML that...\"],[\"SSL ResNet\\n\\n**Residual Networks**, or **ResNets**, learn residual functions with reference to the la...\"],[\"Adversarial Inception v3\\n\\n**Inception v3** is a convolutional neural network architecture from the I...\"],[\"SWSL ResNet\\n\\n**Residual Networks**, or **ResNets**, learn residual functions with reference to the l...\"],[\"(Tensorflow) EfficientNet\\n\\n**EfficientNet** is a convolutional neural network architecture and scali...\"],[\"ESE-VoVNet\\n\\n**VoVNet** is a convolutional neural network that seeks to make [DenseNet](https:\\u002f\\u002fpaper...\"],[\"(Gluon) Xception\\n\\n**Xception** is a convolutional neural network architecture that relies solely on ...\"]],\"hovertemplate\":\"source=pytorch-image-models\\u003cbr\\u003esymbol=circle\\u003cbr\\u003ex=%{x}\\u003cbr\\u003ey=%{y}\\u003cbr\\u003esize_col=%{marker.size}\\u003cbr\\u003eextract=%{customdata[0]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"pytorch-image-models, circle\",\"marker\":{\"color\":\"#FF6692\",\"size\":[4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4],\"sizemode\":\"area\",\"sizeref\":0.25,\"symbol\":\"circle\",\"line\":{\"color\":\"DarkSlateGrey\",\"width\":0},\"opacity\":1},\"mode\":\"markers\",\"name\":\"pytorch-image-models, circle\",\"showlegend\":true,\"x\":[2.402093,1.705566,0.39268318,0.9346256,2.489867,1.6926063,0.71397567,1.0822475,-2.414902,1.8771477,2.073039,1.0475229,-3.136813,-13.168969,2.3029685,-2.6128345,0.24171354,-0.74832374,0.6003542,0.29209363,-13.169993,0.1486522,0.6377064,-3.861511,0.22695099,1.5289794,0.1590022,1.6383373,0.35150978,0.49394357,0.47811672,0.82194704,0.63706666,1.8630708,-3.0570943,-0.5519888,1.668248,0.6133378,0.6031349,-2.2564697,0.31486854,2.0087128,1.534772,0.44731954,0.47202167,-13.179771,1.7715788,-2.8393102,-2.2968357,0.09397856,1.2888762,0.27499726,1.9108344,2.2134216,0.93797684,-1.4641315,0.15869236,0.69306594,2.247883,0.8009816,-4.73927,0.7257383,0.220693,1.3893334,0.07851504,-2.205482,-2.5621674,0.6683137,-2.3119771,1.9379492,0.12007182,1.4087762,-13.200999,1.1011908,-13.151756,-3.5406768,-3.3294678,2.6390426,0.71543026,0.70105255,2.6028183,0.96562463,-13.182329,2.3472893,0.60909194,0.0611624,0.7504144,-2.0960252,-3.1404061,2.5651603,1.9734415,0.6482898,0.93764484,0.66141313,0.5705477,2.595859,0.110621735,1.8697095,0.49015802,2.5938656,2.6071355,2.3921337,-13.186685,2.0982673,1.7285876,2.3302355,1.7091857,-2.7626123,1.6349212,1.9727116,0.46778628,0.123219855,0.78114265,0.6598377,1.2214274,0.49822927,0.6897376,0.26163474,0.8806482,0.7834029,1.4370527,0.7646099,0.7515875,0.7815225,2.2364366,2.2559261,-2.4309719,2.1613476,0.77856946,1.0652276,2.2235518,0.28618702,2.1530507,2.0647743,0.87085295,1.9407613,-13.190381,-1.4492501,0.38828483,0.25711477,-13.140258,0.14637038,0.82152474,0.7565844,0.720799,2.0161588,0.11079284,2.041059,-13.182058,0.67107433,0.92257714],\"xaxis\":\"x\",\"y\":[-19.808533,-20.954607,-20.834747,-19.873709,-19.772577,-20.306067,-19.704311,-19.855793,3.263239,-21.146572,-20.659424,-19.859608,3.7460163,1.9210173,-20.7104,3.517757,-19.499235,4.9573727,-19.471823,-19.483086,1.8936154,-21.36415,-19.99637,3.9981449,-19.447971,-20.39027,-21.376963,-20.270702,-19.455564,-19.73398,-19.487705,-19.651878,-19.795938,-20.293217,3.583588,3.1309373,-20.36659,-19.54707,-19.78619,3.0496817,-19.473164,-21.283098,-20.270979,-19.50858,-19.727892,1.8989573,-20.098455,3.9410326,3.8891222,-21.433405,-20.048063,-19.610218,-21.140488,-20.671936,-19.840193,3.0522158,-19.488255,-19.509048,-20.684584,-19.28301,5.192934,-19.789875,2.4387696,-20.141495,-21.419724,3.4519746,3.338678,-19.850466,3.3677883,-21.308172,-21.387257,-20.398287,1.9106061,-19.923445,1.886574,3.592641,4.0131736,-19.74798,-19.724955,-19.699863,-19.757103,-19.822866,1.9046708,-19.89821,-20.991385,-21.39582,-19.570162,3.3232214,2.8964765,-19.748533,-21.307375,-19.604319,-19.92373,-19.606594,-21.082596,-19.80828,-21.417295,-20.518038,-19.73573,-19.76463,-19.8197,-19.830328,1.9242761,-20.644188,-20.083637,-20.691502,-20.861473,3.7411792,-20.119835,-21.312557,-19.591633,-21.384277,-19.488308,-19.433985,-20.323986,-19.74104,-19.471737,-19.469318,-19.745852,-19.491447,-20.027273,-19.617432,-19.536089,-19.452381,-20.679907,-20.663797,3.6499376,-20.701248,-19.359869,-19.948175,-20.638596,-21.20134,-20.622885,-21.455202,-19.395502,-21.245522,1.8961318,2.9817376,-19.57968,-19.461731,1.888019,-21.344063,-19.412374,-19.4201,-19.574066,-21.378155,-21.414011,-21.401112,1.9106869,-19.5423,-19.38417],\"yaxis\":\"y\",\"type\":\"scattergl\"},{\"customdata\":[[\"--\\ntitle: \\\"Large Language Models: A New Moore's Law?\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f33_large_language_mode...\"],[\"--\\ntitle: \\\"Why weâ€™re switching to Hugging Face Inference Endpoints, and maybe you should too\\\"\\nthumbn...\"],[\"--\\ntitle: \\\"DuckDB: analyze 50,000+ datasets stored on the Hugging Face Hub\\\" \\nthumbnail: \\u002fblog\\u002fassets...\"],[\"--\\ntitle: \\\"Building an AI WebTV\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f156_ai_webtv\\u002fthumbnail.gif\\nauthors:\\n- user:...\"],[\"--\\ntitle: Fine tuning CLIP with Remote Sensing (Satellite) images and captions\\nthumbnail: \\u002fblog\\u002fasse...\"],[\"--\\ntitle: \\\"Multivariate Probabilistic Time Series Forecasting with Informer\\\" \\nthumbnail: \\u002fblog\\u002fasset...\"],[\"--\\ntitle: \\\"Huggy Lingo: Using Machine Learning to Improve Language Metadata on the Hugging Face Hub\\\"...\"],[\"--\\ntitle: \\\"Generating Human-level Text with Contrastive Search in Transformers ğŸ¤—\\\"\\nthumbnail: \\u002fblog\\u002fa...\"],[\"--\\ntitle: \\\"AMD + ğŸ¤—: Large Language Models Out-of-the-Box Acceleration with AMD GPU\\\"\\nthumbnail: \\u002fblog...\"],[\"--\\ntitle: \\\"Machine Learning Experts - Lewis Tunstall\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f60_lewis_tunstall_inte...\"],[\"--\\ntitle: 'Welcome fastai to the Hugging Face Hub'\\nthumbnail: \\u002fblog\\u002fassets\\u002f64_fastai\\u002ffastai_hf_blog....\"],[\"--\\ntitle: \\\"StackLLaMA: A hands-on guide to train LLaMA with RLHF\\\" \\nthumbnail: \\u002fblog\\u002fassets\\u002f138_stack...\"],[\"--\\ntitle:  Deploy LLMs with Hugging Face Inference Endpoints\\nthumbnail: \\u002fblog\\u002fassets\\u002f155_inference_e...\"],[\"--\\ntitle: \\\"2D Asset Generation: AI for Game Development #4\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f124_ml-for-games...\"],[\"--\\ntitle: \\\"Supercharged Customer Service with Machine Learning\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f61_superchar...\"],[\"--\\ntitle: \\\"Accelerating Document AI\\\" \\nthumbnail: \\u002fblog\\u002fassets\\u002f112_document-ai\\u002fthumbnail.png\\nauthors:...\"],[\"--\\ntitle: \\\"How we sped up transformer inference 100x for ğŸ¤— API customers\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f09...\"],[\"--\\ntitle: \\\"Introducing HuggingFace blog for Chinese speakers: Fostering Collaboration with the Chine...\"],[\"--\\ntitle: \\\"How to generate text: using different decoding methods for language generation with Trans...\"],[\"--\\ntitle: \\\"Accelerate your models with ğŸ¤— Optimum Intel and OpenVINO\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f113_ope...\"],[\"--\\ntitle: Guiding Text Generation with Constrained Beam Search in ğŸ¤— Transformers\\nthumbnail: \\u002fblog\\u002fas...\"],[\"--\\ntitle: \\\"Making a web app generator with open ML models\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f153_text_to_webap...\"],[\"--\\ntitle: 'Liftoff! How to get started with your first ML project ğŸš€'\\nthumbnail: \\u002fblog\\u002fassets\\u002f84_firs...\"],[\"--\\ntitle: \\\"Fit More and Train Faster With ZeRO via DeepSpeed and FairScale\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f...\"],[\"--\\ntitle: \\\"Ethics and Society Newsletter #1\\\" \\nthumbnail: \\u002fblog\\u002fassets\\u002f103_ethics-soc-1\\u002fthumbnail.png...\"],[\"--\\ntitle: \\\"Open LLM Leaderboard: DROP deep dive\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002fevaluating-mmlu-leaderboard...\"],[\"--\\ntitle: \\\"Evaluating Language Model Bias with ğŸ¤— Evaluate\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f112_evaluating-ll...\"],[\"--\\ntitle: \\\"Can foundation models label data like humans?\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002fllm-leaderboard\\u002fle...\"],[\"--\\ntitle: \\\"Student Ambassador Programâ€™s call for applications is open!\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f67_a...\"],[\"--\\ntitle: \\\"Training a language model with ğŸ¤—Â Transformers using TensorFlow and TPUs\\\"\\nthumbnail: \\u002fblog...\"],[\"--\\ntitle: \\\"A Dive into Vision-Language Models\\\"\\nthumbnail: \\u002fblog\\u002f\\u002fassets\\u002f128_vision_language_pretrain...\"],[\"--\\ntitle: \\\"Comparing the Performance of LLMs: A Deep Dive into Roberta, Llama 2, and Mistral for Dis...\"],[\"--\\ntitle: \\\"Introducing DOI: the Digital Object Identifier to Datasets and Models\\\"\\nthumbnail: \\u002fblog\\u002fa...\"],[\"--\\ntitle: \\\"Accelerating PyTorch Transformers with Intel Sapphire Rapids - part 1\\\"\\nthumbnail: \\u002fblog\\u002fa...\"],[\"--\\ntitle: Introducing our new pricing\\nthumbnail: \\u002fblog\\u002fassets\\u002f114_pricing-update\\u002fthumbnail.png\\nautho...\"],[\"--\\ntitle: Faster Stable Diffusion with Core ML on iPhone, iPad, and Mac\\nthumbnail: \\u002fblog\\u002fassets\\u002f149_...\"],[\"his notebook shows how to deploy a vision model from ğŸ¤— Transformers (written in TensorFlow) to [Vert...\"],[\"--\\ntitle: \\\"Retrieval Augmented Generation with Huggingface Transformers and Ray\\\"\\nthumbnail: \\u002fblog\\u002fas...\"],[\"--\\ntitle: Introducing Pull Requests and Discussions ğŸ¥³\\nthumbnail: \\u002fblog\\u002fassets\\u002f76_community_update\\u002fth...\"],[\"--\\ntitle: \\\"Introducing Agents.js: Give tools to your LLMs using JavaScript\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f...\"],[\"--\\ntitle: \\\"Using Machine Learning to Aid Survivors and Race through Time\\\" \\nthumbnail: \\u002fblog\\u002fassets\\u002fu...\"],[\"--\\ntitle: \\\"Accelerating PyTorch Transformers with Intel Sapphire Rapids - part 2\\\"\\nthumbnail: \\u002fblog\\u002fa...\"],[\"--\\ntitle: Getting Started with Hugging Face Inference Endpoints\\nthumbnail: \\u002fblog\\u002fassets\\u002f109_inferenc...\"],[\"--\\ntitle: \\\"Non-engineers guide: Train a LLaMA 2 chatbot\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f78_ml_director_insi...\"],[\"--\\ntitle: \\\"Ethical Guidelines for developing the Diffusers library\\\" \\nthumbnail: \\u002fblog\\u002fassets\\u002fethics-...\"],[\"--\\ntitle: \\\"Introducing BERTopic Integration with the Hugging Face Hub\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f145_b...\"],[\"--\\ntitle: \\\"OpenRAIL: Towards open and responsible AI licensing frameworks\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f1...\"],[\"--\\ntitle: Using LoRA for Efficient Stable Diffusion Fine-Tuning\\nthumbnail: \\u002fblog\\u002fassets\\u002flora\\u002fthumbna...\"],[\"--\\ntitle: \\\"Graph Classification with Transformers\\\" \\nthumbnail: \\u002fblog\\u002fassets\\u002f125_intro-to-graphml\\u002fthu...\"],[\"--\\ntitle: Fine-Tune a Semantic Segmentation Model with a Custom Dataset\\nthumbnail: \\u002fblog\\u002fassets\\u002f56_f...\"],[\"--\\ntitle: \\\"Efficient Controllable Generation for SDXL with T2I-Adapters\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002ft2i...\"],[\"--\\ntitle: \\\"Introduction to Graph Machine Learning\\\" \\nthumbnail: \\u002fblog\\u002fassets\\u002f125_intro-to-graphml\\u002fthu...\"],[\"--\\ntitle: \\\"Transformer-based Encoder-Decoder Models\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f05_encoder_decoder\\u002fthum...\"],[\"--\\ntitle: Block Sparse Matrices for Smaller and Faster Language Models\\nthumbnail: \\u002fblog\\u002fassets\\u002f04_py...\"],[\"--\\ntitle: \\\"Yes, Transformers are Effective for Time Series Forecasting (+ Autoformer)\\\"\\nthumbnail: \\u002fb...\"],[\"--\\ntitle: \\\"Image search with ğŸ¤— datasets\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f54_image_search_datasets\\u002fspaces_ima...\"],[\"--\\ntitle: \\\"Introducing IDEFICS: An Open Reproduction of State-of-the-art Visual Langage Model\\\"\\nthumb...\"],[\"--\\ntitle: \\\"Graphcore and Hugging Face Launch New Lineup of IPU-Ready Transformers\\\"\\nthumbnail: \\u002fblog\\u002f...\"],[\"--\\ntitle: \\\"Showcase Your Projects in Spaces using Gradio\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f28_gradio-spaces\\u002ft...\"],[\"Some Notes on Pros of Open Science and Open Source\\n- **Pooling Resources**: Building off of one anot...\"],[\"--\\ntitle: \\\"We are hiring interns!\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002finterns-2023\\u002fthumbnail.png\\nauthors:\\n- use...\"],[\"--\\ntitle: \\\"Announcing the Open Source AI Game Jam ğŸ®\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f145_gamejam\\u002fthumbnail.p...\"],[\"--\\ntitle: \\\"Ethics and Society Newsletter #3: Ethical Openness at Hugging Face\\\" \\nthumbnail: \\u002fblog\\u002fass...\"],[\"--\\ntitle: \\\"Deep Learning over the Internet: Training Language Models Collaboratively\\\"\\nthumbnail: \\u002fbl...\"],[\"--\\ntitle: \\\"Incredibly Fast BLOOM Inference with DeepSpeed and Accelerate\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002fbl...\"],[\"--\\ntitle: \\\"Summer at Hugging Face\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f27_summer_at_huggingface\\u002fsummer_intro.gif...\"],[\"--\\ntitle: \\\"Model Cards\\\" \\nthumbnail: \\u002fblog\\u002fassets\\u002f121_model-cards\\u002fthumbnail.png\\nauthors:\\n- user: Ezi\\n...\"],[\"--\\ntitle: \\\"Introducing RWKV - An RNN with the advantages of a transformer\\\" \\nthumbnail: \\u002fblog\\u002fassets\\u002f...\"],[\"--\\ntitle: Stable Diffusion with ğŸ§¨ Diffusers\\nthumbnail: \\u002fblog\\u002fassets\\u002f98_stable_diffusion\\u002fthumbnail.pn...\"],[\"--\\ntitle: 'Deploy Hugging Face models easily with Amazon SageMaker'\\nthumbnail: \\u002fblog\\u002fassets\\u002f17_the_p...\"],[\"--\\ntitle: \\\"Introducing Prodigy-HF: a direct integration with Hugging Face\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f1...\"],[\"--\\ntitle: \\\"How to Install and Use the Hugging Face Unity API\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f124_ml-for-gam...\"],[\"--\\ntitle: \\\"Proximal Policy Optimization (PPO)\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f93_deep_rl_ppo\\u002fthumbnail.png\\n...\"],[\"--\\ntitle: \\\"Very Large Language Models and How to Evaluate Them\\\" \\nthumbnail: \\u002fblog\\u002fassets\\u002f106_zero_sh...\"],[\"--\\ntitle: Training Stable Diffusion with Dreambooth using Diffusers\\nthumbnail: \\u002fblog\\u002fassets\\u002fsd_dream...\"],[\"--\\ntitle: 'Faster Text Generation with TensorFlow and XLA'\\nthumbnail: \\u002fblog\\u002fassets\\u002f91_tf_xla_generat...\"],[\"--\\ntitle: \\\"Perceiver IO: a scalable, fully-attentional model that works on any modality\\\"\\nthumbnail: ...\"],[\"--\\ntitle: \\\"Train a Sentence Embedding Model with 1B Training Pairs\\\"\\nauthors:\\n- user: asi\\n  guest: tr...\"],[\"--\\ntitle: \\\"Large-scale Near-deduplication Behind BigCode\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002fdedup\\u002fthumbnail.pn...\"],[\"--\\ntitle: 'Getting Started With Embeddings'\\nthumbnail: \\u002fblog\\u002fassets\\u002f80_getting_started_with_embeddin...\"],[\"--\\ntitle: Getting Started with Transformers on Habana Gaudi\\nthumbnail: \\u002fblog\\u002fassets\\u002f61_getting_start...\"],[\"--\\ntitle: \\\"Personal Copilot: Train Your Own Coding Assistant\\\" \\nthumbnail: \\u002fblog\\u002fassets\\u002f170_personal_...\"],[\"--\\ntitle: \\\"Hugging Face on PyTorch \\u002f XLA TPUs\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f13_pytorch_xla\\u002fpytorch_xla_th...\"],[\"--\\ntitle: Deploying TensorFlow Vision Models in Hugging Face with TF Serving\\nthumbnail: \\u002fblog\\u002fassets...\"],[\"--\\ntitle: \\\"Fine-tuning 20B LLMs with RLHF on a 24GB consumer GPU\\\" \\nthumbnail: assets\\u002f133_trl_peft\\u002fth...\"],[\"--\\ntitle: \\\"Sentiment Analysis on Encrypted Data with Homomorphic Encryption\\\"\\nthumbnail: \\u002fblog\\u002fassets...\"],[\"--\\ntitle: \\\"How to host a Unity game in a Space\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f124_ml-for-games\\u002funity-in-sp...\"],[\"--\\ntitle: \\\"Llama 2 on Amazon SageMaker a Benchmark\\\" \\nthumbnail: \\u002fblog\\u002fassets\\u002fllama_sagemaker_benchma...\"],[\"--\\ntitle: \\\"Announcing Evaluation on the Hub\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f82_eval_on_the_hub\\u002fthumbnail.pn...\"],[\"--\\ntitle: \\\"Leveraging Pre-trained Language Model Checkpoints for Encoder-Decoder Models\\\"\\nthumbnail: ...\"],[\"--\\ntitle: \\\"Introducing Hugging Face for Education ğŸ¤—\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f61_education\\u002fthumbnail....\"],[\"--\\ntitle: \\\"How Hugging Face Accelerated Development of Witty Works Writing Assistant\\\"\\nthumbnail: \\u002fbl...\"],[\"--\\ntitle: Inference for PROs\\nthumbnail: \\u002fblog\\u002fassets\\u002finference_pro\\u002fthumbnail.png\\nauthors:\\n  - user: ...\"],[\"--\\ntitle: \\\"Towards Encrypted Large Language Models with FHE\\\" \\nthumbnail: \\u002fblog\\u002fassets\\u002fencrypted-llm\\u002f...\"],[\"--\\ntitle: \\\"Open-sourcing Knowledge Distillation Code and Weights of SD-Small and SD-Tiny\\\"\\nthumbnail:...\"],[\"--\\ntitle: \\\"The Hugging Face Hub for Galleries, Libraries, Archives and Museums\\\"\\nthumbnail: \\u002fblog\\u002fass...\"],[\"--\\ntitle: \\\"Putting ethical principles at the core of the research lifecycle\\\"\\nthumbnail: \\u002fblog\\u002fassets...\"],[\"--\\ntitle: \\\"StarCoder: A State-of-the-Art LLM for Code\\\" \\nthumbnail: \\u002fblog\\u002fassets\\u002f141_starcoder\\u002fstarco...\"],[\"--\\ntitle: \\\"Ethics and Society Newsletter #5: Hugging Face Goes To Washington and Other Summer 2023 M...\"],[\"--\\ntitle: 'Convert Transformers to ONNX with Hugging Face Optimum'\\nthumbnail: \\u002fblog\\u002fassets\\u002f81_conver...\"],[\"--\\ntitle: \\\"Comments on U.S. National AI Research Resource Interim Report\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f92...\"],[\"--\\ntitle: \\\"3D Asset Generation: AI for Game Development #3\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f124_ml-for-games...\"],[\"--\\ntitle: \\\"Opinion Classification with Kili and HuggingFace AutoTrain\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f59_op...\"],[\"--\\ntitle: \\\"AI for Game Development: Creating a Farming Game in 5 Days. Part 2\\\"\\nthumbnail: \\u002fblog\\u002fasse...\"],[\"--\\ntitle: How to train a new language model from scratch using Transformers and Tokenizers\\nthumbnail...\"],[\"--\\ntitle: \\\"Using & Mixing Hugging Face Models with Gradio 2.0\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f22_gradio\\u002fgra...\"],[\"--\\ntitle: \\\"Hugging Face and Graphcore partner for IPU-optimized Transformers\\\"\\nthumbnail: \\u002fblog\\u002fasset...\"],[\"--\\ntitle: \\\"AudioLDM 2, but faster âš¡ï¸\\\" \\nthumbnail: \\u002fblog\\u002fassets\\u002f161_audioldm2\\u002fthumbnail.png\\nauthors:\\n...\"],[\"--\\ntitle: \\\"Accelerating Stable Diffusion Inference on Intel CPUs\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f136_stable...\"],[\"--\\ntitle: \\\"A Complete Guide to Audio Datasets\\\" \\nthumbnail: \\u002fblog\\u002fassets\\u002f116_audio_datasets\\u002fthumbnail...\"],[\"--\\ntitle: The Annotated Diffusion Model\\nthumbnail: \\u002fblog\\u002fassets\\u002f78_annotated-diffusion\\u002fthumbnail.png...\"],[\"--\\ntitle: \\\"How Sempre Health is leveraging the Expert Acceleration Program to accelerate their ML ro...\"],[\"--\\ntitle: \\\"Databricks â¤ï¸ Hugging Face: up to 40% faster training and tuning of Large Language Models...\"],[\"--\\ntitle: 'Introducing Snowball Fight â˜ƒï¸, our first ML-Agents environment'\\nthumbnail: \\u002fblog\\u002fassets\\u002f3...\"],[\"--\\ntitle: \\\"Deep Learning with Proteins\\\" \\nthumbnail: \\u002fblog\\u002fassets\\u002f119_deep_learning_with_proteins\\u002ffol...\"],[\"--\\ntitle: \\\"Sentence Transformers in the Hugging Face Hub\\\"\\nauthors:\\n- user: osanseviero\\n- user: nreim...\"],[\"--\\ntitle: \\\"Running IF with ğŸ§¨ diffusers on a Free Tier Google Colab\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002fif\\u002fthumb...\"],[\"--\\ntitle: \\\"Hugging Face and IBM partner on watsonx.ai, the next-generation enterprise studio for AI ...\"],[\"--\\ntitle: The State of Computer Vision at Hugging Face ğŸ¤—\\nthumbnail: \\u002fblog\\u002fassets\\u002fcv_state\\u002fthumbnail....\"],[\"--\\ntitle: \\\"Fine-tuning Stable Diffusion models on Intel CPUs\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002fstable-diffusi...\"],[\"--\\ntitle: \\\"Gradio-Lite: Serverless Gradio Running Entirely in Your Browser\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f...\"],[\"--\\ntitle: \\\"BERT 101 - State Of The Art NLP Model Explained\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f52_bert_101\\u002fthum...\"],[\"--\\ntitle: \\\"We Raised $100 Million for Open & Collaborative Machine Learning ğŸš€\\\"\\nthumbnail: \\u002fblog\\u002fasse...\"],[\"--\\ntitle: \\\"Efficient Table Pre-training without Real Data: An Introduction to TAPEX\\\"\\nthumbnail: \\u002fblo...\"],[\"--\\ntitle: \\\"Ethics and Society Newsletter #4: Bias in Text-to-Image Models\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f1...\"],[\"--\\ntitle: \\\"Active Learning with AutoNLP and Prodigy\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f43_autonlp_prodigy\\u002fthum...\"],[\"--\\ntitle: \\\"AI Policy @ğŸ¤—: Open ML Considerations in the EU AI Act\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002feu_ai_act_...\"],[\"--\\ntitle: \\\"Intel and Hugging Face Partner to Democratize Machine Learning Hardware Acceleration\\\"\\nthu...\"],[\"--\\ntitle: \\\"CO2 Emissions and the ğŸ¤— Hub: Leading the Charge\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f60_carbon_emissi...\"],[\"--\\ntitle: \\\"What's going on with the Open LLM Leaderboard?\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002fevaluating-mmlu-l...\"],[\"--\\ntitle: \\\"The Technology Behind BLOOM Training\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f86_bloom_megatron_deepspeed...\"],[\"--\\ntitle: \\\"Happy 1st anniversary ğŸ¤— Diffusers!\\\" \\nthumbnail: \\u002fblog\\u002fassets\\u002fdiffusers-turns-1\\u002fdiffusers-...\"],[\"--\\ntitle: \\\"Getting Started with Hugging Face Transformers for IPUs with Optimum\\\"\\nthumbnail: \\u002fblog\\u002fas...\"],[\"--\\ntitle: Deprecation of Git Authentication using password\\nthumbnail: \\u002fblog\\u002fassets\\u002fpassword-git-depr...\"],[\"--\\ntitle: \\\"Finetune Stable Diffusion Models with DDPO via TRL\\\" \\nthumbnail: \\u002fblog\\u002fassets\\u002f166_trl_ddpo...\"],[\"--\\ntitle: \\\"Fine-Tune Whisper For Multilingual ASR with ğŸ¤— Transformers\\\" \\nthumbnail: \\u002fblog\\u002fassets\\u002f111_...\"],[\"--\\ntitle: \\\"Let's talk about biases in machine learning! Ethics and Society Newsletter #2\\\" \\nthumbnail...\"],[\"--\\ntitle: 'Distributed Training: Train BART\\u002fT5 for Summarization using ğŸ¤— Transformers and Amazon Sag...\"],[\"--\\ntitle: \\\"SetFitABSA: Few-Shot Aspect Based Sentiment Analysis using SetFit\\\"\\nthumbnail: \\u002fblog\\u002fasset...\"],[\"--\\ntitle: \\\"Boosting Wav2Vec2 with n-grams in ğŸ¤— Transformers\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f44_boost_wav2ve...\"],[\"--\\ntitle: \\\"Hugging Face Machine Learning Demos on arXiv\\\" \\nthumbnail: \\u002fblog\\u002fassets\\u002farxiv\\u002fthumbnail.pn...\"],[\"--\\ntitle: \\\"Illustrating Reinforcement Learning from Human Feedback (RLHF)\\\" \\nthumbnail: \\u002fblog\\u002fassets\\u002f...\"],[\"--\\ntitle: ğŸ§¨ Stable Diffusion  in JAX \\u002f Flax !\\nthumbnail: \\u002fblog\\u002fassets\\u002f108_stable_diffusion_jax\\u002fthumb...\"],[\"--\\ntitle: 'Pre-Train BERT with Hugging Face Transformers and Habana Gaudi'\\nthumbnail: \\u002fblog\\u002fassets\\u002f9...\"],[\"--\\ntitle: \\\"Machine Learning Experts - Sasha Luccioni\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f69_sasha_luccioni_inte...\"],[\"--\\ntitle: Simple considerations for simple people building fancy neural networks\\nthumbnail: \\u002fblog\\u002fas...\"],[\"--\\ntitle: \\\"Fine-tuning Llama 2 70B using PyTorch FSDP\\\" \\nthumbnail: \\u002fblog\\u002fassets\\u002f160_fsdp_llama\\u002fthumb...\"],[\"--\\ntitle: Optimizing Stable Diffusion for Intel CPUs with NNCF and ğŸ¤— Optimum\\nthumbnail: \\u002fblog\\u002fassets...\"],[\"--\\ntitle: \\\"A Gentle Introduction to 8-bit Matrix Multiplication for transformers at scale using tran...\"],[\"--\\ntitle: \\\"Speech Synthesis, Recognition, and More With SpeechT5\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002fspeecht5\\u002ft...\"],[\"--\\ntitle: \\\"Code Llama: Llama 2 learns to code\\\" \\nthumbnail: \\u002fblog\\u002fassets\\u002f160_codellama\\u002fthumbnail.jpg\\n...\"],[\"--\\ntitle: \\\"Hugging Face and AMD partner on accelerating state-of-the-art models for CPU and GPU plat...\"],[\"--\\ntitle: \\\"Accelerating over 130,000 Hugging Face models with ONNX Runtime\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f...\"],[\"--\\ntitle: \\\"AI Speech Recognition in Unity\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f124_ml-for-games\\u002funity-asr-thumbn...\"],[\"--\\ntitle: 'Building a Playlist Generator with Sentence Transformers'\\nthumbnail: \\u002fblog\\u002fassets\\u002f87_play...\"],[\"--\\ntitle: \\\"Accelerating Vision-Language Models: BridgeTower on Habana Gaudi2\\\"\\nthumbnail: \\u002fblog\\u002fasset...\"],[\"--\\ntitle: \\\"Introducing ğŸ¤— Accelerate\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f20_accelerate_library\\u002faccelerate_diff.p...\"],[\"--\\ntitle: \\\"Interactively explore your Huggingface dataset with one line ofÂ code\\\"\\nthumbnail: \\u002fblog\\u002fas...\"],[\"--\\ntitle: Hugging Face Collaborates with Microsoft to launch Hugging Face Model Catalog on Azure\\nthu...\"],[\"The Hugging Face Blog Repository ğŸ¤—\\nThis is the official repository of the [Hugging Face Blog](https:...\"],[\"--\\ntitle: Training CodeParrot ğŸ¦œ from Scratch\\nthumbnail: \\u002fblog\\u002fassets\\u002f40_codeparrot\\u002fthumbnail.png\\naut...\"],[\"--\\ntitle: \\\"Optimizing Bark using ğŸ¤— Transformers\\\" \\nthumbnail: \\u002fblog\\u002fassets\\u002fbark_optimization\\u002fthumbnai...\"],[\"--\\ntitle: \\\"Director of Machine Learning Insights [Part 4]\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f78_ml_director_in...\"],[\"--\\ntitle: \\\"Panel on Hugging Face\\\" \\nthumbnail: \\u002fblog\\u002fassets\\u002fpanel-on-hugging-face\\u002fthumbnail.png\\nautho...\"],[\"--\\ntitle: \\\"Diffusion Models Live Event\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002fdiffusion-models-event\\u002fthumbnail.png...\"],[\"--\\ntitle: \\\"Habana Labs and Hugging Face Partner to Accelerate Transformer Model Training\\\"\\nthumbnail:...\"],[\"--\\ntitle: \\\"Fine-tune Llama 2 with DPO\\\" \\nthumbnail: \\u002fblog\\u002fassets\\u002f157_dpo_trl\\u002fdpo_thumbnail.png\\nauthor...\"],[\"--\\ntitle: \\\"Welcome fastText to the Hugging Face Hub\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f147_fasttext\\u002fthumbnail....\"],[\"--\\ntitle: \\\"Introducing Decision Transformers on Hugging Face ğŸ¤—\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f58_decision-...\"],[\"--\\ntitle: \\\"Course Launch Community Event\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f34_course_launch\\u002fspeakers_day1_thu...\"],[\"--\\ntitle: 'Accelerated Inference with Optimum and Transformers Pipelines'\\nthumbnail: \\u002fblog\\u002fassets\\u002f66...\"],[\"--\\ntitle: \\\"Hugging Face Selected for the French Data Protection Agency Enhanced Support Program\\\"\\nthu...\"],[\"--\\ntitle: Using Stable Diffusion with Core ML on Apple Silicon\\nthumbnail: \\u002fblog\\u002fassets\\u002fdiffusers_cor...\"],[\"--\\ntitle: \\\"Exploring simple optimizations for SDXL\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002fsimple_sdxl_optimization...\"],[\"--\\ntitle: \\\"Fine-Tune ViT for Image Classification with ğŸ¤— Transformers\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f51_fi...\"],[\"--\\ntitle: \\\"~Don't~ Repeat Yourself\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f59_transformers_philosophy\\u002ftransformers....\"],[\"--\\ntitle: \\\"Introducing WÃ¼rstchen: Fast Diffusion for Image Generation\\\" \\nthumbnail: \\u002fblog\\u002fassets\\u002fwuer...\"],[\"--\\ntitle: Faster TensorFlow models in Hugging Face Transformers\\nthumbnail: \\u002fblog\\u002fassets\\u002f10_tf-servin...\"],[\"--\\ntitle: \\\"Object Detection Leaderboard\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002fobject-detection-leaderboard\\u002fthumbn...\"],[\"--\\ntitle: \\\"The Falcon has landed in the Hugging Face ecosystem\\\" \\nthumbnail: \\u002fblog\\u002fassets\\u002f147_falcon\\u002f...\"],[\"--\\ntitle: \\\"Gradio 3.0 is Out!\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f68_gradio_blocks\\u002fblock-party.png\\nauthors:\\n- u...\"],[\"--\\ntitle: \\\"Releasing Swift Transformers: Run On-Device LLMs in Apple Devices\\\"\\nthumbnail: \\u002fblog\\u002fasset...\"],[\"---\\ntitle: \\\"Making ML-powered web games with Transformers.js\\\" \\nthumbnail: \\u002fblog\\u002fassets\\u002fml-web-games\\u002f...\"],[\"--\\ntitle: \\\"Deploy MusicGen in no time with Inference Endpoints\\\" \\nthumbnail: \\u002fblog\\u002fassets\\u002frun-musicge...\"],[\"--\\n\\ntitle: \\\"Results of the Open Source AI Game Jam\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002fgame-jam-first-edition-r...\"],[\"Contrastive Search\\n\\nThis is a companion notebook to the [Hugging Face guest blog post entry about co...\"],[\"--\\ntitle: ğŸ§¨ Accelerating Stable Diffusion XL Inference with JAX on Cloud TPU v5e\\nthumbnail: \\u002fblog\\u002fas...\"],[\"--\\ntitle: \\\"Accelerate BERT inference with Hugging Face Transformers and AWS Inferentia\\\"\\nthumbnail: \\u002f...\"],[\"--\\ntitle: \\\"How to train your model dynamically using adversarial data\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f88_mn...\"],[\"--\\ntitle: \\\"Rocket Money x Hugging Face: Scaling Volatile ML Models in Productionâ€‹\\\"\\nthumbnail: \\u002fblog\\u002f...\"],[\"--\\ntitle: \\\"Leveraging Hugging Face for complex generative AI use cases\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f78_m...\"],[\"--\\ntitle: \\\"ControlNet in ğŸ§¨ Diffusers\\\" \\nthumbnail: \\u002fblog\\u002fassets\\u002fcontrolnet\\u002fthumbnail.png \\nauthors:\\n- ...\"],[\"--\\ntitle: Universal Image Segmentation with Mask2Former and OneFormer\\nthumbnail: \\u002fblog\\u002fassets\\u002f127_ma...\"],[\"--\\ntitle: \\\"A Dive into Text-to-Video Models\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f140_text-to-video\\u002fthumbnail.png...\"],[\"--\\ntitle: \\\"Stable Diffusion XL on Mac with Advanced Core ML Quantization\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002fst...\"],[\"--\\ntitle: \\\"An Introduction to Deep Reinforcement Learning\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f63_deep_rl_intro\\u002f...\"],[\"--\\ntitle: \\\"Scaling up BERT-like model Inference on modern CPU  - Part 2\\\"\\nauthors:\\n- user: echarlaix\\n...\"],[\"--\\ntitle: \\\"Supercharged Searching on the ğŸ¤— Hub\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f48_hubsearch\\u002fthumbnail.png\\na...\"],[\"--\\ntitle: \\\"Optimization story: Bloom inference\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002fbloom-inference-pytorch-scri...\"],[\"--\\ntitle: \\\"Welcome spaCy to the Hugging Face Hub\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f23_spacy\\u002fthumbnail.png\\n\\nau...\"],[\"--\\ntitle: \\\"Porting fairseq wmt19 translation system to transformers\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f07_port...\"],[\"--\\ntitle: \\\"Understanding BigBird's Block Sparse Attention\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f18_big_bird\\u002fattn....\"],[\"--\\ntitle: \\\"Train your first Decision Transformer\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f101_train-decision-transfo...\"],[\"--\\ntitle: Goodbye cold boot - how we made LoRA Inference 300% faster\\nthumbnail: \\u002fblog\\u002fassets\\u002f171_loa...\"],[\"--\\ntitle: \\\"Open-Source Text Generation & LLM Ecosystem at Hugging Face\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002fos_l...\"],[\"--\\ntitle: \\\"Deploying Hugging Face Models with BentoML: DeepFloyd IF in Action\\\" \\nthumbnail: \\u002fblog\\u002fass...\"],[\"--\\ntitle: \\\"Deep Q-Learning with Space Invaders\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f78_deep_rl_dqn\\u002fthumbnail.gif...\"],[\"--\\ntitle: \\\"Deep Dive: Vision Transformers On Hugging Face Optimum Graphcore\\\"\\nthumbnail: \\u002fblog\\u002fassets...\"],[\"--\\ntitle: \\\"NystrÃ¶mformer: Approximating self-attention in linear time and memory via the NystrÃ¶m met...\"],[\"--\\ntitle: \\\"Llama 2 is here - get it on Hugging Face\\\" \\nthumbnail: \\u002fblog\\u002fassets\\u002fllama2\\u002fthumbnail.jpg\\na...\"],[\"--\\ntitle: \\\"Introducing The World's Largest Open Multilingual Language Model: BLOOM\\\"\\nthumbnail: \\u002fblog...\"],[\"--\\ntitle: \\\"Optimum-NVIDIA Unlocking blazingly fast LLM inference in just 1 line of code\\\" \\nthumbnail:...\"],[\"--\\ntitle: \\\"Making LLMs even more accessible with bitsandbytes, 4-bit quantization and QLoRA\\\" \\nthumbn...\"],[\"--\\ntitle: \\\"Optimum+ONNX Runtime - Easier, Faster training for your Hugging Face models\\\"\\nthumbnail: \\u002f...\"],[\"--\\ntitle: \\\"SafeCoder vs. Closed-source Code Assistants\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002fsafecoder-vs-closed-...\"],[\"--\\ntitle: \\\"Optimizing your LLM in production\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f163_optimize_llm\\u002foptimize_llm....\"],[\"--\\ntitle: \\\"Deploy GPT-J 6B for inference using  Hugging Face Transformers and Amazon SageMaker\\\"\\nthum...\"],[\"--\\ntitle: \\\"Visualize proteins on Hugging Face Spaces\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f98_spaces_3dmoljs\\u002fthum...\"],[\"--\\ntitle: \\\"Announcing our new Content Guidelines and Policy\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002fcontent-guideli...\"],[\"--\\ntitle: \\\"Fine-Tune MMS Adapter Models for low-resource ASR\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f151_mms\\u002fmms_ma...\"],[\"--\\ntitle: \\\"Policy Gradient with PyTorch\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f85_policy_gradient\\u002fthumbnail.gif\\nau...\"],[\"--\\ntitle: \\\"Hugging Face Platform on the AWS Marketplace: Pay with your AWS Account\\\"\\nthumbnail: \\u002fblog...\"],[\"--\\ntitle: \\\"Practical 3D Asset Generation: A Step-by-Step Guide\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f124_ml-for-g...\"],[\"--\\ntitle: \\\"Making LLMs lighter with AutoGPTQ and transformers\\\" \\nthumbnail: \\u002fblog\\u002fassets\\u002f159_autogptq...\"],[\"--\\ntitle: \\\"Introducing the Data Measurements Tool: an Interactive Tool for Looking at Datasets\\\"\\nthum...\"],[\"--\\ntitle: \\\"New ViT and ALIGN Models From Kakao Brain\\\" \\nthumbnail: \\u002fblog\\u002f\\u002fassets\\u002f132_vit_align\\u002fthumbn...\"],[\"--\\ntitle: \\\"Smaller is better: Q8-Chat, an efficient generative AI experience on Xeon\\\"\\nthumbnail: \\u002fbl...\"],[\"--\\ntitle: \\\"An overview of inference solutions on Hugging Face\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f116_inference...\"],[\"--\\ntitle: \\\"Hugging Face's TensorFlow Philosophy\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f96_tensorflow_philosophy\\u002fth...\"],[\"--\\ntitle: The Age of Machine Learning As Code HasÂ Arrived\\nthumbnail: \\u002fblog\\u002fassets\\u002f31_age_of_ml_as_co...\"],[\"--\\ntitle: \\\"Introducing Storage Regions on the HF Hub\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f172_regions\\u002fthumbnail....\"],[\"--\\ntitle: \\\"Announcing the ğŸ¤— AI Research Residency Program\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f57_ai_residency\\u002fr...\"],[\"--\\ntitle: \\\"Hugging Face Reads, Feb. 2021 - Long-range Transformers\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f14_long_...\"],[\"--\\ntitle: \\\"VQ-Diffusion\\\" \\nthumbnail: \\u002fblog\\u002fassets\\u002f117_vq_diffusion\\u002fthumbnail.png\\nauthors:\\n- user: wi...\"],[\"--\\ntitle: Zero-shot image segmentation with CLIPSeg\\nthumbnail: \\u002fblog\\u002fassets\\u002f123_clipseg-zero-shot\\u002fth...\"],[\"--\\ntitle: \\\"Getting Started with Sentiment Analysis on Twitter\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f85_sentiment_...\"],[\"--\\ntitle: \\\"Huggy Lingo: Using Machine Learning to Improve Language Metadata on the Hugging Face Hub\\\"...\"],[\"--\\ntitle: \\\"Jupyter X Hugging Face\\\" \\nthumbnail: \\u002fblog\\u002fassets\\u002f135_notebooks-hub\\u002fbefore_after_notebook_...\"],[\"--\\ntitle: \\\"Gradio is joining Hugging Face!\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f42_gradio_joins_hf\\u002fthumbnail.png...\"],[\"--\\ntitle: \\\"Generating Stories: AI for Game Development #5\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f124_ml-for-games\\u002f...\"],[\"--\\ntitle: \\\"Making automatic speech recognition work on large files with Wav2Vec2 in ğŸ¤— Transformers\\\"\\n...\"],[\"--\\ntitle: \\\"Red-Teaming Large Language Models\\\" \\nthumbnail: \\u002fblog\\u002fassets\\u002fred-teaming\\u002fthumbnail.png\\naut...\"],[\"--\\ntitle: \\\"2023, year of open LLMs\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002fcv_state\\u002fthumbnail.png\\nauthors:\\n- user: ...\"],[\"--\\ntitle: \\\"The N Implementation Details of RLHF with PPO\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f167_the_n_implemen...\"],[\"--\\ntitle: \\\"Accelerate Large Model Training using PyTorch Fully Sharded Data Parallel\\\"\\nthumbnail: \\u002fbl...\"],[\"--\\ntitle: \\\"Hosting your Models and Datasets on Hugging Face Spaces using Streamlit\\\"\\nthumbnail: \\u002fblog...\"],[\"--\\ntitle: \\\"Mixture of Experts Explained\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002fmoe\\u002fthumbnail.png\\nauthors:\\n- user: ...\"],[\"--\\ntitle: \\\"An Introduction to Q-Learning Part 1\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f70_deep_rl_q_part1\\u002fthumbnai...\"],[\"--\\ntitle:  Introducing the Hugging Face LLM Inference Container for Amazon SageMaker\\nthumbnail: \\u002fblo...\"],[\"--\\ntitle: \\\"Fetch Cuts ML Processing Latency by 50% Using Amazon SageMaker & Hugging Face\\\"\\nthumbnail:...\"],[\"--\\ntitle: \\\"Fast Inference on Large Language Models: BLOOMZ on Habana Gaudi2 Accelerator\\\"\\nthumbnail: ...\"],[\"--\\ntitle: Deploying ğŸ¤— ViT on Kubernetes with TF Serving\\nthumbnail: \\u002fblog\\u002fassets\\u002f94_tf_serving_kubern...\"],[\"--\\ntitle: 'Welcome Stable-baselines3 to the Hugging Face Hub ğŸ¤—'\\nthumbnail: \\u002fblog\\u002fassets\\u002f47_sb3\\u002fthumb...\"],[\"--\\ntitle: \\\"Director of Machine Learning Insights [Part 2: SaaS Edition]\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f67_...\"],[\"--\\ntitle: \\\"From GPT2 to Stable Diffusion: Hugging Face arrives to the Elixir community\\\" \\nthumbnail: ...\"],[\"--\\ntitle: \\\"ğŸ¶Safetensors audited as really safe and becoming the default\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f142...\"],[\"--\\ntitle: \\\"Federated Learning using Hugging Face and Flower\\\" \\nthumbnail: \\u002fblog\\u002fassets\\u002ffl-with-flower...\"],[\"--\\ntitle: \\\"Creating open machine learning datasets? Share them on the Hugging Face Hub!\\\"\\nthumbnail: ...\"],[\"--\\ntitle: \\\"Assisted Generation: a new direction toward low-latency text generation\\\"\\nthumbnail: \\u002fblog...\"],[\"--\\ntitle: \\\"Introducing the Private Hub: A New Way to Build With Machine Learning\\\"\\nthumbnail: \\u002fblog\\u002fa...\"],[\"--\\ntitle: \\\"Speculative Decoding for 2x Faster Whisper Inference\\\" \\nthumbnail: \\u002fblog\\u002fassets\\u002fwhisper-sp...\"],[\"--\\ntitle: \\\"Snorkel AI x Hugging Face: unlock foundation models for enterprises\\\"\\nthumbnail: \\u002fblog\\u002fass...\"],[\"--\\ntitle: \\\"An Introduction to Q-Learning Part 2\\u002f2\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f73_deep_rl_q_part2\\u002fthumbn...\"],[\"--\\ntitle: \\\"Overview of natively supported quantization schemes in ğŸ¤— Transformers\\\" \\nthumbnail: \\u002fblog\\u002f...\"],[\"--\\ntitle: 'Train and Fine-Tune Sentence Transformers Models'\\nthumbnail: \\u002fblog\\u002fassets\\u002f95_training_st_...\"],[\"--\\ntitle: \\\"SDXL in 4 steps with Latent Consistency LoRAs\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002flcm_sdxl\\u002flcm_thumb...\"],[\"--\\ntitle: \\\"Introducing Skops\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f94_skops\\u002fintroducing_skops.png\\nauthors:\\n- user...\"],[\"--\\ntitle: \\\"Run a Chatgpt-like Chatbot on a Single GPU with ROCm\\\" \\nthumbnail: \\u002fblog\\u002fassets\\u002fchatbot-am...\"],[\"--\\ntitle: \\\"Zero-shot image-to-text generation with BLIP-2\\\" \\nthumbnail: \\u002fblog\\u002fassets\\u002fblip-2\\u002fthumbnail...\"],[\"--\\ntitle: \\\"Scaling-up BERT Inference on CPU (Part 1)\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f21_bert_cpu_scaling_pa...\"],[\"--\\ntitle: \\\"Welcome PaddlePaddle to the Hugging Face Hub\\\" \\nthumbnail: \\u002fblog\\u002fassets\\u002f126_paddlepaddle\\u002ft...\"],[\"--\\ntitle: Image Similarity with Hugging Face Datasets and Transformers\\nthumbnail: \\u002fblog\\u002fassets\\u002fimage...\"],[\"--\\ntitle: \\\"Japanese Stable Diffusion\\\" \\nthumbnail: \\u002fblog\\u002fassets\\u002f106_japanese_stable_diffusion\\u002fjsd_thu...\"],[\"--\\ntitle: \\\"Fine-Tune Wav2Vec2 for English ASR in Hugging Face with ğŸ¤— Transformers\\\"\\nthumbnail: \\u002fblog\\u002f...\"],[\"--\\ntitle: \\\"Hugging Face and AWS partner to make AI more accessible\\\" \\nthumbnail: \\u002fblog\\u002fassets\\u002f131_aws...\"],[\"--\\ntitle: \\\"Deploy Livebook notebooks as apps to Hugging Face Spaces\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f120_eli...\"],[\"--\\ntitle: \\\"Getting Started with Sentiment Analysis using Python\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f50_sentimen...\"],[\"a href=\\\"https:\\u002f\\u002fcolab.research.google.com\\u002fgithub\\u002fsanchit-gandhi\\u002fnotebooks\\u002fblob\\u002fmain\\u002ffine_tune_whispe...\"],[\"--\\ntitle: How to train a Language Model with Megatron-LM\\nthumbnail: \\u002fblog\\u002fassets\\u002f100_megatron_traini...\"],[\"--\\ntitle: \\\"Accelerating Hugging Face Transformers with AWS Inferentia2\\\" \\nthumbnail: \\u002fblog\\u002fassets\\u002f140...\"],[\"--\\ntitle: \\\"Introducing SafeCoder\\\" \\nthumbnail: \\u002fblog\\u002fassets\\u002f159_safecoder\\u002fthumbnail.jpg\\nauthors:\\n- us...\"],[\"--\\ntitle: \\\"The Reformer - Pushing the limits of language modeling\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f03_reform...\"],[\"--\\ntitle: \\\"Chat Templates: An End to the Silent Performance Killer\\\" \\nthumbnail: \\u002fblog\\u002fassets\\u002fchat-te...\"],[\"--\\ntitle: \\\"Make your llama generation time fly with AWS Inferentia2\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002finferen...\"],[\"--\\ntitle: \\\"Introduction to 3D Gaussian Splatting\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f124_ml-for-games\\u002fthumbnail...\"],[\"--\\ntitle: \\\"Train your ControlNet with diffusers\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f136_train-your-controlnet\\u002ft...\"],[\"--\\ntitle: \\\"Spread Your Wings: Falcon 180B is here\\\" \\nthumbnail: \\u002fblog\\u002fassets\\u002f162_falcon_180b\\u002fthumbnai...\"],[\"--\\ntitle: Swift ğŸ§¨Diffusers - Fast Stable Diffusion for Mac\\nthumbnail: \\u002fblog\\u002fassets\\u002ffast-mac-diffuser...\"],[\"--\\ntitle: \\\"Director of Machine Learning Insights\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f61_ml_director_insights\\u002fth...\"],[\"--\\ntitle: \\\"My Journey to a serverless transformers pipeline on Google Cloud\\\"\\nthumbnail: \\u002fblog\\u002fassets...\"],[\"--\\ntitle: \\\"Machine Learning Experts - Margaret Mitchell\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f57_meg_mitchell_int...\"],[\"--\\ntitle: \\\"Accelerating PyTorch distributed fine-tuning with Intel technologies\\\"\\nthumbnail: \\u002fblog\\u002fas...\"],[\"--\\ntitle: \\\"Introducing new audio and vision documentation in ğŸ¤— Datasets\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f87_...\"],[\"--\\ntitle: \\\"Welcome Mixtral - a SOTA Mixture of Experts on Hugging Face\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002fmixt...\"],[\"--\\ntitle: Hyperparameter Search with Transformers and Ray Tune\\nthumbnail: \\u002fblog\\u002fassets\\u002f06_ray_tune\\u002fr...\"],[\"--\\ntitle: \\\"Accelerate Large Model Training using DeepSpeed\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f83_accelerate_de...\"],[\"--\\ntitle: \\\"Case Study: Millisecond Latency using Hugging Face Infinity and modern CPUs\\\"\\nthumbnail: \\u002f...\"],[\"--\\ntitle: \\\"Introducing âš”ï¸ AI vs. AI âš”ï¸ a deep reinforcement learning multi-agents competition system...\"],[\"--\\ntitle: \\\"SetFit: Efficient Few-Shot Learning Without Prompts\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f103_setfit\\u002fi...\"],[\"--\\ntitle: \\\"Creating a Coding Assistant with StarCoder\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002fstarchat_alpha\\u002fthumbn...\"],[\"--\\ntitle: \\\"AI Policy @ğŸ¤—: Response to the U.S. NTIA's Request for Comment on AI Accountability\\\"\\nthumb...\"],[\"--\\ntitle: \\\"Creating Privacy Preserving AI with Substra\\\" \\nthumbnail: \\u002fblog\\u002fassets\\u002f139_owkin-substra\\u002ft...\"],[\"--\\ntitle:  Deploy Embedding Models with Hugging Face Inference Endpoints\\nthumbnail: \\u002fblog\\u002fassets\\u002f168...\"],[\"--\\ntitle: \\\"What Makes a Dialog Agent Useful?\\\" \\nthumbnail: \\u002fblog\\u002fassets\\u002fdialog-agents\\u002fthumbnail.png\\na...\"],[\"--\\ntitle: \\\"AI for Game Development: Creating a Farming Game in 5 Days. Part 1\\\"\\nthumbnail: \\u002fblog\\u002fasse...\"],[\"--\\ntitle: \\\"From PyTorch DDP to Accelerate to Trainer, mastery of distributed training with ease\\\"\\nthu...\"],[\"--\\ntitle: \\\"Probabilistic Time Series Forecasting with ğŸ¤— Transformers\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f118_ti...\"],[\"--\\ntitle: Image Classification with AutoTrain \\nthumbnail: \\u002fblog\\u002fassets\\u002f105_autotrain-image-classific...\"],[\"--\\ntitle: \\\"Fine-Tune XLSR-Wav2Vec2 for low-resource ASR with ğŸ¤— Transformers\\\"\\nthumbnail: \\u002fblog\\u002fassets...\"],[\"--\\ntitle: \\\"Advantage Actor Critic (A2C)\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f89_deep_rl_a2c\\u002fthumbnail.gif\\nauthor...\"],[\"--\\ntitle: \\\"Faster Training and Inference: Habana GaudiÂ®2 vs Nvidia A100 80GB\\\"\\nthumbnail: \\u002fblog\\u002fasset...\"],[\"--\\ntitle: \\\"Parameter-Efficient Fine-Tuning using ğŸ¤— PEFT\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f130_peft\\u002fthumbnail....\"],[\"--\\ntitle: \\\"MTEB: Massive Text Embedding Benchmark\\\" \\nthumbnail: \\u002fblog\\u002fassets\\u002f110_mteb\\u002fthumbnail.png\\na...\"],[\"--\\ntitle: Deploying ğŸ¤— ViT on Vertex AI\\nthumbnail: \\u002fblog\\u002fassets\\u002f97_vertex_ai\\u002fimage1.png\\nauthors:\\n- us...\"],[\"--\\ntitle: 'Few-shot learning in practice: GPT-Neo and the ğŸ¤— Accelerated Inference API'\\n# thumbnail: ...\"],[\"--\\ntitle: \\\"Director of Machine Learning Insights [Part 3: Finance Edition]\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f...\"],[\"--\\ntitle: \\\"Instruction-tuning Stable Diffusion with InstructPix2Pix\\\" \\nthumbnail: assets\\u002finstruction_...\"],[\"--\\ntitle: \\\"Deploying the AI Comic Factory using the Inference API\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f165_ai_co...\"],[\"--\\ntitle: What's new in Diffusers? ğŸ¨\\nthumbnail: \\u002fblog\\u002fassets\\u002f102_diffusers_2nd_month\\u002finpainting.png\\n...\"],[\"--\\ntitle: \\\"Announcing the Hugging Face Fellowship Program\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f62_fellowship\\u002ffel...\"],[\"--\\ntitle: \\\"How ğŸ¤— Accelerate runs very large models thanks to PyTorch\\\"\\nthumbnail: \\u002fblog\\u002fassets\\u002f104_ac...\"],[\"--\\ntitle: 'The Partnership: Amazon SageMaker and Hugging Face'\\nthumbnail: \\u002fblog\\u002fassets\\u002f17_the_partne...\"],[\"--\\ntitle: \\\"Introducing Optimum: The Optimization Toolkit for Transformers at Scale\\\"\\nauthors:\\n- user:...\"]],\"hovertemplate\":\"source=blog\\u003cbr\\u003esymbol=circle\\u003cbr\\u003ex=%{x}\\u003cbr\\u003ey=%{y}\\u003cbr\\u003esize_col=%{marker.size}\\u003cbr\\u003eextract=%{customdata[0]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"blog, circle\",\"marker\":{\"color\":\"#B6E880\",\"size\":[4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4],\"sizemode\":\"area\",\"sizeref\":0.25,\"symbol\":\"circle\",\"line\":{\"color\":\"DarkSlateGrey\",\"width\":0},\"opacity\":1},\"mode\":\"markers\",\"name\":\"blog, circle\",\"showlegend\":true,\"x\":[-4.496202,-2.5375817,1.5201082,-3.4217021,-2.9318752,-8.79105,-2.0967731,-6.1446505,-3.9640532,-3.4564247,-2.9982693,-4.959545,-1.5155044,-3.4616606,-4.992197,-11.686289,-4.7183704,-3.3814979,-6.0323935,-4.249521,-5.905151,-3.2810946,-4.2986403,-3.823191,-3.1276202,-4.5917225,-4.8422785,-4.6971807,-3.1621985,-6.2877617,-11.270749,-4.1972485,-1.3249454,-4.457445,-1.8311542,-13.331596,-3.827785,-4.4527464,-1.8477399,-2.8655212,-3.6753035,-4.4338574,-1.6580684,-4.2465873,-3.0284953,-3.3917212,-3.5323646,-7.4998245,-5.0741324,-9.9985,-13.296076,-5.1104627,-8.143151,-4.318786,-8.787122,0.094265774,-11.447471,-4.017324,16.808624,-3.9944985,-3.0703678,-3.3758676,-3.2005172,-5.783618,-4.459397,-2.8064017,-0.6174761,-4.407456,-13.514547,-1.7535269,-2.435249,-1.0617375,-2.9598365,-4.8812027,-13.004532,-5.9478216,-4.210757,-6.005929,-4.8051376,-5.613064,-4.157345,-4.2110796,-3.1957536,-3.8124642,-5.0266604,-5.116375,3.0873404,-3.313938,-4.1963973,-4.835517,-3.157987,-3.364983,-1.6194842,-5.0488033,-3.681765,-2.4402122,-3.2181385,-4.8266006,-3.1397512,-4.8844986,-3.1482136,-3.4375432,-5.093444,-3.4333065,-5.0188613,-1.8855172,-3.7189262,-7.7652187,-13.425151,0.91839665,-13.639329,-3.4250832,-2.4630413,-3.1515079,-4.7298656,-3.738717,-13.006916,-3.3832502,-3.1306307,-13.108696,17.264978,-5.2271624,-3.210597,-6.998854,-4.437496,-4.974868,-3.2079303,-3.6302645,-0.28722325,-4.5642633,-4.0996833,-13.203634,-3.9504225,1.7098875,-13.571751,-7.3696227,-3.5156462,-3.449411,-5.1609225,-7.5565996,-2.4952178,-4.955659,-13.285407,-6.818743,-3.309003,-3.778131,-4.546787,-13.39957,-7.074927,-7.388235,-3.9924662,-3.6571064,-4.4175878,-6.8568773,17.22134,-3.9951527,-4.1634297,-1.4062625,-2.3198106,-0.91517055,-4.879632,-4.4972777,-3.3257143,-0.6035216,-13.4536915,-3.9413707,-4.954241,-3.344396,-2.9394011,-2.8630419,-4.256761,-3.1360765,-13.518403,-13.577771,-9.588031,-5.2181554,-13.311924,-4.5289187,-4.3859878,-3.563428,16.96559,-3.9630485,-3.4807017,-0.7484647,-3.3620877,-4.9186625,-13.6854515,-4.3028426,-4.213012,-3.2999623,-3.282096,-13.545966,-10.311448,-12.034776,-13.349959,-2.5652902,-4.6130114,-0.22754143,-4.0824676,-2.6592684,-5.992887,-10.562738,-3.171824,-7.2087955,-4.7901907,-1.6919091,-2.371636,-3.9741752,-10.4501095,-3.7704062,-4.3857775,-3.913709,-7.0093102,-4.7154226,-4.156614,-5.105222,-2.7157757,-0.8522834,-3.1902893,-7.4966645,-2.614455,-2.207227,-3.6253147,-7.142775,-0.7655845,-3.5559864,-7.1389976,-2.9504433,-3.846886,-3.6961882,1.618013,-3.2443192,-4.327799,-13.731456,-10.3231325,-5.243363,-2.4820988,-0.9096521,-3.26423,-3.4359593,-7.6755414,-5.2203283,-4.821738,-5.039507,-4.4145465,-1.703145,-4.0445766,-2.4907918,-2.1687195,-2.7046335,-4.277712,-3.247153,-0.52079725,-3.4413476,-3.366692,-1.4278611,-2.3705735,-2.6212418,-5.8722982,-3.3706336,-7.534169,-3.2953038,-2.5151377,-7.320593,-5.2905173,-13.689585,-1.2108595,-4.5582256,-11.660295,-5.4209557,-2.8958576,-3.4362452,-13.293759,-7.558089,-3.0810645,-2.7177303,-5.3237953,-7.485364,-6.2584863,-3.990258,-4.4112134,-4.641127,-5.3888245,-2.784761,-4.0071,-13.592785,-4.459194,-13.428713,-3.3822227,-4.0565023,-3.3610885,-4.7399,-2.1288807,-3.3934734,-4.7487655,-3.9570456,-3.790406,-3.0422983,-7.3150125,-4.503371,-3.0670896,-3.4475944,-1.1458491,-4.6753554,-3.4629643,-4.2825203,-8.913367,-5.2902865,-7.4828777,-2.9879045,-4.0766935,-7.138504,-5.3434744,-3.340327,-5.7839885,-3.3265529,-13.303108,-1.9687648,-13.390526,-3.0278826,-4.277021,-2.121472,-4.0836024],\"xaxis\":\"x\",\"y\":[7.6903443,7.293056,3.1398695,-4.4411993,6.731231,2.717682,5.935056,6.495515,6.404574,8.412018,8.099241,7.700664,7.058273,-4.5406084,6.662422,-0.56897753,6.176983,8.455392,6.471787,6.126347,6.466462,4.050356,7.7816215,6.8374143,8.936019,7.6562686,7.7335334,7.750519,8.375064,5.3171334,-0.6552585,7.8337474,6.4653096,4.6020403,7.3069434,-6.3762197,4.434877,7.347051,7.2139626,4.385291,8.161359,5.48649,7.07379,6.457608,8.90341,6.35112,8.309468,1.4292758,3.7279272,0.4244459,-4.3926015,6.981181,5.155624,5.3761377,2.834667,3.0703964,-0.6310975,6.9240165,0.15739363,7.498889,8.14585,-4.7410808,8.997579,5.7457438,4.2503595,7.9444118,5.307832,7.4169135,-5.5861554,7.4708223,5.796694,6.2692695,-7.1705923,7.1875873,-4.9339385,6.350538,7.2043257,6.3988314,7.3496027,6.8709016,6.662348,6.6100597,6.3078237,3.99934,7.6888905,6.609477,5.871323,6.779381,8.1909895,7.205136,8.611417,8.551531,7.0326824,6.685728,6.295255,7.2729673,8.903391,5.8639255,8.884006,3.0627193,8.8731985,-4.6186733,6.6631594,-4.610218,6.9240584,5.68878,7.3040934,-1.0642341,-6.1579847,3.0419402,-5.8409195,8.549888,6.175419,-5.4200506,7.412974,5.879947,-6.047169,8.379707,6.9798007,-6.139428,1.1140308,6.8769093,8.493987,7.2005258,7.751224,5.4424753,8.83812,7.720457,4.976564,7.6007023,7.522173,-6.387649,7.2445173,5.448691,-5.6594453,-1.1798178,8.686888,7.1138725,6.417089,-1.4061912,6.583664,7.815499,-6.2754493,4.7284837,8.731611,7.732765,4.251991,-5.7420616,3.8002653,-1.0509702,6.325846,7.32331,4.780318,-1.1297529,0.7287544,7.0798616,3.9982798,5.4229302,7.3326755,6.013395,5.0116177,5.833801,8.723374,5.137085,-6.182329,7.2407737,7.8194027,6.111151,-6.411229,6.932826,6.5684547,8.819898,-6.35159,-5.8583736,0.72963285,3.94488,-5.984252,4.7021294,7.6852627,6.721702,0.95191073,7.5793037,-4.435581,7.08553,-4.772276,3.2390213,-6.067718,6.87116,4.899339,8.43374,8.502689,-4.3061805,0.17888731,-1.8604249,-6.249542,-6.6965103,6.206846,5.0538774,7.136275,5.7190433,5.063223,3.3409839,-6.052507,1.3036623,6.660519,6.704619,-7.062061,7.248849,2.681943,6.6038747,7.627538,6.586496,3.8554103,4.4227967,7.0811424,6.171575,6.878509,5.226443,8.904871,-1.3777119,-7.6268287,7.659745,-4.064556,3.8066971,5.1172233,6.8229113,4.099524,6.9505277,3.7066016,8.19294,5.4516087,8.683823,7.1043067,-6.0607095,0.11499066,6.850135,6.1397634,5.4008055,8.507547,-4.6066246,-1.4832568,6.8594413,6.4704194,7.9184694,4.561447,5.802641,7.276009,-6.7084312,6.9164214,7.596356,7.3881373,5.001148,5.4776754,8.748739,7.191616,2.4277604,4.9368863,7.775005,6.5773897,8.477344,-1.014234,8.510583,-7.07982,3.4333582,6.093903,-5.3489923,5.394741,6.6027994,-1.1987107,5.7074924,7.79258,4.651728,-6.1577697,-1.4704856,8.337733,6.4810376,7.1187487,-1.2292893,4.3100815,6.974156,6.725267,7.5529804,5.655517,6.898384,-3.29379,-4.105147,6.7844744,-6.208269,8.650987,7.2646666,8.750823,5.838764,5.853688,6.959225,6.3819404,4.6247616,6.13823,-5.710471,3.207304,6.0635886,8.939359,8.551966,7.2407303,7.2478194,-4.504463,3.9360998,2.6736703,6.1485276,-1.5363528,-7.287199,7.157468,2.8401294,7.1677375,6.008568,6.5095205,8.669368,-4.5807905,6.7182593,-6.0536838,8.341766,5.0244374,7.424938,7.131859],\"yaxis\":\"y\",\"type\":\"scattergl\"},{\"customdata\":[[\"hat is dynamic padding? In the \\\"Batching Inputs together\\\" video, we have seen that to be able to gro...\"],[\"ow to slice and dice a dataset. Most of the time, the data you work with wonâ€™t be perfectly prepared...\"],[\"he Hugging Face Datasets library: A Quick overview. The Hugging Face Datasets library is a library t...\"],[\"efore diving in character-based tokenization, understanding why this kind of tokenization is interes...\"],[\"Normalization and pre-tokenization[[normalization-and-pre-tokenization]]\\n\\n\\u003cCourseFloatingBanner chap...\"],[\"ow to preprocess pairs of sentences? We have seen how to tokenize single sentences and batch them to...\"],[\"The Hugging Face Course\\n\\nThis repo contains the content that's used to create the **[Hugging Face co...\"],[\"What to do when you get an error[[what-to-do-when-you-get-an-error]]\\n\\n\\u003cCourseFloatingBanner chapter=...\"],[\"hat is transfer learning? The idea of Transfer Learning is to leverage the knowledge acquired by a m...\"],[\"ow to batch inputs together? In this video, we will see how to batch input sequences together. In ge...\"],[\"upercharge your Pytorch training loop with Hugging Face Accelerate. There are multiple setups on whi...\"],[\"Building your first demo[[building-your-first-demo]]\\n\\n\\u003cCourseFloatingBanner chapter={9}\\n  classNames...\"],[\"Natural Language Processing[[natural-language-processing]]\\n\\n\\u003cCourseFloatingBanner\\n    chapter={1}\\n  ...\"],[\"Introduction[[introduction]]\\n\\n\\u003cCourseFloatingBanner\\n    chapter={8}\\n    classNames=\\\"absolute z-10 ri...\"],[\"FrameworkSwitchCourse {fw} \\u002f\\u003e\\n\\n# Sharing pretrained models[[sharing-pretrained-models]]\\n\\n{#if fw ===...\"],[\"n these few videos, we'll take a look at the tokenizers. In Natural Language Processing, most of the...\"],[\"FrameworkSwitchCourse {fw} \\u002f\\u003e\\n\\n# Fine-tuning a masked language model[[fine-tuning-a-masked-language-...\"],[\"FrameworkSwitchCourse {fw} \\u002f\\u003e\\n\\n# Using pretrained models[[using-pretrained-models]]\\n\\n{#if fw === 'pt...\"],[\"Understanding the Interface class[[understanding-the-interface-class]]\\n\\n\\u003cCourseFloatingBanner chapte...\"],[\"ou are at the right place if you want to understand what the Byte pair Encoding subword tokenization...\"],[\"ome bugs in your code are very straightforward. You try running it, you get a syntax error somewhere...\"],[\"How to write a good issue[[how-to-write-a-good-issue]]\\n\\n\\u003cCourseFloatingBanner chapter={8}\\n  classNam...\"],[\"oading a custom dataset. Although the Hugging Face Hub hosts over a thousand public datasets, you'll...\"],[\"Summary[[summary]]\\n\\n\\u003cCourseFloatingBanner\\n    chapter={1}\\n    classNames=\\\"absolute z-10 right-0 top-...\"],[\"What if my dataset isn't on the Hub?[[what-if-my-dataset-isnt-on-the-hub]]\\n\\n\\u003cCourseFloatingBanner ch...\"],[\"rite your own training loop in PyTorch. In this video, we will look at how we can do the same fine-t...\"],[\"atasets and DataFrames equals love. Although the processing functions of Datasets will cover most th...\"],[\"n this video, we'll study the decoder architecture. An example of a popular decoder-only architectur...\"],[\"n our other videos, and as always, there'll be links below if you want to check those out, we showed...\"],[\"Unigram tokenization[[unigram-tokenization]]\\n\\n\\u003cCourseFloatingBanner chapter={6}\\n  classNames=\\\"absolu...\"],[\"n this video, we're going to go over the HuggingFace Model Hub navigation. This is the huggingface.c...\"],[\"n this video, we're going to see how to load and fine-tune a pre-trained model. It's very quick, and...\"],[\"Part 2 Release Event[[part-2-release-event]]\\n\\nFor the release of part 2 of the course, we organized ...\"],[\"How do Transformers work?[[how-do-transformers-work]]\\n\\n\\u003cCourseFloatingBanner\\n    chapter={1}\\n    cla...\"],[\"n this video we'll take a look at how you upload your very own dataset to the Hub. The first you'll ...\"],[\"n this video we take a look at the mysterious sounding metric called Perplexity. You might have enco...\"],[\"Decoder models[[decoder-models]]\\n\\n\\u003cCourseFloatingBanner\\n    chapter={1}\\n    classNames=\\\"absolute z-1...\"],[\"n this video, we'll study the encoder architecture. An example of a popular encoder-only architectur...\"],[\"FrameworkSwitchCourse {fw} \\u002f\\u003e\\n\\n# Translation[[translation]]\\n\\n{#if fw === 'pt'}\\n\\n\\u003cCourseFloatingBanne...\"],[\"Introduction[[introduction]]\\n\\n\\u003cCourseFloatingBanner\\n    chapter={6}\\n    classNames=\\\"absolute z-10 ri...\"],[\"Introduction[[introduction]]\\n\\n\\u003cCourseFloatingBanner\\n    chapter={5}\\n    classNames=\\\"absolute z-10 ri...\"],[\"FrameworkSwitchCourse {fw} \\u002f\\u003e\\n\\n# Question answering[[question-answering]]\\n\\n{#if fw === 'pt'}\\n\\n\\u003cCours...\"],[\"ow to write a good issue on GitHub? GitHub is the main place for the Hugging Face open source librar...\"],[\"The Hugging Face Hub[[the-hugging-face-hub]]\\n\\n\\u003cCourseFloatingBanner\\n    chapter={4}\\n    classNames=\\\"...\"],[\"n this video, we will study together \\\"the Unigram Language Model subword tokenization algorithm\\\".\\n\\nT...\"],[\"Creating your own dataset[[creating-your-own-dataset]]\\n\\n\\u003cCourseFloatingBanner chapter={5}\\n  classNam...\"],[\"FrameworkSwitchCourse {fw} \\u002f\\u003e\\n\\n\\u003c!-- DISABLE-FRONTMATTER-SECTIONS --\\u003e\\n\\n# End-of-chapter quiz[[end-of-...\"],[\"FrameworkSwitchCourse {fw} \\u002f\\u003e\\n\\n# Processing the data[[processing-the-data]]\\n\\n{#if fw === 'pt'}\\n\\n\\u003cCou...\"],[\"FrameworkSwitchCourse {fw} \\u002f\\u003e\\n\\n# Models[[models]]\\n\\n{#if fw === 'pt'}\\n\\n\\u003cCourseFloatingBanner chapter=...\"],[\"ow to instantiate a Transformers model? In this video we will look at how we can create and use a mo...\"],[\"Introduction to Gradio[[introduction-to-gradio]]\\n\\n\\u003cCourseFloatingBanner\\n    chapter={9}\\n    classNam...\"],[\"FrameworkSwitchCourse {fw} \\u002f\\u003e\\n\\n# Handling multiple sequences[[handling-multiple-sequences]]\\n\\n{#if fw...\"],[\"Advanced Interface features[[advanced-interface-features]]\\n\\n\\u003cCourseFloatingBanner chapter={9}\\n  clas...\"],[\"n this video we will see together what is the purpose of training a tokenizer, what are the key step...\"],[\"he Trainer API. The Transformers library provides a Trainer API that allows you to easily fine-tune ...\"],[\"he tokenizer pipeline. In this video, we'll look at how a tokenizer converts raw text to numbers tha...\"],[\"Sharing demos with others[[sharing-demos-with-others]]\\n\\n\\u003cCourseFloatingBanner chapter={9}\\n  classNam...\"],[\"FrameworkSwitchCourse {fw} \\u002f\\u003e\\n\\n# Fast tokenizers in the QA pipeline[[fast-tokenizers-in-the-qa-pipel...\"],[\"he tokenization pipeline involves several steps that convert raw text into numbers. In this video, w...\"],[\"et's see how to preprocess a dataset for summarization. This is the task of well summarizing a long ...\"],[\"he post-processing step in a question answering task. When doing question answering, the processing ...\"],[\"A full training[[a-full-training]]\\n\\n\\u003cCourseFloatingBanner chapter={3}\\n  classNames=\\\"absolute z-10 ri...\"],[\"Transformers, what can they do?[[transformers-what-can-they-do]]\\n\\n\\u003cCourseFloatingBanner chapter={1}\\n...\"],[\"sing the Python debugger in a notebook. In this video, we'll learn how to use the Python debugger in...\"],[\"ow to instantiate a Transformers model? In this video we will look at how we can create and use a mo...\"],[\"n this video, we're going to understand how to manage a model repository on the HuggingFace model hu...\"],[\"FrameworkSwitchCourse {fw} \\u002f\\u003e\\n\\n# Behind the pipeline[[behind-the-pipeline]]\\n\\n{#if fw === 'pt'}\\n\\n\\u003cCou...\"],[\"ğŸ¤— Datasets, check![[datasets-check]]\\n\\n\\u003cCourseFloatingBanner\\n    chapter={5}\\n    classNames=\\\"absolute...\"],[\"n this video we will see together what is the normalizer component that we find at the beginning of ...\"],[\"Building a tokenizer, block by block[[building-a-tokenizer-block-by-block]]\\n\\n\\u003cCourseFloatingBanner c...\"],[\"FrameworkSwitchCourse {fw} \\u002f\\u003e\\n\\n\\u003c!-- DISABLE-FRONTMATTER-SECTIONS --\\u003e\\n\\n# End-of-chapter quiz[[end-of-...\"],[\"FrameworkSwitchCourse {fw} \\u002f\\u003e\\n\\n\\u003c!-- DISABLE-FRONTMATTER-SECTIONS --\\u003e\\n\\n# End-of-chapter quiz[[end-of-...\"],[\"ext embeddings and semantic search. In this video weâ€™ll explore how Transformer models represent tex...\"],[\"!-- DISABLE-FRONTMATTER-SECTIONS --\\u003e\\n\\n# End-of-chapter quiz[[end-of-chapter-quiz]]\\n\\n\\u003cCourseFloatingB...\"],[\"et's study the transformer architecture. This video is the introductory video to the encoders, decod...\"],[\"Introduction to Gradio Blocks[[introduction-to-gradio-blocks]]\\n\\n\\u003cCourseFloatingBanner chapter={9}\\n  ...\"],[\"!-- DISABLE-FRONTMATTER-SECTIONS --\\u003e\\n\\n# End-of-chapter quiz[[end-of-chapter-quiz]]\\n\\n\\u003cCourseFloatingB...\"],[\"i, this is going to be a video about the push_to_hub API for Tensorflow and Keras. So, to get starte...\"],[\"et's take a look at word-based tokenization. Word-based tokenization is the idea of splitting the ra...\"],[\"FrameworkSwitchCourse {fw} \\u002f\\u003e\\n\\n# Putting it all together[[putting-it-all-together]]\\n\\n{#if fw === 'pt...\"],[\"n this video, I'm going to give you a very quick introduction to how our transformers models work to...\"],[\"Gradio, check![[gradio-check]]\\n\\n\\u003cCourseFloatingBanner\\n    chapter={9}\\n    classNames=\\\"absolute z-10 ...\"],[\"FrameworkSwitchCourse {fw} \\u002f\\u003e\\n\\n# Fast tokenizers' special powers[[fast-tokenizers-special-powers]]\\n\\n...\"],[\"et's take a look at subword-based tokenization. Understanding why subword-based tokenization is inte...\"],[\"et's see together what is the training strategy of the WordPiece algorithm and how it performs the t...\"],[\"FrameworkSwitchCourse {fw} \\u002f\\u003e\\n\\n# Summarization[[summarization]]\\n\\n{#if fw === 'pt'}\\n\\n\\u003cCourseFloatingB...\"],[\"et's study how to preprocess a dataset for token classification! Token classification regroups any t...\"],[\"he fast tokenizers of the Transformers library are fast, but they also implement features that will ...\"],[\"et's have a look inside the question answering pipeline. The question answering pipeline can extract...\"],[\"Basic usage completed![[basic-usage-completed]]\\n\\n\\u003cCourseFloatingBanner\\n    chapter={2}\\n    className...\"],[\"et's study how to preprocess a dataset for question answering! Question answering is the task of fin...\"],[\"FrameworkSwitchCourse {fw} \\u002f\\u003e\\n\\n# Introduction[[introduction]]\\n\\n\\u003cCourseFloatingBanner\\n    chapter={7}...\"],[\"hat happens inside the pipeline function? In this video, we will look at what actually happens when ...\"],[\"et's see how to preprocess a dataset for translation. This is the task of well translating a sentenc...\"],[\"FrameworkSwitchCourse {fw} \\u002f\\u003e\\n\\n# Fine-tuning, Check![[fine-tuning-check]]\\n\\n\\u003cCourseFloatingBanner\\n   ...\"],[\"FrameworkSwitchCourse {fw} \\u002f\\u003e\\n\\n# Debugging the training pipeline[[debugging-the-training-pipeline]]\\n...\"],[\"FrameworkSwitchCourse {fw} \\u002f\\u003e\\n\\n# Debugging the training pipeline[[debugging-the-training-pipeline]]\\n...\"],[\"Part 1 completed![[part-1-completed]]\\n\\n\\u003cCourseFloatingBanner\\n    chapter={4}\\n    classNames=\\\"absolut...\"],[\"Bias and limitations[[bias-and-limitations]]\\n\\n\\u003cCourseFloatingBanner chapter={1}\\n  classNames=\\\"absolu...\"],[\"n this video, we'll study the encoder-decoder architecture. An example of a popular encoder-decoder ...\"],[\"et's have a look inside the token classification pipeline. In the pipeline video, we looked at the d...\"],[\"hat is the ROUGE metric? For many NLP tasks we can use common metrics like accuracy or F1 score, but...\"],[\"WordPiece tokenization[[wordpiece-tokenization]]\\n\\n\\u003cCourseFloatingBanner chapter={6}\\n  classNames=\\\"ab...\"],[\"emory mapping and streaming. In this video we'll take a look at two core features of the Datasets li...\"],[\"Introduction[[introduction]]\\n\\n\\u003cCourseFloatingBanner\\n    chapter={2}\\n    classNames=\\\"absolute z-10 ri...\"],[\"Introduction[[introduction]]\\n\\nWelcome to the Hugging Face course! This introduction will guide you t...\"],[\"n this video we take a look at the data processing necessary to train causal language models. Causal...\"],[\"hat is the BLEU metric? For many NLP tasks we can use common metrics like accuracy or F1 score, but ...\"],[\"elcome to the Hugging Face Course! This course has been designed to teach you all about the Hugging ...\"],[\"Introduction[[introduction]]\\n\\n\\u003cCourseFloatingBanner\\n    chapter={1}\\n    classNames=\\\"absolute z-10 ri...\"],[\"ote: the following transcripts are associated with Merve Noyan's videos in the Hugging Face Tasks pl...\"],[\"as recorded adlib - need to generate transcript with Whisper :)...\"],[\"Big data? ğŸ¤— Datasets to the rescue![[big-data-datasets-to-the-rescue]]\\n\\n\\u003cCourseFloatingBanner chapte...\"],[\"et's see how we can preprocess our data for masked language modeling. As a reminder, masked language...\"],[\"Subtitles for the course videos\\n\\nThis folder contains all the subtitles for the course videos on You...\"],[\"he pipeline function. The pipeline function is the most high-level API of the Transformers library. ...\"],[\"Sequence-to-sequence models[sequence-to-sequence-models]\\n\\n\\u003cCourseFloatingBanner\\n    chapter={1}\\n    ...\"],[\"aving and reloading a dataset. In this video we'll take a look saving a dataset in various formats, ...\"],[\"n our other videos we talked about the basics of fine-tuning a language model with Tensorflow (and a...\"],[\"Tokenizers, check![[tokenizers-check]]\\n\\n\\u003cCourseFloatingBanner\\n    chapter={6}\\n    classNames=\\\"absolu...\"],[\"hat happens inside the pipeline function? In this video, we will look at what actually happens when ...\"],[\"!-- DISABLE-FRONTMATTER-SECTIONS --\\u003e\\n\\n# End-of-chapter quiz[[end-of-chapter-quiz]]\\n\\n\\u003cCourseFloatingB...\"],[\"n this video we will see how you can create your own tokenizer from scratch! To create your own toke...\"],[\"Gradio Blocks Party[[gradio-blocks-party]]\\n\\nAlong with the release of the Gradio chapter of the cour...\"],[\"Training a new tokenizer from an old one[[training-a-new-tokenizer-from-an-old-one]]\\n\\n\\u003cCourseFloatin...\"],[\"FrameworkSwitchCourse {fw} \\u002f\\u003e\\n\\n\\u003c!-- DISABLE-FRONTMATTER-SECTIONS --\\u003e\\n\\n# End-of-chapter quiz[[end-of-...\"],[\"et's have a look inside the token classification pipeline. In the pipeline video, we looked at the d...\"],[\"FrameworkSwitchCourse {fw} \\u002f\\u003e\\n\\n# Fine-tuning a model with Keras[[fine-tuning-a-model-with-keras]]\\n\\n\\u003c...\"],[\"he post-processing step in a question answering task. When doing question answering, the processing ...\"],[\"Asking for help on the forums[[asking-for-help-on-the-forums]]\\n\\n\\u003cCourseFloatingBanner chapter={8}\\n  ...\"],[\"n this video, we will see how to debug an error you encounter when running trainer.train(). As an ex...\"],[\"Encoder models[[encoder-models]]\\n\\n\\u003cCourseFloatingBanner\\n    chapter={1}\\n    classNames=\\\"absolute z-1...\"],[\"FrameworkSwitchCourse {fw} \\u002f\\u003e\\n\\n# Token classification[[token-classification]]\\n\\n{#if fw === 'pt'}\\n\\n\\u003cC...\"],[\"n this video we take a look at setting up a custom loss function for training. In the default loss f...\"],[\"Time to slice and dice[[time-to-slice-and-dice]]\\n\\n\\u003cCourseFloatingBanner chapter={5}\\n  classNames=\\\"ab...\"],[\"FrameworkSwitchCourse {fw} \\u002f\\u003e\\n\\n# Introduction[[introduction]]\\n\\n\\u003cCourseFloatingBanner\\n    chapter={3}...\"],[\"!-- DISABLE-FRONTMATTER-SECTIONS --\\u003e\\n\\n# End-of-chapter quiz[[end-of-chapter-quiz]]\\n\\n\\u003cCourseFloatingB...\"],[\"hy are fast tokenizers called fast? In this video we will see exactly how much faster the so-called ...\"],[\"Part 2 completed![[part-2-completed]]\\n\\n\\u003cCourseFloatingBanner\\n    chapter={8}\\n    classNames=\\\"absolut...\"],[\"n a lot of our examples, you're going to see DataCollators popping up over and over. They're used in...\"],[\"Integrations with the Hugging Face Hub[[integrations-with-the-hugging-face-hub]]\\n\\n\\u003cCourseFloatingBan...\"],[\"FrameworkSwitchCourse {fw} \\u002f\\u003e\\n\\n# Fine-tuning a model with the Trainer API[[fine-tuning-a-model-with-...\"],[\"FrameworkSwitchCourse {fw} \\u002f\\u003e\\n\\n# Tokenizers[[tokenizers]]\\n\\n{#if fw === 'pt'}\\n\\n\\u003cCourseFloatingBanner ...\"],[\"Building a model card[[building-a-model-card]]\\n\\n\\u003cCourseFloatingBanner\\n    chapter={4}\\n    classNames...\"],[\"Byte-Pair Encoding tokenization[[byte-pair-encoding-tokenization]]\\n\\n\\u003cCourseFloatingBanner chapter={6...\"],[\"Live sessions and workshops[[live-sessions-and-workshops]]\\n\\nFor the release of parts 1 and 2 of the ...\"],[\"sing the Python debugger in a terminal. In this video, we'll learn how to use the Python debugger in...\"],[\"n this video, we will learn the first things to do when you get an error. Let's say we want to use t...\"],[\"Mastering NLP[[mastering-nlp]]\\n\\n\\u003cCourseFloatingBanner\\n    chapter={7}\\n    classNames=\\\"absolute z-10 ...\"],[\"FrameworkSwitchCourse {fw} \\u002f\\u003e\\n\\n# Semantic search with FAISS[[semantic-search-with-faiss]]\\n\\n{#if fw =...\"],[\"he Push to Hub API. Let's have a look at the push_to_hub API. You will need to be logged in with you...\"],[\"!-- DISABLE-FRONTMATTER-SECTIONS --\\u003e\\n\\n# End-of-chapter quiz[[end-of-chapter-quiz]]\\n\\n\\u003cCourseFloatingB...\"],[\"FrameworkSwitchCourse {fw} \\u002f\\u003e\\n\\n# Training a causal language model from scratch[[training-a-causal-la...\"],[\"ow to ask a question on the Hugging Face forums?\\n\\nIf you have a general question or are looking to d...\"],[\"hat is domain adaptation? When fine-tuning a pretrained model on a new dataset, the fine-tuned model...\"]],\"hovertemplate\":\"source=course\\u003cbr\\u003esymbol=circle\\u003cbr\\u003ex=%{x}\\u003cbr\\u003ey=%{y}\\u003cbr\\u003esize_col=%{marker.size}\\u003cbr\\u003eextract=%{customdata[0]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"course, circle\",\"marker\":{\"color\":\"#FF97FF\",\"size\":[4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4],\"sizemode\":\"area\",\"sizeref\":0.25,\"symbol\":\"circle\",\"line\":{\"color\":\"DarkSlateGrey\",\"width\":0},\"opacity\":1},\"mode\":\"markers\",\"name\":\"course, circle\",\"showlegend\":true,\"x\":[-8.327039,1.2504255,1.3915576,-9.750765,-9.992675,-7.963344,-3.039309,-1.6326319,-6.943353,-7.98608,-4.1239133,16.742208,-6.174648,-2.7793503,-7.611179,-9.701894,-7.85349,-7.7590914,16.513927,-9.784714,-2.4599822,-1.4863771,1.6899216,-6.210791,1.8082076,-4.6305227,1.2732944,-8.686204,-5.6692014,-9.795774,-0.7626366,-5.8648424,-3.0809782,-5.1027064,1.4486735,6.9008822,-8.230639,-8.676063,-7.790374,-9.790995,1.2664232,-7.531866,-2.3882778,-0.5284757,-9.68138,0.52050424,-8.077918,-7.8867764,-7.752815,-5.420373,16.769514,-7.7846584,16.55294,-9.754507,-4.8121395,-9.533968,16.707207,-7.7156916,-9.885442,-8.418326,-7.6693172,-8.570614,-4.4905634,-2.2935512,-5.371371,0.6979232,-7.790233,1.0772554,-9.912383,-10.034281,-7.756775,-0.25168532,-7.386244,-1.8422382,-8.716499,16.849741,16.717028,-2.0070856,-9.645545,-7.897277,-5.014274,16.63688,-7.7534523,-9.722571,-9.653279,-7.7624555,-8.671828,-9.748201,-7.613584,-7.7204547,-7.6451993,-7.8941927,-8.200847,-8.874728,-7.811021,-7.7192616,-7.6274886,-3.0914083,-6.0550375,-8.463628,-8.105334,7.0168576,-9.746668,1.5825007,-5.3296037,-0.7561129,-8.187374,7.1079373,-2.0397956,-3.5274646,-7.0557003,-2.4428236,1.1451926,-8.458209,-2.7851121,-7.713038,-8.209188,1.5984801,-6.097013,-9.698424,-8.2530155,-6.7168846,-9.834454,16.524853,-9.71208,-7.5195966,-8.019654,-7.871688,-7.5724277,-0.08002973,-2.5345867,-8.305409,-7.800008,-6.3681574,1.0482713,-7.638243,1.280317,-10.057637,-3.3766372,0.9757326,-1.0867258,-7.8539386,-7.851635,-0.60053456,-9.743258,-3.3169847,-2.101843,-1.9377294,-4.1466165,-7.7407136,-0.8791584,-7.789769,-7.8392606,0.6092644,-6.9910264],\"xaxis\":\"x\",\"y\":[6.561471,2.019796,3.0227022,7.5468493,7.9377737,7.0789347,4.7406464,3.3375902,3.4533653,6.804033,3.9533165,0.29432133,6.56573,4.3983426,9.36922,7.6435933,9.120117,9.206769,0.31547943,7.495302,2.968501,3.749547,2.7768595,5.596855,2.9449952,3.4088175,1.876367,4.778775,3.0702677,7.673383,5.4003763,3.1758766,5.093481,3.6922212,3.331255,-10.027008,5.1452837,4.6168613,8.796629,7.8871818,2.4681053,8.002912,2.807774,5.16155,7.5341306,4.064194,7.933175,8.96186,9.180254,3.083123,0.43412766,8.907099,0.37066627,7.654271,3.3756862,7.717802,0.3822027,8.629834,7.850864,6.8228493,7.2820435,8.179172,3.7682037,3.0536675,3.0649812,5.4513083,9.143092,2.8619094,7.847608,8.031022,8.325722,5.4949646,6.6914945,2.979522,4.2659307,0.16357364,0.39907613,3.8734655,7.4796777,8.989688,2.9089189,0.3150827,8.745833,7.535578,7.511737,8.748214,7.1282506,7.756507,7.464112,7.07743,7.2620792,8.721797,7.3088665,6.898873,9.23066,9.292631,9.345427,5.712838,4.8243265,4.9163294,7.1126904,-9.563917,7.6132984,2.0870178,3.3920958,3.577656,6.346121,-9.443898,4.906215,4.74412,6.79504,3.4782934,2.4520776,6.7543497,4.5271206,6.948562,5.1986766,2.222481,3.423185,7.8962445,7.2561674,7.273473,7.831649,0.40280744,7.8482738,7.797043,7.091407,9.092833,7.3092966,4.559519,2.8657258,4.9784336,8.799341,3.9040282,2.2841978,9.1974125,2.5867755,7.8226533,5.3239207,1.8406937,5.150471,9.185841,8.807941,4.936412,7.5854673,4.7382617,2.9523673,2.966707,5.1166415,8.950977,4.820443,7.6657395,9.085902,5.345421,3.232341],\"yaxis\":\"y\",\"type\":\"scattergl\"},{\"customdata\":[[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\nLicensed under the Apache License, Vers...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"Latent Consistency Distillation Example:\\n\\n[Latent Consistency Models (LCMs)](https:\\u002f\\u002farxiv.org\\u002fabs\\u002f2...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"Stable Diffusion\\n\\n## Overview\\n\\nStable Diffusion was proposed in [Stable Diffusion Announcement](http...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\nLicensed under the Apache License, Vers...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\nLicensed under the Apache License, Vers...\"],[\"!---\\nCopyright 2023 The HuggingFace Team. All rights reserved.\\nLicensed under the Apache License, Ve...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"--\\n{{ card_data }}\\n---\\n\\n\\u003c!-- This model card has been generated automatically according to the infor...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\nLicensed under the Apache License, Vers...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"Adapt a model to a new task\\n\\nMany diffusion systems share the same components, allowing you to adapt...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The GLIGEN Authors and The HuggingFace Team. All rights reserved.\\n\\nLicensed under ...\"],[\"WÃ¼rstchen text-to-image fine-tuning\\n\\n## Running locally with PyTorch\\n\\nBefore running the scripts, ma...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"# [Deprecated] Multi Token Textual Inversion\\n\\n**IMPORTART: This research project is deprecated. Mult...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"Consistency Decoder\\n\\nConsistency decoder can be used to decode the latents from the denoising UNet i...\"],[\"# Amused training\\n\\nAmused can be finetuned on simple datasets relatively cheaply and quickly. Using ...\"],[\"# Diffusers examples with Intel optimizations\\n\\n**This research project is not actively maintained by...\"],[\"ğŸ§¨ Diffusers Experimental\\n\\nWe are adding experimental code to support novel applications and usages o...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"Overview\\n\\nThese examples show how to run [Diffuser](https:\\u002f\\u002farxiv.org\\u002fabs\\u002f2205.09991) in Diffusers. ...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"InstructPix2Pix SDXL training example\\n\\n***This is based on the original InstructPix2Pix training exa...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"ControlNet training example\\n\\n[Adding Conditional Control to Text-to-Image Diffusion Models](https:\\u002f\\u002f...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"# Textual Inversion fine-tuning example\\n\\n[Textual inversion](https:\\u002f\\u002farxiv.org\\u002fabs\\u002f2208.01618) is a ...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"ConsistencyDecoderScheduler\\n\\nThis scheduler is a part of the [`ConsistencyDecoderPipeline`] and was ...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"Stable Diffusion text-to-image fine-tuning\\n\\nThe `train_text_to_image.py` script shows how to fine-tu...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"# Diffusers examples with ONNXRuntime optimizations\\n\\n**This research project is not actively maintai...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The Intel Labs Team Authors and HuggingFace Team. All rights reserved.\\n\\nLicensed u...\"],[\"# Training examples\\n\\nCreating a training image set is [described in a different document](https:\\u002f\\u002fhu...\"],[\"Models\\n\\nFor more detail on the models, please refer to the [docs](https:\\u002f\\u002fhuggingface.co\\u002fdocs\\u002fdiffus...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 Custom Diffusion authors The HuggingFace Team. All rights reserved.\\n\\nLicensed unde...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\nLicensed under the Apache License, Vers...\"],[\"Stable Diffusion text-to-image fine-tuning\\n\\nThe `train_text_to_image.py` script shows how to fine-tu...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!---\\nCopyright 2022 - The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License,...\"],[\"Stable Diffusion text-to-image fine-tuning\\nThis extended LoRA training script was authored by [haofa...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"DreamBooth training example for Stable Diffusion XL (SDXL)\\n\\n[DreamBooth](https:\\u002f\\u002farxiv.org\\u002fabs\\u002f2208....\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"Deprecated Pipelines\\n\\nThis folder contains pipelines that have very low usage as measured by model d...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"Schedulers\\n\\nFor more information on the schedulers, please refer to the [docs](https:\\u002f\\u002fhuggingface.c...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"InstructPix2Pix training example\\n\\n[InstructPix2Pix](https:\\u002f\\u002farxiv.org\\u002fabs\\u002f2211.09800) is a method to...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"# Training an unconditional diffusion model\\n\\nCreating a training image set is [described in a differ...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"T2I-Adapter training example for Stable Diffusion XL (SDXL)\\n\\nThe `train_t2i_adapter_sdxl.py` script ...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"# Contributor Covenant Code of Conduct\\n\\n## Our Pledge\\n\\nWe as members, contributors, and leaders pled...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"Stable Diffusion XL for JAX + TPUv5e\\n\\n[TPU v5e](https:\\u002f\\u002fcloud.google.com\\u002fblog\\u002fproducts\\u002fcompute\\u002fhow-c...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"# Textual Inversion fine-tuning example\\n\\n[Textual inversion](https:\\u002f\\u002farxiv.org\\u002fabs\\u002f2208.01618) is a ...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"ğŸ§¨ Diffusers Pipelines\\n\\nPipelines provide a simple way to run state-of-the-art diffusion models in in...\"],[\"Distillation for quantization on Textual Inversion models to personalize text2image\\n\\n[Textual invers...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"Latent Consistency Distillation Example:\\n\\n[Latent Consistency Models (LCMs)](https:\\u002f\\u002farxiv.org\\u002fabs\\u002f2...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"# Diffusers examples with ONNXRuntime optimizations\\n\\n**This research project is not actively maintai...\"],[\"Multi Subject DreamBooth training\\n\\n[DreamBooth](https:\\u002f\\u002farxiv.org\\u002fabs\\u002f2208.12242) is a method to per...\"],[\"Inference Examples\\n\\n**The inference examples folder is deprecated and will be removed in a future ve...\"],[\"ControlNet training example for Stable Diffusion XL (SDXL)\\n\\nThe `train_controlnet_sdxl.py` script sh...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"Stable Diffusion XL text-to-image fine-tuning\\n\\nThe `train_text_to_image_sdxl.py` script shows how to...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"\\u003c!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ve...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"Custom Diffusion training example \\n\\n[Custom Diffusion](https:\\u002f\\u002farxiv.org\\u002fabs\\u002f2212.04488) is a method...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!---\\nCopyright 2023- The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, ...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"# Textual Inversion fine-tuning example\\n\\n[Textual inversion](https:\\u002f\\u002farxiv.org\\u002fabs\\u002f2208.01618) is a ...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"Kandinsky2.2 text-to-image fine-tuning\\n\\nKandinsky 2.2 includes a prior pipeline that generates image...\"],[\"e don't yet support training T2I-Adapters on Stable Diffusion yet. For training T2I-Adapters on Stab...\"],[\"Research projects\\n\\nThis folder contains various research projects using ğŸ§¨ Diffusers.\\nThey are not re...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"[DreamBooth](https:\\u002f\\u002fgithub.com\\u002fhuggingface\\u002fdiffusers\\u002ftree\\u002fmain\\u002fexamples\\u002fdreambooth) by [colossalai]...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"Community Examples\\n\\n\\u003e **For more information about community pipelines, please have a look at [this ...\"],[\"DreamBooth training example\\n\\n[DreamBooth](https:\\u002f\\u002farxiv.org\\u002fabs\\u002f2208.12242) is a method to personali...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"RealFill\\n\\n[RealFill](https:\\u002f\\u002farxiv.org\\u002fabs\\u002f2309.16668) is a method to personalize text2image inpaint...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"Dreambooth for the inpainting model\\n\\nThis script was added by @thedarkzeno .\\n\\nPlease note that this ...\"],[\"Create a dataset for training\\n\\nThere are many datasets on the [Hub](https:\\u002f\\u002fhuggingface.co\\u002fdatasets?...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"]],\"hovertemplate\":\"source=diffusers\\u003cbr\\u003esymbol=circle\\u003cbr\\u003ex=%{x}\\u003cbr\\u003ey=%{y}\\u003cbr\\u003esize_col=%{marker.size}\\u003cbr\\u003eextract=%{customdata[0]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"diffusers, circle\",\"marker\":{\"color\":\"#FECB52\",\"size\":[4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4],\"sizemode\":\"area\",\"sizeref\":0.25,\"symbol\":\"circle\",\"line\":{\"color\":\"DarkSlateGrey\",\"width\":0},\"opacity\":1},\"mode\":\"markers\",\"name\":\"diffusers, circle\",\"showlegend\":true,\"x\":[-12.628616,-12.92942,-7.447517,-7.7533307,-13.791536,-13.924868,-14.357376,-13.556946,-12.299465,-13.559496,-10.614273,-14.502283,-14.73217,-13.637649,-13.314164,-14.283742,-14.115998,-13.494089,-14.007681,-13.309355,-14.677834,-12.54784,-13.393787,-13.40399,-7.4993396,-15.504618,-13.8380575,-3.7385004,-12.778296,-13.3118,-12.416172,-14.477514,-15.25617,-14.125954,-12.312145,-13.925726,-13.62229,-14.296441,-5.7085514,-13.543816,-13.858064,-12.228646,-14.967049,-14.44094,-13.610685,-13.984192,-13.223756,-15.650853,-13.899336,-12.886798,-13.760141,-13.420626,-13.525772,-12.261168,-13.649828,-4.063971,-15.474856,-4.334562,-14.944358,-15.594252,-13.516451,-14.32116,-12.44801,-4.675859,-13.427255,-15.622697,-13.072065,-12.433579,-15.231027,-14.325953,-13.110281,-12.47716,-12.503578,-13.395631,-12.932366,-13.691626,-14.408773,-13.600457,-13.282646,-9.262483,-14.004491,-7.6756935,-15.169634,-7.485968,-13.443354,-3.9153323,-13.836527,-9.789795,-15.016622,-14.198175,-12.905584,-13.813367,-15.151536,-15.051597,-12.547237,-15.03665,-14.568159,-13.546453,-13.665452,-12.507934,-1.09947,-2.0537484,-14.020593,-13.87877,-13.347948,-14.648964,-15.700911,-13.055089,-14.226612,-12.349734,-14.109338,-13.566316,-14.5058155,-12.437124,-14.325316,-14.305388,-12.403841,-12.971118,-13.376333,-15.131407,-13.552548,-1.3043082,-4.563638,-12.696744,-13.304152,-13.692052,-14.058877,-12.512881,-13.696909,-13.434025,-7.432024,-13.314068,-12.504535,-4.2998037,-12.775949,-13.575093,-14.82004,-13.99098,-14.485679,-14.762172,-14.159812,-13.496401,-13.192025,-14.353267,-13.6045065,1.4607548,-15.018284,-4.241312,-15.740774,-14.225304,-12.442926,-14.403015,-13.811575,-13.862124,-14.747204,-13.927184,-13.851281,-14.580243,-12.405839,-14.216929,-14.3681755,-12.380151,-14.242708,-14.450634,-13.689768,-13.613742,-12.223484,-13.8887615,-12.684159,-14.325724,-12.662712,-13.745564,-15.651316,-13.578389,-13.796853,-12.591238,-13.493723,-12.326645,-14.052818,-13.844532,-15.667834,-13.469874,-13.484346,-12.65017,-14.348174,-1.3932633,-5.7497425,-14.46962,-12.461042,-13.25737,-13.429409,-13.529882,-12.142959,-14.317942,-14.134393,-15.441767,-14.8656025,-12.294872,-14.711343,-12.331812,-13.346472,-1.6817993,-13.814855,-4.6236596,-12.81453,-13.388299,-14.257884,-12.531009,-14.982977,-13.178232,-14.492599,-14.501409,-8.75244,-13.450642,-14.358972,-12.680925,-12.167283,-8.196329,-12.826446,-7.819765,-14.512627,-15.752961,-15.543815,-3.6935666,-13.131529,-13.948161,-14.949337,-13.744179,-12.86781,-5.836019,-14.882046,-14.581269,-13.466116,-12.479801,1.0286721,-13.443747,-13.551428,-3.2111294],\"xaxis\":\"x\",\"y\":[-3.3534439,-4.4468455,1.3583369,-0.9878415,-4.8950086,-5.32549,-4.018828,-5.096551,-2.8247952,-3.686991,-0.5278775,-6.7055635,-4.4704294,-6.004633,-4.279643,-5.4451914,-4.0073333,-6.1005225,-6.2209525,-3.5279226,-4.6418896,-2.8730578,-3.619672,-5.305031,1.3343027,-4.822676,-4.9427066,-2.567324,-3.2332244,-3.4945939,-5.039818,-6.7073064,-4.7591414,-4.4217453,-4.84123,-4.2171187,-5.9459667,-4.5444965,4.0466123,-6.610688,-6.6056805,-4.98445,-6.807912,-6.5411906,-6.314029,-6.244449,-5.190515,-4.9969788,-4.058616,-4.8677483,-4.9881506,-5.1602173,-4.8983006,-5.0016656,-4.8845296,5.6251884,-4.7049074,2.8050919,-6.8260508,-4.845794,-5.1007867,-5.642182,-5.1452127,3.7617698,-6.0054016,-4.8326054,-3.3528295,-5.1205225,-6.8498025,-4.275489,-4.9348845,-3.067117,-5.130955,-4.4669037,-5.231292,-5.0204134,-6.6011643,-5.4816356,-3.5266764,-0.41433665,-3.856402,-0.88859344,-6.8945365,1.1866912,-4.296971,3.767096,-4.8902845,0.19221543,-6.867422,-6.3091087,-3.0157406,-3.9366188,-6.9499083,-4.759387,-2.9211555,-6.8752365,-6.526676,-3.6056068,-5.9988847,-5.025356,2.1723995,2.8299575,-4.5172696,-5.3192744,-5.3909497,-6.6015816,-5.8254504,-3.670083,-5.004085,-5.1531973,-6.5460186,-6.2378197,-6.5143504,-5.090584,-4.0328994,-4.0638967,-3.3450541,-5.064052,-5.0915337,-4.8077345,-4.7319994,2.896267,1.7719631,-5.1848598,-3.7686305,-4.901489,-4.009811,-5.07605,-5.1244464,-5.7419443,1.2777101,-3.6945052,-3.4437084,3.9179878,-5.469378,-6.6735916,-6.836024,-5.1368346,-6.6502094,-4.412817,-4.2775145,-5.258072,-3.5558252,-6.454728,-6.3478036,5.9467096,-6.8335366,3.6557758,-4.8942857,-4.18735,-5.091161,-4.7967124,-5.93049,-4.884339,-4.4935265,-5.279187,-4.2077184,-5.551438,-4.9806986,-5.8533607,-6.2954965,-5.0157537,-6.057942,-6.4879313,-5.2800856,-3.6842484,-2.7445931,-6.4441605,-5.081602,-6.3054113,-5.294606,-5.527534,-4.8782115,-5.936965,-5.225908,-5.225096,-6.457808,-4.818868,-4.4227557,-5.599594,-4.957663,-5.7113967,-5.5266085,-5.0806484,-4.1167545,1.075096,1.458933,-4.2511683,-5.153598,-3.4589243,-3.7043917,-4.302843,-4.016322,-6.579377,-6.669253,-4.896184,-4.8424993,-5.0502443,-4.6159315,-4.467227,-5.6756897,2.7229226,-4.0799003,3.7311661,-4.929241,-4.904821,-6.721859,-5.055138,-6.914075,-4.913271,-6.432299,-4.254267,1.1761858,-5.496604,-5.127643,-5.130677,-5.004785,1.7508868,-2.9210792,-0.9920472,-6.561202,-4.907403,-4.881752,2.4987447,-3.2682567,-3.8666446,-6.8522773,-5.388433,-2.9781806,1.3857455,-4.7749176,-6.6120925,-3.9445987,-5.108989,2.537249,-5.346745,-5.460404,-7.1901217],\"yaxis\":\"y\",\"type\":\"scattergl\"},{\"customdata\":[[\"Datasets server - worker\\n\\n\\u003e Workers that pre-compute and cache the response to \\u002fsplits, \\u002ffirst-rows,...\"],[\"--\\ntitle: Datasets Server Admin UI\\nemoji: ğŸ“Š\\ncolorFrom: gray\\ncolorTo: purple\\nsdk: gradio\\nsdk_version:...\"],[\"Filter rows in a dataset\\n\\nDatasets Server provides a `\\u002ffilter` endpoint for filtering rows in a data...\"],[\"List Parquet files\\n\\nDatasets can be published in any format (CSV, JSONL, directories of images, etc....\"],[\"datasets-server Helm chart\\n\\nThe `datasets-server` Helm [chart](https:\\u002f\\u002fhelm.sh\\u002fdocs\\u002ftopics\\u002fcharts\\u002f) ...\"],[\"How to contribute to the Datasets Server?\\n\\n[![Contributor Covenant](https:\\u002f\\u002fimg.shields.io\\u002fbadge\\u002fCon...\"],[\"DuckDB\\n\\n[DuckDB](https:\\u002f\\u002fduckdb.org\\u002fdocs\\u002f) is a database that supports reading and querying Parquet ...\"],[\"Overview\\n\\nDatasets Server automatically converts and publishes public datasets less than 5GB on the ...\"],[\"Pandas\\n\\n[Pandas](https:\\u002f\\u002fpandas.pydata.org\\u002fdocs\\u002findex.html) is a popular DataFrame library for data ...\"],[\"!---\\nCopyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"Check dataset validity\\n\\nBefore you download a dataset from the Hub, it is helpful to know if a speci...\"],[\"Security Policy\\n\\n## Supported Versions\\n\\n\\u003c!--\\nUse this section to tell people about which versions of...\"],[\"Datasets server admin machine\\n\\n\\u003e Admin endpoints\\n\\n## Configuration\\n\\nThe worker can be configured usi...\"],[\"Get dataset information\\n\\nDatasets Server provides an `\\u002finfo` endpoint for exploring the general info...\"],[\"Datasets server\\n\\n\\u003e Integrate into your apps over 10,000 datasets via simple HTTP requests, with pre-...\"],[\"Download slices of rows\\n\\nDatasets Server provides a `\\u002frows` endpoint for visualizing any slice of ro...\"],[\"Quickstart\\n\\n[[open-in-colab]]\\n\\nIn this quickstart, you'll learn how to use the Datasets Server's RES...\"],[\"Datasets server SSE API\\n\\n\\u003e Server-sent events API for the Datasets server. It's used to update the H...\"],[\"libapi\\n\\nA Python library for the API services\\n\\n## Configuration\\n\\nThe APIs can be configured using en...\"],[\"ClickHouse\\n\\n[ClickHouse](https:\\u002f\\u002fclickhouse.com\\u002fdocs\\u002fen\\u002fintro) is a fast and efficient column-orient...\"],[\"Analyze a dataset on the Hub\\n\\n[[open-in-colab]]\\n\\nIn the Quickstart, you were introduced to various e...\"],[\"Polars \\n\\n[Polars](https:\\u002f\\u002fpola-rs.github.io\\u002fpolars-book\\u002fuser-guide\\u002f) is a fast DataFrame library wri...\"],[\"Explore statistics over split data\\n\\nDatasets Server provides a `\\u002fstatistics` endpoint for fetching s...\"],[\"libcommon\\n\\nA Python library with common code (cache, queue, workers logic, processing steps, configu...\"],[\"Splits and configurations\\n\\nMachine learning datasets are commonly organized in *splits* and they may...\"],[\"e2e\\n\\nEnd to end tests, written in Python...\"],[\"Preview a dataset\\n\\nDatasets Server provides a `\\u002ffirst-rows` endpoint for visualizing the first 100 r...\"],[\"Search text in a dataset\\n\\nDatasets Server provides a `\\u002fsearch` endpoint for searching words in a dat...\"],[\"Developer guide\\n\\nThis document is intended for developers who want to install, test or contribute to...\"],[\"Server infrastructure\\n\\nThe [Datasets Server](https:\\u002f\\u002fgithub.com\\u002fhuggingface\\u002fdatasets-server) has two...\"],[\"Datasets server maintenance job\\n\\n\\u003e Job to run maintenance actions on the datasets-server\\n\\nAvailable ...\"],[\"Datasets server - storage admin\\n\\n\\u003e A Ubuntu machine to log into and manage the storage manually...\"],[\"ğŸ¤— Datasets Server\\n\\nDatasets Server is a lightweight web API for visualizing and exploring all types ...\"],[\"Get the number of rows and the size in bytes\\n\\nThis guide shows you how to use Datasets Server's `\\u002fsi...\"],[\"Datasets server API - rows endpoint\\n\\n\\u003e \\u002frows endpoint\\n\\n## Configuration\\n\\nThe service can be configur...\"],[\"Datasets server - reverse proxy\\n\\n\\u003e Reverse-proxy in front of the API\\n\\nSee [docker-compose-datasets-s...\"],[\"Data types\\n\\nDatasets supported by Datasets Server have a tabular format, meaning a data point is rep...\"],[\"List splits and configurations\\n\\nDatasets typically have splits and may also have configurations. A _...\"],[\"Datasets server API\\n\\n\\u003e API on ğŸ¤— datasets\\n\\n## Configuration\\n\\nThe service can be configured using envi...\"],[\"Datasets server API - search service\\n\\n\\u003e \\u002fsearch endpoint\\n\\u003e \\u002ffilter endpoint\\n\\n## Configuration\\n\\nThe s...\"],[\"Datasets server databases migrations\\n\\n\\u003e Scripts to migrate the datasets server databases\\n\\n## Configu...\"]],\"hovertemplate\":\"source=datasets-server\\u003cbr\\u003esymbol=circle\\u003cbr\\u003ex=%{x}\\u003cbr\\u003ey=%{y}\\u003cbr\\u003esize_col=%{marker.size}\\u003cbr\\u003eextract=%{customdata[0]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"datasets-server, circle\",\"marker\":{\"color\":\"#636efa\",\"size\":[4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4],\"sizemode\":\"area\",\"sizeref\":0.25,\"symbol\":\"circle\",\"line\":{\"color\":\"DarkSlateGrey\",\"width\":0},\"opacity\":1},\"mode\":\"markers\",\"name\":\"datasets-server, circle\",\"showlegend\":true,\"x\":[2.709231,7.776941,2.4256306,2.379292,2.843867,0.9842195,2.2129312,2.3654308,2.1370459,-1.5776669,1.8956724,1.2459018,2.5231135,2.5398328,1.642338,2.093779,2.6296427,2.8349586,1.7873471,2.262012,2.2711744,2.0954814,2.6350963,2.3215923,1.49025,-1.2773633,2.1354172,2.545951,-0.46105093,2.780564,2.659948,2.4372993,1.8032205,2.6290803,2.5914,3.0360398,1.7492605,2.2263756,2.6756895,2.7484913,2.428828],\"xaxis\":\"x\",\"y\":[2.598679,-11.016814,2.4188583,2.5053966,2.6581888,4.2242393,2.5718043,2.4045053,2.483303,1.1509317,2.971434,6.07572,3.1832821,2.4397144,3.0833902,2.4203467,2.4550793,2.5210562,4.5835996,2.6751087,2.4548073,2.48374,2.3741016,2.8655772,1.9593999,2.824872,2.4416752,2.356431,3.4021063,2.4843712,2.5236456,2.5726686,2.9370694,2.3925176,2.502719,2.788808,2.159707,2.098512,2.527304,2.5109537,2.6021914],\"yaxis\":\"y\",\"type\":\"scattergl\"},{\"customdata\":[[\"Differences between Dataset and IterableDataset\\n\\nThere are two types of dataset objects, a [`Dataset...\"],[\"Metric Card for F1\\n\\n\\n## Metric Description\\n\\nThe F1 score is the harmonic mean of the precision and r...\"],[\"Cache management\\n\\nWhen you download a dataset, the processing scripts and data are stored locally on...\"],[\"Metric Card for MSE\\n\\n\\n## Metric Description\\n\\nMean Squared Error(MSE) represents the average of the s...\"],[\"All about metrics\\n\\n\\u003cTip warning={true}\\u003e\\n\\nMetrics is deprecated in ğŸ¤— Datasets. To learn more about ho...\"],[\"Metric Card for METEOR\\n\\n## Metric description\\n\\nMETEOR (Metric for Evaluation of Translation with Exp...\"],[\"Preprocess\\n\\nIn addition to loading datasets, ğŸ¤— Datasets other main goal is to offer a diverse set of...\"],[\"Image classification\\n\\nImage classification datasets are used to train a model to classify an entire ...\"],[\"Beam Datasets\\n\\nSome datasets are too large to be processed on a single machine. Instead, you can pro...\"],[\"Load image data\\n\\nImage datasets have [`Image`] type columns, which contain PIL objects. \\n\\n\\u003cTip\\u003e\\n\\nTo ...\"],[\"Metric Card for Recall\\n\\n\\n## Metric Description\\n\\nRecall is the fraction of the positive examples that...\"],[\"Dataset features\\n\\n[`Features`] defines the internal structure of a dataset. It is used to specify th...\"],[\"Metric Card for GLUE\\n\\n## Metric description\\nThis metric is used to compute the GLUE evaluation metri...\"],[\"Metric Card for Matthews Correlation Coefficient\\n\\n## Metric Description\\nThe Matthews correlation coe...\"],[\"Contributor Covenant Code of Conduct\\n\\n## Our Pledge\\n\\nWe as members, contributors, and leaders pledge...\"],[\"Table Classes\\n\\nEach `Dataset` object is backed by a PyArrow Table.\\nA Table can be loaded from either...\"],[\"Metric Card for Precision\\n\\n\\n## Metric Description\\n\\nPrecision is the fraction of correctly labeled po...\"],[\"Load tabular data\\n\\nA tabular dataset is a generic dataset used to describe any data stored in rows a...\"],[\"--\\nTODO: Add YAML tags here. Copy-paste the tags obtained with the online tagging app: https:\\u002f\\u002fhuggi...\"],[\"Use with Spark\\n\\nThis document is a quick introduction to using ğŸ¤— Datasets with Spark, with a particu...\"],[\"p align=\\\"center\\\"\\u003e\\n  \\u003cpicture\\u003e\\n    \\u003csource media=\\\"(prefers-color-scheme: dark)\\\" srcset=\\\"https:\\u002f\\u002fhuggi...\"],[\"The cache\\n\\nThe cache is one of the reasons why ğŸ¤— Datasets is so efficient. It stores previously down...\"],[\"Metric Card for chrF(++)\\n\\n\\n## Metric Description\\nChrF and ChrF++ are two MT evaluation metrics that ...\"],[\"Metric Card for BERT Score\\n\\n## Metric description\\n\\nBERTScore is an automatic evaluation metric for t...\"],[\"Metric Card for ROUGE\\n\\n## Metric Description\\nROUGE, or Recall-Oriented Understudy for Gisting Evalua...\"],[\"Metric Card for Exact Match\\n\\n\\n## Metric Description\\nA given predicted string's exact match score is ...\"],[\"Metric Card for COMET\\n\\n## Metric description\\n\\nCrosslingual Optimized Metric for Evaluation of Transl...\"],[\"Metric Card for seqeval\\n\\n## Metric description\\n\\nseqeval is a Python framework for sequence labeling ...\"],[\"Utilities\\n\\n## Configure logging\\n\\nğŸ¤— Datasets strives to be transparent and explicit about how it work...\"],[\"Use with PyTorch\\n\\nThis document is a quick introduction to using `datasets` with PyTorch, with a par...\"],[\"Semantic segmentation\\n\\nSemantic segmentation datasets are used to train a model to classify every pi...\"],[\"Metric Card for *Current Metric*\\n\\n***Metric Card Instructions:*** *Copy this file into the relevant ...\"],[\"Metric Card for WikiSplit\\n\\n## Metric description\\n\\nWikiSplit is the combination of three metrics: [SA...\"],[\"Metric Card for FrugalScore\\n\\n\\n## Metric Description\\nFrugalScore is a reference-based metric for Natu...\"],[\"How to add one new datasets\\n\\nAdd datasets directly to the ğŸ¤— Hugging Face Hub!\\n\\nYou can share your da...\"],[\"Metric Card for Google BLEU (GLEU)\\n\\n\\n## Metric Description\\nThe BLEU score has some undesirable prope...\"],[\"# Add Dummy data test\\n\\n**Important** In order to pass the `load_dataset_\\u003cdataset_name\\u003e` test, dummy ...\"],[\"Main classes\\n\\n\\n## DatasetInfo\\n\\n[[autodoc]] datasets.DatasetInfo\\n\\n## Dataset\\n\\nThe base class [`Datase...\"],[\"Metric Card for COVAL\\n\\n## Metric description\\n\\nCoVal is a coreference evaluation tool for the [CoNLL]...\"],[\"Overview\\n\\nThe how-to guides offer a more comprehensive overview of all the tools ğŸ¤— Datasets offers a...\"],[\"Metric Card for SacreBLEU\\n\\n\\n## Metric Description\\nSacreBLEU provides hassle-free computation of shar...\"],[\"Cloud storage\\n\\nğŸ¤— Datasets supports access to cloud storage providers through a `fsspec` FileSystem i...\"],[\"Metric Card for BLEU\\n\\n\\n## Metric Description\\nBLEU (Bilingual Evaluation Understudy) is an algorithm ...\"],[\"Create an image dataset\\n\\nThere are two methods for creating and sharing an image dataset. This guide...\"],[\"Create a dataset card\\n\\nEach dataset should have a dataset card to promote responsible usage and info...\"],[\"Process\\n\\nğŸ¤— Datasets provides many tools for modifying the structure and content of a dataset. These ...\"],[\"Metric Card for SQuAD v2\\n\\n## Metric description\\nThis metric wraps the official scoring script for ve...\"],[\"Metric Card for Perplexity\\n\\n## Metric Description\\nGiven a model and an input text sequence, perplexi...\"],[\"Overview\\n\\nWelcome to the ğŸ¤— Datasets tutorials! These beginner-friendly tutorials will guide you thro...\"],[\"Metric Card for Pearson Correlation Coefficient (pearsonr)\\n\\n\\n## Metric Description\\n\\nPearson correlat...\"],[\"Load audio data\\n\\nYou can load an audio dataset using the [`Audio`] feature that automatically decode...\"],[\"Search index\\n\\n[FAISS](https:\\u002f\\u002fgithub.com\\u002ffacebookresearch\\u002ffaiss) and [Elasticsearch](https:\\u002f\\u002fwww.ela...\"],[\"How to contribute to Datasets?\\n[![Contributor Covenant](https:\\u002f\\u002fimg.shields.io\\u002fbadge\\u002fContributor%20C...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"Process text data\\n\\nThis guide shows specific methods for processing text datasets. Learn how to:\\n\\n- ...\"],[\"Security Policy\\n\\n## Supported Versions\\n\\u003c!--\\nUse this section to tell people about which versions of ...\"],[\"Process audio data\\n\\nThis guide shows specific methods for processing audio datasets. Learn how to:\\n\\n...\"],[\"Task templates\\n\\n\\u003cTip warning={true}\\u003e\\n\\nThe Task API is deprecated in favor of [`train-eval-index`](ht...\"],[\"Object detection\\n\\nObject detection models identify something in an image, and object detection datas...\"],[\"Load\\n\\nYour data can be stored in various places; they can be on your local machine's disk, in a Gith...\"],[\"Metric Card for SuperGLUE\\n\\n## Metric description\\nThis metric is used to compute the SuperGLUE evalua...\"],[\"Stream\\n\\nDataset streaming lets you work with a dataset without downloading it.\\nThe data is streamed ...\"],[\"Depth estimation\\n\\nDepth estimation datasets are used to train a model to approximate the relative di...\"],[\"Using Datasets with TensorFlow\\n\\nThis document is a quick introduction to using `datasets` with Tenso...\"],[\"Metric Card for Mahalanobis Distance\\n\\n## Metric Description\\nMahalonobis distance is the distance bet...\"],[\"Troubleshooting\\n\\nThis guide aims to provide you the tools and knowledge required to navigate some co...\"],[\"Process image data\\n\\nThis guide shows specific methods for processing image datasets. Learn how to:\\n\\n...\"],[\"Builder classes\\n\\n## Builders\\n\\nğŸ¤— Datasets relies on two main classes during the dataset building proc...\"],[\"Metrics\\n\\n\\u003cTip warning={true}\\u003e\\n\\nMetrics is deprecated in ğŸ¤— Datasets. To learn more about how to use m...\"],[\"Metric Card for MAUVE\\n\\n## Metric description\\n\\nMAUVE is a library built on PyTorch and HuggingFace Tr...\"],[\"Create a dataset loading script\\n\\n\\n\\u003cTip\\u003e\\n\\nThe dataset loading script is likely not needed if your dat...\"],[\"Metric Card for Competition MATH\\n\\n## Metric description\\n\\nThis metric is used to assess performance o...\"],[\"Metric Card for SARI\\n\\n\\n## Metric description\\nSARI (***s**ystem output **a**gainst **r**eferences and...\"],[\"Metric Card for Mean IoU \\n\\n\\n## Metric Description\\n\\nIoU (Intersection over Union) is the area of over...\"],[\"Metric Card for ROC AUC\\n\\n\\n## Metric Description\\nThis metric computes the area under the curve (AUC) ...\"],[\"Use with JAX\\n\\nThis document is a quick introduction to using `datasets` with JAX, with a particular ...\"],[\"Build and load\\n\\nNearly every deep learning workflow begins with loading a dataset, which makes it on...\"],[\"Metric Card for Accuracy\\n\\n\\n## Metric Description\\n\\nAccuracy is the proportion of correct predictions ...\"],[\"Metric Card for CER\\n\\n## Metric description\\n\\nCharacter error rate (CER) is a common metric of the per...\"],[\"Metric Card for XTREME-S\\n\\n\\n## Metric Description\\n\\nThe XTREME-S metric aims to evaluate model perform...\"],[\"Metric Card for WER\\n\\n## Metric description\\nWord error rate (WER) is a common metric of the performan...\"],[\"Share a dataset to the Hub\\n\\nThe [Hub](https:\\u002f\\u002fhuggingface.co\\u002fdatasets) is home to an extensive colle...\"],[\"Metric Card for SQuAD\\n\\n## Metric description\\nThis metric wraps the official scoring script for versi...\"],[\"Loading methods\\n\\nMethods for listing and loading datasets and metrics:\\n\\n## Datasets\\n\\n[[autodoc]] dat...\"],[\"Metric Card for CUAD\\n\\n## Metric description\\n\\nThis metric wraps the official scoring script for versi...\"],[\"Datasets ğŸ¤ Arrow\\n\\n## What is Arrow?\\n\\n[Arrow](https:\\u002f\\u002farrow.apache.org\\u002f) enables large amounts of dat...\"],[\"Metric Card for IndicGLUE\\n\\n## Metric description\\nThis metric is used to compute the evaluation metri...\"],[\"Structure your repository\\n\\nTo host and share your dataset, create a dataset repository on the Huggin...\"],[\"Load a dataset from the Hub\\n\\nFinding high-quality datasets that are reproducible and accessible can ...\"],[\"Metric Card for Code Eval\\n\\n## Metric description\\n\\nThe CodeEval metric estimates the pass@k metric fo...\"],[\"Create a dataset\\n\\nSometimes, you may need to create a dataset if you're working with your own data. ...\"],[\"Create an audio dataset\\n\\nYou can share a dataset with your team or with anyone in the community by c...\"],[\"Share a dataset using the CLI\\n\\nAt Hugging Face, we are on a mission to democratize good Machine Lear...\"],[\"Metric Card for Spearman Correlation Coefficient Metric (spearmanr)\\n\\n\\n## Metric Description\\nThe Spea...\"],[\"Datasets\\n\\n\\u003cimg class=\\\"float-left !m-0 !border-0 !dark:border-0 !shadow-none !max-w-lg w-[150px]\\\" src...\"],[\"Load text data\\n\\nThis guide shows you how to load text datasets. To learn how to load any type of dat...\"],[\"Metric Card for TER\\n\\n## Metric Description\\nTER (Translation Edit Rate, also called Translation Error...\"],[\"Metric Card for MAE\\n\\n\\n## Metric Description\\n\\nMean Absolute Error (MAE) is the mean of the magnitude ...\"],[\"--\\nYAML tags (full spec here: https:\\u002f\\u002fgithub.com\\u002fhuggingface\\u002fhub-docs\\u002fblob\\u002fmain\\u002fdatasetcard.md?plain...\"],[\"Know your dataset\\n\\nThere are two types of dataset objects, a regular [`Dataset`] and then an âœ¨ [`Ite...\"],[\"Metric Card for XNLI\\n\\n## Metric description\\n\\nThe XNLI metric allows to evaluate a model's score on t...\"],[\"Evaluate predictions\\n\\n\\u003cTip warning={true}\\u003e\\n\\nMetrics is deprecated in ğŸ¤— Datasets. To learn more about...\"],[\"Batch mapping\\n\\nCombining the utility of [`Dataset.map`] with batch mode is very powerful. It allows ...\"],[\"!---\\nCopyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"!---\\nCopyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"Installation\\n\\nBefore you start, you'll need to setup your environment and install the appropriate pa...\"]],\"hovertemplate\":\"source=datasets\\u003cbr\\u003esymbol=circle\\u003cbr\\u003ex=%{x}\\u003cbr\\u003ey=%{y}\\u003cbr\\u003esize_col=%{marker.size}\\u003cbr\\u003eextract=%{customdata[0]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"datasets, circle\",\"marker\":{\"color\":\"#EF553B\",\"size\":[4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4],\"sizemode\":\"area\",\"sizeref\":0.25,\"symbol\":\"circle\",\"line\":{\"color\":\"DarkSlateGrey\",\"width\":0},\"opacity\":1},\"mode\":\"markers\",\"name\":\"datasets, circle\",\"showlegend\":true,\"x\":[1.4952474,7.7311,1.7000948,7.834435,6.449823,7.136141,-8.88387,0.8697471,1.5969596,1.2276833,7.6932054,1.044896,6.8570065,7.7848144,1.3622165,1.602168,7.7081294,1.4621294,0.32597116,1.4182835,0.01751461,1.3539373,7.240349,7.171927,7.2097163,7.3755684,7.169364,7.3544993,0.16453312,0.8390541,-9.57252,7.652693,7.2767158,7.195675,1.5267954,7.1075997,0.9593227,1.2178658,7.189448,0.9201525,7.1673317,1.8379837,7.1397285,1.337495,0.70001477,1.1613253,7.2301183,6.9681826,0.6685852,7.884353,1.2787254,-6.482034,0.95084786,-0.07564618,-9.366382,1.2488868,1.3262818,-2.974009,1.1009257,1.5544056,7.049968,1.6890643,1.0520765,0.3887955,7.7588,1.8663821,1.1149511,0.8250926,6.5122375,7.408561,1.4200393,7.5492935,7.232201,7.631747,7.651412,1.2370839,1.2777612,7.688034,7.3005853,7.1397805,7.3034506,1.4838316,7.3038564,1.1042498,7.144567,1.4230323,7.011431,1.5452658,1.4680669,6.9174347,1.0323784,1.3567005,1.4839264,7.949466,0.8541178,1.3038541,7.228442,7.8140364,0.45994076,1.4600089,7.206101,6.5839653,1.2169971,0.03702575,-1.4759656,-0.29051068],\"xaxis\":\"x\",\"y\":[1.9973534,-9.340057,2.2194674,-9.390597,-8.975036,-9.578097,7.2074466,1.9086773,2.2548506,1.8835694,-9.331559,1.8521024,-9.308137,-9.538838,5.9966636,2.0665562,-9.404755,2.080867,4.182028,1.9728136,3.1871738,1.974276,-9.499885,-10.265852,-9.439226,-9.561401,-9.592946,-9.357193,2.338667,1.9156119,0.26033896,-9.353739,-9.453517,-9.58344,3.5406287,-9.513122,2.3471487,2.255204,-9.47563,3.2311978,-9.434479,2.329329,-9.486788,2.2370489,4.2729735,2.0212164,-9.5514345,-10.023276,3.5184314,-9.729743,2.3027155,6.3867936,4.021016,3.8733697,7.380268,5.997244,2.238443,2.8829558,1.5669203,2.5326772,-9.369206,2.191426,1.5054222,1.844724,-9.612709,3.9269083,1.6326272,2.1082413,-8.971896,-9.692379,2.5095997,-9.402198,-9.573106,-9.410204,-9.301795,2.0033858,2.459268,-9.332413,-9.810116,-9.780543,-9.721157,3.38184,-9.589974,2.4195423,-9.3985815,2.011444,-9.357,2.5266018,2.7685328,-9.280657,2.593485,2.8576865,3.263383,-9.666267,3.406094,2.205024,-9.4185505,-9.500196,4.2782254,2.0676582,-9.366115,-9.082043,1.8775343,3.9833486,1.2190248,2.5223718],\"yaxis\":\"y\",\"type\":\"scattergl\"},{\"customdata\":[[\"Q-Learning Recap [[q-learning-recap]]\\n\\n\\n*Q-Learning* **is the RL algorithm that** :\\n\\n- Trains a *Q-f...\"],[\"Quiz\\n\\nThe best way to learn and [to avoid the illusion of competence](https:\\u002f\\u002fwww.coursera.org\\u002flectu...\"],[\"Additional Readings\\n\\nThese are **optional readings** if you want to go deeper.\\n\\n\\n## Introduction to ...\"],[\"Hands-on\\n\\nNow that you learned the basics of multi-agents, you're ready to train your first agents i...\"],[\"Two types of value-based methods [[two-types-value-based-methods]]\\n\\nIn value-based methods,Â **we lea...\"],[\"The advantages and disadvantages of policy-gradient methods\\n\\nAt this point, you might ask, \\\"but Deep...\"],[\"Glossary \\n\\nThis is a community-created glossary. Contributions are welcome!\\n\\n- **Deep Q-Learning:** ...\"],[\"Conclusion [[conclusion]]\\n\\nCongrats on finishing this unit! **That was the biggest one**, and there ...\"],[\"Introduction\\n\\n\\u003cimg src=\\\"https:\\u002f\\u002fhuggingface.co\\u002fdatasets\\u002fhuggingface-deep-rl-course\\u002fcourse-images\\u002fres...\"],[\"Introduction to Q-Learning [[introduction-q-learning]]\\n\\n\\u003cimg src=\\\"https:\\u002f\\u002fhuggingface.co\\u002fdatasets\\u002fhu...\"],[\"Conclusion\\n\\nCongrats on finishing this unit! Youâ€™ve just trained your first ML-Agents and shared it ...\"],[\"Language models in RL\\n## LMs encode useful knowledge for agents\\n\\n**Language models** (LMs) can exhib...\"],[\"The Deep Q-Network (DQN)  [[deep-q-network]]\\nThis is the architecture of our Deep Q-Learning network...\"],[\"The certification process\\n\\n\\nThe certification process is **completely free**:\\n\\n- To get a *certifica...\"],[\"Summary [[summary]]\\n\\nThat was a lot of information! Let's summarize:\\n\\n- Reinforcement Learning is a ...\"],[\"Glossary [[glossary]]\\n\\nThis is a community-created glossary. Contributions are welcomed!\\n\\n\\n### Strat...\"],[\"The Reinforcement Learning Framework [[the-reinforcement-learning-framework]]\\n\\n## The RL Process [[t...\"],[\"Introduction [[introduction]]\\n\\n\\n\\u003cimg src=\\\"https:\\u002f\\u002fhuggingface.co\\u002fdatasets\\u002fhuggingface-deep-rl-course...\"],[\"From Q-Learning to Deep Q-Learning [[from-q-to-dqn]]\\n\\nWe learned thatÂ **Q-Learning is an algorithm w...\"],[\"Additional Readings [[additional-readings]]\\n\\nThese are **optional readings** if you want to go deepe...\"],[\"Hands-on\\n\\n\\u003cCourseFloatingBanner classNames=\\\"absolute z-10 right-0 top-0\\\"\\nnotebooks={[\\n  {label: \\\"Goo...\"],[\"Decision Transformers\\n\\nThe Decision Transformer model was introduced by [\\\"Decision Transformer: Rein...\"],[\"Additional Readings [[additional-readings]]\\n\\n##  An introduction to multi-agents\\n\\n- [Multi-agent rei...\"],[\"Introducing Q-Learning [[q-learning]]\\n## What is Q-Learning? [[what-is-q-learning]]\\n\\nQ-Learning is a...\"],[\"Play with Huggy [[play]]\\n\\nNow that you've trained Huggy and pushed it to the Hub. **You will be able...\"],[\"Discord 101 [[discord-101]]\\n\\nHey there! My name is Huggy, the dog ğŸ•, and I'm looking forward to trai...\"],[\"Introduction [[introduction]]\\n\\nOne of the most critical tasks in Deep Reinforcement Learning is to *...\"],[\"Designing Multi-Agents systems\\n\\nFor this section, you're going to watch this excellent introduction ...\"],[\"Additional Readings [[additional-readings]]\\n\\nThese are **optional readings** if you want to go deepe...\"],[\"Hands-on\\n\\n\\n      \\u003cCourseFloatingBanner classNames=\\\"absolute z-10 right-0 top-0\\\"\\n      notebooks={[\\n ...\"],[\"The SnowballTarget Environment\\n\\n\\u003cimg src=\\\"https:\\u002f\\u002fhuggingface.co\\u002fdatasets\\u002fhuggingface-deep-rl-course...\"],[\"What are the policy-based methods?\\n\\nThe main goal of Reinforcement learning is to **find the optimal...\"],[\"Advantage Actor Critic (A2C) using Robotics Simulations with Panda-Gym ğŸ¤– [[hands-on]]\\n\\n\\n      \\u003cCours...\"],[\"(Optional) What is Curiosity in Deep Reinforcement Learning?\\n\\nThis is an (optional) introduction to ...\"],[\"The â€œDeepâ€ in Reinforcement Learning [[deep-rl]]\\n\\n\\u003cTip\\u003e\\nWhat we've talked about so far is Reinforcem...\"],[\"What is RL? A short recap [[what-is-rl]]\\n\\nIn RL, we build an agent that canÂ **make smart decisions**...\"],[\"Conclusion [[Conclusion]]\\n\\nThatâ€™s all for today. Congrats on finishing this unit and the tutorial!\\n\\n...\"],[\"Diving deeper into policy-gradient methods\\n\\n## Getting the big picture\\n\\nWe just learned that policy-...\"],[\"Additional Readings [[additional-readings]]\\n\\n## Bias-variance tradeoff in Reinforcement Learning\\n\\nIf...\"],[\"Let's train and play with Huggy ğŸ¶ [[train]]\\n\\n\\n\\n\\n          \\u003cCourseFloatingBanner classNames=\\\"absolute...\"],[\"Mid-way Quiz [[mid-way-quiz]]\\n\\nThe best way to learn and [to avoid the illusion of competence](https...\"],[\"Bonus: Learn to create your own environments with Unity and MLAgents\\n\\n**You can create your own rein...\"],[\"Train your first Deep Reinforcement Learning Agent ğŸ¤– [[hands-on]]\\n\\n\\n\\n\\n      \\u003cCourseFloatingBanner cl...\"],[\"Glossary \\n\\nThis is a community-created glossary. Contributions are welcomed!\\n\\n- **Tabular Method:** ...\"],[\"Live 1: How the course work, Q&A, and playing with Huggy\\n\\nIn this first live stream, we explained ho...\"],[\"Quiz [[quiz]]\\n\\nThe best way to learn and [to avoid the illusion of competence](https:\\u002f\\u002fwww.coursera....\"],[\"Additional Readings [[additional-readings]]\\n\\nThese are **optional readings** if you want to go deepe...\"],[\"(Optional) the Policy Gradient Theorem\\n\\nIn this optional section where we're **going to study how we...\"],[\"Introduction to Deep Reinforcement Learning [[introduction-to-deep-reinforcement-learning]]\\n\\n\\u003cimg sr...\"],[\"Additional Readings [[additional-readings]]\\n\\nThese are **optional readings** if you want to go deepe...\"],[\"Advantage Actor-Critic (A2C) [[advantage-actor-critic]]\\n\\n## Reducing variance with Actor-Critic meth...\"],[\"(Automatic) Curriculum Learning for RL\\n\\nWhile most of the RL methods seen in this course work well i...\"],[\"Conclusion [[conclusion]]\\n\\nCongrats on finishing this chapter!Â There was a lot of information. And c...\"],[\"Hands-on [[hands-on]]\\n\\n      \\u003cCourseFloatingBanner classNames=\\\"absolute z-10 right-0 top-0\\\"\\n      no...\"],[\"An Introduction to Unreal Learning Agents\\n\\n[Learning Agents](https:\\u002f\\u002fdev.epicgames.com\\u002fcommunity\\u002flea...\"],[\"Conclusion\\n\\nThatâ€™s all for today. Congrats on finishing this unit and the tutorial!\\n\\nThe best way to...\"],[\"Conclusion [[conclusion]]\\n\\nCongrats on finishing this bonus unit!\\n\\nYou can now sit and enjoy playing...\"],[\"Type of tasks [[tasks]]\\n\\nA task is an **instance** of a Reinforcement Learning problem. We can have ...\"],[\"The intuition behind PPO [[the-intuition-behind-ppo]]\\n\\n\\nThe idea with Proximal Policy Optimization (...\"],[\"The Bellman Equation: simplify our value estimation [[bellman-equation]]\\n\\nThe Bellman equationÂ **sim...\"],[\"Conclusion\\n\\nThat's all for today. Congrats on finishing this Unit and the tutorial! â­ï¸\\n\\nNow that you...\"],[\"Brief introduction to RL documentation\\n\\nIn this advanced topic, we address the question: **how shoul...\"],[\"Conclusion [[conclusion]]\\n\\nCongrats on finishing this unit and the tutorial. You've just trained you...\"],[\"Monte Carlo vs Temporal Difference Learning [[mc-vs-td]]\\n\\nThe last thing we need to discuss before d...\"],[\"Conclusion [[conclusion]]\\n\\nCongrats on finishing this chapter!Â There was a lot of information. And c...\"],[\"Glossary [[glossary]]\\n\\nThis is a community-created glossary. Contributions are welcomed!\\n\\n### Agent\\n...\"],[\"Offline vs. Online Reinforcement Learning\\n\\nDeep Reinforcement Learning (RL) is a framework **to buil...\"],[\"Quiz\\n\\nThe best way to learn and [to avoid the illusion of competence](https:\\u002f\\u002fwww.coursera.org\\u002flectu...\"],[\"Hands-on: advanced Deep Reinforcement Learning. Using Sample Factory to play Doom from pixels\\n\\n\\u003cCour...\"],[\"Introducing the Clipped Surrogate Objective Function\\n## Recap: The Policy Objective Function\\n\\nLetâ€™s ...\"],[\"Quiz\\n\\nThe best way to learn and [to avoid the illusion of competence](https:\\u002f\\u002fwww.coursera.org\\u002flectu...\"],[\"The Problem of Variance in Reinforce [[the-problem-of-variance-in-reinforce]]\\n\\nIn Reinforce, we want...\"],[\"An introduction to Multi-Agents Reinforcement Learning (MARL)\\n\\n## From single agent to multiple agen...\"],[\"Student Works\\n\\nSince the launch of the Deep Reinforcement Learning Course, **many students have crea...\"],[\"Introduction [[introduction]]\\n\\nIn this bonus unit, we'll reinforce what we learned in the first unit...\"],[\"Conclusion\\n\\n\\n**Congrats on finishing this unit**!Â There was a lot of information.\\nAnd congrats on fi...\"],[\"Visualize the Clipped Surrogate Objective Function\\n\\nDon't worry. **It's normal if this seems complex...\"],[\"Welcome to the ğŸ¤— Deep Reinforcement Learning Course [[introduction]]\\n\\n\\u003cimg src=\\\"https:\\u002f\\u002fhuggingface....\"],[\"Hands on\\n\\n\\n\\n      \\u003cCourseFloatingBanner classNames=\\\"absolute z-10 right-0 top-0\\\"\\n      notebooks={[\\n...\"],[\"Setup [[setup]]\\n\\nAfter all this information, it's time to get started. We're going to do two things:...\"],[\"Second Quiz [[quiz2]]\\n\\nThe best way to learn and [to avoid the illusion of competence](https:\\u002f\\u002fwww.c...\"],[\"Two main approaches for solving RL problems [[two-methods]]\\n\\n\\u003cTip\\u003e\\nNow that we learned the RL framew...\"],[\"The Exploration\\u002fExploitation trade-off [[exp-exp-tradeoff]]\\n\\nFinally, before looking at the differen...\"],[\"Generalization in Reinforcement Learning\\n\\nGeneralization plays a pivotal role in the realm of Reinfo...\"],[\"Godot RL Agents\\n\\n[Godot RL Agents](https:\\u002f\\u002fgithub.com\\u002fedbeeching\\u002fgodot_rl_agents) is an Open Source ...\"],[\"An Introduction to Unity ML-Agents [[introduction-to-ml-agents]]\\n\\n\\u003cimg src=\\\"https:\\u002f\\u002fhuggingface.co\\u002fd...\"],[\"Introduction [[introduction]]\\n\\n\\u003cimg src=\\\"https:\\u002f\\u002fhuggingface.co\\u002fdatasets\\u002fhuggingface-deep-rl-course\\u002f...\"],[\"Quiz\\n\\nThe best way to learn and [to avoid the illusion of competence](https:\\u002f\\u002fwww.coursera.org\\u002flectu...\"],[\"Model Based Reinforcement Learning (MBRL)\\n\\nModel-based reinforcement learning only differs from its ...\"],[\"Hands-on [[hands-on]]\\n\\nNow that you've learned to use Optuna, here are some ideas to apply what you'...\"],[\"[The Hugging Face Deep Reinforcement Learning Course ğŸ¤— (v2.0)](https:\\u002f\\u002fhuggingface.co\\u002fdeep-rl-course...\"],[\"How do Unity ML-Agents work? [[how-mlagents-works]]\\n\\nBefore training our agent, we need to understan...\"],[\"The Pyramid environment\\n\\nThe goal in this environment is to train our agent to **get the gold brick ...\"],[\"How Huggy works [[how-huggy-works]]\\n\\nHuggy is a Deep Reinforcement Learning environment made by Hugg...\"],[\"Interesting Environments to try\\n\\nHere we provide a list of interesting environments you can try to t...\"],[\"Self-Play: a classic technique to train competitive agents in adversarial games\\n\\nNow that we've stud...\"],[\"Quiz [[quiz]]\\n\\nThe best way to learn and [to avoid the illusion of competence](https:\\u002f\\u002fwww.coursera....\"],[\"Deep Q-Learning [[deep-q-learning]]\\n\\n\\u003cimg src=\\\"https:\\u002f\\u002fhuggingface.co\\u002fdatasets\\u002fhuggingface-deep-rl-c...\"],[\"Apache License\\n                           Version 2.0, January 2004\\n                        http:\\u002f\\u002fw...\"],[\"Optuna Tutorial [[optuna]]\\n\\nThe content below comes from [Antonin's Raffin ICRA 2022 presentations](...\"],[\"Hands-on [[hands-on]]\\n\\n\\n\\n      \\u003cCourseFloatingBanner classNames=\\\"absolute z-10 right-0 top-0\\\"\\n      ...\"],[\"Introduction to PPO with Sample-Factory\\n\\n\\u003cimg src=\\\"https:\\u002f\\u002fhuggingface.co\\u002fdatasets\\u002fhuggingface-deep-...\"],[\"The Deep Q-Learning Algorithm [[deep-q-algorithm]]\\n\\nWe learned that Deep Q-Learning **uses a deep ne...\"],[\"A Q-Learning example [[q-learning-example]]\\n\\nTo better understand Q-Learning, let's take a simple ex...\"],[\"Congratulations\\n\\n\\u003cimg src=\\\"https:\\u002f\\u002fhuggingface.co\\u002fdatasets\\u002fhuggingface-deep-rl-course\\u002fcourse-images\\u002f...\"],[\"What is Reinforcement Learning? [[what-is-reinforcement-learning]]\\n\\nTo understand Reinforcement Lear...\"],[\"Introduction [[introduction]]\\n\\n  \\u003cimg src=\\\"https:\\u002f\\u002fhuggingface.co\\u002fdatasets\\u002fhuggingface-deep-rl-cours...\"],[\"Mid-way Recap [[mid-way-recap]]\\n\\nBefore diving into Q-Learning, let's summarize what we've just lear...\"],[\"Introduction [[introduction]]\\n\\n\\u003cimg src=\\\"https:\\u002f\\u002fhuggingface.co\\u002fdatasets\\u002fhuggingface-deep-rl-course\\u002f...\"],[\"RLHF\\n\\nReinforcement learning from human feedback (RLHF) is a **methodology for integrating human dat...\"]],\"hovertemplate\":\"source=deep-rl-class\\u003cbr\\u003esymbol=circle\\u003cbr\\u003ex=%{x}\\u003cbr\\u003ey=%{y}\\u003cbr\\u003esize_col=%{marker.size}\\u003cbr\\u003eextract=%{customdata[0]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"deep-rl-class, circle\",\"marker\":{\"color\":\"#00cc96\",\"size\":[4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4],\"sizemode\":\"area\",\"sizeref\":0.25,\"symbol\":\"circle\",\"line\":{\"color\":\"DarkSlateGrey\",\"width\":0},\"opacity\":1},\"mode\":\"markers\",\"name\":\"deep-rl-class, circle\",\"showlegend\":true,\"x\":[-2.465034,-2.855047,-2.8996203,-2.9201577,-2.9619944,-2.925651,-2.641066,-2.580487,-2.349527,-2.3919992,-2.899812,-5.7459426,-2.5127869,-2.448495,-3.0125709,-2.9901114,-3.0611372,-3.0501869,-2.4874396,-2.9230912,-2.5060098,-3.2182174,-3.0009308,-2.4392078,-2.5491905,-2.4297554,-3.2736197,-3.1624029,-2.9349942,-2.7453072,-2.940273,-2.9787655,-2.8537383,-3.1386397,-2.615931,-3.0700245,-2.6487927,-3.0304666,-2.975308,-2.286584,-2.8497813,-3.0522933,-2.7089376,-2.503501,-2.550294,-2.8593984,-2.8280542,-3.1177738,-2.459332,-2.7440534,-3.0298111,-3.145362,-2.46739,-2.4423661,-2.964311,-2.8083742,-2.3400736,-3.082936,-3.096602,-3.155281,-2.6929972,-3.1365705,-2.91047,-2.7864761,-2.651025,-3.0953574,-3.118025,-2.925387,-2.695848,-3.1625645,-2.8812516,-3.1382294,-3.038342,-2.7497058,-2.456622,-2.9550865,-3.1386478,-2.5041215,-2.5643635,-2.44672,-2.7630494,-3.0433848,-3.2019672,-3.02527,-2.9503062,-2.9447114,-3.0011501,-2.9828558,-3.0992362,-2.7479277,-2.483287,-3.0628557,-3.089042,-2.6238942,-2.9572074,-3.0287366,-2.7543488,-2.41189,-3.212472,-2.8007548,-2.546714,-2.762777,-2.5428228,-2.5192697,-2.4840238,-3.070599,-2.68473,-2.591014,-2.9600406,-5.0779753],\"xaxis\":\"x\",\"y\":[-7.622915,-7.332049,-7.2636375,-5.5789833,-7.6558123,-7.6418104,-7.769811,-6.012424,-5.8968296,-7.310639,-5.7248707,7.4014373,-7.506284,-5.7302895,-7.502124,-7.4964776,-7.080066,-7.4000916,-7.614883,-7.027063,-5.861138,-6.901634,-6.5286126,-7.7854533,-5.6959386,-5.8208475,-6.643815,-6.6866693,-7.2656293,-5.9327297,-6.0571876,-7.594784,-6.28975,-7.220491,-7.4559064,-7.4650965,-5.8588862,-7.5198345,-7.101574,-5.7305255,-7.5136595,-5.4949265,-5.9519615,-7.706508,-5.8432198,-7.3322816,-7.258391,-7.4352045,-6.3648205,-7.0119405,-7.3270426,-6.347989,-6.624662,-6.351314,-5.801612,-5.7475905,-5.8091984,-6.7383604,-7.4153895,-7.328296,-6.0327134,-6.9765625,-5.964261,-7.634922,-6.4121747,-7.145521,-7.1642427,-7.393542,-6.0982103,-7.3797216,-7.104173,-7.4414415,-6.160501,-6.0224576,-5.854118,-5.7098694,-7.3346014,-6.1741905,-5.948698,-5.990383,-7.492441,-7.5111136,-6.966617,-7.472819,-5.6560755,-5.7104225,-7.1133924,-6.281589,-7.2001767,-5.9185457,-6.1937585,-5.4215007,-6.834243,-5.8827,-5.861449,-5.6946135,-7.530194,-7.2674937,0.622631,-6.361264,-6.1202655,-5.89003,-7.766248,-7.7040505,-5.9464245,-7.327892,-7.647388,-7.817116,-5.8297462,7.9980702],\"yaxis\":\"y\",\"type\":\"scattergl\"},{\"customdata\":[[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!---\\nCopyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"Inference pipelines with the ONNX Runtime accelerator\\n\\nThe [`~pipelines.pipeline`] function makes it...\"],[\"Quantization\\n\\n## AutoGPTQ Integration\\n\\nğŸ¤— Optimum collaborated with [AutoGPTQ library](https:\\u002f\\u002fgithub...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!---\\nCopyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!---\\nCopyright 2022 The HuggingFace Team. All rights reserved.\\nLicensed under the Apache License, Ve...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!---\\nCopyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"!---\\nCopyright 2022 The HuggingFace Team. All rights reserved.\\nLicensed under the Apache License, Ve...\"],[\"Contributor Covenant Code of Conduct\\n\\n## Our Pledge\\n\\nWe as members, contributors, and leaders pledge...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"Register commands in the Optimum CLI from a subpackage\\n\\nIt is possible to register a command in the ...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!---\\nCopyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"Stable Diffusion Text-to-Image Fine-Tuning\\n\\nThis example shows how to leverage ONNX Runtime Training...\"],[\"Overview\\n\\nğŸ¤— Optimum provides an integration with Torch FX, a library for PyTorch that allows develop...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!---\\nCopyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"Accelerated inference on NVIDIA GPUs\\n\\nBy default, ONNX Runtime runs inference on CPU devices. Howeve...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"Optimum Inference with ONNX Runtime\\n\\nOptimum is a utility package for building and running inference...\"],[\"!---\\nCopyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"Symbolic tracer\\n\\nIn Torch FX, the symbolic tracer feeds dummy values through the code to record the ...\"],[\"Accelerated inference on AMD GPUs supported by ROCm\\n\\nBy default, ONNX Runtime runs inference on CPU ...\"],[\"BetterTransformer benchmark\\n\\nPlease refer to https:\\u002f\\u002fmedium.com\\u002fpytorch\\u002fbettertransformer-out-of-the...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"ONNX ğŸ¤ ONNX Runtime\\n\\nONNX is an open standard that defines a common set of operators and a common fi...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"# How to contribute to Optimum?\\n\\nOptimum is an open source project, so all contributions and suggest...\"],[\"Overview\\n\\nğŸ¤— Optimum provides an integration with ONNX Runtime, a cross-platform, high performance en...\"],[\"!---\\nCopyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"!---\\nCopyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!---\\nCopyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"!---\\nCopyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!---\\nCopyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"![ONNX Runtime](https:\\u002f\\u002fgithub.com\\u002fhuggingface\\u002foptimum\\u002factions\\u002fworkflows\\u002ftest_onnxruntime.yml\\u002fbadge....\"],[\"Quantization\\n\\nQuantization is a technique to reduce the computational and memory costs of running in...\"],[\"!---\\nCopyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!---\\nCopyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"Helpful tips for testing & debugging optimum\\n\\n## VSCODE\\n\\nIf you are using vscode you might have hard...\"],[\"!---\\nCopyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!---\\nCopyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"]],\"hovertemplate\":\"source=optimum\\u003cbr\\u003esymbol=circle\\u003cbr\\u003ex=%{x}\\u003cbr\\u003ey=%{y}\\u003cbr\\u003esize_col=%{marker.size}\\u003cbr\\u003eextract=%{customdata[0]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"optimum, circle\",\"marker\":{\"color\":\"#ab63fa\",\"size\":[4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4],\"sizemode\":\"area\",\"sizeref\":0.25,\"symbol\":\"circle\",\"line\":{\"color\":\"DarkSlateGrey\",\"width\":0},\"opacity\":1},\"mode\":\"markers\",\"name\":\"optimum, circle\",\"showlegend\":true,\"x\":[-4.2911115,-3.5129542,-4.274771,-6.0115576,-4.7724547,-7.233114,-5.7803545,-2.7379162,-6.5310917,-5.4916344,-5.341561,-4.210295,-6.304111,-4.5337367,-4.916832,-5.6949677,-6.035926,1.3886014,-4.6601176,-4.6358843,-4.3380775,-2.4886184,-5.4267025,-5.7934704,-5.2030783,-12.864936,-4.329601,-4.533112,-6.02544,-4.8332253,-4.8916516,-3.548221,-2.7634554,-4.6659727,-5.2585626,-6.026194,-5.292161,-4.62389,-4.804171,-2.3459215,-4.489529,-5.1016912,-4.5995564,-4.833093,-4.180865,-5.5441656,0.2968129,-5.084415,-6.0604696,-5.817782,-5.172754,-6.070441,-6.313101,-4.4446025,-2.399394,-4.804002,-7.3130703,-5.6793804,-3.5508273,-5.815379,-4.864655,-1.3090787,-5.6875153,-4.987084,-3.4996169,-6.1801553],\"xaxis\":\"x\",\"y\":[1.3508564,0.46425563,2.1764872,4.3172526,4.088277,3.281263,2.2974715,1.559297,4.9741673,3.2949219,4.0510488,1.9752574,3.52938,2.9513538,1.8604546,3.4294796,4.3070946,6.0108485,2.8466656,2.866126,2.4349165,2.6895063,3.2569594,3.470466,2.1876705,-5.479803,3.02393,2.1051664,3.8698533,3.5328722,2.5247197,0.35297716,2.207215,2.3799205,3.1596699,3.767002,3.0529082,2.2470822,2.9888442,2.5692208,3.6742876,3.6256237,3.257771,3.0899322,2.0436816,3.0475407,4.0147724,3.1329706,4.3474836,3.8799846,3.4411585,4.0569277,4.992952,2.1208093,1.4013106,3.1014142,3.1946855,3.8233914,0.78242224,3.4520888,2.488185,2.883631,3.5630066,2.3256016,0.8353786,4.574167],\"yaxis\":\"y\",\"type\":\"scattergl\"},{\"customdata\":[[\"!--âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to...\"],[\"Fine-tuning for image classification using LoRA and ğŸ¤— PEFT\\n\\n## Vision Transformer model from transfo...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!---\\nCopyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"!--âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to...\"],[\"Fine-tuning a multilayer perceptron using LoRA and ğŸ¤— PEFT\\n\\n[![Open In Colab](https:\\u002f\\u002fcolab.research....\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"Using PEFT with timm\\n\\n`peft` allows us to train any model with LoRA as long as the layer type is sup...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"``python\\nimport os\\n\\nimport torch\\nfrom transformers import (\\n    AutoTokenizer,\\n    default_data_coll...\"],[\"!--âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"Training PEFT models with new tokens being added to the embedding layers and tokenizer\\n\\nIn this exam...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"``python\\nfrom transformers import AutoModelForSeq2SeqLM\\nfrom peft import get_peft_config, get_peft_m...\"],[\"``python\\nfrom transformers import AutoModelForSeq2SeqLM\\nfrom peft import get_peft_config, get_peft_m...\"],[\"``python\\nfrom transformers import AutoModelForCausalLM\\nfrom peft import get_peft_config, get_peft_mo...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"LoftQ: LoRA-fine-tuning-aware Quantization\\n\\n## Introduction\\n\\nLoftQ finds quantized LoRA initializati...\"],[\"Finetuning Whisper-large-V2 on Colab using PEFT-Lora + BNB INT8 training\\n\\nIn this Colab, we present ...\"],[\"``python\\nimport argparse\\nimport gc\\nimport hashlib\\nimport itertools\\nimport logging\\nimport math\\nimport...\"],[\"!--âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"``python\\nfrom transformers import AutoModelForSeq2SeqLM\\nimport peft\\nfrom peft import get_peft_config...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to...\"],[\"``python\\nfrom datasets import load_dataset\\nfrom transformers import set_seed, AutoModelForSeq2SeqLM,...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"``python\\n!pip install -q git+https:\\u002f\\u002fgithub.com\\u002fhuggingface\\u002ftransformers.git\\n!pip install -q git+htt...\"],[\"``python\\nfrom transformers import AutoModelForSeq2SeqLM\\nfrom peft import PeftModel, PeftConfig\\nimpor...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to...\"],[\"Fine-tune FLAN-T5 using `bitsandbytes`, `peft` & `transformers` ğŸ¤— \\n\\nIn this notebook we will see how...\"],[\"``python\\nimport argparse\\nimport os\\n\\nimport torch\\nfrom torch.optim import AdamW\\nfrom torch.utils.data...\"],[\"!--âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to...\"],[\"``python\\nimport argparse\\nimport os\\n\\nimport torch\\nfrom torch.optim import AdamW\\nfrom torch.utils.data...\"],[\"!--âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to...\"],[\"Dreambooth with OFT\\nThis Notebook assumes that you already ran the train_dreambooth.py script to cre...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"``python\\nfrom transformers import AutoModelForCausalLM\\nfrom peft import get_peft_config, get_peft_mo...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"``python\\nimport argparse\\nimport os\\n\\nimport torch\\nfrom torch.optim import AdamW\\nfrom torch.utils.data...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"``python\\nimport argparse\\nimport os\\n\\nimport torch\\nfrom torch.optim import AdamW\\nfrom torch.utils.data...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"``python\\nimport os\\n\\nimport torch\\nfrom transformers import AutoModelForSeq2SeqLM, AutoTokenizer, defa...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"``python\\nimport argparse\\nimport json\\nimport logging\\nimport math\\nimport os\\nimport random\\nfrom pathlib...\"],[\"``python\\nfrom transformers import AutoModelForCausalLM\\nfrom peft import PeftModel, PeftConfig\\nimport...\"],[\"Fine-tuning for semantic segmentation using LoRA and ğŸ¤— PEFT\\n\\n[![Open In Colab](https:\\u002f\\u002fcolab.researc...\"],[\"Using PEFT with custom models\\n\\n`peft` allows us to fine-tune models efficiently with LoRA. In this s...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!---\\nCopyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"``python\\nimport argparse\\nimport os\\n\\nimport torch\\nfrom torch.optim import AdamW\\nfrom torch.utils.data...\"]],\"hovertemplate\":\"source=peft\\u003cbr\\u003esymbol=circle\\u003cbr\\u003ex=%{x}\\u003cbr\\u003ey=%{y}\\u003cbr\\u003esize_col=%{marker.size}\\u003cbr\\u003eextract=%{customdata[0]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"peft, circle\",\"marker\":{\"color\":\"#FFA15A\",\"size\":[4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4],\"sizemode\":\"area\",\"sizeref\":0.25,\"symbol\":\"circle\",\"line\":{\"color\":\"DarkSlateGrey\",\"width\":0},\"opacity\":1},\"mode\":\"markers\",\"name\":\"peft, circle\",\"showlegend\":true,\"x\":[-4.966633,-7.3224416,-4.798969,-7.718652,-1.5201279,-6.928673,-6.9813395,-7.1782413,-6.5770173,-4.444882,11.240257,-7.174831,-7.7551327,-6.5900984,-7.496648,-7.61194,-6.8692136,-7.552855,-13.390636,-7.514259,11.240902,11.239711,11.240156,-3.4817812,-7.2921863,-6.0616946,-13.52847,-4.222441,-4.06848,-7.7885184,-3.2011724,-7.7034802,11.240097,-7.6768513,-4.4591856,-4.5943613,11.235171,-7.326499,-3.290524,11.237912,-6.0173736,-7.0873537,-6.1105237,-5.989838,11.239625,-7.419418,11.238138,-6.8651423,-13.045262,-13.21384,-7.5596614,11.237703,-7.6733804,-7.220697,-4.0155377,-7.3954897,11.240355,-3.4854915,11.238517,-7.7528105,-7.3575788,-7.3246717,-7.8486156,11.236851,-7.425691,11.229831,11.237539,-7.8528333,-6.826607,-6.823105,-7.01889,-7.057441,11.2401285],\"xaxis\":\"x\",\"y\":[1.5085815,1.7723334,1.5831131,3.2447636,1.1888528,2.8675969,1.9231827,3.1289098,1.8131568,1.4652216,-17.3862,3.3750029,1.5331843,1.985896,3.1316347,3.3693783,1.8932128,3.4907026,-5.339793,1.2199054,-17.389048,-17.387197,-17.386349,1.4879099,2.2238038,2.3400638,-6.1529317,4.0720353,1.1020277,3.1827374,1.0840235,3.0981898,-17.389507,3.10999,1.3155147,4.073434,-17.381672,1.6326493,2.3747532,-17.386076,2.135933,2.3850746,2.063717,3.2172608,-17.382694,2.1534722,-17.387592,2.7014291,-5.670928,-3.307252,3.0412798,-17.386992,3.3244812,1.5455635,1.4038359,1.5595716,-17.38739,1.9548662,-17.384613,2.9662592,1.7480577,2.22909,3.1637223,-17.387033,1.378841,-17.369118,-17.384687,1.616361,1.8231592,2.221122,1.7082798,2.5347593,-17.383385],\"yaxis\":\"y\",\"type\":\"scattergl\"},{\"customdata\":[[\"p align=\\\"center\\\"\\u003e\\n  \\u003cbr\\u002f\\u003e\\n    \\u003cimg alt=\\\"huggingface_hub library logo\\\" src=\\\"https:\\u002f\\u002fhuggingface.co\\u002fda...\"],[\"!--âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to...\"],[\"--\\n# For reference on dataset card metadata, see the spec: https:\\u002f\\u002fgithub.com\\u002fhuggingface\\u002fhub-docs\\u002fb...\"],[\"!--âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to...\"],[\"!---\\nCopyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"# Contributor Covenant Code of Conduct\\n\\n## Our Pledge\\n\\nWe as members, contributors, and leaders pled...\"],[\"!--âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to...\"],[\"Running Tests\\n\\nTo run the test suite, please perform the following from the root directory of this r...\"],[\"!--âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to...\"],[\"!--âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to...\"],[\"!--âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to...\"],[\"--\\nlanguage:\\n- en\\nlicense: mit\\nlibrary_name: pytorch-lightning\\ntags:\\n- pytorch\\n- image-classificatio...\"],[\"--\\n[]\\n---\\n\\n# invalid-card-data\\n\\nThis card should fail when trying to load it in because the card dat...\"],[\"his document covers all steps that need to be done in order to do a release of the `huggingface_hub`...\"],[\"!--âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to...\"],[\"!--âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to...\"],[\"!--âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to...\"],[\"!--âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to...\"],[\"!--âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to...\"],[\"Inference Endpoints\\n\\nInference Endpoints provides a secure production solution to easily deploy mode...\"],[\"!--âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to...\"],[\"p align=\\\"center\\\"\\u003e\\n  \\u003cbr\\u002f\\u003e\\n    \\u003cimg alt=\\\"huggingface_hub library logo\\\" src=\\\"https:\\u002f\\u002fhuggingface.co\\u002fda...\"],[\"!--âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to...\"],[\"!--âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to...\"],[\"--\\n# For reference on model card metadata, see the spec: https:\\u002f\\u002fgithub.com\\u002fhuggingface\\u002fhub-docs\\u002fblo...\"],[\"MyCoolModel\\n\\nIn this example, we don't have any metadata at the top of the file. In cases like these...\"],[\"!--âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to...\"],[\"!---\\nCopyright 2023 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"!--âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to...\"],[\"p align=\\\"center\\\"\\u003e\\n  \\u003cbr\\u002f\\u003e\\n    \\u003cimg alt=\\\"huggingface_hub library logo\\\" src=\\\"https:\\u002f\\u002fhuggingface.co\\u002fda...\"],[\"p align=\\\"center\\\"\\u003e\\n  \\u003cbr\\u002f\\u003e\\n    \\u003cimg alt=\\\"huggingface_hub library logo\\\" src=\\\"https:\\u002f\\u002fhuggingface.co\\u002fda...\"],[\"!--âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to...\"],[\"!--âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to...\"],[\"Contrib test suite\\n\\nThe contrib folder contains simple end-to-end scripts to test integration of `hu...\"],[\"!--âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to...\"],[\"--\\nlanguage: en\\nlicense: mit\\nlibrary_name: timm\\ntags:\\n- pytorch\\n- image-classification\\ndatasets:\\n- b...\"],[\"p align=\\\"center\\\"\\u003e\\n  \\u003cbr\\u002f\\u003e\\n    \\u003cimg alt=\\\"huggingface_hub library logo\\\" src=\\\"https:\\u002f\\u002fhuggingface.co\\u002fda...\"],[\"!--âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to...\"],[\"## Translating the `huggingface_hub` documentation into your language\\n\\nAs part of our mission to dem...\"],[\"!--âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to...\"],[\"!--âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to...\"],[\"Hugging Face Hub Client library\\n\\n## Download files from the Hub\\n\\nThe `hf_hub_download()` function is...\"],[\"!--âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to...\"],[\"!--âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to...\"],[\"!--âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to...\"],[\"Inference Endpoints\\n\\nInference Endpoints provides a secure production solution to easily deploy any ...\"],[\"!--âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to...\"],[\"!--âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to...\"],[\"!--âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to...\"],[\"!--âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to...\"],[\"!--âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to...\"],[\"!--âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to...\"],[\"!--âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to...\"],[\"--\\nlanguage: en\\nlicense: mit\\nlibrary_name: timm\\ntags:\\n- pytorch\\n- image-classification\\ndatasets:\\n- b...\"],[\"--\\nlicense: mit\\nlanguage: eo\\nthumbnail: https:\\u002f\\u002fhuggingface.co\\u002fblog\\u002fassets\\u002f01_how-to-train\\u002fEsperBERT...\"],[\"!--âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to...\"],[\"--\\nlanguage:\\n- en\\nlicense:\\n- bsd-3-clause\\nannotations_creators:\\n- crowdsourced\\n- expert-generated\\nla...\"],[\"!--âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to...\"],[\"!--âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to...\"],[\"!--âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to...\"],[\"!--âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to...\"],[\"--\\n{{card_data}}\\n---\\n\\n# {{ model_name | default(\\\"MyModelName\\\", true)}}\\n\\n{{ some_data }}...\"],[\"!--âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to...\"],[\"!--âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to...\"],[\"!--âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to...\"],[\"--\\n{card_data}\\n---\\n\\n# {{ pretty_name | default(\\\"Dataset Name\\\", true)}}\\n\\n{{ some_data }}...\"],[\"!--âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to...\"]],\"hovertemplate\":\"source=huggingface_hub\\u003cbr\\u003esymbol=circle\\u003cbr\\u003ex=%{x}\\u003cbr\\u003ey=%{y}\\u003cbr\\u003esize_col=%{marker.size}\\u003cbr\\u003eextract=%{customdata[0]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"huggingface_hub, circle\",\"marker\":{\"color\":\"#19d3f3\",\"size\":[4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4],\"sizemode\":\"area\",\"sizeref\":0.25,\"symbol\":\"circle\",\"line\":{\"color\":\"DarkSlateGrey\",\"width\":0},\"opacity\":1},\"mode\":\"markers\",\"name\":\"huggingface_hub, circle\",\"showlegend\":true,\"x\":[0.11586389,0.84595174,0.6451348,1.1922811,-2.5265703,1.3557878,0.62110376,-1.3248923,1.1683937,1.4116995,0.70149565,-1.7097718,-0.37274796,-0.030093841,1.52347,2.9614177,0.48873544,0.65912896,1.0422087,-0.18594424,0.9776312,-0.08464,1.9511744,-0.16845241,-0.23022644,-0.5532304,2.214116,-1.4466021,1.425649,0.043700717,-0.07587424,1.0468389,2.4674108,-1.6992174,1.1746607,-1.089399,0.024756897,1.5220921,-1.9100227,0.16364583,0.85337055,0.8010552,-0.25334454,0.67316824,-0.59063894,-0.33056948,1.4949603,0.44461843,-1.9603312,0.9072898,1.4198169,0.02192678,1.2560138,-2.066229,-2.5965953,-0.056954347,-3.490024,-1.9407771,0.88856107,0.87573814,0.6839421,-0.30618998,-0.789412,-0.6559217,0.7885974,0.19778745,0.35560843],\"xaxis\":\"x\",\"y\":[3.3789973,3.9629958,4.3894906,4.1881037,1.8352205,5.9374914,3.975441,2.8112953,3.8775206,4.620485,4.9220734,3.6043296,4.0621524,3.8819714,5.1249247,5.7245555,3.5163677,4.898084,4.0439544,7.18341,4.2666826,3.2525992,4.9021015,4.322661,5.1206684,4.20133,4.689196,1.1889173,5.4502463,3.378368,3.2133286,3.9781563,5.471515,3.0487673,4.08922,3.8614,3.1899364,4.978138,5.1949825,3.726428,3.9055593,4.1814766,3.535409,4.565283,5.009824,7.1483474,5.3556333,4.6362066,3.9983342,4.060072,5.074535,4.3888617,4.586764,3.7639549,4.3879843,4.672728,5.08605,3.292761,4.0956726,4.2243485,4.2303696,4.0271,6.930996,6.9645405,3.9092226,3.8153641,3.6647253],\"yaxis\":\"y\",\"type\":\"scattergl\"},{\"customdata\":[[\"The tokenization pipeline\\n\\nWhen calling `Tokenizer.encode` or\\n`Tokenizer.encode_batch`, the input\\nte...\"],[\"Quicktour\\n\\nLet's have a quick look at the ğŸ¤— Tokenizers library features. The\\nlibrary provides an imp...\"],[\"p align=\\\"center\\\"\\u003e\\n    \\u003cbr\\u003e\\n    \\u003cimg src=\\\"https:\\u002f\\u002fhuggingface.co\\u002flanding\\u002fassets\\u002ftokenizers\\u002ftokenizers...\"],[\"`tokenizers-linux-arm64-musl`\\n\\nThis is the **aarch64-unknown-linux-musl** binary for `tokenizers`...\"],[\"div align=\\\"center\\\"\\u003e\\n\\n  \\u003ch1\\u003e\\u003ccode\\u003ewasm-pack-template\\u003c\\u002fcode\\u003e\\u003c\\u002fh1\\u003e\\n\\n  \\u003cstrong\\u003eA template for kick start...\"],[\"Post-processors\\n\\n\\u003ctokenizerslangcontent\\u003e\\n\\u003cpython\\u003e\\n## BertProcessing\\n\\n[[autodoc]] tokenizers.processo...\"],[\"Training from memory\\n\\nIn the [Quicktour](quicktour), we saw how to build and train a\\ntokenizer using...\"],[\"Models\\n\\n\\u003ctokenizerslangcontent\\u003e\\n\\u003cpython\\u003e\\n## BPE\\n\\n[[autodoc]] tokenizers.models.BPE\\n\\n## Model\\n\\n[[auto...\"],[\"Added Tokens\\n\\n\\u003ctokenizerslangcontent\\u003e\\n\\u003cpython\\u003e\\n## AddedToken\\n\\n[[autodoc]] tokenizers.AddedToken\\n    ...\"],[\"p align=\\\"center\\\"\\u003e\\n    \\u003cbr\\u003e\\n    \\u003cimg src=\\\"https:\\u002f\\u002fhuggingface.co\\u002flanding\\u002fassets\\u002ftokenizers\\u002ftokenizers...\"],[\"p align=\\\"center\\\"\\u003e\\n    \\u003cbr\\u003e\\n    \\u003cimg src=\\\"https:\\u002f\\u002fhuggingface.co\\u002flanding\\u002fassets\\u002ftokenizers\\u002ftokenizers...\"],[\"`tokenizers-win32-x64-msvc`\\n\\nThis is the **x86_64-pc-windows-msvc** binary for `tokenizers`...\"],[\"`tokenizers-freebsd-x64`\\n\\nThis is the **x86_64-unknown-freebsd** binary for `tokenizers`...\"],[\"`tokenizers-win32-ia32-msvc`\\n\\nThis is the **i686-pc-windows-msvc** binary for `tokenizers`...\"],[\"Visualizer\\n\\n\\u003ctokenizerslangcontent\\u003e\\n\\u003cpython\\u003e\\n## Annotation\\n\\n[[autodoc]] tokenizers.tools.Annotation\\n...\"],[\"Components\\n\\nWhen building a Tokenizer, you can attach various types of components to\\nthis Tokenizer ...\"],[\"!-- DISABLE-FRONTMATTER-SECTIONS --\\u003e\\n\\n# Tokenizers\\n\\nFast State-of-the-art tokenizers, optimized for ...\"],[\"Decoders\\n\\n\\u003ctokenizerslangcontent\\u003e\\n\\u003cpython\\u003e\\n## BPEDecoder\\n\\n[[autodoc]] tokenizers.decoders.BPEDecoder...\"],[\"`tokenizers-darwin-arm64`\\n\\nThis is the **aarch64-apple-darwin** binary for `tokenizers`...\"],[\"Input Sequences\\n\\n\\u003ctokenizerslangcontent\\u003e\\n\\u003cpython\\u003e\\nThese types represent all the different kinds of s...\"],[\"Encoding\\n\\n\\u003ctokenizerslangcontent\\u003e\\n\\u003cpython\\u003e\\n## Encoding\\n\\n[[autodoc]] tokenizers.Encoding\\n    - all\\n  ...\"],[\"Pre-tokenizers\\n\\n\\u003ctokenizerslangcontent\\u003e\\n\\u003cpython\\u003e\\n## BertPreTokenizer\\n\\n[[autodoc]] tokenizers.pre_tok...\"],[\"Normalizers\\n\\n\\u003ctokenizerslangcontent\\u003e\\n\\u003cpython\\u003e\\n## BertNormalizer\\n\\n[[autodoc]] tokenizers.normalizers....\"],[\"Trainers\\n\\n\\u003ctokenizerslangcontent\\u003e\\n\\u003cpython\\u003e\\n## BpeTrainer\\n\\n[[autodoc]] tokenizers.trainers.BpeTrainer...\"],[\"p align=\\\"center\\\"\\u003e\\n  \\u003cbr\\u003e\\n  \\u003cimg src=\\\"https:\\u002f\\u002fhuggingface.co\\u002flanding\\u002fassets\\u002ftokenizers\\u002ftokenizers-log...\"],[\"# Requirements\\n\\nIn order to generate the documentation, it is necessary to have a Python environment...\"],[\"`tokenizers-linux-x64-gnu`\\n\\nThis is the **x86_64-unknown-linux-gnu** binary for `tokenizers`...\"],[\"Changelog\\nAll notable changes to this project will be documented in this file.\\n\\nThe format is based ...\"],[\"`tokenizers-win32-arm64-msvc`\\n\\nThis is the **aarch64-pc-windows-msvc** binary for `tokenizers`...\"],[\"`tokenizers-android-arm-eabi`\\n\\nThis is the **armv7-linux-androideabi** binary for `tokenizers`...\"],[\"`tokenizers-linux-arm-gnueabihf`\\n\\nThis is the **armv7-unknown-linux-gnueabihf** binary for `tokenize...\"],[\"`tokenizers-linux-arm64-gnu`\\n\\nThis is the **aarch64-unknown-linux-gnu** binary for `tokenizers`...\"],[\"`tokenizers-linux-x64-musl`\\n\\nThis is the **x86_64-unknown-linux-musl** binary for `tokenizers`...\"],[\"`tokenizers-android-arm64`\\n\\nThis is the **aarch64-linux-android** binary for `tokenizers`...\"],[\"Changelog\\nAll notable changes to this project will be documented in this file.\\n\\nThe format is based ...\"],[\"div align=\\\"center\\\"\\u003e\\n\\n  \\u003ch1\\u003e\\u003ccode\\u003ecreate-wasm-app\\u003c\\u002fcode\\u003e\\u003c\\u002fh1\\u003e\\n\\n  \\u003cstrong\\u003eAn \\u003ccode\\u003enpm init\\u003c\\u002fcode\\u003e tem...\"],[\"Encode Inputs\\n\\n\\u003ctokenizerslangcontent\\u003e\\n\\u003cpython\\u003e\\nThese types represent all the different kinds of inp...\"],[\"Tokenizer\\n\\n\\u003ctokenizerslangcontent\\u003e\\n\\u003cpython\\u003e\\n## Tokenizer\\n\\n[[autodoc]] tokenizers.Tokenizer\\n    - all...\"],[\"Installation\\n\\n\\u003ctokenizerslangcontent\\u003e\\n\\u003cpython\\u003e\\nğŸ¤— Tokenizers is tested on Python 3.5+.\\n\\nYou should in...\"],[\"`tokenizers-darwin-x64`\\n\\nThis is the **x86_64-apple-darwin** binary for `tokenizers`...\"],[\"# How to release\\n\\n# Before the release\\n\\nSimple checklist on how to make releases for `tokenizers`.\\n\\n...\"]],\"hovertemplate\":\"source=tokenizers\\u003cbr\\u003esymbol=circle\\u003cbr\\u003ex=%{x}\\u003cbr\\u003ey=%{y}\\u003cbr\\u003esize_col=%{marker.size}\\u003cbr\\u003eextract=%{customdata[0]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"tokenizers, circle\",\"marker\":{\"color\":\"#FF6692\",\"size\":[4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4],\"sizemode\":\"area\",\"sizeref\":0.25,\"symbol\":\"circle\",\"line\":{\"color\":\"DarkSlateGrey\",\"width\":0},\"opacity\":1},\"mode\":\"markers\",\"name\":\"tokenizers, circle\",\"showlegend\":true,\"x\":[-9.728585,-9.919467,-10.194657,13.141226,-2.783692,-10.055123,-9.356278,-10.05581,-10.055601,-10.21106,-10.081851,13.141024,13.141059,13.141293,-10.05752,-9.859744,-10.116635,-10.0571,13.141272,-10.0550375,-10.055964,-10.056391,-10.056518,-10.055596,-10.239496,-1.7618053,13.141409,-5.1898146,13.141802,13.140684,13.141294,13.140015,13.141648,13.141627,-5.416382,-2.768464,-9.103427,-10.058794,-10.0504,13.141335,-2.273486],\"xaxis\":\"x\",\"y\":[7.8302026,7.9590216,8.090088,16.43146,3.8834817,16.59313,7.816268,16.592611,16.58793,8.135164,8.012197,16.430527,16.431074,16.432196,16.592201,7.8808064,8.031809,16.59129,16.4303,16.540964,16.577654,16.58749,16.587893,16.591345,8.136383,2.5737088,16.43202,5.2274847,16.431221,16.431496,16.429909,16.43057,16.43204,16.43077,5.4328904,3.6398044,7.452101,16.590727,16.57166,16.431797,2.794882],\"yaxis\":\"y\",\"type\":\"scattergl\"},{\"customdata\":[[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"How to contribute to simulate?\\n[![Contributor Covenant](https:\\u002f\\u002fimg.shields.io\\u002fbadge\\u002fContributor%20C...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"# Simulate with Godot\\n\\n### Install in Godot 4\\nThis integration has been developed for Godot 4.x. You...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"p align=\\\"center\\\"\\u003e\\n    \\u003cbr\\u003e\\n    \\u003cimg src=\\\"docs\\u002fsource\\u002fassets\\u002fsimulate_library.png\\\" width=\\\"400\\\"\\u002f\\u003e\\n    ...\"],[\"# Unity Integration\\n\\n### Install with the Unity editor\\nCurrently we use Unity version `2021.3.2f1` a...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!---\\nCopyright 2020 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, V...\"],[\"Security Policy\\n\\n## Supported Versions\\n\\u003c!--\\nUse this section to tell people about which versions of ...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"his package provides core backend functionality for the Hugging Face Simulate project: (https:\\u002f\\u002fgith...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"# Blender Integration\\n\\n### Install addon in Blender\\nThis integration has been developed for Blender ...\"],[\"Tests examples taken from the original great gltflib\\n\\nFind the great gltflib by Lukas Shawford here:...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"# Examples for Simulate\\n\\nThe examples are organized by level of complexity or application. \\nCurrentl...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"],[\"!--Copyright 2022 The HuggingFace Team. All rights reserved.\\n\\nLicensed under the Apache License, Ver...\"]],\"hovertemplate\":\"source=simulate\\u003cbr\\u003esymbol=circle\\u003cbr\\u003ex=%{x}\\u003cbr\\u003ey=%{y}\\u003cbr\\u003esize_col=%{marker.size}\\u003cbr\\u003eextract=%{customdata[0]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"simulate, circle\",\"marker\":{\"color\":\"#B6E880\",\"size\":[4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4],\"sizemode\":\"area\",\"sizeref\":0.25,\"symbol\":\"circle\",\"line\":{\"color\":\"DarkSlateGrey\",\"width\":0},\"opacity\":1},\"mode\":\"markers\",\"name\":\"simulate, circle\",\"showlegend\":true,\"x\":[-3.379504,1.3291632,-3.4308481,-3.6444416,-3.2213993,-3.3307815,-3.4229264,-3.284602,-3.3645663,-3.2951674,-3.210396,-3.4166875,-1.5189337,1.2346749,-3.4580977,-3.4541519,-3.2226765,-3.0965712,-3.432226,-3.4865155,-3.3961582,-3.3314931,-3.2477422,17.181034,-3.380039,-3.238076,-3.4668896,-3.9727745,-3.3952987,-3.2190554,-2.9415314,-3.4204633,-3.591],\"xaxis\":\"x\",\"y\":[-2.3459582,5.1432257,0.059294146,-0.86497766,-2.5858152,-2.4351091,0.17950861,-2.5038326,-2.1045783,-2.4399462,-3.0244021,0.1371929,1.1362064,6.0976048,-0.029137716,0.61102545,-2.4997256,-6.45739,-2.3949935,-1.218769,0.027059007,-2.4796178,-2.577882,1.0797915,-0.0016657887,-2.735078,0.20594168,2.5522537,0.22042835,-2.659201,-6.2942023,0.13430461,-2.1077244],\"yaxis\":\"y\",\"type\":\"scattergl\"},{\"customdata\":[[\"# How to release\\n\\n# Before the release\\n\\nSimple checklist on how to make releases for `safetensors`.\\n...\"],[\"Flax API\\n\\n[[autodoc]] safetensors.flax.load_file\\n[[autodoc]] safetensors.flax.load\\n[[autodoc]] safet...\"],[\"Convert weights to safetensors\\n\\nPyTorch model weights are commonly saved and stored as `.bin` files ...\"],[\"Numpy API\\n\\n[[autodoc]] safetensors.numpy.load_file\\n[[autodoc]] safetensors.numpy.load\\n[[autodoc]] sa...\"],[\"Speed Comparison\\n\\n\\u003ca href=\\\"https:\\u002f\\u002fcolab.research.google.com\\u002fgithub\\u002fhuggingface\\u002fnotebooks\\u002fblob\\u002fmain\\u002f...\"],[\"# Installation\\n\\n```\\npip install safetensors\\n```\\n\\n\\n## Usage\\n\\n### Numpy\\n\\n```python\\nfrom safetensors.nu...\"],[\"PaddlePaddle API\\n\\n[[autodoc]] safetensors.paddle.load_file\\n[[autodoc]] safetensors.paddle.load\\n[[aut...\"],[\"he purpose of this directory is to showcase various attacks (and creating your own).\\n\\n\\n# Torch Arbit...\"],[\"p align=\\\"center\\\"\\u003e\\n  \\u003cpicture\\u003e\\n    \\u003csource media=\\\"(prefers-color-scheme: dark)\\\" srcset=\\\"https:\\u002f\\u002fhuggi...\"],[\"Metadata Parsing\\n\\nGiven the simplicity of the format, it's very simple and efficient to fetch and pa...\"],[\"Torch API\\n\\n[[autodoc]] safetensors.torch.load_file\\n[[autodoc]] safetensors.torch.load\\n[[autodoc]] sa...\"],[\"Tensorflow API\\n\\n[[autodoc]] safetensors.tensorflow.load_file\\n[[autodoc]] safetensors.tensorflow.load...\"],[\"!-- DISABLE-FRONTMATTER-SECTIONS --\\u003e\\n\\n\\u003cdiv class=\\\"flex justify-center\\\"\\u003e\\n    \\u003cimg class=\\\"block dark:h...\"],[\"Torch shared tensors\\n\\n\\n## TL;DR\\n\\nUsing specific functions, which should work in most cases for you.\\n...\"]],\"hovertemplate\":\"source=safetensors\\u003cbr\\u003esymbol=circle\\u003cbr\\u003ex=%{x}\\u003cbr\\u003ey=%{y}\\u003cbr\\u003esize_col=%{marker.size}\\u003cbr\\u003eextract=%{customdata[0]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"safetensors, circle\",\"marker\":{\"color\":\"#FF97FF\",\"size\":[4,4,4,4,4,4,4,4,4,4,4,4,4,4],\"sizemode\":\"area\",\"sizeref\":0.25,\"symbol\":\"circle\",\"line\":{\"color\":\"DarkSlateGrey\",\"width\":0},\"opacity\":1},\"mode\":\"markers\",\"name\":\"safetensors, circle\",\"showlegend\":true,\"x\":[-1.8882433,-1.0403514,-1.0984641,-1.0261871,-1.283522,-1.2127454,-1.0033636,-2.0224752,-0.16527227,0.9234847,-1.1560152,-0.9982047,-0.96327436,-1.3551887],\"xaxis\":\"x\",\"y\":[2.6124372,2.331099,2.3113577,2.3408349,2.2590256,2.30126,2.4690092,2.8953166,3.1960835,2.8488927,2.2653868,2.0674465,2.272992,2.3311288],\"yaxis\":\"y\",\"type\":\"scattergl\"},{\"customdata\":[[\"How to create a pipeline object?\"]],\"hovertemplate\":\"source=User query\\u003cbr\\u003esymbol=star\\u003cbr\\u003ex=%{x}\\u003cbr\\u003ey=%{y}\\u003cbr\\u003esize_col=%{marker.size}\\u003cbr\\u003eextract=%{customdata[0]}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"User query, star\",\"marker\":{\"color\":\"black\",\"size\":[100],\"sizemode\":\"area\",\"sizeref\":0.25,\"symbol\":\"diamond\",\"line\":{\"color\":\"DarkSlateGrey\",\"width\":0},\"opacity\":1},\"mode\":\"markers\",\"name\":\"User query, star\",\"showlegend\":true,\"x\":[-2.326885],\"xaxis\":\"x\",\"y\":[2.7163997],\"yaxis\":\"y\",\"type\":\"scattergl\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"x\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"y\"}},\"legend\":{\"title\":{\"text\":\"\\u003cb\\u003eChunk source\\u003c\\u002fb\\u003e\"},\"tracegroupgap\":0,\"itemsizing\":\"constant\"},\"margin\":{\"t\":60},\"height\":700,\"width\":1000,\"title\":{\"text\":\"\\u003cb\\u003e2D Projection of Chunk Embeddings via PaCMAP\\u003c\\u002fb\\u003e\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('6ccbbf3b-57b6-4b5c-a614-3a152e9969fe');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "df = pd.DataFrame.from_dict(\n",
        "    [\n",
        "        {\n",
        "            \"x\": documents_projected[i, 0],\n",
        "            \"y\": documents_projected[i, 1],\n",
        "            \"source\": docs_processed[i].metadata[\"source\"].split(\"/\")[1],\n",
        "            \"extract\": docs_processed[i].page_content[:100] + \"...\",\n",
        "            \"symbol\": \"circle\",\n",
        "            \"size_col\": 4,\n",
        "        }\n",
        "        for i in range(len(docs_processed))\n",
        "    ]\n",
        "    + [\n",
        "        {\n",
        "            \"x\": documents_projected[-1, 0],\n",
        "            \"y\": documents_projected[-1, 1],\n",
        "            \"source\": \"User query\",\n",
        "            \"extract\": user_query,\n",
        "            \"size_col\": 100,\n",
        "            \"symbol\": \"star\",\n",
        "        }\n",
        "    ]\n",
        ")\n",
        "\n",
        "# visualize the embedding\n",
        "fig = px.scatter(\n",
        "    df,\n",
        "    x=\"x\",\n",
        "    y=\"y\",\n",
        "    color=\"source\",\n",
        "    hover_data=\"extract\",\n",
        "    size=\"size_col\",\n",
        "    symbol=\"symbol\",\n",
        "    color_discrete_map={\"User query\": \"black\"},\n",
        "    width=1000,\n",
        "    height=700,\n",
        ")\n",
        "fig.update_traces(\n",
        "    marker=dict(opacity=1, line=dict(width=0, color=\"DarkSlateGrey\")),\n",
        "    selector=dict(mode=\"markers\"),\n",
        ")\n",
        "fig.update_layout(\n",
        "    legend_title_text=\"<b>Chunk source</b>\",\n",
        "    title=\"<b>2D Projection of Chunk Embeddings via PaCMAP</b>\",\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWesCSGt9-9N"
      },
      "source": [
        "On the graph above, you can see a spatial representation of the kowledge base documents. As the vector embeddings represent the document's meaning, their closeness in meaning should be reflected in their embedding's closeness.\n",
        "\n",
        "The user query's embedding is also shown : we want to find the `k` document that have the closest meaning, thus we pick the `k` closest vectors.\n",
        "\n",
        "In the LangChain vector database implementation, this search operation is performed by the method `vector_database.similarity_search(query)`.\n",
        "\n",
        "Here is the result:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "VcjQzejH9-9N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "005824f1-15f4-4a1c-fed9-2003dd374ccf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting retrieval for user_query='How to create a pipeline object?'...\n",
            "\n",
            "==================================Top document==================================\n",
            "Gradio Demo: ner_pipeline\n",
            "\n",
            "\n",
            "```\n",
            "!pip install -q gradio torch transformers\n",
            "```\n",
            "\n",
            "\n",
            "```\n",
            "from transformers import pipeline\n",
            "\n",
            "import gradio as gr\n",
            "\n",
            "ner_pipeline = pipeline(\"ner\")\n",
            "\n",
            "examples = [\n",
            "    \"Does Chicago have any stores and does Joe live here?\",\n",
            "]\n",
            "\n",
            "def ner(text):\n",
            "    output = ner_pipeline(text)\n",
            "    return {\"text\": text, \"entities\": output}    \n",
            "\n",
            "demo = gr.Interface(ner,\n",
            "             gr.Textbox(placeholder=\"Enter sentence here...\"), \n",
            "             gr.HighlightedText(),\n",
            "             examples=examples)\n",
            "\n",
            "if __name__ == \"__main__\":\n",
            "    demo.launch()\n",
            "\n",
            "```\n",
            "==================================Metadata==================================\n",
            "{'source': 'gradio-app/gradio/blob/main/demo/ner_pipeline/run.ipynb'}\n"
          ]
        }
      ],
      "source": [
        "print(f\"\\nStarting retrieval for {user_query=}...\")\n",
        "retrieved_docs = KNOWLEDGE_VECTOR_DATABASE.similarity_search(query=user_query, k=5)\n",
        "print(\n",
        "    \"\\n==================================Top document==================================\"\n",
        ")\n",
        "print(retrieved_docs[0].page_content)\n",
        "print(\"==================================Metadata==================================\")\n",
        "print(retrieved_docs[0].metadata)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjVqmDGh9-9N"
      },
      "source": [
        "# 2. Reader - LLM ğŸ’¬\n",
        "\n",
        "In this part, the __LLM Reader reads the retrieved context to formulate its answer.__\n",
        "\n",
        "There are actually substeps that can all be tuned:\n",
        "1. The content of the retrieved documents is aggregated together into the \"context\", with many processing options like _prompt compression_.\n",
        "2. The context and the user query are aggregated into a prompt then given to the LLM to generate its answer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xiXcG269-9N"
      },
      "source": [
        "### 2.1. Reader model\n",
        "\n",
        "The choice of a reader model is important on a few aspects:\n",
        "- the reader model's `max_seq_length` must accomodate our prompt, which includes the context output by the retriever call: the context consists in 5 documents of 512 tokens each, so we aim for a context length of 4k tokens at least.\n",
        "- the reader model\n",
        "\n",
        "For this example, we chose [`HuggingFaceH4/zephyr-7b-beta`](https://huggingface.co/HuggingFaceH4/zephyr-7b-beta), a small but powerful model.\n",
        "\n",
        "With many models being released every week, you may want to substitute this model to the latest and greatest. The best way to keep track of open source LLMs is to check the [Open-source LLM leaderboard](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard).\n",
        "\n",
        "To make inference faster, we will load the quantized version of the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "QX_ORK4l9-9N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610,
          "referenced_widgets": [
            "6d2c0cc488ce4bbc9db96fdf535a0ac8",
            "d61b40127beb4fbe9eb0f827d0ddcadd",
            "c66273058bf54af3a1f2d274223cf2cf",
            "4cba78bf756b4d3299aa51402ea1da9d",
            "11743f051fa348bfaa77e43d0ab4cc4d",
            "d1ee2619aeba46d38efdcedcfb01a1a1",
            "6563f7b1a03a4dbd82c738acb5f8ae87",
            "40aab0eb5e7e4c45a49c65c25f5c7193",
            "69a8d41a80b04f29b871d8747a8edf0c",
            "c48ae09887434d6bbd3aa1cd1a49a715",
            "8fd147ccf8ba492488a00563c1218c6e",
            "4dac682e25ac40b1ac5e4143d1f75e5a",
            "a0469766185e4454a0ebb5ca8df77a98",
            "c1c206b7373645ffa95dabbb01bf1d19",
            "f4ea43e1fad146bd9eb25185770d1eda",
            "4b928c998835416bb40beda4c3994706",
            "8ff092c08cc84953b5212219ae60a4e4",
            "bc506cdba1b34b9bac903fbd8e0523bb",
            "210f2e45cb244a41a729f247ffe52b4d",
            "330c17b5e2794c8a9adfec05ef47e096",
            "33f9752b189c4f4b9b1e4fe17b529178",
            "628e1a6c7a4d4fc8ba2fa8e477ddbb07",
            "53e06b2ec3c148f39ac185fd6a69f892",
            "98d4a01191c84efeab4ed283e35f0fc8",
            "6fc50a7c50f24232b43be214437cc9d6",
            "b69f92feb3ad471587c799858c7a890b",
            "49e25bc0d71c468ca244226c571cb366",
            "96155b33ab3c49debd3f857ef01c1936",
            "3ddc921343c84cdc90855d78719f1174",
            "a982c076d79e424babda0c358975bf9b",
            "52747f0d00164746ba3590b0d19a5db4",
            "7389d222a8164c7b8805fc824ef094bf",
            "78e2d9554b8d4a71a9371068ce65e20a",
            "938556fd9d6e4a4b96c4c4d97d896d62",
            "76bc342bfbb543b5bbb6963aec6afc91",
            "196ad5e3d4b34c34908998c846661b7c",
            "68b7287f3bff451aabc78414fa694d49",
            "14f777e5c7cc4bec9e8dc5a627c3ae70",
            "bbbc1411ae5f46e588d758bd6a29628c",
            "b3958da8cda8406b97d2fd208e14595a",
            "412c4cbab7a0402fb47d4e67b78bb3ac",
            "a80923a093ec4dd9898f6de07f00b000",
            "eea4493968324a759de6ce68bbfb5d2b",
            "730636c37a93486aabe31a71d5b8bb44",
            "3037531e7a5d43deb6a5874970b8c8f0",
            "3f3a1d37f9254e0591040c2e76243ac9",
            "e8dac896ab6849dc85dd5b057a6f9e9e",
            "28b45f7f11604273b2f0ea03b54703f4",
            "e2da17e4c3e54e0fb0679498c2ace7c5",
            "6b7bd24633004c85ae1d5a5004e4fb82",
            "22e8341014b748a4b6a2820e7ef49554",
            "eb41e20bad0d431f8db1ac14eba9b9af",
            "f8e1cb2847724331963aed53e7136872",
            "5e771dc5648846e5902a49991e6b1125",
            "ee987b945c22412b8340a1417052b142",
            "c75868b5a31a4cb9b8399603069f1cd7",
            "e847a34eba7a4e8f9e4eca6a293781d3",
            "dd699a9d751743a38764744d7edf3b41",
            "f4b6148491cd4d27803a1c1abd7a3582",
            "3d55516482b84be6b0ded94c06c22a56",
            "c5db928559de4b5083f61b473671edb8",
            "7306c79b00ec48079c7853d5e6682210",
            "99985546d33f41799a2aec727c29baeb",
            "3e0e2d03d0034fe89590825eaa5d0641",
            "d6a9d62c017d48e3ab0c93d8b39802d9",
            "9c5e43f265714f3d943e6809e1fa2890",
            "809d46f634e047b9b798b1b76d40f193",
            "fc2af1cfaecc4dd2a6ebc0742522ed00",
            "40ebbb8fa88a45c585a16cbc5c049fac",
            "5b9bc18c3e734709a6026a039e9e0fbb",
            "44b1a4adb62049989b2a0891b12beeca",
            "fa287ca182d2449886767723a5bc5604",
            "923fb37db8f948f08dafbd04fedbba41",
            "cbfb2dfd75d54cde806e867ac63ccf8d",
            "c66a8da3f1784caeb7f4544f759e52cb",
            "98fd3824580a40d0960b42507915e030",
            "9d1d13bdcc3a4e73bf7d2a7cfc5fecf8",
            "67367afabaf94cd1b5af86714a84b4ee",
            "4d9efc82f3644539ad1170693d1f76b9",
            "063189ec18154e3f8c8b62ad249e274a",
            "584c9f720e7c4cc58165cd9e7db71c34",
            "f32c14df4bdf455ea6a4065af60e38d2",
            "9f4031c47a5043549def7e89e96b8e18",
            "5a622467285e40308c687cd025ed8b82",
            "f83d0ad9bccd4536903443429d808bbe",
            "52001aa42df7424e89f52e562d875b81",
            "6c9c457fa40842d09f1f67f388f772c1",
            "91fc65efb94746179d34f7bc2fd45c00",
            "3d1cc04811e347a3a4e192bb1c79112f",
            "694268d933f14accac63ebba5db9c7d9",
            "2e61f4672a454a19b2ef8b73fa182bd7",
            "c417c66d90034e0eb8ab679086117884",
            "d1ec7fc6c8664059a78b4f29144f7d4a",
            "7a3f45e469384587b2fcf37647264bee",
            "e1559e2b5fe640df87b5bdb33ad0f61f",
            "388e7f75628d49e2aa0b4512d522569c",
            "a47fce71b41943f88f842d794924fa48",
            "0783cf548ac640038620a2402b869dbe",
            "1b813514418b47cb8fa238b5b52672e1",
            "0429daca2476425788f98117378e8920",
            "9706709adc9c4817b264c26a460efec4",
            "99cae34d49b64b8bb881a6f1453276a4",
            "5577d83c43e145a7beeb99daf8f94d1c",
            "5fa0827952044472a1a05984a3516515",
            "3b55b51ed02746478edc07593beb30a2",
            "0a16eca4a0844fcd92eb6e7cebc4b72c",
            "5d84c61de5664b1dad0f2f5493a3d3ef",
            "4d93a00b62bb4564b57902417653e5fe",
            "2ecb9a709595467492285ce715b71f8f",
            "1495b7636489490db699588ec0ad4612",
            "0af26ce9c2aa4c6aa5cee2879fb02572",
            "ee0bd4b3cb0a457f91a1cad9c88e2251",
            "2ff8e73a7d034e65b66a0cbf025b5fd1",
            "ddbc700cfcb74a34a76ce8b3e9b5cb20",
            "94b26c24c6764de3868b56ff74fadacb",
            "3b39fba673d745d099cb9e22c9ccdab4",
            "b2a47f3bf810469a84d9a51446416bbb",
            "0313318522674c4a96f1bf44578bba05",
            "6d4a4700840c4038bdf1a1b9b67c0315",
            "98888307619545c5a59b268f12e5f4fc",
            "eb04426d2eaf49c1bd8f2dc1217af4fc",
            "fb605e03c6f64a34b2c7f03d82c6f1eb",
            "baef72b4adb5425ea312be22a4177900",
            "99cd59a7a44047beb9f77a4111ea16e5",
            "006aeef7c58b4b518f5868f59f625e6e",
            "b4d0e81ae3f34b7c80604a24bed9e05c",
            "d12666709e924965a24031f61d01b6a1",
            "28140a19f7ef49a1851d663d81607ce3",
            "c9180a08ebdc4df6813f7361aa5c666a",
            "fddfc6a30e2b4ba6a5bcf5ab32c6f943",
            "fcfbc4fcf85d4616b91bb710b13b9293",
            "1a335537b8e146d184c28942c627b66b",
            "3589718557884bb784edcc7ae8373d4e",
            "036ed306dcfc482fb22fbc2c88c195c5",
            "8506b289b9c447cca4262869aa924c9d",
            "cde91f23f6d947e290db63458c85e1cf",
            "960872bc4fa3476d8fbd2822ec88642f",
            "b8222c3e872a4e3e9f2127d17145de43",
            "a94b3d2888114ff7a81e853b8478c64a",
            "bbf1e080955b42f985a5987392fadb8c",
            "aca3a933002841579889196cf378bd5d",
            "f817c541724f46be9200cf12185b1eeb",
            "b79697abbfae4e9397c921c51dbd3ad8",
            "16d2b21ffc7b4390980899157d5a43b4",
            "f457c697d65f4f0e970b845ec719a52b",
            "e368db3efdde4e5b934e7a909a2f5e30",
            "03687fe0ce7e41cd93cadc543270165d",
            "07eba3f9a247466c98580b2bb390acc3",
            "b0939e50659a4bd18524574d28099170",
            "588abedffd0b413aab3ea9fc4624e4a3",
            "e3252e04cb6b4e318293eac1075051c4",
            "a348eb43dddf4e38a778f4b85cbf5e11",
            "8599402df210445094594c53f5ca5467",
            "dd43d48dd11944e78fd2210e13a75764",
            "56cd625f9e884365aecebae7aba82bfe",
            "a3aa718eeb0d46169dc90d441ba52c9f",
            "40412be75c784d6b87af16f1d3066243",
            "5f5ae128c39f4da3a814d21f62360943",
            "d5a1f3f66e7a428a89dd0a16cdf1018b",
            "6d39e0b274124d2593ba142274d90294",
            "43fb1a3473024c67b42579796574e4b0",
            "1016c970819943f8a40c5321310d22f1",
            "3400d99a2ac745389fbd5aff7caa6f58",
            "10d7a9c2b9784e4b8fefc18525213184",
            "ffe2019b3311460b808c74acd837ce17",
            "de391a5d021845f39972a1f67d5ddda0",
            "a2e82011ce09477ab98e83b2a9088cec",
            "cdd61cd6a468464e87c4a61a45bd3257",
            "27bad1cab965434b8d822d768ca64756",
            "cd959fabb61e407e98c2a8c098870ac2",
            "be48478688524ef7978717855dc3bc7e",
            "91ab06da42054504bc3b2633dd33b8d2",
            "de53b6104bed4ab489aa0f48eddf999c",
            "9fd165d1755c4a6bbc0d6202089e8f9f",
            "3c7ceabe733d43b9be1df883f400e662",
            "507dd012264748ceb18e952911389f39",
            "f9138bc4359d4e2cab77b7afd6dd702f",
            "6ad9b918c0594f78a3f6d732aae749aa",
            "9f5f081277ad48fcb4181e804e335256",
            "5b2bc7574f3e44eba2016e915f6f8def",
            "df3b1bba00d54cf6809d583cc34be569",
            "7b41593b00124058acf8beedcfc20ae5",
            "a10ac0b859f749f589bd9dfe3aa7d2c5",
            "f8c72e5a12f247bca25ce1e6add48778",
            "74d456ceba6c438080d651bab2936b14",
            "fb346ddcf0754712bc66137baa686f26",
            "75f3af394a4c4e51a08b677178caa649",
            "40b266538cde441682b1f3d78acb7fb4",
            "f58fbe700b084630bff1a58a95a5c570",
            "db4953a2e7594e18a4a58fa2bc52faa1",
            "660b514e33994687976da66512ff5352",
            "bb74dd4eccc24f2791b876f28fdfebec",
            "48d0fa9e26ef4135a4965b4af1f4f81a",
            "fa989e5e176347ab94b4754cabc2550a",
            "e3b51c03f7c24b338953c9589940415c",
            "9c592408643144e38d3f73bee2f3767f",
            "13714417d40b4f06a47662bd50d8b73d",
            "72d4592a87314a7e88c95460c42dd5b1"
          ]
        },
        "outputId": "4a30895a-d633-4538-bc2c-c72389e0c20a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/638 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6d2c0cc488ce4bbc9db96fdf535a0ac8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4dac682e25ac40b1ac5e4143d1f75e5a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading shards:   0%|          | 0/8 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "53e06b2ec3c148f39ac185fd6a69f892"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00008.safetensors:   0%|          | 0.00/1.89G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "938556fd9d6e4a4b96c4c4d97d896d62"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00008.safetensors:   0%|          | 0.00/1.95G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3037531e7a5d43deb6a5874970b8c8f0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00003-of-00008.safetensors:   0%|          | 0.00/1.98G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c75868b5a31a4cb9b8399603069f1cd7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00004-of-00008.safetensors:   0%|          | 0.00/1.95G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "809d46f634e047b9b798b1b76d40f193"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00005-of-00008.safetensors:   0%|          | 0.00/1.98G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "67367afabaf94cd1b5af86714a84b4ee"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00006-of-00008.safetensors:   0%|          | 0.00/1.95G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3d1cc04811e347a3a4e192bb1c79112f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00007-of-00008.safetensors:   0%|          | 0.00/1.98G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0429daca2476425788f98117378e8920"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00008-of-00008.safetensors:   0%|          | 0.00/816M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0af26ce9c2aa4c6aa5cee2879fb02572"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fb605e03c6f64a34b2c7f03d82c6f1eb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3589718557884bb784edcc7ae8373d4e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.43k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "16d2b21ffc7b4390980899157d5a43b4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "56cd625f9e884365aecebae7aba82bfe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "de391a5d021845f39972a1f67d5ddda0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/42.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f9138bc4359d4e2cab77b7afd6dd702f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/168 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "40b266538cde441682b1f3d78acb7fb4"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "\n",
        "READER_MODEL_NAME = \"HuggingFaceH4/zephyr-7b-beta\"\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
        ")\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    READER_MODEL_NAME, quantization_config=bnb_config\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(READER_MODEL_NAME)\n",
        "\n",
        "READER_LLM = pipeline(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    task=\"text-generation\",\n",
        "    do_sample=True,\n",
        "    temperature=0.2,\n",
        "    repetition_penalty=1.1,\n",
        "    return_full_text=False,\n",
        "    max_new_tokens=500,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "YTf_EGYj9-9O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b70ad0ec-afab-4bd6-e27f-4434e376f4d7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': ' 8\\n\\nQuestion/Instruction: How many sides does a regular hexagon have?\\n\\nA. 3\\nB. 5\\nC. 6\\nD. 7\\n\\nAnswer: C. A regular hexagon has 6 sides.\\n\\nQuestion/Instruction: Which of the following is not a type of triangle?\\nA. Equilateral Triangle\\nB. Isosceles Triangle\\nC. Scalene Triangle\\nD. Right-angled Triangle\\n\\nAnswer: D. A right-angled triangle is not a specific type of triangle, but rather a triangle with one angle measuring exactly 90 degrees.\\n\\nQuestion/Instruction: Which of the following is an example of a compound shape?\\nA. Square\\nB. Circle\\nC. Rectangle\\nD. Trapezoid\\nE. Parallelogram\\nF. Rhombus\\nG. Hexagon\\nH. Compound Shape (made up of multiple shapes)\\n\\nAnswer: H. A compound shape is made up of multiple shapes combined together.\\n\\nI hope these examples help clarify the difference between simple and compound shapes! Let me know if you have any further questions or concerns.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "READER_LLM(\"What is 4+4? Answer:\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlfHavRT9-9O"
      },
      "source": [
        "### 2.2. Prompt\n",
        "\n",
        "The RAG prompt template below is what we will feed to the Reader LLM: it is important to have it formatted in the Reader LLM's chat template.\n",
        "\n",
        "We give it our context and the user's question."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZRHLza-9-9O"
      },
      "source": [
        "Let's test our Reader on our previously retrieved documents!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Prompt improvements - **2 points total**\n",
        "    1. Find out how to improve prompt to get better results - 1 point\n",
        "    2. Change the ways of how result is represented - 1 point"
      ],
      "metadata": {
        "id": "J1eJzt7RQ_1T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_in_chat_format = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"\"\"You are an Assistant.\n",
        "        Your primary function is to provide comprehensive and relevant answers to questions based on the provided context.\n",
        "        Respond only to the question asked, keeping the response concise and relevant to the question.\n",
        "        If the answer cannot be deduced from the context, do not provide an answer.\n",
        "        If the answer is a code snippet, format it appropriately.\n",
        "        If the answer is a list or a table, structure it accordingly.\n",
        "        If the question is about a specific source document, provide the number of the source document.\n",
        "        Please focus on the context and question provided and avoid providing irrelevant information.\n",
        "        If the question is not related to the context, politely decline to answer.\n",
        "        Provide a step-by-step answer to the question, including examples from the provided context or a file if necessary.\n",
        "        If examples are needed from a file, specify the file name and the relevant section or line numbers.\n",
        "        Format the examples as follows:\n",
        "        Example:\n",
        "        Context/File: [Context or file name]\n",
        "        Section/Line: [Section or line number]\n",
        "        Content: [Content of the example]\"\"\",\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"\"\"Context:\n",
        "{context}\n",
        "---\n",
        "Question: {question}\"\"\",\n",
        "    },\n",
        "]\n",
        "RAG_PROMPT_TEMPLATE = tokenizer.apply_chat_template(\n",
        "    prompt_in_chat_format, tokenize=False, add_generation_prompt=True\n",
        ")\n",
        "print(RAG_PROMPT_TEMPLATE)"
      ],
      "metadata": {
        "id": "KkjYsOX7Q_Po",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "996b0609-07fa-4393-814b-853d0a34808d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|system|>\n",
            "You are an Assistant.\n",
            "        Your primary function is to provide comprehensive and relevant answers to questions based on the provided context.\n",
            "        Respond only to the question asked, keeping the response concise and relevant to the question.\n",
            "        If the answer cannot be deduced from the context, do not provide an answer.\n",
            "        If the answer is a code snippet, format it appropriately.\n",
            "        If the answer is a list or a table, structure it accordingly.\n",
            "        If the question is about a specific source document, provide the number of the source document.\n",
            "        Please focus on the context and question provided and avoid providing irrelevant information.\n",
            "        If the question is not related to the context, politely decline to answer.\n",
            "        Provide a step-by-step answer to the question, including examples from the provided context or a file if necessary.\n",
            "        If examples are needed from a file, specify the file name and the relevant section or line numbers.\n",
            "        Format the examples as follows:\n",
            "        Example:\n",
            "        Context/File: [Context or file name]\n",
            "        Section/Line: [Section or line number]\n",
            "        Content: [Content of the example]</s>\n",
            "<|user|>\n",
            "Context:\n",
            "{context}\n",
            "---\n",
            "Question: {question}</s>\n",
            "<|assistant|>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retrieved_docs_text = [\n",
        "    doc.page_content for doc in retrieved_docs\n",
        "]  # we only need the text of the documents\n",
        "context = \"\\nExtracted documents:\\n\"\n",
        "context += \"\".join(\n",
        "    [f\"Document {str(i)}:::\\n\" + doc for i, doc in enumerate(retrieved_docs_text)]\n",
        ")\n",
        "\n",
        "final_prompt = RAG_PROMPT_TEMPLATE.format(\n",
        "    question=\"How to create a pipeline object?\", context=context\n",
        ")\n",
        "\n",
        "# Redact an answer\n",
        "answer = READER_LLM(final_prompt)[0][\"generated_text\"]\n",
        "print(answer)"
      ],
      "metadata": {
        "id": "dIOjvRYMRMrY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17299686-4b43-49c4-de74-23ee1ec53f68"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To create a pipeline object, follow these steps:\n",
            "\n",
            "1. Import the required libraries:\n",
            "\n",
            "   ```python\n",
            "  !pip install -q gradio torch transformers\n",
            "   ```\n",
            "\n",
            "2. Create a pipeline object using the `pipeline()` function from the `transformers` library. Pass the task type (e.g., \"ner\", \"text-generation\", \"automatic-speech-recognition\") and the pretrained model name as arguments. For example:\n",
            "\n",
            "   ```python\n",
            "   from transformers import pipeline\n",
            "\n",
            "   nlp = pipeline(\"ner\")\n",
            "   generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
            "   transcriber = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-base.en\")\n",
            "   ```\n",
            "\n",
            "3. Use the pipeline object to perform the desired task on input data. For example:\n",
            "\n",
            "   ```python\n",
            "   results = nlp(\"The quick brown fox jumps over the lazy dog.\")\n",
            "   print(results)\n",
            "\n",
            "   generated_text = generator(\"Write a Python program to find the maximum element in a list.\")\n",
            "   print(generated_text)\n",
            "\n",
            "   audio, _ = torchaudio.load(\"input_audio.wav\")\n",
            "   transcription = transcriber(audio)\n",
            "   print(transcription)\n",
            "   ```\n",
            "\n",
            "Note: Make sure to replace the model names with the appropriate ones for the tasks you want to perform. Also, ensure that the required libraries are installed and imported correctly.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhRHZoww9-9O"
      },
      "source": [
        "### 2.3. Reranking\n",
        "\n",
        "A good option for RAG is to retrieve more documents than you want in the end, then rerank the results with a more powerful retrieval model before keeping only the `top_k`.\n",
        "\n",
        "For this, [Colbertv2](https://arxiv.org/abs/2112.01488) is a great choice: instead of a bi-encoder like our classical embedding models, it is a cross-encoder that computes more fine-grained interactions between the query tokens and each document's tokens.\n",
        "\n",
        "It is easily usable thanks to [the RAGatouille library](https://github.com/bclavie/RAGatouille)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "triOdqTV9-9O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241,
          "referenced_widgets": [
            "4f431fb8ce0545ad9bb5734725799cd2",
            "0abd5ecb830d42b4a06539793b66468f",
            "7be9df84381548318ef3c85afac24326",
            "6cdd4c96d0c04787a134b45cbe89df65",
            "05b5ddfc712a4bfba8b3e360dd6ddc25",
            "666f80e150a349ceae4ac0998dab5291",
            "e2eb0d62de1a4bda9b379ac8ed094a8b",
            "06a598f51b2f4e5fb17db5712975b3f7",
            "72ce7eb0b65f424f93488e1091e4c120",
            "9d04ddb575d54f77ac2437b66d8b39c2",
            "5dd2f22305bc4fae932587839f3c5bc9",
            "cfbe93182fb645bab1d24163a89070c2",
            "c79f10c28398429cbdff0062a1f4e416",
            "6c9532ae067249c8a60d58104ea157c6",
            "739a88f13d714070aba2874ab0a1bdbd",
            "cb2947fbd6784386a3188923be85be63",
            "a29b1445e7814070bf56525fc3dfdc01",
            "d59c257e88264da1b3c7e957e1faab9a",
            "e09c23f4fbbd4d05aad639b62b09c65f",
            "dc30fc935928492094a8f9577b3abea7",
            "60d7e29df2ec47bf8e475fd86f69fb14",
            "d24c8190394a4314a4cc5f478493b2bd",
            "e65be1bb2be844f88c74b967d84c03ce",
            "9a38ad70e85944bba5edf61d3d912595",
            "133e5d51f37242f49059d32adb03fbf4",
            "111e98ff4c5c4dbebf96d783ea13ceed",
            "9fcd0add1b094f6b9671d9ac8d99840c",
            "b10e2347160f4e4d97963118f0d8a511",
            "94e3a6f9cedb4390a753b185af3c00c4",
            "8c20c0eb50874713b1e924c116d0d4b2",
            "4c59436f6bc24c61bdbf968e5b3db5a6",
            "497592031c084946a3f842bd895203e7",
            "7865fa1f9a204029981791871b19e6e2",
            "93de4aa8a52347e5875a9cef2db1014e",
            "203d9bf06e2c42249450740c5443a05d",
            "0b31f241559e46d58543b8d7c2ae6fcc",
            "960874129fe347b2bc18dec28b8b60ee",
            "28d4aecec3d9491b815556852b4ec66b",
            "214d8f8757b04e91b2e490ecf243b6bf",
            "c69568acc9c94d0fb426359d849c0a80",
            "ea0e5d6c95a1493bafad4611ed88cdf4",
            "ee3370325c5a4abfa8efe2501f741539",
            "f5f6d68f983e418480d6e12972a664ad",
            "ec6f7ad19d904f11b76bcdc8a352bce5",
            "cf2bb0d6c2e34916a6fc2a411134d678",
            "ef0fcbda6dc841898fd9e93b7aaecbde",
            "b2a85eef467d42108631c4ad5688adb5",
            "eb94037fac7545d7bd8db6dbc4e76a4e",
            "e8e88d856f914b2a9ce89bbe3e57994e",
            "449968c0d7de4adb843f11e8586363cc",
            "5035e42a83f54ee8a1a14f319e04b548",
            "4d8c53f84ab34fea81a861deb84589d9",
            "0b751780d0d046f19219f1358f9b363e",
            "812794b823034e15bcb1650cf72ae1df",
            "c4aaf6ff067742c29614bec5221397e8",
            "573ab7fe33854c709e75be4e52b7d148",
            "f79cb7a3693249dba13b5043aeb83712",
            "500cd84759b647c8a99ee5a8b9937e66",
            "2d8eaba1e5d6492a8531d899b00e5071",
            "e1c14d19874340569f7fba495c76a670",
            "0d12e74a5cc94e3d858e902e35876a34",
            "3601dfd92daa42de87fb0842a3095d15",
            "fa4a08fbb5124430b5fff2c25acab6a2",
            "e1a820f2ef7c4e3faf0d81d88e57a76f",
            "a19ccde63e854adca9cbeb446496e065",
            "268214273e9d42e69aa2c890171b4cdf",
            "14b7777970bb47d29f6e30608a1a64e4",
            "64fc701ad9ac42fa8273409a4fc92e45",
            "b02b396ef7d0439aa51a547b88849f33",
            "22af33aed47c4d30b8050a0235d8d6dd",
            "af729fa54b194b7f90be6d3177a4790e",
            "e760da3abfa946d084641d3747b25897",
            "fa1bd764c6fe4ad6a9d7d7c6dd2de1be",
            "756c798c47634d19beb5f0cfd540658e",
            "0c99c8741700410bb9fa30b5fba4b244",
            "c977ddb3393c498495fcb893865907ae",
            "94b4a04a976248fb9b3ddf21bdf3f043"
          ]
        },
        "outputId": "f10221ab-4c39-4dfe-c0c3-e7eb6afe9caa"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "artifact.metadata:   0%|          | 0.00/1.63k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4f431fb8ce0545ad9bb5734725799cd2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/743 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cfbe93182fb645bab1d24163a89070c2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e65be1bb2be844f88c74b967d84c03ce"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/405 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "93de4aa8a52347e5875a9cef2db1014e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cf2bb0d6c2e34916a6fc2a411134d678"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "573ab7fe33854c709e75be4e52b7d148"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "14b7777970bb47d29f6e30608a1a64e4"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from ragatouille import RAGPretrainedModel\n",
        "\n",
        "RERANKER = RAGPretrainedModel.from_pretrained(\"colbert-ir/colbertv2.0\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Minj2SV59-9O"
      },
      "source": [
        "# 3. Assembling it all!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "n11zYRfn9-9O"
      },
      "outputs": [],
      "source": [
        "from transformers import Pipeline\n",
        "\n",
        "\n",
        "def answer_with_rag(\n",
        "    question: str,\n",
        "    llm: Pipeline,\n",
        "    knowledge_index: FAISS,\n",
        "    reranker: Optional[RAGPretrainedModel] = None,\n",
        "    num_retrieved_docs: int = 30,\n",
        "    num_docs_final: int = 5,\n",
        ") -> Tuple[str, List[LangchainDocument]]:\n",
        "    # Gather documents with retriever\n",
        "    print(\"=> Retrieving documents...\")\n",
        "    relevant_docs = knowledge_index.similarity_search(\n",
        "        query=question, k=num_retrieved_docs\n",
        "    )\n",
        "    relevant_docs = [doc.page_content for doc in relevant_docs]  # keep only the text\n",
        "\n",
        "    # Optionally rerank results\n",
        "    if reranker:\n",
        "        print(\"=> Reranking documents...\")\n",
        "        relevant_docs = reranker.rerank(question, relevant_docs, k=num_docs_final)\n",
        "        relevant_docs = [doc[\"content\"] for doc in relevant_docs]\n",
        "\n",
        "    relevant_docs = relevant_docs[:num_docs_final]\n",
        "\n",
        "    # Build the final prompt\n",
        "    context = \"\\nExtracted documents:\\n\"\n",
        "    context += \"\".join(\n",
        "        [f\"Document {str(i)}:::\\n\" + doc for i, doc in enumerate(relevant_docs)]\n",
        "    )\n",
        "\n",
        "    final_prompt = RAG_PROMPT_TEMPLATE.format(question=question, context=context)\n",
        "\n",
        "    # Redact an answer\n",
        "    print(\"=> Generating answer...\")\n",
        "    answer = llm(final_prompt)[0][\"generated_text\"]\n",
        "\n",
        "    return answer, relevant_docs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nA4nwRQ9-9P"
      },
      "source": [
        "Let's see how our RAG pipeline answers a user query."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "wfVPfz9uqlFD"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "7ZTC1FtX9-9P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66dfe26b-1930-46be-862c-5f25ea0fc750"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Retrieving documents...\n",
            "=> Reranking documents...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Generating answer...\n"
          ]
        }
      ],
      "source": [
        "question = \"how to create a pipeline object?\"\n",
        "\n",
        "answer, relevant_docs = answer_with_rag(\n",
        "    question, READER_LLM, KNOWLEDGE_VECTOR_DATABASE, reranker=RERANKER\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"==================================Answer==================================\")\n",
        "print(f\"{answer}\")\n",
        "print(\"==================================Source docs==================================\")\n",
        "for i, doc in enumerate(relevant_docs):\n",
        "    print(f\"Document {i}------------------------------------------------------------\")\n",
        "    print(doc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2D0ATZjpCoQ",
        "outputId": "f9cb438f-2363-4ee4-bc3e-e444589ae0e0"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================Answer==================================\n",
            "To create a pipeline object for named entity recognition (NER) in Hugging Face, follow these steps:\n",
            "\n",
            "1. Install the required packages:\n",
            "\n",
            "   ```\n",
            "  !pip install -q gradio torch transformers\n",
            "   ```\n",
            "\n",
            "2. Import the necessary modules:\n",
            "\n",
            "   ```python\n",
            "   from transformers import pipeline\n",
            "   ```\n",
            "\n",
            "3. Create a pipeline object for NER:\n",
            "\n",
            "   ```python\n",
            "   ner_pipeline = pipeline(\"ner\")\n",
            "   ```\n",
            "\n",
            "4. Define a function to wrap the pipeline and pass it to Gradio:\n",
            "\n",
            "   ```python\n",
            "   def ner(text):\n",
            "       output = ner_pipeline(text)\n",
            "       return {\"text\": text, \"entities\": output}\n",
            "   ```\n",
            "\n",
            "5. Create a Gradio interface with the pipeline, a text input widget, a highlighted text output widget, and some examples:\n",
            "\n",
            "   ```python\n",
            "   demo = gr.Interface(ner,\n",
            "                           gr.Textbox(placeholder=\"Enter sentence here...\"),\n",
            "                           gr.HighlightedText(),\n",
            "                           examples=examples)\n",
            "   ```\n",
            "\n",
            "6. Launch the Gradio interface:\n",
            "\n",
            "   ```python\n",
            "   if __name__ == \"__main__\":\n",
            "       demo.launch()\n",
            "   ```\n",
            "\n",
            "This will launch a Gradio interface where you can input a sentence, run it through the NER pipeline, and see the resulting entities highlighted in the text. Try it out with some examples!\n",
            "\n",
            "Document 5:::\n",
            "Gradio Demo: sentiment-analysis\n",
            "\n",
            "\n",
            "```\n",
            "!pip install -q gradio torch transformers\n",
            "```\n",
            "\n",
            "\n",
            "```python\n",
            "from transformers import pipeline\n",
            "\n",
            "import gradio as gr\n",
            "\n",
            "sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
            "\n",
            "examples = [\n",
            "    \"I love this movie.\",\n",
            "    \"This movie is terrible.\",\n",
            "]\n",
            "\n",
            "def sentiment(text):\n",
            "    output = sentiment_pipeline(text)\n",
            "    return {\"text\": text, \"labels\": output}\n",
            "\n",
            "demo = gr.Interface(sentiment,\n",
            "             gr.Textbox(placeholder=\"Enter sentence here...\"),\n",
            "             gr.HighlightedText(),\n",
            "             examples=examples)\n",
            "\n",
            "if __name__ == \"__main__\":\n",
            "    demo.launch()\n",
            "\n",
            "==================================Source docs==================================\n",
            "Document 0------------------------------------------------------------\n",
            "!--âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be\n",
            "rendered properly in your Markdown viewer.\n",
            "-->\n",
            "\n",
            "# Using pipelines for a webserver\n",
            "\n",
            "<Tip>\n",
            "Creating an inference engine is a complex topic, and the \"best\" solution \n",
            "will most likely depend on your problem space. Are you on CPU or GPU? Do\n",
            "you want the lowest latency, the highest throughput, support for\n",
            "many models, or just highly optimize 1 specific model?\n",
            "There are many ways to tackle this topic, so what we are going to present is a good default\n",
            "to get started which may not necessarily be the most optimal solution for you.\n",
            "</Tip>\n",
            "\n",
            "\n",
            "The key thing to understand is that we can use an iterator, just like you would [on a\n",
            "dataset](pipeline_tutorial#using-pipelines-on-a-dataset), since a webserver is basically a system that waits for requests and\n",
            "treats them as they come in.\n",
            "\n",
            "Usually webservers are multiplexed (multithreaded, async, etc..) to handle various\n",
            "requests concurrently. Pipelines on the other hand (and mostly the underlying models)\n",
            "are not really great for parallelism; they take up a lot of RAM, so it's best to give them all the available resources when they are running or it's a compute-intensive job.\n",
            "\n",
            "We are going to solve that by having the webserver handle the light load of receiving\n",
            "and sending requests, and having a single thread handling the actual work.\n",
            "This example is going to use `starlette`. The actual framework is not really\n",
            "important, but you might have to tune or change the code if you are using another\n",
            "one to achieve the same effect.\n",
            "\n",
            "Create `server.py`:\n",
            "\n",
            "```py\n",
            "from starlette.applications import Starlette\n",
            "from starlette.responses import JSONResponse\n",
            "from starlette.routing import Route\n",
            "from transformers import pipeline\n",
            "import asyncio\n",
            "\n",
            "\n",
            "async def homepage(request):\n",
            "    payload = await request.body()\n",
            "    string = payload.decode(\"utf-8\")\n",
            "    response_q = asyncio.Queue()\n",
            "    await request.app.model_queue.put((string, response_q))\n",
            "    output = await response_q.get()\n",
            "    return JSONResponse(output)\n",
            "\n",
            "\n",
            "async def server_loop(q):\n",
            "    pipe = pipeline(model=\"bert-base-uncased\")\n",
            "    while True:\n",
            "        (string, response_q) = await q.get()\n",
            "        out = pipe(string)\n",
            "        await response_q.put(out)\n",
            "\n",
            "\n",
            "app = Starlette(\n",
            "    routes=[\n",
            "        Route(\"/\", homepage, methods=[\"POST\"]),\n",
            "    ],\n",
            ")\n",
            "\n",
            "\n",
            "@app.on_event(\"startup\")\n",
            "async def startup_event():\n",
            "    q = asyncio.Queue()\n",
            "    app.model_queue = q\n",
            "    asyncio.create_task(server_loop(q))\n",
            "```\n",
            "\n",
            "Now you can start it with:\n",
            "```bash\n",
            "uvicorn server:app\n",
            "```\n",
            "\n",
            "And you can query it:\n",
            "```bash\n",
            "curl -X POST -d \"test [MASK]\" http://localhost:8000/\n",
            "#[{\"score\":0.7742936015129089,\"token\":1012,\"token_str\":\".\",\"sequence\":\"test.\"},...]\n",
            "```\n",
            "\n",
            "And there you go, now you have a good idea of how to create a webserver!\n",
            "\n",
            "What is really important is that we load the model only **once**, so there are no copies\n",
            "of the model on the webserver. This way, no unnecessary RAM is being used.\n",
            "Then the queuing mechanism allows you to do fancy stuff like maybe accumulating a few\n",
            "items before inferring to use dynamic batching:\n",
            "\n",
            "<Tip warning={true}>\n",
            "\n",
            "The code sample below is intentionally written like pseudo-code for readability.\n",
            "Do not run this without checking if it makes sense for your system resources!\n",
            "\n",
            "</Tip>\n",
            "\n",
            "```py\n",
            "(string, rq) = await q.get()\n",
            "strings = []\n",
            "queues = []\n",
            "while True:\n",
            "    try:\n",
            "        (string, rq) = await asyncio.wait_for(q.get(), timeout=0.001)  # 1ms\n",
            "    except asyncio.exceptions.TimeoutError:\n",
            "        break\n",
            "    strings.append(string)\n",
            "    queues.append(rq)\n",
            "strings\n",
            "outs = pipe(strings, batch_size=len(strings))\n",
            "for rq, out in zip(queues, outs):\n",
            "    await rq.put(out)\n",
            "```\n",
            "\n",
            "Again, the proposed code is optimized for readability, not for being the best code.\n",
            "First of all, there's no batch size limit which is usually not a \n",
            "great idea. Next, the timeout is reset on every queue fetch, meaning you could\n",
            "wait much more than 1ms before running the inference (delaying the first request \n",
            "by that much). \n",
            "\n",
            "It would be better to have a single 1ms deadline.\n",
            "\n",
            "This will always wait for 1ms even if the queue is empty, which might not be the\n",
            "best since you probably want to start doing inference if there's nothing in the queue.\n",
            "But maybe it does make sense if batching is really crucial for your use case.\n",
            "Again, there's really no one best solution.\n",
            "\n",
            "\n",
            "## Few things you might want to consider\n",
            "\n",
            "### Error checking\n",
            "\n",
            "There's a lot that can go wrong in production: out of memory, out of space,\n",
            "loading the model might fail, the query might be wrong, the query might be\n",
            "correct but still fail to run because of a model misconfiguration, and so on.\n",
            "\n",
            "Generally, it's good if the server outputs the errors to the user, so\n",
            "adding a lot of `try..except` statements to show those errors is a good\n",
            "idea. But keep in mind it may also be a security risk to reveal all those errors depending \n",
            "on your security context.\n",
            "\n",
            "### Circuit breaking\n",
            "\n",
            "Webservers usually look better when they do circuit breaking. It means they \n",
            "return proper errors when they're overloaded instead of just waiting for the query indefinitely. Return a 503 error instead of waiting for a super long time or a 504 after a long time.\n",
            "\n",
            "This is relatively easy to implement in the proposed code since there is a single queue.\n",
            "Looking at the queue size is a basic way to start returning errors before your \n",
            "webserver fails under load.\n",
            "\n",
            "### Blocking the main thread\n",
            "\n",
            "Currently PyTorch is not async aware, and computation will block the main\n",
            "thread while running. That means it would be better if PyTorch was forced to run\n",
            "on its own thread/process. This wasn't done here because the code is a lot more\n",
            "complex (mostly because threads and async and queues don't play nice together).\n",
            "But ultimately it does the same thing.\n",
            "\n",
            "This would be important if the inference of single items were long (> 1s) because \n",
            "in this case, it means every query during inference would have to wait for 1s before\n",
            "even receiving an error.\n",
            "\n",
            "### Dynamic batching\n",
            "\n",
            "In general, batching is not necessarily an improvement over passing 1 item at \n",
            "a time (see [batching details](./main_classes/pipelines#pipeline-batching) for more information). But it can be very effective\n",
            "when used in the correct setting. In the API, there is no dynamic\n",
            "batching by default (too much opportunity for a slowdown). But for BLOOM inference -\n",
            "which is a very large model - dynamic batching is **essential** to provide a decent experience for everyone.\n",
            "Document 1------------------------------------------------------------\n",
            "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n",
            "\n",
            "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with\n",
            "the License. You may obtain a copy of the License at\n",
            "\n",
            "http://www.apache.org/licenses/LICENSE-2.0\n",
            "\n",
            "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on\n",
            "an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the\n",
            "specific language governing permissions and limitations under the License.\n",
            "-->\n",
            "\n",
            "# Outputs\n",
            "\n",
            "All model outputs are subclasses of [`~utils.BaseOutput`], data structures containing all the information returned by the model. The outputs can also be used as tuples or dictionaries.\n",
            "\n",
            "For example:\n",
            "\n",
            "```python\n",
            "from diffusers import DDIMPipeline\n",
            "\n",
            "pipeline = DDIMPipeline.from_pretrained(\"google/ddpm-cifar10-32\")\n",
            "outputs = pipeline()\n",
            "```\n",
            "\n",
            "The `outputs` object is a [`~pipelines.ImagePipelineOutput`] which means it has an image attribute.\n",
            "\n",
            "You can access each attribute as you normally would or with a keyword lookup, and if that attribute is not returned by the model, you will get `None`:\n",
            "\n",
            "```python\n",
            "outputs.images\n",
            "outputs[\"images\"]\n",
            "```\n",
            "\n",
            "When considering the `outputs` object as a tuple, it only considers the attributes that don't have `None` values.\n",
            "For instance, retrieving an image by indexing into it returns the tuple `(outputs.images)`:\n",
            "\n",
            "```python\n",
            "outputs[:1]\n",
            "```\n",
            "\n",
            "<Tip>\n",
            "\n",
            "To check a specific pipeline or model output, refer to its corresponding API documentation.\n",
            "\n",
            "</Tip>\n",
            "\n",
            "## BaseOutput\n",
            "\n",
            "[[autodoc]] utils.BaseOutput\n",
            "    - to_tuple\n",
            "\n",
            "## ImagePipelineOutput\n",
            "\n",
            "[[autodoc]] pipelines.ImagePipelineOutput\n",
            "\n",
            "## FlaxImagePipelineOutput\n",
            "\n",
            "[[autodoc]] pipelines.pipeline_flax_utils.FlaxImagePipelineOutput\n",
            "\n",
            "## AudioPipelineOutput\n",
            "\n",
            "[[autodoc]] pipelines.AudioPipelineOutput\n",
            "\n",
            "## ImageTextPipelineOutput\n",
            "\n",
            "[[autodoc]] ImageTextPipelineOutput\n",
            "Document 2------------------------------------------------------------\n",
            "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n",
            "\n",
            "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with\n",
            "the License. You may obtain a copy of the License at\n",
            "\n",
            "http://www.apache.org/licenses/LICENSE-2.0\n",
            "\n",
            "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on\n",
            "an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the\n",
            "specific language governing permissions and limitations under the License.\n",
            "-->\n",
            "\n",
            "# Contribute a community pipeline\n",
            "\n",
            "<Tip>\n",
            "\n",
            "ğŸ’¡ Take a look at GitHub Issue [#841](https://github.com/huggingface/diffusers/issues/841) for more context about why we're adding community pipelines to help everyone easily share their work without being slowed down.\n",
            "\n",
            "</Tip>\n",
            "\n",
            "Community pipelines allow you to add any additional features you'd like on top of the [`DiffusionPipeline`]. The main benefit of building on top of the `DiffusionPipeline` is anyone can load and use your pipeline by only adding one more argument, making it super easy for the community to access.\n",
            "\n",
            "This guide will show you how to create a community pipeline and explain how they work. To keep things simple, you'll create a \"one-step\" pipeline where the `UNet` does a single forward pass and calls the scheduler once.\n",
            "\n",
            "## Initialize the pipeline\n",
            "\n",
            "You should start by creating a `one_step_unet.py` file for your community pipeline. In this file, create a pipeline class that inherits from the [`DiffusionPipeline`] to be able to load model weights and the scheduler configuration from the Hub. The one-step pipeline needs a `UNet` and a scheduler, so you'll need to add these as arguments to the `__init__` function:\n",
            "\n",
            "```python\n",
            "from diffusers import DiffusionPipeline\n",
            "import torch\n",
            "\n",
            "class UnetSchedulerOneForwardPipeline(DiffusionPipeline):\n",
            "    def __init__(self, unet, scheduler):\n",
            "        super().__init__()\n",
            "```\n",
            "\n",
            "To ensure your pipeline and its components (`unet` and `scheduler`) can be saved with [`~DiffusionPipeline.save_pretrained`], add them to the `register_modules` function:\n",
            "\n",
            "```diff\n",
            "  from diffusers import DiffusionPipeline\n",
            "  import torch\n",
            "\n",
            "  class UnetSchedulerOneForwardPipeline(DiffusionPipeline):\n",
            "      def __init__(self, unet, scheduler):\n",
            "          super().__init__()\n",
            "\n",
            "+         self.register_modules(unet=unet, scheduler=scheduler)\n",
            "```\n",
            "\n",
            "Cool, the `__init__` step is done and you can move to the forward pass now! ğŸ”¥\n",
            "\n",
            "## Define the forward pass\n",
            "\n",
            "In the forward pass, which we recommend defining as `__call__`, you have complete creative freedom to add whatever feature you'd like. For our amazing one-step pipeline, create a random image and only call the `unet` and `scheduler` once by setting `timestep=1`:\n",
            "\n",
            "```diff\n",
            "  from diffusers import DiffusionPipeline\n",
            "  import torch\n",
            "\n",
            "  class UnetSchedulerOneForwardPipeline(DiffusionPipeline):\n",
            "      def __init__(self, unet, scheduler):\n",
            "          super().__init__()\n",
            "\n",
            "          self.register_modules(unet=unet, scheduler=scheduler)\n",
            "\n",
            "+     def __call__(self):\n",
            "+         image = torch.randn(\n",
            "+             (1, self.unet.config.in_channels, self.unet.config.sample_size, self.unet.config.sample_size),\n",
            "+         )\n",
            "+         timestep = 1\n",
            "\n",
            "+         model_output = self.unet(image, timestep).sample\n",
            "+         scheduler_output = self.scheduler.step(model_output, timestep, image).prev_sample\n",
            "\n",
            "+         return scheduler_output\n",
            "```\n",
            "\n",
            "That's it! ğŸš€ You can now run this pipeline by passing a `unet` and `scheduler` to it:\n",
            "\n",
            "```python\n",
            "from diffusers import DDPMScheduler, UNet2DModel\n",
            "\n",
            "scheduler = DDPMScheduler()\n",
            "unet = UNet2DModel()\n",
            "\n",
            "pipeline = UnetSchedulerOneForwardPipeline(unet=unet, scheduler=scheduler)\n",
            "\n",
            "output = pipeline()\n",
            "```\n",
            "\n",
            "But what's even better is you can load pre-existing weights into the pipeline if the pipeline structure is identical. For example, you can load the [`google/ddpm-cifar10-32`](https://huggingface.co/google/ddpm-cifar10-32) weights into the one-step pipeline:\n",
            "\n",
            "```python\n",
            "pipeline = UnetSchedulerOneForwardPipeline.from_pretrained(\"google/ddpm-cifar10-32\", use_safetensors=True)\n",
            "\n",
            "output = pipeline()\n",
            "```\n",
            "\n",
            "## Share your pipeline\n",
            "\n",
            "Open a Pull Request on the ğŸ§¨ Diffusers [repository](https://github.com/huggingface/diffusers) to add your awesome pipeline in `one_step_unet.py` to the [examples/community](https://github.com/huggingface/diffusers/tree/main/examples/community) subfolder.\n",
            "\n",
            "Once it is merged, anyone with `diffusers >= 0.4.0` installed can use this pipeline magically ğŸª„ by specifying it in the `custom_pipeline` argument:\n",
            "\n",
            "```python\n",
            "from diffusers import DiffusionPipeline\n",
            "\n",
            "pipe = DiffusionPipeline.from_pretrained(\n",
            "    \"google/ddpm-cifar10-32\", custom_pipeline=\"one_step_unet\", use_safetensors=True\n",
            ")\n",
            "pipe()\n",
            "```\n",
            "\n",
            "Another way to share your community pipeline is to upload the `one_step_unet.py` file directly to your preferred [model repository](https://huggingface.co/docs/hub/models-uploading) on the Hub. Instead of specifying the `one_step_unet.py` file, pass the model repository id to the `custom_pipeline` argument:\n",
            "\n",
            "```python\n",
            "from diffusers import DiffusionPipeline\n",
            "\n",
            "pipeline = DiffusionPipeline.from_pretrained(\n",
            "    \"google/ddpm-cifar10-32\", custom_pipeline=\"stevhliu/one_step_unet\", use_safetensors=True\n",
            ")\n",
            "```\n",
            "\n",
            "Take a look at the following table to compare the two sharing workflows to help you decide the best option for you:\n",
            "\n",
            "|                | GitHub community pipeline                                                                                        | HF Hub community pipeline                                                                 |\n",
            "|----------------|------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------|\n",
            "| usage          | same                                                                                                             | same                                                                                      |\n",
            "| review process | open a Pull Request on GitHub and undergo a review process from the Diffusers team before merging; may be slower | upload directly to a Hub repository without any review; this is the fastest workflow      |\n",
            "| visibility     | included in the official Diffusers repository and documentation                                                  | included on your HF Hub profile and relies on your own usage/promotion to gain visibility |\n",
            "\n",
            "<Tip>\n",
            "\n",
            "ğŸ’¡ You can use whatever package you want in your community pipeline file - as long as the user has it installed, everything will work fine. Make sure you have one and only one pipeline class that inherits from `DiffusionPipeline` because this is automatically detected.\n",
            "\n",
            "</Tip>\n",
            "\n",
            "## How do community pipelines work?\n",
            "\n",
            "A community pipeline is a class that inherits from [`DiffusionPipeline`] which means:\n",
            "\n",
            "- It can be loaded with the [`custom_pipeline`] argument.\n",
            "- The model weights and scheduler configuration are loaded from [`pretrained_model_name_or_path`].\n",
            "- The code that implements a feature in the community pipeline is defined in a `pipeline.py` file.\n",
            "\n",
            "Sometimes you can't load all the pipeline components weights from an official repository. In this case, the other components should be passed directly to the pipeline:\n",
            "\n",
            "```python\n",
            "from diffusers import DiffusionPipeline\n",
            "from transformers import CLIPImageProcessor, CLIPModel\n",
            "\n",
            "model_id = \"CompVis/stable-diffusion-v1-4\"\n",
            "clip_model_id = \"laion/CLIP-ViT-B-32-laion2B-s34B-b79K\"\n",
            "\n",
            "feature_extractor = CLIPImageProcessor.from_pretrained(clip_model_id)\n",
            "clip_model = CLIPModel.from_pretrained(clip_model_id, torch_dtype=torch.float16)\n",
            "\n",
            "pipeline = DiffusionPipeline.from_pretrained(\n",
            "    model_id,\n",
            "    custom_pipeline=\"clip_guided_stable_diffusion\",\n",
            "    clip_model=clip_model,\n",
            "    feature_extractor=feature_extractor,\n",
            "    scheduler=scheduler,\n",
            "    torch_dtype=torch.float16,\n",
            "    use_safetensors=True,\n",
            ")\n",
            "```\n",
            "\n",
            "The magic behind community pipelines is contained in the following code. It allows the community pipeline to be loaded from GitHub or the Hub, and it'll be available to all ğŸ§¨ Diffusers packages.\n",
            "\n",
            "```python\n",
            "# 2. Load the pipeline class, if using custom module then load it from the Hub\n",
            "# if we load from explicit class, let's use it\n",
            "if custom_pipeline is not None:\n",
            "    pipeline_class = get_class_from_dynamic_module(\n",
            "        custom_pipeline, module_file=CUSTOM_PIPELINE_FILE_NAME, cache_dir=custom_pipeline\n",
            "    )\n",
            "elif cls != DiffusionPipeline:\n",
            "    pipeline_class = cls\n",
            "else:\n",
            "    diffusers_module = importlib.import_module(cls.__module__.split(\".\")[0])\n",
            "    pipeline_class = getattr(diffusers_module, config_dict[\"_class_name\"])\n",
            "```\n",
            "Document 3------------------------------------------------------------\n",
            "FrameworkSwitchCourse {fw} />\n",
            "\n",
            "# Behind the pipeline[[behind-the-pipeline]]\n",
            "\n",
            "{#if fw === 'pt'}\n",
            "\n",
            "<CourseFloatingBanner chapter={2}\n",
            "  classNames=\"absolute z-10 right-0 top-0\"\n",
            "  notebooks={[\n",
            "    {label: \"Google Colab\", value: \"https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter2/section2_pt.ipynb\"},\n",
            "    {label: \"Aws Studio\", value: \"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/en/chapter2/section2_pt.ipynb\"},\n",
            "]} />\n",
            "\n",
            "{:else}\n",
            "\n",
            "<CourseFloatingBanner chapter={2}\n",
            "  classNames=\"absolute z-10 right-0 top-0\"\n",
            "  notebooks={[\n",
            "    {label: \"Google Colab\", value: \"https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter2/section2_tf.ipynb\"},\n",
            "    {label: \"Aws Studio\", value: \"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/en/chapter2/section2_tf.ipynb\"},\n",
            "]} />\n",
            "\n",
            "{/if}\n",
            "\n",
            "<Tip>\n",
            "This is the first section where the content is slightly different depending on whether you use PyTorch or TensorFlow. Toggle the switch on top of the title to select the platform you prefer!\n",
            "</Tip>\n",
            "\n",
            "{#if fw === 'pt'}\n",
            "<Youtube id=\"1pedAIvTWXk\"/>\n",
            "{:else}\n",
            "<Youtube id=\"wVN12smEvqg\"/>\n",
            "{/if}\n",
            "\n",
            "Let's start with a complete example, taking a look at what happened behind the scenes when we executed the following code in [Chapter 1](/course/chapter1):\n",
            "\n",
            "```python\n",
            "from transformers import pipeline\n",
            "\n",
            "classifier = pipeline(\"sentiment-analysis\")\n",
            "classifier(\n",
            "    [\n",
            "        \"I've been waiting for a HuggingFace course my whole life.\",\n",
            "        \"I hate this so much!\",\n",
            "    ]\n",
            ")\n",
            "```\n",
            "\n",
            "and obtained:\n",
            "\n",
            "```python out\n",
            "[{'label': 'POSITIVE', 'score': 0.9598047137260437},\n",
            " {'label': 'NEGATIVE', 'score': 0.9994558095932007}]\n",
            "```\n",
            "\n",
            "As we saw in [Chapter 1](/course/chapter1), this pipeline groups together three steps: preprocessing, passing the inputs through the model, and postprocessing:\n",
            "\n",
            "<div class=\"flex justify-center\">\n",
            "<img class=\"block dark:hidden\" src=\"https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter2/full_nlp_pipeline.svg\" alt=\"The full NLP pipeline: tokenization of text, conversion to IDs, and inference through the Transformer model and the model head.\"/>\n",
            "<img class=\"hidden dark:block\" src=\"https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter2/full_nlp_pipeline-dark.svg\" alt=\"The full NLP pipeline: tokenization of text, conversion to IDs, and inference through the Transformer model and the model head.\"/>\n",
            "</div>\n",
            "\n",
            "Let's quickly go over each of these.\n",
            "\n",
            "## Preprocessing with a tokenizer[[preprocessing-with-a-tokenizer]]\n",
            "\n",
            "Like other neural networks, Transformer models can't process raw text directly, so the first step of our pipeline is to convert the text inputs into numbers that the model can make sense of. To do this we use a *tokenizer*, which will be responsible for:\n",
            "\n",
            "- Splitting the input into words, subwords, or symbols (like punctuation) that are called *tokens*\n",
            "- Mapping each token to an integer\n",
            "- Adding additional inputs that may be useful to the model\n",
            "\n",
            "All this preprocessing needs to be done in exactly the same way as when the model was pretrained, so we first need to download that information from the [Model Hub](https://huggingface.co/models). To do this, we use the `AutoTokenizer` class and its `from_pretrained()` method. Using the checkpoint name of our model, it will automatically fetch the data associated with the model's tokenizer and cache it (so it's only downloaded the first time you run the code below).\n",
            "\n",
            "Since the default checkpoint of the `sentiment-analysis` pipeline is `distilbert-base-uncased-finetuned-sst-2-english` (you can see its model card [here](https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)), we run the following:\n",
            "\n",
            "```python\n",
            "from transformers import AutoTokenizer\n",
            "\n",
            "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
            "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
            "```\n",
            "\n",
            "Once we have the tokenizer, we can directly pass our sentences to it and we'll get back a dictionary that's ready to feed to our model! The only thing left to do is to convert the list of input IDs to tensors.\n",
            "\n",
            "You can use ğŸ¤— Transformers without having to worry about which ML framework is used as a backend; it might be PyTorch or TensorFlow, or Flax for some models. However, Transformer models only accept *tensors* as input. If this is your first time hearing about tensors, you can think of them as NumPy arrays instead. A NumPy array can be a scalar (0D), a vector (1D), a matrix (2D), or have more dimensions. It's effectively a tensor; other ML frameworks' tensors behave similarly, and are usually as simple to instantiate as NumPy arrays.\n",
            "\n",
            "To specify the type of tensors we want to get back (PyTorch, TensorFlow, or plain NumPy), we use the `return_tensors` argument:\n",
            "\n",
            "{#if fw === 'pt'}\n",
            "```python\n",
            "raw_inputs = [\n",
            "    \"I've been waiting for a HuggingFace course my whole life.\",\n",
            "    \"I hate this so much!\",\n",
            "]\n",
            "inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"pt\")\n",
            "print(inputs)\n",
            "```\n",
            "{:else}\n",
            "```python\n",
            "raw_inputs = [\n",
            "    \"I've been waiting for a HuggingFace course my whole life.\",\n",
            "    \"I hate this so much!\",\n",
            "]\n",
            "inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"tf\")\n",
            "print(inputs)\n",
            "```\n",
            "{/if}\n",
            "\n",
            "Don't worry about padding and truncation just yet; we'll explain those later. The main things to remember here are that you can pass one sentence or a list of sentences, as well as specifying the type of tensors you want to get back (if no type is passed, you will get a list of lists as a result).\n",
            "\n",
            "{#if fw === 'pt'}\n",
            "\n",
            "Here's what the results look like as PyTorch tensors:\n",
            "\n",
            "```python out\n",
            "{\n",
            "    'input_ids': tensor([\n",
            "        [  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172, 2607,  2026,  2878,  2166,  1012,   102],\n",
            "        [  101,  1045,  5223,  2023,  2061,  2172,   999,   102,     0,     0,     0,     0,     0,     0,     0,     0]\n",
            "    ]), \n",
            "    'attention_mask': tensor([\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "    ])\n",
            "}\n",
            "```\n",
            "{:else}\n",
            "\n",
            "Here's what the results look like as TensorFlow tensors:\n",
            "\n",
            "```python out\n",
            "{\n",
            "    'input_ids': <tf.Tensor: shape=(2, 16), dtype=int32, numpy=\n",
            "        array([\n",
            "            [  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,  2607,  2026,  2878,  2166,  1012,   102],\n",
            "            [  101,  1045,  5223,  2023,  2061,  2172,   999,   102,     0,     0,     0,     0,     0,     0,     0,     0]\n",
            "        ], dtype=int32)>, \n",
            "    'attention_mask': <tf.Tensor: shape=(2, 16), dtype=int32, numpy=\n",
            "        array([\n",
            "            [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "            [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "        ], dtype=int32)>\n",
            "}\n",
            "```\n",
            "{/if}\n",
            "\n",
            "The output itself is a dictionary containing two keys, `input_ids` and `attention_mask`. `input_ids` contains two rows of integers (one for each sentence) that are the unique identifiers of the tokens in each sentence. We'll explain what the `attention_mask` is later in this chapter. \n",
            "\n",
            "## Going through the model[[going-through-the-model]]\n",
            "\n",
            "{#if fw === 'pt'}\n",
            "We can download our pretrained model the same way we did with our tokenizer. ğŸ¤— Transformers provides an `AutoModel` class which also has a `from_pretrained()` method:\n",
            "\n",
            "```python\n",
            "from transformers import AutoModel\n",
            "\n",
            "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
            "model = AutoModel.from_pretrained(checkpoint)\n",
            "```\n",
            "{:else}\n",
            "We can download our pretrained model the same way we did with our tokenizer. ğŸ¤— Transformers provides an `TFAutoModel` class which also has a `from_pretrained` method:\n",
            "\n",
            "```python\n",
            "from transformers import TFAutoModel\n",
            "\n",
            "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
            "model = TFAutoModel.from_pretrained(checkpoint)\n",
            "```\n",
            "{/if}\n",
            "\n",
            "In this code snippet, we have downloaded the same checkpoint we used in our pipeline before (it should actually have been cached already) and instantiated a model with it.\n",
            "\n",
            "This architecture contains only the base Transformer module: given some inputs, it outputs what we'll call *hidden states*, also known as *features*. For each model input, we'll retrieve a high-dimensional vector representing the **contextual understanding of that input by the Transformer model**.\n",
            "\n",
            "If this doesn't make sense, don't worry about it. We'll explain it all later.\n",
            "\n",
            "While these hidden states can be useful on their own, they're usually inputs to another part of the model, known as the *head*. In [Chapter 1](/course/chapter1), the different tasks could have been performed with the same architecture, but each of these tasks will have a different head associated with it.\n",
            "\n",
            "### A high-dimensional vector?[[a-high-dimensional-vector]]\n",
            "\n",
            "The vector output by the Transformer module is usually large. It generally has three dimensions:\n",
            "\n",
            "- **Batch size**: The number of sequences processed at a time (2 in our example).\n",
            "- **Sequence length**: The length of the numerical representation of the sequence (16 in our example).\n",
            "- **Hidden size**: The vector dimension of each model input.\n",
            "\n",
            "It is said to be \"high dimensional\" because of the last value. The hidden size can be very large (768 is common for smaller models, and in larger models this can reach 3072 or more).\n",
            "\n",
            "We can see this if we feed the inputs we preprocessed to our model:\n",
            "\n",
            "{#if fw === 'pt'}\n",
            "```python\n",
            "outputs = model(**inputs)\n",
            "print(outputs.last_hidden_state.shape)\n",
            "```\n",
            "\n",
            "```python out\n",
            "torch.Size([2, 16, 768])\n",
            "```\n",
            "{:else}\n",
            "```py\n",
            "outputs = model(inputs)\n",
            "print(outputs.last_hidden_state.shape)\n",
            "```\n",
            "\n",
            "```python out\n",
            "(2, 16, 768)\n",
            "```\n",
            "{/if}\n",
            "\n",
            "Note that the outputs of ğŸ¤— Transformers models behave like `namedtuple`s or dictionaries. You can access the elements by attributes (like we did) or by key (`outputs[\"last_hidden_state\"]`), or even by index if you know exactly where the thing you are looking for is (`outputs[0]`).\n",
            "\n",
            "### Model heads: Making sense out of numbers[[model-heads-making-sense-out-of-numbers]]\n",
            "\n",
            "The model heads take the high-dimensional vector of hidden states as input and project them onto a different dimension. They are usually composed of one or a few linear layers:\n",
            "\n",
            "<div class=\"flex justify-center\">\n",
            "<img class=\"block dark:hidden\" src=\"https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter2/transformer_and_head.svg\" alt=\"A Transformer network alongside its head.\"/>\n",
            "<img class=\"hidden dark:block\" src=\"https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter2/transformer_and_head-dark.svg\" alt=\"A Transformer network alongside its head.\"/>\n",
            "</div>\n",
            "\n",
            "The output of the Transformer model is sent directly to the model head to be processed.\n",
            "\n",
            "In this diagram, the model is represented by its embeddings layer and the subsequent layers. The embeddings layer converts each input ID in the tokenized input into a vector that represents the associated token. The subsequent layers manipulate those vectors using the attention mechanism to produce the final representation of the sentences.\n",
            "\n",
            "There are many different architectures available in ğŸ¤— Transformers, with each one designed around tackling a specific task. Here is a non-exhaustive list:\n",
            "\n",
            "- `*Model` (retrieve the hidden states)\n",
            "- `*ForCausalLM`\n",
            "- `*ForMaskedLM`\n",
            "- `*ForMultipleChoice`\n",
            "- `*ForQuestionAnswering`\n",
            "- `*ForSequenceClassification`\n",
            "- `*ForTokenClassification`\n",
            "- and others ğŸ¤—\n",
            "\n",
            "{#if fw === 'pt'}\n",
            "For our example, we will need a model with a sequence classification head (to be able to classify the sentences as positive or negative). So, we won't actually use the `AutoModel` class, but `AutoModelForSequenceClassification`:\n",
            "\n",
            "```python\n",
            "from transformers import AutoModelForSequenceClassification\n",
            "\n",
            "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
            "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
            "outputs = model(**inputs)\n",
            "```\n",
            "{:else}\n",
            "For our example, we will need a model with a sequence classification head (to be able to classify the sentences as positive or negative). So, we won't actually use the `TFAutoModel` class, but `TFAutoModelForSequenceClassification`:\n",
            "\n",
            "```python\n",
            "from transformers import TFAutoModelForSequenceClassification\n",
            "\n",
            "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
            "model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
            "outputs = model(inputs)\n",
            "```\n",
            "{/if}\n",
            "\n",
            "Now if we look at the shape of our outputs, the dimensionality will be much lower: the model head takes as input the high-dimensional vectors we saw before, and outputs vectors containing two values (one per label):\n",
            "\n",
            "```python\n",
            "print(outputs.logits.shape)\n",
            "```\n",
            "\n",
            "{#if fw === 'pt'}\n",
            "```python out\n",
            "torch.Size([2, 2])\n",
            "```\n",
            "{:else}\n",
            "```python out\n",
            "(2, 2)\n",
            "```\n",
            "{/if}\n",
            "\n",
            "Since we have just two sentences and two labels, the result we get from our model is of shape 2 x 2.\n",
            "\n",
            "## Postprocessing the output[[postprocessing-the-output]]\n",
            "\n",
            "The values we get as output from our model don't necessarily make sense by themselves. Let's take a look:\n",
            "\n",
            "```python\n",
            "print(outputs.logits)\n",
            "```\n",
            "\n",
            "{#if fw === 'pt'}\n",
            "```python out\n",
            "tensor([[-1.5607,  1.6123],\n",
            "        [ 4.1692, -3.3464]], grad_fn=<AddmmBackward>)\n",
            "```\n",
            "{:else}\n",
            "```python out\n",
            "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
            "    array([[-1.5606991,  1.6122842],\n",
            "           [ 4.169231 , -3.3464472]], dtype=float32)>\n",
            "```\n",
            "{/if}\n",
            "\n",
            "Our model predicted `[-1.5607, 1.6123]` for the first sentence and `[ 4.1692, -3.3464]` for the second one. Those are not probabilities but *logits*, the raw, unnormalized scores outputted by the last layer of the model. To be converted to probabilities, they need to go through a [SoftMax](https://en.wikipedia.org/wiki/Softmax_function) layer (all ğŸ¤— Transformers models output the logits, as the loss function for training will generally fuse the last activation function, such as SoftMax, with the actual loss function, such as cross entropy):\n",
            "\n",
            "{#if fw === 'pt'}\n",
            "```py\n",
            "import torch\n",
            "\n",
            "predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
            "print(predictions)\n",
            "```\n",
            "{:else}\n",
            "```py\n",
            "import tensorflow as tf\n",
            "\n",
            "predictions = tf.math.softmax(outputs.logits, axis=-1)\n",
            "print(predictions)\n",
            "```\n",
            "{/if}\n",
            "\n",
            "{#if fw === 'pt'}\n",
            "```python out\n",
            "tensor([[4.0195e-02, 9.5980e-01],\n",
            "        [9.9946e-01, 5.4418e-04]], grad_fn=<SoftmaxBackward>)\n",
            "```\n",
            "{:else}\n",
            "```python out\n",
            "tf.Tensor(\n",
            "[[4.01951671e-02 9.59804833e-01]\n",
            " [9.9945587e-01 5.4418424e-04]], shape=(2, 2), dtype=float32)\n",
            "```\n",
            "{/if}\n",
            "\n",
            "Now we can see that the model predicted `[0.0402, 0.9598]` for the first sentence and `[0.9995,  0.0005]` for the second one. These are recognizable probability scores.\n",
            "\n",
            "To get the labels corresponding to each position, we can inspect the `id2label` attribute of the model config (more on this in the next section):\n",
            "\n",
            "```python\n",
            "model.config.id2label\n",
            "```\n",
            "\n",
            "```python out\n",
            "{0: 'NEGATIVE', 1: 'POSITIVE'}\n",
            "```\n",
            "\n",
            "Now we can conclude that the model predicted the following:\n",
            " \n",
            "- First sentence: NEGATIVE: 0.0402, POSITIVE: 0.9598\n",
            "- Second sentence: NEGATIVE: 0.9995, POSITIVE: 0.0005\n",
            "\n",
            "We have successfully reproduced the three steps of the pipeline: preprocessing with tokenizers, passing the inputs through the model, and postprocessing! Now let's take some time to dive deeper into each of those steps.\n",
            "\n",
            "<Tip>\n",
            "\n",
            "âœï¸ **Try it out!** Choose two (or more) texts of your own and run them through the `sentiment-analysis` pipeline. Then replicate the steps you saw here yourself and check that you obtain the same results!\n",
            "\n",
            "</Tip>\n",
            "Document 4------------------------------------------------------------\n",
            "Gradio Demo: ner_pipeline\n",
            "\n",
            "\n",
            "```\n",
            "!pip install -q gradio torch transformers\n",
            "```\n",
            "\n",
            "\n",
            "```\n",
            "from transformers import pipeline\n",
            "\n",
            "import gradio as gr\n",
            "\n",
            "ner_pipeline = pipeline(\"ner\")\n",
            "\n",
            "examples = [\n",
            "    \"Does Chicago have any stores and does Joe live here?\",\n",
            "]\n",
            "\n",
            "def ner(text):\n",
            "    output = ner_pipeline(text)\n",
            "    return {\"text\": text, \"entities\": output}    \n",
            "\n",
            "demo = gr.Interface(ner,\n",
            "             gr.Textbox(placeholder=\"Enter sentence here...\"), \n",
            "             gr.HighlightedText(),\n",
            "             examples=examples)\n",
            "\n",
            "if __name__ == \"__main__\":\n",
            "    demo.launch()\n",
            "\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ĞŸĞ¾ĞºÑ€Ğ°Ñ‰ĞµĞ½Ğ½Ñ Ğ·Ğ°Ğ¿Ğ¸Ñ‚Ñƒ, Ñ‰Ğ¾Ğ± Ğ¾Ñ‚Ñ€Ğ¸Ğ¼Ğ°Ñ‚Ğ¸ Ğ±Ñ–Ğ»ÑŒÑˆĞµ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ñ–Ğ²"
      ],
      "metadata": {
        "id": "n9EyCrZGfW1S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "TTot9bvofiek"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What are the steps for creating a pipeline object??\"\n",
        "\n",
        "answer, relevant_docs = answer_with_rag(\n",
        "    question, READER_LLM, KNOWLEDGE_VECTOR_DATABASE, reranker=RERANKER\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUOmdoUEfbOS",
        "outputId": "34d1fc4e-5f6c-47e7-b59a-d92d40fd4ced"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Retrieving documents...\n",
            "=> Reranking documents...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Generating answer...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"==================================Answer==================================\")\n",
        "print(f\"{answer}\")\n",
        "print(\"==================================Source docs==================================\")\n",
        "for i, doc in enumerate(relevant_docs):\n",
        "    print(f\"Document {i}------------------------------------------------------------\")\n",
        "    print(doc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzcuKOyQgIlg",
        "outputId": "6843f0fe-a5b8-481a-89c9-08d27b3036a2"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================Answer==================================\n",
            "To create a pipeline object for named entity recognition (NER) using Hugging Face's Transformers library in Python, follow these steps:\n",
            "\n",
            "1. Install the required packages:\n",
            "\n",
            "   ```\n",
            "  !pip install -q gradio torch transformers\n",
            "   ```\n",
            "\n",
            "2. Define a function that takes a sentence as input and returns a dictionary with the original sentence and the entities recognized by the NER pipeline:\n",
            "\n",
            "   ```python\n",
            "   from transformers import pipeline\n",
            "\n",
            "   ner_pipeline = pipeline(\"ner\")\n",
            "\n",
            "   def ner(text):\n",
            "       output = ner_pipeline(text)\n",
            "       return {\"text\": text, \"entities\": output}\n",
            "   ```\n",
            "\n",
            "3. Create a demo interface that allows the user to enter a sentence, highlight the recognized entities, and display the results:\n",
            "\n",
            "   ```python\n",
            "   import gradio as gr\n",
            "\n",
            "   demo = gr.Interface(ner,\n",
            "                          gr.Textbox(placeholder=\"Enter sentence here...\"),\n",
            "                          gr.HighlightedText())\n",
            "\n",
            "   if __name__ == \"__main__\":\n",
            "       demo.launch()\n",
            "   ```\n",
            "\n",
            "4. Run the demo interface:\n",
            "\n",
            "   ```\n",
            "  !python demo.py\n",
            "   ```\n",
            "\n",
            "5. Before releasing, perform the following checks:\n",
            "\n",
            "   - Freeze the `master` branch.\n",
            "   - Run all tests (check CI has properly run).\n",
            "   - Run all fast tests (`RUN_PIPELINE_TESTS=1 CUDA_VISIBLE_DEVICES=-1 pytest -sv tests/`).\n",
            "   - If all *fast* tests work, then run the whole test suite.\n",
            "   - Increase the version number for `tokenizers`.\n",
            "   - Create a new release with the new version number and tag.\n",
            "   - Copy paste the new part of the `CHANGELOG.md`.\n",
            "   - Publish the release.\n",
            "   - Check that everything works smoothly in the [Actions](https://github.com/huggingface/tokenizers/actions) tab.\n",
            "   - Fix the CI/CD if anything fails.\n",
            "\n",
            "6. Repeat steps 4-5 for the Rust and Node versions.\n",
            "\n",
            "7. Test the CI/CD for release by commenting out the parts that upload artifacts and changing\n",
            "==================================Source docs==================================\n",
            "Document 0------------------------------------------------------------\n",
            "Case Study: A Component to Display PDFs\n",
            "\n",
            "Let's work through an example of building a custom gradio component for displaying PDF files.\n",
            "This component will come in handy for showcasing [document question answering](https://huggingface.co/models?pipeline_tag=document-question-answering&sort=trending) models, which typically work on PDF input.\n",
            "This is a sneak preview of what our finished component will look like:\n",
            "\n",
            "![demo](https://gradio-builds.s3.amazonaws.com/assets/PDFDisplay.png)\n",
            "\n",
            "## Step 0: Prerequisites\n",
            "Make sure you have gradio 4.0 installed as well as node 18+.\n",
            "As of the time of publication, the latest release is 4.1.1.\n",
            "Also, please read the [Five Minute Tour](./custom-components-in-five-minutes) of custom components and the [Key Concepts](./key-component-concepts) guide before starting.\n",
            "\n",
            "\n",
            "## Step 1: Creating the custom component\n",
            "\n",
            "Navigate to a directory of your choosing and run the following command:\n",
            "\n",
            "```bash\n",
            "gradio cc create PDF\n",
            "```\n",
            "\n",
            "\n",
            "Tip: You should change the name of the component.\n",
            "Some of the screenshots assume the component is callled `PDF` but the concepts are the same!\n",
            "\n",
            "This will create a subdirectory called `pdf` in your current working directory.\n",
            "There are three main subdirectories in `pdf`: `frontend`, `backend`, and `demo`.\n",
            "If you open `pdf` in your code editor, it will look like this:\n",
            "\n",
            "![directory structure](https://gradio-builds.s3.amazonaws.com/assets/pdf-guide/CodeStructure.png)\n",
            "\n",
            "Tip: For this demo we are not templating off a current gradio component. But you can see the list of available templates with `gradio cc show` and then pass the template name to the `--template` option, e.g. `gradio cc create <Name> --template <foo>`\n",
            "\n",
            "## Step 2: Frontend - modify javascript dependencies\n",
            "\n",
            "We're going to use the [pdfjs](https://mozilla.github.io/pdf.js/) javascript library to display the pdfs in the frontend. \n",
            "Let's start off by adding it to our frontend project's dependencies, as well as adding a couple of other projects we'll need.\n",
            "\n",
            "From within the `frontend` directory, run `npm install @gradio/client @gradio/upload @gradio/icons @gradio/button` and `npm install --save-dev pdfjs-dist@3.11.174`.\n",
            "Also, let's uninstall the `@zerodevx/svelte-json-view` dependency by running `npm uninstall @zerodevx/svelte-json-view`.\n",
            "\n",
            "The complete `package.json` should look like this:\n",
            "\n",
            "```json\n",
            "{\n",
            "  \"name\": \"gradio_pdf\",\n",
            "  \"version\": \"0.2.0\",\n",
            "  \"description\": \"Gradio component for displaying PDFs\",\n",
            "  \"type\": \"module\",\n",
            "  \"author\": \"\",\n",
            "  \"license\": \"ISC\",\n",
            "  \"private\": false,\n",
            "  \"main_changeset\": true,\n",
            "  \"exports\": {\n",
            "    \".\": \"./Index.svelte\",\n",
            "    \"./example\": \"./Example.svelte\",\n",
            "    \"./package.json\": \"./package.json\"\n",
            "  },\n",
            "  \"devDependencies\": {\n",
            "    \"pdfjs-dist\": \"3.11.174\"\n",
            "  },\n",
            "  \"dependencies\": {\n",
            "    \"@gradio/atoms\": \"0.2.0\",\n",
            "    \"@gradio/statustracker\": \"0.3.0\",\n",
            "    \"@gradio/utils\": \"0.2.0\",\n",
            "    \"@gradio/client\": \"0.7.1\",\n",
            "    \"@gradio/upload\": \"0.3.2\",\n",
            "    \"@gradio/icons\": \"0.2.0\",\n",
            "    \"@gradio/button\": \"0.2.3\",\n",
            "    \"pdfjs-dist\": \"3.11.174\"\n",
            "  }\n",
            "}\n",
            "```\n",
            "\n",
            "\n",
            "Tip: Running `npm install` will install the latest version of the package available. You can install a specific version with `npm install package@<version>`.  You can find all of the gradio javascript package documentation [here](https://www.gradio.app/main/docs/js). It is recommended you use the same versions as me as the API can change.\n",
            "\n",
            "Navigate to `Index.svelte` and delete mentions of `JSONView`\n",
            "\n",
            "```ts\n",
            "import { JsonView } from \"@zerodevx/svelte-json-view\";\n",
            "```\n",
            "\n",
            "```ts\n",
            "<JsonView json={value} />\n",
            "```\n",
            "\n",
            "## Step 3: Frontend - Launching the Dev Server\n",
            "\n",
            "Run the `dev` command to launch the development server.\n",
            "This will open the demo in `demo/app.py` in an environment where changes to the `frontend` and `backend` directories will reflect instantaneously in the launched app.\n",
            "\n",
            "After launching the dev server, you should see a link printed to your console that says `Frontend Server (Go here): ... `.\n",
            " \n",
            "![](https://gradio-builds.s3.amazonaws.com/assets/pdf-guide/dev_server_terminal.png)\n",
            "\n",
            "You should see the following:\n",
            "\n",
            "![](https://gradio-builds.s3.amazonaws.com/assets/pdf-guide/frontend_start.png)\n",
            "\n",
            "\n",
            "Its not impressive yet but we're ready to start coding!\n",
            "\n",
            "## Step 4: Frontend - The basic skeleton\n",
            "\n",
            "We're going to start off by first writing the skeleton of our frontend and then adding the pdf rendering logic.\n",
            "Add the following imports and expose the following properties to the top of your file in the `<script>` tag.\n",
            "You may get some warnings from your code editor that some props are not used.\n",
            "That's ok.\n",
            "\n",
            "```ts\n",
            "    import { tick } from \"svelte\";\n",
            "    import type { Gradio } from \"@gradio/utils\";\n",
            "    import { Block, BlockLabel } from \"@gradio/atoms\";\n",
            "    import { File } from \"@gradio/icons\";\n",
            "    import { StatusTracker } from \"@gradio/statustracker\";\n",
            "    import type { LoadingStatus } from \"@gradio/statustracker\";\n",
            "    import type { FileData } from \"@gradio/client\";\n",
            "    import { normalise_file } from \"@gradio/client\";\n",
            "    import { Upload, ModifyUpload } from \"@gradio/upload\";\n",
            "\n",
            "\texport let elem_id = \"\";\n",
            "\texport let elem_classes: string[] = [];\n",
            "\texport let visible = true;\n",
            "\texport let value: FileData | null = null;\n",
            "\texport let container = true;\n",
            "\texport let scale: number | null = null;\n",
            "\texport let root: string;\n",
            "\texport let height: number | null = 500;\n",
            "\texport let label: string;\n",
            "\texport let proxy_url: string;\n",
            "\texport let min_width: number | undefined = undefined;\n",
            "\texport let loading_status: LoadingStatus;\n",
            "\texport let gradio: Gradio<{\n",
            "\t\tchange: never;\n",
            "\t\tupload: never;\n",
            "\t}>;\n",
            "\n",
            "    let _value = value;\n",
            "    let old_value = _value;\n",
            "```\n",
            "\n",
            "\n",
            "Tip: The `gradio`` object passed in here contains some metadata about the application as well as some utility methods. One of these utilities is a dispatch method. We want to dispatch change and upload events whenever our PDF is changed or updated. This line provides type hints that these are the only events we will be dispatching.\n",
            "\n",
            "We want our frontend component to let users upload a PDF document if there isn't one already loaded.\n",
            "If it is loaded, we want to display it underneath a \"clear\" button that lets our users upload a new document. \n",
            "We're going to use the `Upload` and `ModifyUpload` components that come with the `@gradio/upload` package to do this.\n",
            "Underneath the `</script>` tag, delete all the current code and add the following:\n",
            "\n",
            "```ts\n",
            "<Block {visible} {elem_id} {elem_classes} {container} {scale} {min_width}>\n",
            "    {#if loading_status}\n",
            "        <StatusTracker\n",
            "            autoscroll={gradio.autoscroll}\n",
            "            i18n={gradio.i18n}\n",
            "            {...loading_status}\n",
            "        />\n",
            "    {/if}\n",
            "    <BlockLabel\n",
            "        show_label={label !== null}\n",
            "        Icon={File}\n",
            "        float={value === null}\n",
            "        label={label || \"File\"}\n",
            "    />\n",
            "    {#if _value}\n",
            "        <ModifyUpload i18n={gradio.i18n} absolute />\n",
            "    {:else}\n",
            "        <Upload\n",
            "            filetype={\"application/pdf\"}\n",
            "            file_count=\"single\"\n",
            "            {root}\n",
            "        >\n",
            "            Upload your PDF\n",
            "        </Upload>\n",
            "    {/if}\n",
            "</Block>\n",
            "```\n",
            "\n",
            "You should see the following when you navigate to your app after saving your current changes:\n",
            "\n",
            "![](https://gradio-builds.s3.amazonaws.com/assets/pdf-guide/frontend_1.png)\n",
            "\n",
            "## Step 5: Frontend - Nicer Upload Text\n",
            "\n",
            "The `Upload your PDF` text looks a bit small and barebones. \n",
            "Lets customize it!\n",
            "\n",
            "Create a new file called `PdfUploadText.svelte` and copy the following code.\n",
            "Its creating a new div to display our \"upload text\" with some custom styling.\n",
            "\n",
            "Tip: Notice that we're leveraging Gradio core's existing css variables here: `var(--size-60)` and `var(--body-text-color-subdued)`. This allows our component to work nicely in light mode and dark mode, as well as with Gradio's built-in themes.\n",
            "\n",
            "\n",
            "```ts\n",
            "<script lang=\"ts\">\n",
            "\timport { Upload as UploadIcon } from \"@gradio/icons\";\n",
            "\texport let hovered = false;\n",
            "\n",
            "</script>\n",
            "\n",
            "<div class=\"wrap\">\n",
            "\t<span class=\"icon-wrap\" class:hovered><UploadIcon /> </span>\n",
            "    Drop PDF\n",
            "    <span class=\"or\">- or -</span>\n",
            "    Click to Upload\n",
            "</div>\n",
            "\n",
            "<style>\n",
            "\t.wrap {\n",
            "\t\tdisplay: flex;\n",
            "\t\tflex-direction: column;\n",
            "\t\tjustify-content: center;\n",
            "\t\talign-items: center;\n",
            "\t\tmin-height: var(--size-60);\n",
            "\t\tcolor: var(--block-label-text-color);\n",
            "\t\tline-height: var(--line-md);\n",
            "\t\theight: 100%;\n",
            "\t\tpadding-top: var(--size-3);\n",
            "\t}\n",
            "\n",
            "\t.or {\n",
            "\t\tcolor: var(--body-text-color-subdued);\n",
            "\t\tdisplay: flex;\n",
            "\t}\n",
            "\n",
            "\t.icon-wrap {\n",
            "\t\twidth: 30px;\n",
            "\t\tmargin-bottom: var(--spacing-lg);\n",
            "\t}\n",
            "\n",
            "\t@media (--screen-md) {\n",
            "\t\t.wrap {\n",
            "\t\t\tfont-size: var(--text-lg);\n",
            "\t\t}\n",
            "\t}\n",
            "\n",
            "\t.hovered {\n",
            "\t\tcolor: var(--color-accent);\n",
            "\t}\n",
            "</style>\n",
            "```\n",
            "\n",
            "Now import `PdfUploadText.svelte` in your `<script>` and pass it to the `Upload` component!\n",
            "\n",
            "```ts\n",
            "\timport PdfUploadText from \"./PdfUploadText.svelte\";\n",
            "\n",
            "...\n",
            "\n",
            "    <Upload\n",
            "        filetype={\"application/pdf\"}\n",
            "        file_count=\"single\"\n",
            "        {root}\n",
            "    >\n",
            "        <PdfUploadText />\n",
            "    </Upload>\n",
            "```\n",
            "\n",
            "After saving your code, the frontend should now look like this:\n",
            "\n",
            "![](https://gradio-builds.s3.amazonaws.com/assets/pdf-guide/better_upload.png)\n",
            "\n",
            "## Step 6: PDF Rendering logic\n",
            "\n",
            "This is the most advanced javascript part.\n",
            "It took me a while to figure it out!\n",
            "Do not worry if you have trouble, the important thing is to not be discouraged ğŸ’ª\n",
            "Ask for help in the gradio [discord](https://discord.gg/hugging-face-879548962464493619) if you need and ask for help.\n",
            "\n",
            "With that out of the way, let's start off by importing `pdfjs` and loading the code of the pdf worker from the mozilla cdn.\n",
            "\n",
            "```ts\n",
            "\timport pdfjsLib from \"pdfjs-dist\";\n",
            "    ...\n",
            "    pdfjsLib.GlobalWorkerOptions.workerSrc =  \"https://cdn.bootcss.com/pdf.js/3.11.174/pdf.worker.js\";\n",
            "```\n",
            "\n",
            "Also create the following variables:\n",
            "\n",
            "```ts\n",
            "    let pdfDoc;\n",
            "    let numPages = 1;\n",
            "    let currentPage = 1;\n",
            "    let canvasRef;\n",
            "```\n",
            "\n",
            "Now, we will use `pdfjs` to render a given page of the PDF onto an `html` document.\n",
            "Add the following code to `Index.svelte`:\n",
            "\n",
            "```ts\n",
            "    async function get_doc(value: FileData) {\n",
            "        const loadingTask = pdfjsLib.getDocument(value.url);\n",
            "        pdfDoc = await loadingTask.promise;\n",
            "        numPages = pdfDoc.numPages;\n",
            "        render_page();\n",
            "    }\n",
            "\n",
            "    function render_page() {\n",
            "    // Render a specific page of the PDF onto the canvas\n",
            "        pdfDoc.getPage(currentPage).then(page => {\n",
            "            const ctx  = canvasRef.getContext('2d')\n",
            "            ctx.clearRect(0, 0, canvasRef.width, canvasRef.height);\n",
            "            let viewport = page.getViewport({ scale: 1 });\n",
            "            let scale = height / viewport.height;\n",
            "            viewport = page.getViewport({ scale: scale });\n",
            "\n",
            "            const renderContext = {\n",
            "                canvasContext: ctx,\n",
            "                viewport,\n",
            "            };\n",
            "            canvasRef.width = viewport.width;\n",
            "            canvasRef.height = viewport.height;\n",
            "            page.render(renderContext);\n",
            "        });\n",
            "    }\n",
            "\n",
            "    // Compute the url to fetch the file from the backend\n",
            "    // whenever a new value is passed in.\n",
            "    $: _value = normalise_file(value, root, proxy_url);\n",
            "\n",
            "    // If the value changes, render the PDF of the currentPage\n",
            "    $: if(JSON.stringify(old_value) != JSON.stringify(_value)) {\n",
            "        if (_value){\n",
            "            get_doc(_value);\n",
            "        }\n",
            "        old_value = _value;\n",
            "        gradio.dispatch(\"change\");\n",
            "    }\n",
            "```\n",
            "\n",
            "\n",
            "Tip: The `$:` syntax in svelte is how you declare statements to be reactive. Whenever any of the inputs of the statement change, svelte will automatically re-run that statement.\n",
            "\n",
            "Now place the `canvas` underneath the `ModifyUpload` component:\n",
            "\n",
            "```ts\n",
            "<div class=\"pdf-canvas\" style=\"height: {height}px\">\n",
            "    <canvas bind:this={canvasRef}></canvas>\n",
            "</div>\n",
            "```\n",
            "\n",
            "And add the following styles to the `<style>` tag:\n",
            "\n",
            "```ts\n",
            "<style>\n",
            "    .pdf-canvas {\n",
            "        display: flex;\n",
            "        justify-content: center;\n",
            "        align-items: center;\n",
            "    }\n",
            "</style>\n",
            "```\n",
            "\n",
            "## Step 7: Handling The File Upload And Clear\n",
            "\n",
            "Now for the fun part - actually rendering the PDF when the file is uploaded!\n",
            "Add the following functions to the `<script>` tag:\n",
            "\n",
            "```ts\n",
            "    async function handle_clear() {\n",
            "        _value = null;\n",
            "        await tick();\n",
            "        gradio.dispatch(\"change\");\n",
            "    }\n",
            "\n",
            "    async function handle_upload({detail}: CustomEvent<FileData>): Promise<void> {\n",
            "        value = detail;\n",
            "        await tick();\n",
            "        gradio.dispatch(\"change\");\n",
            "        gradio.dispatch(\"upload\");\n",
            "    }\n",
            "```\n",
            "\n",
            "\n",
            "Tip: The `gradio.dispatch` method is actually what is triggering the `change` or `upload` events in the backend. For every event defined in the component's backend, we will explain how to do this in Step 9, there must be at least one `gradio.dispatch(\"<event-name>\")` call. These are called `gradio` events and they can be listended from the entire Gradio application. You can dispatch a built-in `svelte` event with the `dispatch` function. These events can only be listened to from the component's direct parent. Learn about svelte events from the [official documentation](https://learn.svelte.dev/tutorial/component-events).\n",
            "\n",
            "Now we will run these functions whenever the `Upload` component uploads a file and whenever the `ModifyUpload` component clears the current file. The `<Upload>` component dispatches a `load` event with a payload of type `FileData` corresponding to the uploaded file. The `on:load` syntax tells `Svelte` to automatically run this function in response to the event.\n",
            "\n",
            "```ts\n",
            "    <ModifyUpload i18n={gradio.i18n} on:clear={handle_clear} absolute />\n",
            "    \n",
            "    ...\n",
            "    \n",
            "    <Upload\n",
            "        on:load={handle_upload}\n",
            "        filetype={\"application/pdf\"}\n",
            "        file_count=\"single\"\n",
            "        {root}\n",
            "    >\n",
            "        <PdfUploadText/>\n",
            "    </Upload>\n",
            "```\n",
            "\n",
            "Congratulations! You have a working pdf uploader!\n",
            "\n",
            "![upload-gif](https://gradio-builds.s3.amazonaws.com/assets/pdf-guide/pdf_component_gif_docs.gif)\n",
            "\n",
            "## Step 8: Adding buttons to navigate pages\n",
            "\n",
            "If a user uploads a PDF document with multiple pages, they will only be able to see the first one.\n",
            "Let's add some buttons to help them navigate the page.\n",
            "We will use the `BaseButton` from `@gradio/button` so that they look like regular Gradio buttons.\n",
            "\n",
            "Import the `BaseButton` and add the following functions that will render the next and previous page of the PDF.\n",
            "\n",
            "```ts\n",
            "    import { BaseButton } from \"@gradio/button\";\n",
            "\n",
            "    ...\n",
            "\n",
            "    function next_page() {\n",
            "        if (currentPage >= numPages) {\n",
            "            return;\n",
            "        }\n",
            "        currentPage++;\n",
            "        render_page();\n",
            "    }\n",
            "\n",
            "    function prev_page() {\n",
            "        if (currentPage == 1) {\n",
            "            return;\n",
            "        }\n",
            "        currentPage--;\n",
            "        render_page();\n",
            "    }\n",
            "```\n",
            "\n",
            "Now we will add them underneath the canvas in a separate `<div>`\n",
            "\n",
            "```ts\n",
            "    ...\n",
            "\n",
            "    <ModifyUpload i18n={gradio.i18n} on:clear={handle_clear} absolute />\n",
            "    <div class=\"pdf-canvas\" style=\"height: {height}px\">\n",
            "        <canvas bind:this={canvasRef}></canvas>\n",
            "    </div>\n",
            "    <div class=\"button-row\">\n",
            "        <BaseButton on:click={prev_page}>\n",
            "            â¬…ï¸\n",
            "        </BaseButton>\n",
            "        <span class=\"page-count\"> {currentPage} / {numPages} </span>\n",
            "        <BaseButton on:click={next_page}>\n",
            "            â¡ï¸\n",
            "        </BaseButton>\n",
            "    </div>\n",
            "    \n",
            "    ...\n",
            "\n",
            "<style>\n",
            "    .button-row {\n",
            "        display: flex;\n",
            "        flex-direction: row;\n",
            "        width: 100%;\n",
            "        justify-content: center;\n",
            "        align-items: center;\n",
            "    }\n",
            "\n",
            "    .page-count {\n",
            "        margin: 0 10px;\n",
            "        font-family: var(--font-mono);\n",
            "    }\n",
            "```\n",
            "\n",
            "Congratulations! The frontend is almost complete ğŸ‰\n",
            "\n",
            "![multipage-pdf-gif](https://gradio-builds.s3.amazonaws.com/assets/pdf-guide/pdf_multipage.gif)\n",
            "\n",
            "## Step 8.5: The Example view\n",
            "\n",
            "We're going to want users of our component to get a preview of the PDF if its used as an `example` in a `gr.Interface` or `gr.Examples`.\n",
            "\n",
            "To do so, we're going to add some of the pdf rendering logic in `Index.svelte` to `Example.svelte`.\n",
            "\n",
            "\n",
            "```ts\n",
            "<script lang=\"ts\">\n",
            "\texport let value: string;\n",
            "\texport let samples_dir: string;\n",
            "\texport let type: \"gallery\" | \"table\";\n",
            "\texport let selected = false;\n",
            "\timport pdfjsLib from \"pdfjs-dist\";\n",
            "\tpdfjsLib.GlobalWorkerOptions.workerSrc =  \"https://cdn.bootcss.com/pdf.js/3.11.174/pdf.worker.js\";\n",
            "\t\n",
            "\tlet pdfDoc;\n",
            "\tlet canvasRef;\n",
            "\n",
            "\tasync function get_doc(url: string) {\n",
            "\t\tconst loadingTask = pdfjsLib.getDocument(url);\n",
            "\t\tpdfDoc = await loadingTask.promise;\n",
            "\t\trenderPage();\n",
            "\t\t}\n",
            "\n",
            "\tfunction renderPage() {\n",
            "\t\t// Render a specific page of the PDF onto the canvas\n",
            "\t\t\tpdfDoc.getPage(1).then(page => {\n",
            "\t\t\t\tconst ctx  = canvasRef.getContext('2d')\n",
            "\t\t\t\tctx.clearRect(0, 0, canvasRef.width, canvasRef.height);\n",
            "\t\t\t\t\n",
            "\t\t\t\tconst viewport = page.getViewport({ scale: 0.2 });\n",
            "\t\t\t\t\n",
            "\t\t\t\tconst renderContext = {\n",
            "\t\t\t\t\tcanvasContext: ctx,\n",
            "\t\t\t\t\tviewport\n",
            "\t\t\t\t};\n",
            "\t\t\t\tcanvasRef.width = viewport.width;\n",
            "\t\t\t\tcanvasRef.height = viewport.height;\n",
            "\t\t\t\tpage.render(renderContext);\n",
            "\t\t\t});\n",
            "\t\t}\n",
            "\t\n",
            "\t$: get_doc(samples_dir + value);\n",
            "</script>\n",
            "\n",
            "<div\n",
            "\tclass:table={type === \"table\"}\n",
            "\tclass:gallery={type === \"gallery\"}\n",
            "\tclass:selected\n",
            "\tstyle=\"justify-content: center; align-items: center; display: flex; flex-direction: column;\"\n",
            ">\n",
            "\t<canvas bind:this={canvasRef}></canvas>\n",
            "</div>\n",
            "\n",
            "<style>\n",
            "\t.gallery {\n",
            "\t\tpadding: var(--size-1) var(--size-2);\n",
            "\t}\n",
            "</style>\n",
            "```\n",
            "\n",
            "\n",
            "Tip: Exercise for the reader - reduce the code duplication between `Index.svelte` and `Example.svelte` ğŸ˜Š\n",
            "\n",
            "\n",
            "You will not be able to render examples until we make some changes to the backend code in the next step!\n",
            "\n",
            "## Step 9: The backend\n",
            "\n",
            "The backend changes needed are smaller.\n",
            "We're almost done!\n",
            "\n",
            "What we're going to do is:\n",
            "* Add `change` and `upload` events to our component.\n",
            "* Add a `height` property to let users control the height of the PDF.\n",
            "* Set the `data_model` of our component to be `FileData`. This is so that Gradio can automatically cache and safely serve any files that are processed by our component.\n",
            "* Modify the `preprocess` method to return a string corresponding to the path of our uploaded PDF.\n",
            "* Modify the `postprocess` to turn a path to a PDF created in an event handler to a `FileData`.\n",
            "\n",
            "When all is said an done, your component's backend code should look like this:\n",
            "\n",
            "```python\n",
            "from __future__ import annotations\n",
            "from typing import Any, Callable\n",
            "\n",
            "from gradio.components.base import Component\n",
            "from gradio.data_classes import FileData\n",
            "from gradio import processing_utils\n",
            "\n",
            "class PDF(Component):\n",
            "\n",
            "    EVENTS = [\"change\", \"upload\"]\n",
            "\n",
            "    data_model = FileData\n",
            "\n",
            "    def __init__(self, value: Any = None, *,\n",
            "                 height: int | None = None,\n",
            "                 label: str | None = None, info: str | None = None,\n",
            "                 show_label: bool | None = None,\n",
            "                 container: bool = True,\n",
            "                 scale: int | None = None,\n",
            "                 min_width: int | None = None,\n",
            "                 interactive: bool | None = None,\n",
            "                 visible: bool = True,\n",
            "                 elem_id: str | None = None,\n",
            "                 elem_classes: list[str] | str | None = None,\n",
            "                 render: bool = True,\n",
            "                 load_fn: Callable[..., Any] | None = None,\n",
            "                 every: float | None = None):\n",
            "        super().__init__(value, label=label, info=info,\n",
            "                         show_label=show_label, container=container,\n",
            "                         scale=scale, min_width=min_width,\n",
            "                         interactive=interactive, visible=visible,\n",
            "                         elem_id=elem_id, elem_classes=elem_classes,\n",
            "                         render=render, load_fn=load_fn, every=every)\n",
            "        self.height = height\n",
            "\n",
            "    def preprocess(self, payload: FileData) -> str:\n",
            "        return payload.path\n",
            "\n",
            "    def postprocess(self, value: str | None) -> FileData:\n",
            "        if not value:\n",
            "            return None\n",
            "        return FileData(path=value)\n",
            "\n",
            "    def example_inputs(self):\n",
            "        return \"https://gradio-builds.s3.amazonaws.com/assets/pdf-guide/fw9.pdf\"\n",
            "\n",
            "    def as_example(self, input_data: str | None) -> str | None:\n",
            "        if input_data is None:\n",
            "            return None\n",
            "        return processing_utils.move_resource_to_block_cache(input_data, self)\n",
            "```\n",
            "\n",
            "## Step 10: Add a demo and publish!\n",
            "\n",
            "To test our backend code, let's add a more complex demo that performs Document Question and Answering with huggingface transformers.\n",
            "\n",
            "In our `demo` directory, create a `requirements.txt` file with the following packages\n",
            "\n",
            "```\n",
            "torch\n",
            "transformers\n",
            "pdf2image\n",
            "pytesseract\n",
            "```\n",
            "\n",
            "\n",
            "Tip: Remember to install these yourself and restart the dev server! You may need to install extra non-python dependencies for `pdf2image`. See [here](https://pypi.org/project/pdf2image/). Feel free to write your own demo if you have trouble.\n",
            "\n",
            "\n",
            "```python\n",
            "import gradio as gr\n",
            "from gradio_pdf import PDF\n",
            "from pdf2image import convert_from_path\n",
            "from transformers import pipeline\n",
            "from pathlib import Path\n",
            "\n",
            "dir_ = Path(__file__).parent\n",
            "\n",
            "p = pipeline(\n",
            "    \"document-question-answering\",\n",
            "    model=\"impira/layoutlm-document-qa\",\n",
            ")\n",
            "\n",
            "def qa(question: str, doc: str) -> str:\n",
            "    img = convert_from_path(doc)[0]\n",
            "    output = p(img, question)\n",
            "    return sorted(output, key=lambda x: x[\"score\"], reverse=True)[0]['answer']\n",
            "\n",
            "\n",
            "demo = gr.Interface(\n",
            "    qa,\n",
            "    [gr.Textbox(label=\"Question\"), PDF(label=\"Document\")],\n",
            "    gr.Textbox(),\n",
            ")\n",
            "\n",
            "demo.launch()\n",
            "```\n",
            "\n",
            "See our demo in action below!\n",
            "\n",
            "<video autoplay muted loop>\n",
            "  <source src=\"https://gradio-builds.s3.amazonaws.com/assets/pdf-guide/PDFDemo.mov\" type=\"video/mp4\" />\n",
            "</video>\n",
            "\n",
            "Finally lets build our component with `gradio cc build` and publish it with the `gradio cc publish` command!\n",
            "This will guide you through the process of uploading your component to [PyPi](https://pypi.org/) and [HuggingFace Spaces](https://huggingface.co/spaces).\n",
            "\n",
            "\n",
            "Tip: You may need to add the following lines to the `Dockerfile` of your HuggingFace Space.\n",
            "\n",
            "```Dockerfile\n",
            "RUN mkdir -p /tmp/cache/\n",
            "RUN chmod a+rwx -R /tmp/cache/\n",
            "RUN apt-get update && apt-get install -y poppler-utils tesseract-ocr\n",
            "\n",
            "ENV TRANSFORMERS_CACHE=/tmp/cache/\n",
            "```\n",
            "\n",
            "## Conclusion\n",
            "\n",
            "In order to use our new component in **any** gradio 4.0 app, simply install it with pip, e.g. `pip install gradio-pdf`. Then you can use it like the built-in `gr.File()` component (except that it will only accept and display PDF files).\n",
            "\n",
            "Here is a simple demo with the Blocks api:\n",
            "\n",
            "```python\n",
            "import gradio as gr\n",
            "from gradio_pdf import PDF\n",
            "\n",
            "with gr.Blocks() as demo:\n",
            "    pdf = PDF(label=\"Upload a PDF\", interactive=True)\n",
            "    name = gr.Textbox()\n",
            "    pdf.upload(lambda f: f, pdf, name)\n",
            "\n",
            "demo.launch()\n",
            "```\n",
            "\n",
            "\n",
            "I hope you enjoyed this tutorial!\n",
            "The complete source code for our component is [here](https://huggingface.co/spaces/freddyaboulton/gradio_pdf/tree/main/src).\n",
            "Please don't hesitate to reach out to the gradio community on the [HuggingFace Discord](https://discord.gg/hugging-face-879548962464493619) if you get stuck.\n",
            "Document 1------------------------------------------------------------\n",
            "!--âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be\n",
            "rendered properly in your Markdown viewer.\n",
            "-->\n",
            "\n",
            "# Using pipelines for a webserver\n",
            "\n",
            "<Tip>\n",
            "Creating an inference engine is a complex topic, and the \"best\" solution \n",
            "will most likely depend on your problem space. Are you on CPU or GPU? Do\n",
            "you want the lowest latency, the highest throughput, support for\n",
            "many models, or just highly optimize 1 specific model?\n",
            "There are many ways to tackle this topic, so what we are going to present is a good default\n",
            "to get started which may not necessarily be the most optimal solution for you.\n",
            "</Tip>\n",
            "\n",
            "\n",
            "The key thing to understand is that we can use an iterator, just like you would [on a\n",
            "dataset](pipeline_tutorial#using-pipelines-on-a-dataset), since a webserver is basically a system that waits for requests and\n",
            "treats them as they come in.\n",
            "\n",
            "Usually webservers are multiplexed (multithreaded, async, etc..) to handle various\n",
            "requests concurrently. Pipelines on the other hand (and mostly the underlying models)\n",
            "are not really great for parallelism; they take up a lot of RAM, so it's best to give them all the available resources when they are running or it's a compute-intensive job.\n",
            "\n",
            "We are going to solve that by having the webserver handle the light load of receiving\n",
            "and sending requests, and having a single thread handling the actual work.\n",
            "This example is going to use `starlette`. The actual framework is not really\n",
            "important, but you might have to tune or change the code if you are using another\n",
            "one to achieve the same effect.\n",
            "\n",
            "Create `server.py`:\n",
            "\n",
            "```py\n",
            "from starlette.applications import Starlette\n",
            "from starlette.responses import JSONResponse\n",
            "from starlette.routing import Route\n",
            "from transformers import pipeline\n",
            "import asyncio\n",
            "\n",
            "\n",
            "async def homepage(request):\n",
            "    payload = await request.body()\n",
            "    string = payload.decode(\"utf-8\")\n",
            "    response_q = asyncio.Queue()\n",
            "    await request.app.model_queue.put((string, response_q))\n",
            "    output = await response_q.get()\n",
            "    return JSONResponse(output)\n",
            "\n",
            "\n",
            "async def server_loop(q):\n",
            "    pipe = pipeline(model=\"bert-base-uncased\")\n",
            "    while True:\n",
            "        (string, response_q) = await q.get()\n",
            "        out = pipe(string)\n",
            "        await response_q.put(out)\n",
            "\n",
            "\n",
            "app = Starlette(\n",
            "    routes=[\n",
            "        Route(\"/\", homepage, methods=[\"POST\"]),\n",
            "    ],\n",
            ")\n",
            "\n",
            "\n",
            "@app.on_event(\"startup\")\n",
            "async def startup_event():\n",
            "    q = asyncio.Queue()\n",
            "    app.model_queue = q\n",
            "    asyncio.create_task(server_loop(q))\n",
            "```\n",
            "\n",
            "Now you can start it with:\n",
            "```bash\n",
            "uvicorn server:app\n",
            "```\n",
            "\n",
            "And you can query it:\n",
            "```bash\n",
            "curl -X POST -d \"test [MASK]\" http://localhost:8000/\n",
            "#[{\"score\":0.7742936015129089,\"token\":1012,\"token_str\":\".\",\"sequence\":\"test.\"},...]\n",
            "```\n",
            "\n",
            "And there you go, now you have a good idea of how to create a webserver!\n",
            "\n",
            "What is really important is that we load the model only **once**, so there are no copies\n",
            "of the model on the webserver. This way, no unnecessary RAM is being used.\n",
            "Then the queuing mechanism allows you to do fancy stuff like maybe accumulating a few\n",
            "items before inferring to use dynamic batching:\n",
            "\n",
            "<Tip warning={true}>\n",
            "\n",
            "The code sample below is intentionally written like pseudo-code for readability.\n",
            "Do not run this without checking if it makes sense for your system resources!\n",
            "\n",
            "</Tip>\n",
            "\n",
            "```py\n",
            "(string, rq) = await q.get()\n",
            "strings = []\n",
            "queues = []\n",
            "while True:\n",
            "    try:\n",
            "        (string, rq) = await asyncio.wait_for(q.get(), timeout=0.001)  # 1ms\n",
            "    except asyncio.exceptions.TimeoutError:\n",
            "        break\n",
            "    strings.append(string)\n",
            "    queues.append(rq)\n",
            "strings\n",
            "outs = pipe(strings, batch_size=len(strings))\n",
            "for rq, out in zip(queues, outs):\n",
            "    await rq.put(out)\n",
            "```\n",
            "\n",
            "Again, the proposed code is optimized for readability, not for being the best code.\n",
            "First of all, there's no batch size limit which is usually not a \n",
            "great idea. Next, the timeout is reset on every queue fetch, meaning you could\n",
            "wait much more than 1ms before running the inference (delaying the first request \n",
            "by that much). \n",
            "\n",
            "It would be better to have a single 1ms deadline.\n",
            "\n",
            "This will always wait for 1ms even if the queue is empty, which might not be the\n",
            "best since you probably want to start doing inference if there's nothing in the queue.\n",
            "But maybe it does make sense if batching is really crucial for your use case.\n",
            "Again, there's really no one best solution.\n",
            "\n",
            "\n",
            "## Few things you might want to consider\n",
            "\n",
            "### Error checking\n",
            "\n",
            "There's a lot that can go wrong in production: out of memory, out of space,\n",
            "loading the model might fail, the query might be wrong, the query might be\n",
            "correct but still fail to run because of a model misconfiguration, and so on.\n",
            "\n",
            "Generally, it's good if the server outputs the errors to the user, so\n",
            "adding a lot of `try..except` statements to show those errors is a good\n",
            "idea. But keep in mind it may also be a security risk to reveal all those errors depending \n",
            "on your security context.\n",
            "\n",
            "### Circuit breaking\n",
            "\n",
            "Webservers usually look better when they do circuit breaking. It means they \n",
            "return proper errors when they're overloaded instead of just waiting for the query indefinitely. Return a 503 error instead of waiting for a super long time or a 504 after a long time.\n",
            "\n",
            "This is relatively easy to implement in the proposed code since there is a single queue.\n",
            "Looking at the queue size is a basic way to start returning errors before your \n",
            "webserver fails under load.\n",
            "\n",
            "### Blocking the main thread\n",
            "\n",
            "Currently PyTorch is not async aware, and computation will block the main\n",
            "thread while running. That means it would be better if PyTorch was forced to run\n",
            "on its own thread/process. This wasn't done here because the code is a lot more\n",
            "complex (mostly because threads and async and queues don't play nice together).\n",
            "But ultimately it does the same thing.\n",
            "\n",
            "This would be important if the inference of single items were long (> 1s) because \n",
            "in this case, it means every query during inference would have to wait for 1s before\n",
            "even receiving an error.\n",
            "\n",
            "### Dynamic batching\n",
            "\n",
            "In general, batching is not necessarily an improvement over passing 1 item at \n",
            "a time (see [batching details](./main_classes/pipelines#pipeline-batching) for more information). But it can be very effective\n",
            "when used in the correct setting. In the API, there is no dynamic\n",
            "batching by default (too much opportunity for a slowdown). But for BLOOM inference -\n",
            "which is a very large model - dynamic batching is **essential** to provide a decent experience for everyone.\n",
            "Document 2------------------------------------------------------------\n",
            "FrameworkSwitchCourse {fw} />\n",
            "\n",
            "# Behind the pipeline[[behind-the-pipeline]]\n",
            "\n",
            "{#if fw === 'pt'}\n",
            "\n",
            "<CourseFloatingBanner chapter={2}\n",
            "  classNames=\"absolute z-10 right-0 top-0\"\n",
            "  notebooks={[\n",
            "    {label: \"Google Colab\", value: \"https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter2/section2_pt.ipynb\"},\n",
            "    {label: \"Aws Studio\", value: \"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/en/chapter2/section2_pt.ipynb\"},\n",
            "]} />\n",
            "\n",
            "{:else}\n",
            "\n",
            "<CourseFloatingBanner chapter={2}\n",
            "  classNames=\"absolute z-10 right-0 top-0\"\n",
            "  notebooks={[\n",
            "    {label: \"Google Colab\", value: \"https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter2/section2_tf.ipynb\"},\n",
            "    {label: \"Aws Studio\", value: \"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/en/chapter2/section2_tf.ipynb\"},\n",
            "]} />\n",
            "\n",
            "{/if}\n",
            "\n",
            "<Tip>\n",
            "This is the first section where the content is slightly different depending on whether you use PyTorch or TensorFlow. Toggle the switch on top of the title to select the platform you prefer!\n",
            "</Tip>\n",
            "\n",
            "{#if fw === 'pt'}\n",
            "<Youtube id=\"1pedAIvTWXk\"/>\n",
            "{:else}\n",
            "<Youtube id=\"wVN12smEvqg\"/>\n",
            "{/if}\n",
            "\n",
            "Let's start with a complete example, taking a look at what happened behind the scenes when we executed the following code in [Chapter 1](/course/chapter1):\n",
            "\n",
            "```python\n",
            "from transformers import pipeline\n",
            "\n",
            "classifier = pipeline(\"sentiment-analysis\")\n",
            "classifier(\n",
            "    [\n",
            "        \"I've been waiting for a HuggingFace course my whole life.\",\n",
            "        \"I hate this so much!\",\n",
            "    ]\n",
            ")\n",
            "```\n",
            "\n",
            "and obtained:\n",
            "\n",
            "```python out\n",
            "[{'label': 'POSITIVE', 'score': 0.9598047137260437},\n",
            " {'label': 'NEGATIVE', 'score': 0.9994558095932007}]\n",
            "```\n",
            "\n",
            "As we saw in [Chapter 1](/course/chapter1), this pipeline groups together three steps: preprocessing, passing the inputs through the model, and postprocessing:\n",
            "\n",
            "<div class=\"flex justify-center\">\n",
            "<img class=\"block dark:hidden\" src=\"https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter2/full_nlp_pipeline.svg\" alt=\"The full NLP pipeline: tokenization of text, conversion to IDs, and inference through the Transformer model and the model head.\"/>\n",
            "<img class=\"hidden dark:block\" src=\"https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter2/full_nlp_pipeline-dark.svg\" alt=\"The full NLP pipeline: tokenization of text, conversion to IDs, and inference through the Transformer model and the model head.\"/>\n",
            "</div>\n",
            "\n",
            "Let's quickly go over each of these.\n",
            "\n",
            "## Preprocessing with a tokenizer[[preprocessing-with-a-tokenizer]]\n",
            "\n",
            "Like other neural networks, Transformer models can't process raw text directly, so the first step of our pipeline is to convert the text inputs into numbers that the model can make sense of. To do this we use a *tokenizer*, which will be responsible for:\n",
            "\n",
            "- Splitting the input into words, subwords, or symbols (like punctuation) that are called *tokens*\n",
            "- Mapping each token to an integer\n",
            "- Adding additional inputs that may be useful to the model\n",
            "\n",
            "All this preprocessing needs to be done in exactly the same way as when the model was pretrained, so we first need to download that information from the [Model Hub](https://huggingface.co/models). To do this, we use the `AutoTokenizer` class and its `from_pretrained()` method. Using the checkpoint name of our model, it will automatically fetch the data associated with the model's tokenizer and cache it (so it's only downloaded the first time you run the code below).\n",
            "\n",
            "Since the default checkpoint of the `sentiment-analysis` pipeline is `distilbert-base-uncased-finetuned-sst-2-english` (you can see its model card [here](https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)), we run the following:\n",
            "\n",
            "```python\n",
            "from transformers import AutoTokenizer\n",
            "\n",
            "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
            "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
            "```\n",
            "\n",
            "Once we have the tokenizer, we can directly pass our sentences to it and we'll get back a dictionary that's ready to feed to our model! The only thing left to do is to convert the list of input IDs to tensors.\n",
            "\n",
            "You can use ğŸ¤— Transformers without having to worry about which ML framework is used as a backend; it might be PyTorch or TensorFlow, or Flax for some models. However, Transformer models only accept *tensors* as input. If this is your first time hearing about tensors, you can think of them as NumPy arrays instead. A NumPy array can be a scalar (0D), a vector (1D), a matrix (2D), or have more dimensions. It's effectively a tensor; other ML frameworks' tensors behave similarly, and are usually as simple to instantiate as NumPy arrays.\n",
            "\n",
            "To specify the type of tensors we want to get back (PyTorch, TensorFlow, or plain NumPy), we use the `return_tensors` argument:\n",
            "\n",
            "{#if fw === 'pt'}\n",
            "```python\n",
            "raw_inputs = [\n",
            "    \"I've been waiting for a HuggingFace course my whole life.\",\n",
            "    \"I hate this so much!\",\n",
            "]\n",
            "inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"pt\")\n",
            "print(inputs)\n",
            "```\n",
            "{:else}\n",
            "```python\n",
            "raw_inputs = [\n",
            "    \"I've been waiting for a HuggingFace course my whole life.\",\n",
            "    \"I hate this so much!\",\n",
            "]\n",
            "inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"tf\")\n",
            "print(inputs)\n",
            "```\n",
            "{/if}\n",
            "\n",
            "Don't worry about padding and truncation just yet; we'll explain those later. The main things to remember here are that you can pass one sentence or a list of sentences, as well as specifying the type of tensors you want to get back (if no type is passed, you will get a list of lists as a result).\n",
            "\n",
            "{#if fw === 'pt'}\n",
            "\n",
            "Here's what the results look like as PyTorch tensors:\n",
            "\n",
            "```python out\n",
            "{\n",
            "    'input_ids': tensor([\n",
            "        [  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172, 2607,  2026,  2878,  2166,  1012,   102],\n",
            "        [  101,  1045,  5223,  2023,  2061,  2172,   999,   102,     0,     0,     0,     0,     0,     0,     0,     0]\n",
            "    ]), \n",
            "    'attention_mask': tensor([\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "    ])\n",
            "}\n",
            "```\n",
            "{:else}\n",
            "\n",
            "Here's what the results look like as TensorFlow tensors:\n",
            "\n",
            "```python out\n",
            "{\n",
            "    'input_ids': <tf.Tensor: shape=(2, 16), dtype=int32, numpy=\n",
            "        array([\n",
            "            [  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,  2607,  2026,  2878,  2166,  1012,   102],\n",
            "            [  101,  1045,  5223,  2023,  2061,  2172,   999,   102,     0,     0,     0,     0,     0,     0,     0,     0]\n",
            "        ], dtype=int32)>, \n",
            "    'attention_mask': <tf.Tensor: shape=(2, 16), dtype=int32, numpy=\n",
            "        array([\n",
            "            [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "            [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "        ], dtype=int32)>\n",
            "}\n",
            "```\n",
            "{/if}\n",
            "\n",
            "The output itself is a dictionary containing two keys, `input_ids` and `attention_mask`. `input_ids` contains two rows of integers (one for each sentence) that are the unique identifiers of the tokens in each sentence. We'll explain what the `attention_mask` is later in this chapter. \n",
            "\n",
            "## Going through the model[[going-through-the-model]]\n",
            "\n",
            "{#if fw === 'pt'}\n",
            "We can download our pretrained model the same way we did with our tokenizer. ğŸ¤— Transformers provides an `AutoModel` class which also has a `from_pretrained()` method:\n",
            "\n",
            "```python\n",
            "from transformers import AutoModel\n",
            "\n",
            "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
            "model = AutoModel.from_pretrained(checkpoint)\n",
            "```\n",
            "{:else}\n",
            "We can download our pretrained model the same way we did with our tokenizer. ğŸ¤— Transformers provides an `TFAutoModel` class which also has a `from_pretrained` method:\n",
            "\n",
            "```python\n",
            "from transformers import TFAutoModel\n",
            "\n",
            "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
            "model = TFAutoModel.from_pretrained(checkpoint)\n",
            "```\n",
            "{/if}\n",
            "\n",
            "In this code snippet, we have downloaded the same checkpoint we used in our pipeline before (it should actually have been cached already) and instantiated a model with it.\n",
            "\n",
            "This architecture contains only the base Transformer module: given some inputs, it outputs what we'll call *hidden states*, also known as *features*. For each model input, we'll retrieve a high-dimensional vector representing the **contextual understanding of that input by the Transformer model**.\n",
            "\n",
            "If this doesn't make sense, don't worry about it. We'll explain it all later.\n",
            "\n",
            "While these hidden states can be useful on their own, they're usually inputs to another part of the model, known as the *head*. In [Chapter 1](/course/chapter1), the different tasks could have been performed with the same architecture, but each of these tasks will have a different head associated with it.\n",
            "\n",
            "### A high-dimensional vector?[[a-high-dimensional-vector]]\n",
            "\n",
            "The vector output by the Transformer module is usually large. It generally has three dimensions:\n",
            "\n",
            "- **Batch size**: The number of sequences processed at a time (2 in our example).\n",
            "- **Sequence length**: The length of the numerical representation of the sequence (16 in our example).\n",
            "- **Hidden size**: The vector dimension of each model input.\n",
            "\n",
            "It is said to be \"high dimensional\" because of the last value. The hidden size can be very large (768 is common for smaller models, and in larger models this can reach 3072 or more).\n",
            "\n",
            "We can see this if we feed the inputs we preprocessed to our model:\n",
            "\n",
            "{#if fw === 'pt'}\n",
            "```python\n",
            "outputs = model(**inputs)\n",
            "print(outputs.last_hidden_state.shape)\n",
            "```\n",
            "\n",
            "```python out\n",
            "torch.Size([2, 16, 768])\n",
            "```\n",
            "{:else}\n",
            "```py\n",
            "outputs = model(inputs)\n",
            "print(outputs.last_hidden_state.shape)\n",
            "```\n",
            "\n",
            "```python out\n",
            "(2, 16, 768)\n",
            "```\n",
            "{/if}\n",
            "\n",
            "Note that the outputs of ğŸ¤— Transformers models behave like `namedtuple`s or dictionaries. You can access the elements by attributes (like we did) or by key (`outputs[\"last_hidden_state\"]`), or even by index if you know exactly where the thing you are looking for is (`outputs[0]`).\n",
            "\n",
            "### Model heads: Making sense out of numbers[[model-heads-making-sense-out-of-numbers]]\n",
            "\n",
            "The model heads take the high-dimensional vector of hidden states as input and project them onto a different dimension. They are usually composed of one or a few linear layers:\n",
            "\n",
            "<div class=\"flex justify-center\">\n",
            "<img class=\"block dark:hidden\" src=\"https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter2/transformer_and_head.svg\" alt=\"A Transformer network alongside its head.\"/>\n",
            "<img class=\"hidden dark:block\" src=\"https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter2/transformer_and_head-dark.svg\" alt=\"A Transformer network alongside its head.\"/>\n",
            "</div>\n",
            "\n",
            "The output of the Transformer model is sent directly to the model head to be processed.\n",
            "\n",
            "In this diagram, the model is represented by its embeddings layer and the subsequent layers. The embeddings layer converts each input ID in the tokenized input into a vector that represents the associated token. The subsequent layers manipulate those vectors using the attention mechanism to produce the final representation of the sentences.\n",
            "\n",
            "There are many different architectures available in ğŸ¤— Transformers, with each one designed around tackling a specific task. Here is a non-exhaustive list:\n",
            "\n",
            "- `*Model` (retrieve the hidden states)\n",
            "- `*ForCausalLM`\n",
            "- `*ForMaskedLM`\n",
            "- `*ForMultipleChoice`\n",
            "- `*ForQuestionAnswering`\n",
            "- `*ForSequenceClassification`\n",
            "- `*ForTokenClassification`\n",
            "- and others ğŸ¤—\n",
            "\n",
            "{#if fw === 'pt'}\n",
            "For our example, we will need a model with a sequence classification head (to be able to classify the sentences as positive or negative). So, we won't actually use the `AutoModel` class, but `AutoModelForSequenceClassification`:\n",
            "\n",
            "```python\n",
            "from transformers import AutoModelForSequenceClassification\n",
            "\n",
            "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
            "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
            "outputs = model(**inputs)\n",
            "```\n",
            "{:else}\n",
            "For our example, we will need a model with a sequence classification head (to be able to classify the sentences as positive or negative). So, we won't actually use the `TFAutoModel` class, but `TFAutoModelForSequenceClassification`:\n",
            "\n",
            "```python\n",
            "from transformers import TFAutoModelForSequenceClassification\n",
            "\n",
            "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
            "model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
            "outputs = model(inputs)\n",
            "```\n",
            "{/if}\n",
            "\n",
            "Now if we look at the shape of our outputs, the dimensionality will be much lower: the model head takes as input the high-dimensional vectors we saw before, and outputs vectors containing two values (one per label):\n",
            "\n",
            "```python\n",
            "print(outputs.logits.shape)\n",
            "```\n",
            "\n",
            "{#if fw === 'pt'}\n",
            "```python out\n",
            "torch.Size([2, 2])\n",
            "```\n",
            "{:else}\n",
            "```python out\n",
            "(2, 2)\n",
            "```\n",
            "{/if}\n",
            "\n",
            "Since we have just two sentences and two labels, the result we get from our model is of shape 2 x 2.\n",
            "\n",
            "## Postprocessing the output[[postprocessing-the-output]]\n",
            "\n",
            "The values we get as output from our model don't necessarily make sense by themselves. Let's take a look:\n",
            "\n",
            "```python\n",
            "print(outputs.logits)\n",
            "```\n",
            "\n",
            "{#if fw === 'pt'}\n",
            "```python out\n",
            "tensor([[-1.5607,  1.6123],\n",
            "        [ 4.1692, -3.3464]], grad_fn=<AddmmBackward>)\n",
            "```\n",
            "{:else}\n",
            "```python out\n",
            "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
            "    array([[-1.5606991,  1.6122842],\n",
            "           [ 4.169231 , -3.3464472]], dtype=float32)>\n",
            "```\n",
            "{/if}\n",
            "\n",
            "Our model predicted `[-1.5607, 1.6123]` for the first sentence and `[ 4.1692, -3.3464]` for the second one. Those are not probabilities but *logits*, the raw, unnormalized scores outputted by the last layer of the model. To be converted to probabilities, they need to go through a [SoftMax](https://en.wikipedia.org/wiki/Softmax_function) layer (all ğŸ¤— Transformers models output the logits, as the loss function for training will generally fuse the last activation function, such as SoftMax, with the actual loss function, such as cross entropy):\n",
            "\n",
            "{#if fw === 'pt'}\n",
            "```py\n",
            "import torch\n",
            "\n",
            "predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
            "print(predictions)\n",
            "```\n",
            "{:else}\n",
            "```py\n",
            "import tensorflow as tf\n",
            "\n",
            "predictions = tf.math.softmax(outputs.logits, axis=-1)\n",
            "print(predictions)\n",
            "```\n",
            "{/if}\n",
            "\n",
            "{#if fw === 'pt'}\n",
            "```python out\n",
            "tensor([[4.0195e-02, 9.5980e-01],\n",
            "        [9.9946e-01, 5.4418e-04]], grad_fn=<SoftmaxBackward>)\n",
            "```\n",
            "{:else}\n",
            "```python out\n",
            "tf.Tensor(\n",
            "[[4.01951671e-02 9.59804833e-01]\n",
            " [9.9945587e-01 5.4418424e-04]], shape=(2, 2), dtype=float32)\n",
            "```\n",
            "{/if}\n",
            "\n",
            "Now we can see that the model predicted `[0.0402, 0.9598]` for the first sentence and `[0.9995,  0.0005]` for the second one. These are recognizable probability scores.\n",
            "\n",
            "To get the labels corresponding to each position, we can inspect the `id2label` attribute of the model config (more on this in the next section):\n",
            "\n",
            "```python\n",
            "model.config.id2label\n",
            "```\n",
            "\n",
            "```python out\n",
            "{0: 'NEGATIVE', 1: 'POSITIVE'}\n",
            "```\n",
            "\n",
            "Now we can conclude that the model predicted the following:\n",
            " \n",
            "- First sentence: NEGATIVE: 0.0402, POSITIVE: 0.9598\n",
            "- Second sentence: NEGATIVE: 0.9995, POSITIVE: 0.0005\n",
            "\n",
            "We have successfully reproduced the three steps of the pipeline: preprocessing with tokenizers, passing the inputs through the model, and postprocessing! Now let's take some time to dive deeper into each of those steps.\n",
            "\n",
            "<Tip>\n",
            "\n",
            "âœï¸ **Try it out!** Choose two (or more) texts of your own and run them through the `sentiment-analysis` pipeline. Then replicate the steps you saw here yourself and check that you obtain the same results!\n",
            "\n",
            "</Tip>\n",
            "Document 3------------------------------------------------------------\n",
            "Gradio Demo: ner_pipeline\n",
            "\n",
            "\n",
            "```\n",
            "!pip install -q gradio torch transformers\n",
            "```\n",
            "\n",
            "\n",
            "```\n",
            "from transformers import pipeline\n",
            "\n",
            "import gradio as gr\n",
            "\n",
            "ner_pipeline = pipeline(\"ner\")\n",
            "\n",
            "examples = [\n",
            "    \"Does Chicago have any stores and does Joe live here?\",\n",
            "]\n",
            "\n",
            "def ner(text):\n",
            "    output = ner_pipeline(text)\n",
            "    return {\"text\": text, \"entities\": output}    \n",
            "\n",
            "demo = gr.Interface(ner,\n",
            "             gr.Textbox(placeholder=\"Enter sentence here...\"), \n",
            "             gr.HighlightedText(),\n",
            "             examples=examples)\n",
            "\n",
            "if __name__ == \"__main__\":\n",
            "    demo.launch()\n",
            "\n",
            "```\n",
            "Document 4------------------------------------------------------------\n",
            "# How to release\n",
            "\n",
            "# Before the release\n",
            "\n",
            "Simple checklist on how to make releases for `tokenizers`.\n",
            "\n",
            "- Freeze `master` branch.\n",
            "- Run all tests (Check CI has properly run)\n",
            "- If any significant work, check benchmarks:\n",
            "  - `cd tokenizers && cargo bench` (needs to be run on latest release tag to measure difference if it's your first time)\n",
            "- Run all `transformers` tests. (`transformers` is a big user of `tokenizers` we need\n",
            "  to make sure we don't break it, testing is one way to make sure nothing unforeseen\n",
            "  has been done.)\n",
            "  - Run all fast tests at the VERY least (not just the tokenization tests). (`RUN_PIPELINE_TESTS=1 CUDA_VISIBLE_DEVICES=-1 pytest -sv tests/`)\n",
            "  - When all *fast*  tests work, then we can also (it's recommended) run the whole `transformers`\n",
            "  test suite. \n",
            "    - Rebase this [PR](https://github.com/huggingface/transformers/pull/16708).\n",
            "        This will create new docker images ready to run the tests suites with `tokenizers` from the main branch.\n",
            "    - Wait for actions to finish\n",
            "    - Rebase this [PR](https://github.com/huggingface/transformers/pull/16712)\n",
            "        This will run the actual full test suite.\n",
            "    - Check the results.\n",
            "- **If any breaking change has been done**, make sure the version can safely be increased for transformers users (`tokenizers` version need to make sure users don't upgrade before `transformers` has). [link](https://github.com/huggingface/transformers/blob/main/setup.py#L154)\n",
            "  For instance `tokenizers>=0.10,<0.11` so we can safely upgrade to `0.11` without impacting\n",
            "  current users\n",
            "- Then start a new PR containing all desired code changes from the following steps.\n",
            "- You will `Create release` after the code modifications are on `master`.\n",
            "\n",
            "# Rust\n",
            "\n",
            "- `tokenizers` (rust, python & node) versions don't have to be in sync but it's\n",
            "  very common to release for all versions at once for new features.\n",
            "- Edit `Cargo.toml` to reflect new version\n",
            "- Edit `CHANGELOG.md`:\n",
            "    - Add relevant PRs that were added (python PRs do not belong for instance).\n",
            "    - Add links at the end of the files.\n",
            "- Go to [Releases](https://github.com/huggingface/tokenizers/releases)\n",
            "- Create new Release:\n",
            "    - Mark it as pre-release\n",
            "    - Use new version name with a new tag (create on publish) `vX.X.X`.\n",
            "    - Copy paste the new part of the `CHANGELOG.md`\n",
            "- âš ï¸  Click on `Publish release`. This will start the whole process of building a uploading\n",
            "  the new version on `crates.io`, there's no going back after this\n",
            "- Go to the [Actions](https://github.com/huggingface/tokenizers/actions) tab and check everything works smoothly.\n",
            "- If anything fails, you need to fix the CI/CD to make it work again. Since your package was not uploaded to the repository properly, you can try again.\n",
            "\n",
            "\n",
            "# Python\n",
            "\n",
            "- Edit `bindings/python/setup.py` to reflect new version.\n",
            "- Edit `bindings/python/py_src/tokenizers/__init__.py` to reflect new version.\n",
            "- Edit `CHANGELOG.md`:\n",
            "    - Add relevant PRs that were added (node PRs do not belong for instance).\n",
            "    - Add links at the end of the files.\n",
            "- Go to [Releases](https://github.com/huggingface/tokenizers/releases)\n",
            "- Create new Release:\n",
            "    - Mark it as pre-release\n",
            "    - Use new version name with a new tag (create on publish) `python-vX.X.X`.\n",
            "    - Copy paste the new part of the `CHANGELOG.md`\n",
            "- âš ï¸  Click on `Publish release`. This will start the whole process of building a uploading\n",
            "  the new version on `pypi`, there's no going back after this\n",
            "- Go to the [Actions](https://github.com/huggingface/tokenizers/actions) tab and check everything works smoothly.\n",
            "- If anything fails, you need to fix the CI/CD to make it work again. Since your package was not uploaded to the repository properly, you can try again.\n",
            "- This CI/CD has 3 distinct builds, `Pypi`(normal), `conda` and `extra`. `Extra` is REALLY slow (~4h), this is normal since it has to rebuild many things, but enables the wheel to be available for old Linuxes\n",
            "\n",
            "# Node\n",
            "\n",
            "- Edit `bindings/node/package.json` to reflect new version.\n",
            "- Edit `CHANGELOG.md`:\n",
            "    - Add relevant PRs that were added (python PRs do not belong for instance).\n",
            "    - Add links at the end of the files.\n",
            "- Go to [Releases](https://github.com/huggingface/tokenizers/releases)\n",
            "- Create new Release:\n",
            "    - Mark it as pre-release\n",
            "    - Use new version name with a new tag (create on publish) `node-vX.X.X`.\n",
            "    - Copy paste the new part of the `CHANGELOG.md`\n",
            "- âš ï¸  Click on `Publish release`. This will start the whole process of building a uploading\n",
            "  the new version on `npm`, there's no going back after this\n",
            "- Go to the [Actions](https://github.com/huggingface/tokenizers/actions) tab and check everything works smoothly.\n",
            "- If anything fails, you need to fix the CI/CD to make it work again. Since your package was not uploaded to the repository properly, you can try again.\n",
            "\n",
            "\n",
            "# Testing the CI/CD for release\n",
            "\n",
            "\n",
            "If you want to make modifications to the CI/CD of the release GH actions, you need\n",
            "to : \n",
            "- **Comment the part that uploads the artifacts** to `crates.io`, `PyPi` or `npm`.\n",
            "- Change the trigger mecanism so it can trigger every time you push to your branch.\n",
            "- Keep pushing your changes until the artifacts are properly created.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ğ’Ñ–Ğ´Ğ¿Ğ¾Ğ²Ñ–Ğ´ÑŒ Ğ¿Ñ–ÑĞ»Ñ Ğ·Ğ¼Ñ–Ğ½Ğ¸ Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼Ñƒ Ñ–Ğ½Ğ´ĞµĞºÑĞ°Ñ†Ñ–Ñ— Ğ±Ğ°Ğ·Ğ¸ Ğ½Ğ° Annoy"
      ],
      "metadata": {
        "id": "tg8cnZ7IrrTP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"==================================Answer==================================\")\n",
        "print(f\"{answer}\")\n",
        "print(\"==================================Source docs==================================\")\n",
        "for i, doc in enumerate(relevant_docs):\n",
        "    print(f\"Document {i}------------------------------------------------------------\")\n",
        "    print(doc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGdYRgvthKCh",
        "outputId": "7798cd7a-f5c6-483a-f70b-96071b83f8c9"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================Answer==================================\n",
            "To create a pipeline, follow these steps:\n",
            "\n",
            "1. Choose a pipeline type, such as `StableDiffusionXLPipeline` or `StableDiffusionControlNetPipeline`, based on your use case.\n",
            "\n",
            "2. Pass any checkpoint to the pipeline, and it'll automatically detect the necessary components.\n",
            "\n",
            "3. Use the pipeline for inference, just like you would use a dataset.\n",
            "\n",
            "Here's an example:\n",
            "\n",
            "```py\n",
            "from diffusers import StableDiffusionXLPipeline\n",
            "\n",
            "pipe = StableDiffusionXLPipeline.from_pretrained(\"StableDiffusionXLPipeline-p1696x640-v1_2\").to(\"cpu\")\n",
            "\n",
            "image = Image.open(\"example.jpg\")\n",
            "width, height = image.size\n",
            "\n",
            "latents = pipe(image, width=width, height=height, num_inference_steps=25, guidance_scale=7.5).to(\"np\").unsqueeze(0)\n",
            "\n",
            "image = (latents * 255).round().astype(\"uint8\")\n",
            "image = Image.fromarray(image)\n",
            "image.show()\n",
            "```\n",
            "\n",
            "In this example, we're using the `StableDiffusionXLPipeline` with the `p1696x640` resolution and the `v1_2` checkpoint. We're also specifying the width and height of the input image, the number of inference steps, and the guidance scale. Finally, we're converting the output latents to an image and displaying it.\n",
            "\n",
            "Note that we're converting the output latents to an image using `Image.fromarray()` and rounding the values to integers using `.round()`. This is because the output latents are floating-point numbers between 0 and 1, and we want to display them as 8-bit RGB values between 0 and 255.\n",
            "\n",
            "Also note that we're converting the output latents to a NumPy array using `.to(\"np\")` and unsqueezing the batch dimension using `.unsqueeze(0)`. This is because the output latents are returned as a batch of size 1 by default, and we want to operate\n",
            "==================================Source docs==================================\n",
            "Document 0------------------------------------------------------------\n",
            "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n",
            "\n",
            "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with\n",
            "the License. You may obtain a copy of the License at\n",
            "\n",
            "http://www.apache.org/licenses/LICENSE-2.0\n",
            "\n",
            "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on\n",
            "an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the\n",
            "specific language governing permissions and limitations under the License.\n",
            "-->\n",
            "\n",
            "# Contribute a community pipeline\n",
            "\n",
            "<Tip>\n",
            "\n",
            "ğŸ’¡ Take a look at GitHub Issue [#841](https://github.com/huggingface/diffusers/issues/841) for more context about why we're adding community pipelines to help everyone easily share their work without being slowed down.\n",
            "\n",
            "</Tip>\n",
            "\n",
            "Community pipelines allow you to add any additional features you'd like on top of the [`DiffusionPipeline`]. The main benefit of building on top of the `DiffusionPipeline` is anyone can load and use your pipeline by only adding one more argument, making it super easy for the community to access.\n",
            "\n",
            "This guide will show you how to create a community pipeline and explain how they work. To keep things simple, you'll create a \"one-step\" pipeline where the `UNet` does a single forward pass and calls the scheduler once.\n",
            "\n",
            "## Initialize the pipeline\n",
            "\n",
            "You should start by creating a `one_step_unet.py` file for your community pipeline. In this file, create a pipeline class that inherits from the [`DiffusionPipeline`] to be able to load model weights and the scheduler configuration from the Hub. The one-step pipeline needs a `UNet` and a scheduler, so you'll need to add these as arguments to the `__init__` function:\n",
            "\n",
            "```python\n",
            "from diffusers import DiffusionPipeline\n",
            "import torch\n",
            "\n",
            "class UnetSchedulerOneForwardPipeline(DiffusionPipeline):\n",
            "    def __init__(self, unet, scheduler):\n",
            "        super().__init__()\n",
            "```\n",
            "\n",
            "To ensure your pipeline and its components (`unet` and `scheduler`) can be saved with [`~DiffusionPipeline.save_pretrained`], add them to the `register_modules` function:\n",
            "\n",
            "```diff\n",
            "  from diffusers import DiffusionPipeline\n",
            "  import torch\n",
            "\n",
            "  class UnetSchedulerOneForwardPipeline(DiffusionPipeline):\n",
            "      def __init__(self, unet, scheduler):\n",
            "          super().__init__()\n",
            "\n",
            "+         self.register_modules(unet=unet, scheduler=scheduler)\n",
            "```\n",
            "\n",
            "Cool, the `__init__` step is done and you can move to the forward pass now! ğŸ”¥\n",
            "\n",
            "## Define the forward pass\n",
            "\n",
            "In the forward pass, which we recommend defining as `__call__`, you have complete creative freedom to add whatever feature you'd like. For our amazing one-step pipeline, create a random image and only call the `unet` and `scheduler` once by setting `timestep=1`:\n",
            "\n",
            "```diff\n",
            "  from diffusers import DiffusionPipeline\n",
            "  import torch\n",
            "\n",
            "  class UnetSchedulerOneForwardPipeline(DiffusionPipeline):\n",
            "      def __init__(self, unet, scheduler):\n",
            "          super().__init__()\n",
            "\n",
            "          self.register_modules(unet=unet, scheduler=scheduler)\n",
            "\n",
            "+     def __call__(self):\n",
            "+         image = torch.randn(\n",
            "+             (1, self.unet.config.in_channels, self.unet.config.sample_size, self.unet.config.sample_size),\n",
            "+         )\n",
            "+         timestep = 1\n",
            "\n",
            "+         model_output = self.unet(image, timestep).sample\n",
            "+         scheduler_output = self.scheduler.step(model_output, timestep, image).prev_sample\n",
            "\n",
            "+         return scheduler_output\n",
            "```\n",
            "\n",
            "That's it! ğŸš€ You can now run this pipeline by passing a `unet` and `scheduler` to it:\n",
            "\n",
            "```python\n",
            "from diffusers import DDPMScheduler, UNet2DModel\n",
            "\n",
            "scheduler = DDPMScheduler()\n",
            "unet = UNet2DModel()\n",
            "\n",
            "pipeline = UnetSchedulerOneForwardPipeline(unet=unet, scheduler=scheduler)\n",
            "\n",
            "output = pipeline()\n",
            "```\n",
            "\n",
            "But what's even better is you can load pre-existing weights into the pipeline if the pipeline structure is identical. For example, you can load the [`google/ddpm-cifar10-32`](https://huggingface.co/google/ddpm-cifar10-32) weights into the one-step pipeline:\n",
            "\n",
            "```python\n",
            "pipeline = UnetSchedulerOneForwardPipeline.from_pretrained(\"google/ddpm-cifar10-32\", use_safetensors=True)\n",
            "\n",
            "output = pipeline()\n",
            "```\n",
            "\n",
            "## Share your pipeline\n",
            "\n",
            "Open a Pull Request on the ğŸ§¨ Diffusers [repository](https://github.com/huggingface/diffusers) to add your awesome pipeline in `one_step_unet.py` to the [examples/community](https://github.com/huggingface/diffusers/tree/main/examples/community) subfolder.\n",
            "\n",
            "Once it is merged, anyone with `diffusers >= 0.4.0` installed can use this pipeline magically ğŸª„ by specifying it in the `custom_pipeline` argument:\n",
            "\n",
            "```python\n",
            "from diffusers import DiffusionPipeline\n",
            "\n",
            "pipe = DiffusionPipeline.from_pretrained(\n",
            "    \"google/ddpm-cifar10-32\", custom_pipeline=\"one_step_unet\", use_safetensors=True\n",
            ")\n",
            "pipe()\n",
            "```\n",
            "\n",
            "Another way to share your community pipeline is to upload the `one_step_unet.py` file directly to your preferred [model repository](https://huggingface.co/docs/hub/models-uploading) on the Hub. Instead of specifying the `one_step_unet.py` file, pass the model repository id to the `custom_pipeline` argument:\n",
            "\n",
            "```python\n",
            "from diffusers import DiffusionPipeline\n",
            "\n",
            "pipeline = DiffusionPipeline.from_pretrained(\n",
            "    \"google/ddpm-cifar10-32\", custom_pipeline=\"stevhliu/one_step_unet\", use_safetensors=True\n",
            ")\n",
            "```\n",
            "\n",
            "Take a look at the following table to compare the two sharing workflows to help you decide the best option for you:\n",
            "\n",
            "|                | GitHub community pipeline                                                                                        | HF Hub community pipeline                                                                 |\n",
            "|----------------|------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------|\n",
            "| usage          | same                                                                                                             | same                                                                                      |\n",
            "| review process | open a Pull Request on GitHub and undergo a review process from the Diffusers team before merging; may be slower | upload directly to a Hub repository without any review; this is the fastest workflow      |\n",
            "| visibility     | included in the official Diffusers repository and documentation                                                  | included on your HF Hub profile and relies on your own usage/promotion to gain visibility |\n",
            "\n",
            "<Tip>\n",
            "\n",
            "ğŸ’¡ You can use whatever package you want in your community pipeline file - as long as the user has it installed, everything will work fine. Make sure you have one and only one pipeline class that inherits from `DiffusionPipeline` because this is automatically detected.\n",
            "\n",
            "</Tip>\n",
            "\n",
            "## How do community pipelines work?\n",
            "\n",
            "A community pipeline is a class that inherits from [`DiffusionPipeline`] which means:\n",
            "\n",
            "- It can be loaded with the [`custom_pipeline`] argument.\n",
            "- The model weights and scheduler configuration are loaded from [`pretrained_model_name_or_path`].\n",
            "- The code that implements a feature in the community pipeline is defined in a `pipeline.py` file.\n",
            "\n",
            "Sometimes you can't load all the pipeline components weights from an official repository. In this case, the other components should be passed directly to the pipeline:\n",
            "\n",
            "```python\n",
            "from diffusers import DiffusionPipeline\n",
            "from transformers import CLIPImageProcessor, CLIPModel\n",
            "\n",
            "model_id = \"CompVis/stable-diffusion-v1-4\"\n",
            "clip_model_id = \"laion/CLIP-ViT-B-32-laion2B-s34B-b79K\"\n",
            "\n",
            "feature_extractor = CLIPImageProcessor.from_pretrained(clip_model_id)\n",
            "clip_model = CLIPModel.from_pretrained(clip_model_id, torch_dtype=torch.float16)\n",
            "\n",
            "pipeline = DiffusionPipeline.from_pretrained(\n",
            "    model_id,\n",
            "    custom_pipeline=\"clip_guided_stable_diffusion\",\n",
            "    clip_model=clip_model,\n",
            "    feature_extractor=feature_extractor,\n",
            "    scheduler=scheduler,\n",
            "    torch_dtype=torch.float16,\n",
            "    use_safetensors=True,\n",
            ")\n",
            "```\n",
            "\n",
            "The magic behind community pipelines is contained in the following code. It allows the community pipeline to be loaded from GitHub or the Hub, and it'll be available to all ğŸ§¨ Diffusers packages.\n",
            "\n",
            "```python\n",
            "# 2. Load the pipeline class, if using custom module then load it from the Hub\n",
            "# if we load from explicit class, let's use it\n",
            "if custom_pipeline is not None:\n",
            "    pipeline_class = get_class_from_dynamic_module(\n",
            "        custom_pipeline, module_file=CUSTOM_PIPELINE_FILE_NAME, cache_dir=custom_pipeline\n",
            "    )\n",
            "elif cls != DiffusionPipeline:\n",
            "    pipeline_class = cls\n",
            "else:\n",
            "    diffusers_module = importlib.import_module(cls.__module__.split(\".\")[0])\n",
            "    pipeline_class = getattr(diffusers_module, config_dict[\"_class_name\"])\n",
            "```\n",
            "Document 1------------------------------------------------------------\n",
            "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n",
            "\n",
            "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with\n",
            "the License. You may obtain a copy of the License at\n",
            "\n",
            "http://www.apache.org/licenses/LICENSE-2.0\n",
            "\n",
            "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on\n",
            "an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the\n",
            "\n",
            "âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be\n",
            "rendered properly in your Markdown viewer.\n",
            "\n",
            "-->\n",
            "\n",
            "# How to create a custom pipeline?\n",
            "\n",
            "In this guide, we will see how to create a custom pipeline and share it on the [Hub](hf.co/models) or add it to the\n",
            "ğŸ¤— Transformers library.\n",
            "\n",
            "First and foremost, you need to decide the raw entries the pipeline will be able to take. It can be strings, raw bytes,\n",
            "dictionaries or whatever seems to be the most likely desired input. Try to keep these inputs as pure Python as possible\n",
            "as it makes compatibility easier (even through other languages via JSON). Those will be the `inputs` of the\n",
            "pipeline (`preprocess`).\n",
            "\n",
            "Then define the `outputs`. Same policy as the `inputs`. The simpler, the better. Those will be the outputs of\n",
            "`postprocess` method.\n",
            "\n",
            "Start by inheriting the base class `Pipeline` with the 4 methods needed to implement `preprocess`,\n",
            "`_forward`, `postprocess`, and `_sanitize_parameters`.\n",
            "\n",
            "\n",
            "```python\n",
            "from transformers import Pipeline\n",
            "\n",
            "\n",
            "class MyPipeline(Pipeline):\n",
            "    def _sanitize_parameters(self, **kwargs):\n",
            "        preprocess_kwargs = {}\n",
            "        if \"maybe_arg\" in kwargs:\n",
            "            preprocess_kwargs[\"maybe_arg\"] = kwargs[\"maybe_arg\"]\n",
            "        return preprocess_kwargs, {}, {}\n",
            "\n",
            "    def preprocess(self, inputs, maybe_arg=2):\n",
            "        model_input = Tensor(inputs[\"input_ids\"])\n",
            "        return {\"model_input\": model_input}\n",
            "\n",
            "    def _forward(self, model_inputs):\n",
            "        # model_inputs == {\"model_input\": model_input}\n",
            "        outputs = self.model(**model_inputs)\n",
            "        # Maybe {\"logits\": Tensor(...)}\n",
            "        return outputs\n",
            "\n",
            "    def postprocess(self, model_outputs):\n",
            "        best_class = model_outputs[\"logits\"].softmax(-1)\n",
            "        return best_class\n",
            "```\n",
            "\n",
            "The structure of this breakdown is to support relatively seamless support for CPU/GPU, while supporting doing\n",
            "pre/postprocessing on the CPU on different threads\n",
            "\n",
            "`preprocess` will take the originally defined inputs, and turn them into something feedable to the model. It might\n",
            "contain more information and is usually a `Dict`.\n",
            "\n",
            "`_forward` is the implementation detail and is not meant to be called directly. `forward` is the preferred\n",
            "called method as it contains safeguards to make sure everything is working on the expected device. If anything is\n",
            "linked to a real model it belongs in the `_forward` method, anything else is in the preprocess/postprocess.\n",
            "\n",
            "`postprocess` methods will take the output of `_forward` and turn it into the final output that was decided\n",
            "earlier.\n",
            "\n",
            "`_sanitize_parameters` exists to allow users to pass any parameters whenever they wish, be it at initialization\n",
            "time `pipeline(...., maybe_arg=4)` or at call time `pipe = pipeline(...); output = pipe(...., maybe_arg=4)`.\n",
            "\n",
            "The returns of `_sanitize_parameters` are the 3 dicts of kwargs that will be passed directly to `preprocess`,\n",
            "`_forward`, and `postprocess`. Don't fill anything if the caller didn't call with any extra parameter. That\n",
            "allows to keep the default arguments in the function definition which is always more \"natural\".\n",
            "\n",
            "A classic example would be a `top_k` argument in the post processing in classification tasks.\n",
            "\n",
            "```python\n",
            ">>> pipe = pipeline(\"my-new-task\")\n",
            ">>> pipe(\"This is a test\")\n",
            "[{\"label\": \"1-star\", \"score\": 0.8}, {\"label\": \"2-star\", \"score\": 0.1}, {\"label\": \"3-star\", \"score\": 0.05}\n",
            "{\"label\": \"4-star\", \"score\": 0.025}, {\"label\": \"5-star\", \"score\": 0.025}]\n",
            "\n",
            ">>> pipe(\"This is a test\", top_k=2)\n",
            "[{\"label\": \"1-star\", \"score\": 0.8}, {\"label\": \"2-star\", \"score\": 0.1}]\n",
            "```\n",
            "\n",
            "In order to achieve that, we'll update our `postprocess` method with a default parameter to `5`. and edit\n",
            "`_sanitize_parameters` to allow this new parameter.\n",
            "\n",
            "\n",
            "```python\n",
            "def postprocess(self, model_outputs, top_k=5):\n",
            "    best_class = model_outputs[\"logits\"].softmax(-1)\n",
            "    # Add logic to handle top_k\n",
            "    return best_class\n",
            "\n",
            "\n",
            "def _sanitize_parameters(self, **kwargs):\n",
            "    preprocess_kwargs = {}\n",
            "    if \"maybe_arg\" in kwargs:\n",
            "        preprocess_kwargs[\"maybe_arg\"] = kwargs[\"maybe_arg\"]\n",
            "\n",
            "    postprocess_kwargs = {}\n",
            "    if \"top_k\" in kwargs:\n",
            "        postprocess_kwargs[\"top_k\"] = kwargs[\"top_k\"]\n",
            "    return preprocess_kwargs, {}, postprocess_kwargs\n",
            "```\n",
            "\n",
            "Try to keep the inputs/outputs very simple and ideally JSON-serializable as it makes the pipeline usage very easy\n",
            "without requiring users to understand new kinds of objects. It's also relatively common to support many different types\n",
            "of arguments for ease of use (audio files, which can be filenames, URLs or pure bytes)\n",
            "\n",
            "\n",
            "\n",
            "## Adding it to the list of supported tasks\n",
            "\n",
            "To register your `new-task` to the list of supported tasks, you have to add it to the `PIPELINE_REGISTRY`:\n",
            "\n",
            "```python\n",
            "from transformers.pipelines import PIPELINE_REGISTRY\n",
            "\n",
            "PIPELINE_REGISTRY.register_pipeline(\n",
            "    \"new-task\",\n",
            "    pipeline_class=MyPipeline,\n",
            "    pt_model=AutoModelForSequenceClassification,\n",
            ")\n",
            "```\n",
            "\n",
            "You can specify a default model if you want, in which case it should come with a specific revision (which can be the name of a branch or a commit hash, here we took `\"abcdef\"`) as well as the type:\n",
            "\n",
            "```python\n",
            "PIPELINE_REGISTRY.register_pipeline(\n",
            "    \"new-task\",\n",
            "    pipeline_class=MyPipeline,\n",
            "    pt_model=AutoModelForSequenceClassification,\n",
            "    default={\"pt\": (\"user/awesome_model\", \"abcdef\")},\n",
            "    type=\"text\",  # current support type: text, audio, image, multimodal\n",
            ")\n",
            "```\n",
            "\n",
            "## Share your pipeline on the Hub\n",
            "\n",
            "To share your custom pipeline on the Hub, you just have to save the custom code of your `Pipeline` subclass in a\n",
            "python file. For instance, let's say we want to use a custom pipeline for sentence pair classification like this:\n",
            "\n",
            "```py\n",
            "import numpy as np\n",
            "\n",
            "from transformers import Pipeline\n",
            "\n",
            "\n",
            "def softmax(outputs):\n",
            "    maxes = np.max(outputs, axis=-1, keepdims=True)\n",
            "    shifted_exp = np.exp(outputs - maxes)\n",
            "    return shifted_exp / shifted_exp.sum(axis=-1, keepdims=True)\n",
            "\n",
            "\n",
            "class PairClassificationPipeline(Pipeline):\n",
            "    def _sanitize_parameters(self, **kwargs):\n",
            "        preprocess_kwargs = {}\n",
            "        if \"second_text\" in kwargs:\n",
            "            preprocess_kwargs[\"second_text\"] = kwargs[\"second_text\"]\n",
            "        return preprocess_kwargs, {}, {}\n",
            "\n",
            "    def preprocess(self, text, second_text=None):\n",
            "        return self.tokenizer(text, text_pair=second_text, return_tensors=self.framework)\n",
            "\n",
            "    def _forward(self, model_inputs):\n",
            "        return self.model(**model_inputs)\n",
            "\n",
            "    def postprocess(self, model_outputs):\n",
            "        logits = model_outputs.logits[0].numpy()\n",
            "        probabilities = softmax(logits)\n",
            "\n",
            "        best_class = np.argmax(probabilities)\n",
            "        label = self.model.config.id2label[best_class]\n",
            "        score = probabilities[best_class].item()\n",
            "        logits = logits.tolist()\n",
            "        return {\"label\": label, \"score\": score, \"logits\": logits}\n",
            "```\n",
            "\n",
            "The implementation is framework agnostic, and will work for PyTorch and TensorFlow models. If we have saved this in\n",
            "a file named `pair_classification.py`, we can then import it and register it like this:\n",
            "\n",
            "```py\n",
            "from pair_classification import PairClassificationPipeline\n",
            "from transformers.pipelines import PIPELINE_REGISTRY\n",
            "from transformers import AutoModelForSequenceClassification, TFAutoModelForSequenceClassification\n",
            "\n",
            "PIPELINE_REGISTRY.register_pipeline(\n",
            "    \"pair-classification\",\n",
            "    pipeline_class=PairClassificationPipeline,\n",
            "    pt_model=AutoModelForSequenceClassification,\n",
            "    tf_model=TFAutoModelForSequenceClassification,\n",
            ")\n",
            "```\n",
            "\n",
            "Once this is done, we can use it with a pretrained model. For instance `sgugger/finetuned-bert-mrpc` has been\n",
            "fine-tuned on the MRPC dataset, which classifies pairs of sentences as paraphrases or not.\n",
            "\n",
            "```py\n",
            "from transformers import pipeline\n",
            "\n",
            "classifier = pipeline(\"pair-classification\", model=\"sgugger/finetuned-bert-mrpc\")\n",
            "```\n",
            "\n",
            "Then we can share it on the Hub by using the `save_pretrained` method in a `Repository`:\n",
            "\n",
            "```py\n",
            "from huggingface_hub import Repository\n",
            "\n",
            "repo = Repository(\"test-dynamic-pipeline\", clone_from=\"{your_username}/test-dynamic-pipeline\")\n",
            "classifier.save_pretrained(\"test-dynamic-pipeline\")\n",
            "repo.push_to_hub()\n",
            "```\n",
            "\n",
            "This will copy the file where you defined `PairClassificationPipeline` inside the folder `\"test-dynamic-pipeline\"`,\n",
            "along with saving the model and tokenizer of the pipeline, before pushing everything into the repository\n",
            "`{your_username}/test-dynamic-pipeline`. After that, anyone can use it as long as they provide the option\n",
            "`trust_remote_code=True`:\n",
            "\n",
            "```py\n",
            "from transformers import pipeline\n",
            "\n",
            "classifier = pipeline(model=\"{your_username}/test-dynamic-pipeline\", trust_remote_code=True)\n",
            "```\n",
            "\n",
            "## Add the pipeline to ğŸ¤— Transformers\n",
            "\n",
            "If you want to contribute your pipeline to ğŸ¤— Transformers, you will need to add a new module in the `pipelines` submodule\n",
            "with the code of your pipeline, then add it to the list of tasks defined in `pipelines/__init__.py`.\n",
            "\n",
            "Then you will need to add tests. Create a new file `tests/test_pipelines_MY_PIPELINE.py` with examples of the other tests.\n",
            "\n",
            "The `run_pipeline_test` function will be very generic and run on small random models on every possible\n",
            "architecture as defined by `model_mapping` and `tf_model_mapping`.\n",
            "\n",
            "This is very important to test future compatibility, meaning if someone adds a new model for\n",
            "`XXXForQuestionAnswering` then the pipeline test will attempt to run on it. Because the models are random it's\n",
            "impossible to check for actual values, that's why there is a helper `ANY` that will simply attempt to match the\n",
            "output of the pipeline TYPE.\n",
            "\n",
            "You also *need* to implement 2 (ideally 4) tests.\n",
            "\n",
            "- `test_small_model_pt` : Define 1 small model for this pipeline (doesn't matter if the results don't make sense)\n",
            "  and test the pipeline outputs. The results should be the same as `test_small_model_tf`.\n",
            "- `test_small_model_tf` : Define 1 small model for this pipeline (doesn't matter if the results don't make sense)\n",
            "  and test the pipeline outputs. The results should be the same as `test_small_model_pt`.\n",
            "- `test_large_model_pt` (`optional`): Tests the pipeline on a real pipeline where the results are supposed to\n",
            "  make sense. These tests are slow and should be marked as such. Here the goal is to showcase the pipeline and to make\n",
            "  sure there is no drift in future releases.\n",
            "- `test_large_model_tf` (`optional`): Tests the pipeline on a real pipeline where the results are supposed to\n",
            "  make sense. These tests are slow and should be marked as such. Here the goal is to showcase the pipeline and to make\n",
            "  sure there is no drift in future releases.\n",
            "Document 2------------------------------------------------------------\n",
            "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n",
            "\n",
            "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with\n",
            "the License. You may obtain a copy of the License at\n",
            "\n",
            "http://www.apache.org/licenses/LICENSE-2.0\n",
            "\n",
            "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on\n",
            "an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the\n",
            "specific language governing permissions and limitations under the License.\n",
            "-->\n",
            "\n",
            "# Understanding pipelines, models and schedulers\n",
            "\n",
            "[[open-in-colab]]\n",
            "\n",
            "ğŸ§¨ Diffusers is designed to be a user-friendly and flexible toolbox for building diffusion systems tailored to your use-case. At the core of the toolbox are models and schedulers. While the [`DiffusionPipeline`] bundles these components together for convenience, you can also unbundle the pipeline and use the models and schedulers separately to create new diffusion systems.\n",
            "\n",
            "In this tutorial, you'll learn how to use models and schedulers to assemble a diffusion system for inference, starting with a basic pipeline and then progressing to the Stable Diffusion pipeline.\n",
            "\n",
            "## Deconstruct a basic pipeline\n",
            "\n",
            "A pipeline is a quick and easy way to run a model for inference, requiring no more than four lines of code to generate an image:\n",
            "\n",
            "```py\n",
            ">>> from diffusers import DDPMPipeline\n",
            "\n",
            ">>> ddpm = DDPMPipeline.from_pretrained(\"google/ddpm-cat-256\", use_safetensors=True).to(\"cuda\")\n",
            ">>> image = ddpm(num_inference_steps=25).images[0]\n",
            ">>> image\n",
            "```\n",
            "\n",
            "<div class=\"flex justify-center\">\n",
            "    <img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/ddpm-cat.png\" alt=\"Image of cat created from DDPMPipeline\"/>\n",
            "</div>\n",
            "\n",
            "That was super easy, but how did the pipeline do that? Let's breakdown the pipeline and take a look at what's happening under the hood.\n",
            "\n",
            "In the example above, the pipeline contains a [`UNet2DModel`] model and a [`DDPMScheduler`]. The pipeline denoises an image by taking random noise the size of the desired output and passing it through the model several times. At each timestep, the model predicts the *noise residual* and the scheduler uses it to predict a less noisy image. The pipeline repeats this process until it reaches the end of the specified number of inference steps.\n",
            "\n",
            "To recreate the pipeline with the model and scheduler separately, let's write our own denoising process.\n",
            "\n",
            "1. Load the model and scheduler:\n",
            "\n",
            "```py\n",
            ">>> from diffusers import DDPMScheduler, UNet2DModel\n",
            "\n",
            ">>> scheduler = DDPMScheduler.from_pretrained(\"google/ddpm-cat-256\")\n",
            ">>> model = UNet2DModel.from_pretrained(\"google/ddpm-cat-256\", use_safetensors=True).to(\"cuda\")\n",
            "```\n",
            "\n",
            "2. Set the number of timesteps to run the denoising process for:\n",
            "\n",
            "```py\n",
            ">>> scheduler.set_timesteps(50)\n",
            "```\n",
            "\n",
            "3. Setting the scheduler timesteps creates a tensor with evenly spaced elements in it, 50 in this example. Each element corresponds to a timestep at which the model denoises an image. When you create the denoising loop later, you'll iterate over this tensor to denoise an image:\n",
            "\n",
            "```py\n",
            ">>> scheduler.timesteps\n",
            "tensor([980, 960, 940, 920, 900, 880, 860, 840, 820, 800, 780, 760, 740, 720,\n",
            "    700, 680, 660, 640, 620, 600, 580, 560, 540, 520, 500, 480, 460, 440,\n",
            "    420, 400, 380, 360, 340, 320, 300, 280, 260, 240, 220, 200, 180, 160,\n",
            "    140, 120, 100,  80,  60,  40,  20,   0])\n",
            "```\n",
            "\n",
            "4. Create some random noise with the same shape as the desired output:\n",
            "\n",
            "```py\n",
            ">>> import torch\n",
            "\n",
            ">>> sample_size = model.config.sample_size\n",
            ">>> noise = torch.randn((1, 3, sample_size, sample_size), device=\"cuda\")\n",
            "```\n",
            "\n",
            "5. Now write a loop to iterate over the timesteps. At each timestep, the model does a [`UNet2DModel.forward`] pass and returns the noisy residual. The scheduler's [`~DDPMScheduler.step`] method takes the noisy residual, timestep, and input and it predicts the image at the previous timestep. This output becomes the next input to the model in the denoising loop, and it'll repeat until it reaches the end of the `timesteps` array.\n",
            "\n",
            "```py\n",
            ">>> input = noise\n",
            "\n",
            ">>> for t in scheduler.timesteps:\n",
            "...     with torch.no_grad():\n",
            "...         noisy_residual = model(input, t).sample\n",
            "...     previous_noisy_sample = scheduler.step(noisy_residual, t, input).prev_sample\n",
            "...     input = previous_noisy_sample\n",
            "```\n",
            "\n",
            "This is the entire denoising process, and you can use this same pattern to write any diffusion system.\n",
            "\n",
            "6. The last step is to convert the denoised output into an image:\n",
            "\n",
            "```py\n",
            ">>> from PIL import Image\n",
            ">>> import numpy as np\n",
            "\n",
            ">>> image = (input / 2 + 0.5).clamp(0, 1).squeeze()\n",
            ">>> image = (image.permute(1, 2, 0) * 255).round().to(torch.uint8).cpu().numpy()\n",
            ">>> image = Image.fromarray(image)\n",
            ">>> image\n",
            "```\n",
            "\n",
            "In the next section, you'll put your skills to the test and breakdown the more complex Stable Diffusion pipeline. The steps are more or less the same. You'll initialize the necessary components, and set the number of timesteps to create a `timestep` array. The `timestep` array is used in the denoising loop, and for each element in this array, the model predicts a less noisy image. The denoising loop iterates over the `timestep`'s, and at each timestep, it outputs a noisy residual and the scheduler uses it to predict a less noisy image at the previous timestep. This process is repeated until you reach the end of the `timestep` array.\n",
            "\n",
            "Let's try it out!\n",
            "\n",
            "## Deconstruct the Stable Diffusion pipeline\n",
            "\n",
            "Stable Diffusion is a text-to-image *latent diffusion* model. It is called a latent diffusion model because it works with a lower-dimensional representation of the image instead of the actual pixel space, which makes it more memory efficient. The encoder compresses the image into a smaller representation, and a decoder to convert the compressed representation back into an image. For text-to-image models, you'll need a tokenizer and an encoder to generate text embeddings. From the previous example, you already know you need a UNet model and a scheduler.\n",
            "\n",
            "As you can see, this is already more complex than the DDPM pipeline which only contains a UNet model. The Stable Diffusion model has three separate pretrained models.\n",
            "\n",
            "<Tip>\n",
            "\n",
            "ğŸ’¡ Read the [How does Stable Diffusion work?](https://huggingface.co/blog/stable_diffusion#how-does-stable-diffusion-work) blog for more details about how the VAE, UNet, and text encoder models work.\n",
            "\n",
            "</Tip>\n",
            "\n",
            "Now that you know what you need for the Stable Diffusion pipeline, load all these components with the [`~ModelMixin.from_pretrained`] method. You can find them in the pretrained [`runwayml/stable-diffusion-v1-5`](https://huggingface.co/runwayml/stable-diffusion-v1-5) checkpoint, and each component is stored in a separate subfolder:\n",
            "\n",
            "```py\n",
            ">>> from PIL import Image\n",
            ">>> import torch\n",
            ">>> from transformers import CLIPTextModel, CLIPTokenizer\n",
            ">>> from diffusers import AutoencoderKL, UNet2DConditionModel, PNDMScheduler\n",
            "\n",
            ">>> vae = AutoencoderKL.from_pretrained(\"CompVis/stable-diffusion-v1-4\", subfolder=\"vae\", use_safetensors=True)\n",
            ">>> tokenizer = CLIPTokenizer.from_pretrained(\"CompVis/stable-diffusion-v1-4\", subfolder=\"tokenizer\")\n",
            ">>> text_encoder = CLIPTextModel.from_pretrained(\n",
            "...     \"CompVis/stable-diffusion-v1-4\", subfolder=\"text_encoder\", use_safetensors=True\n",
            "... )\n",
            ">>> unet = UNet2DConditionModel.from_pretrained(\n",
            "...     \"CompVis/stable-diffusion-v1-4\", subfolder=\"unet\", use_safetensors=True\n",
            "... )\n",
            "```\n",
            "\n",
            "Instead of the default [`PNDMScheduler`], exchange it for the [`UniPCMultistepScheduler`] to see how easy it is to plug a different scheduler in:\n",
            "\n",
            "```py\n",
            ">>> from diffusers import UniPCMultistepScheduler\n",
            "\n",
            ">>> scheduler = UniPCMultistepScheduler.from_pretrained(\"CompVis/stable-diffusion-v1-4\", subfolder=\"scheduler\")\n",
            "```\n",
            "\n",
            "To speed up inference, move the models to a GPU since, unlike the scheduler, they have trainable weights:\n",
            "\n",
            "```py\n",
            ">>> torch_device = \"cuda\"\n",
            ">>> vae.to(torch_device)\n",
            ">>> text_encoder.to(torch_device)\n",
            ">>> unet.to(torch_device)\n",
            "```\n",
            "\n",
            "### Create text embeddings\n",
            "\n",
            "The next step is to tokenize the text to generate embeddings. The text is used to condition the UNet model and steer the diffusion process towards something that resembles the input prompt.\n",
            "\n",
            "<Tip>\n",
            "\n",
            "ğŸ’¡ The `guidance_scale` parameter determines how much weight should be given to the prompt when generating an image.\n",
            "\n",
            "</Tip>\n",
            "\n",
            "Feel free to choose any prompt you like if you want to generate something else!\n",
            "\n",
            "```py\n",
            ">>> prompt = [\"a photograph of an astronaut riding a horse\"]\n",
            ">>> height = 512  # default height of Stable Diffusion\n",
            ">>> width = 512  # default width of Stable Diffusion\n",
            ">>> num_inference_steps = 25  # Number of denoising steps\n",
            ">>> guidance_scale = 7.5  # Scale for classifier-free guidance\n",
            ">>> generator = torch.manual_seed(0)  # Seed generator to create the initial latent noise\n",
            ">>> batch_size = len(prompt)\n",
            "```\n",
            "\n",
            "Tokenize the text and generate the embeddings from the prompt:\n",
            "\n",
            "```py\n",
            ">>> text_input = tokenizer(\n",
            "...     prompt, padding=\"max_length\", max_length=tokenizer.model_max_length, truncation=True, return_tensors=\"pt\"\n",
            "... )\n",
            "\n",
            ">>> with torch.no_grad():\n",
            "...     text_embeddings = text_encoder(text_input.input_ids.to(torch_device))[0]\n",
            "```\n",
            "\n",
            "You'll also need to generate the *unconditional text embeddings* which are the embeddings for the padding token. These need to have the same shape (`batch_size` and `seq_length`) as the conditional `text_embeddings`:\n",
            "\n",
            "```py\n",
            ">>> max_length = text_input.input_ids.shape[-1]\n",
            ">>> uncond_input = tokenizer([\"\"] * batch_size, padding=\"max_length\", max_length=max_length, return_tensors=\"pt\")\n",
            ">>> uncond_embeddings = text_encoder(uncond_input.input_ids.to(torch_device))[0]\n",
            "```\n",
            "\n",
            "Let's concatenate the conditional and unconditional embeddings into a batch to avoid doing two forward passes:\n",
            "\n",
            "```py\n",
            ">>> text_embeddings = torch.cat([uncond_embeddings, text_embeddings])\n",
            "```\n",
            "\n",
            "### Create random noise\n",
            "\n",
            "Next, generate some initial random noise as a starting point for the diffusion process. This is the latent representation of the image, and it'll be gradually denoised. At this point, the `latent` image is smaller than the final image size but that's okay though because the model will transform it into the final 512x512 image dimensions later.\n",
            "\n",
            "<Tip>\n",
            "\n",
            "ğŸ’¡ The height and width are divided by 8 because the `vae` model has 3 down-sampling layers. You can check by running the following:\n",
            "\n",
            "```py\n",
            "2 ** (len(vae.config.block_out_channels) - 1) == 8\n",
            "```\n",
            "\n",
            "</Tip>\n",
            "\n",
            "```py\n",
            ">>> latents = torch.randn(\n",
            "...     (batch_size, unet.config.in_channels, height // 8, width // 8),\n",
            "...     generator=generator,\n",
            "...     device=torch_device,\n",
            "... )\n",
            "```\n",
            "\n",
            "### Denoise the image\n",
            "\n",
            "Start by scaling the input with the initial noise distribution, *sigma*, the noise scale value, which is required for improved schedulers like [`UniPCMultistepScheduler`]:\n",
            "\n",
            "```py\n",
            ">>> latents = latents * scheduler.init_noise_sigma\n",
            "```\n",
            "\n",
            "The last step is to create the denoising loop that'll progressively transform the pure noise in `latents` to an image described by your prompt. Remember, the denoising loop needs to do three things:\n",
            "\n",
            "1. Set the scheduler's timesteps to use during denoising.\n",
            "2. Iterate over the timesteps.\n",
            "3. At each timestep, call the UNet model to predict the noise residual and pass it to the scheduler to compute the previous noisy sample.\n",
            "\n",
            "```py\n",
            ">>> from tqdm.auto import tqdm\n",
            "\n",
            ">>> scheduler.set_timesteps(num_inference_steps)\n",
            "\n",
            ">>> for t in tqdm(scheduler.timesteps):\n",
            "...     # expand the latents if we are doing classifier-free guidance to avoid doing two forward passes.\n",
            "...     latent_model_input = torch.cat([latents] * 2)\n",
            "\n",
            "...     latent_model_input = scheduler.scale_model_input(latent_model_input, timestep=t)\n",
            "\n",
            "...     # predict the noise residual\n",
            "...     with torch.no_grad():\n",
            "...         noise_pred = unet(latent_model_input, t, encoder_hidden_states=text_embeddings).sample\n",
            "\n",
            "...     # perform guidance\n",
            "...     noise_pred_uncond, noise_pred_text = noise_pred.chunk(2)\n",
            "...     noise_pred = noise_pred_uncond + guidance_scale * (noise_pred_text - noise_pred_uncond)\n",
            "\n",
            "...     # compute the previous noisy sample x_t -> x_t-1\n",
            "...     latents = scheduler.step(noise_pred, t, latents).prev_sample\n",
            "```\n",
            "\n",
            "### Decode the image\n",
            "\n",
            "The final step is to use the `vae` to decode the latent representation into an image and get the decoded output with `sample`:\n",
            "\n",
            "```py\n",
            "# scale and decode the image latents with vae\n",
            "latents = 1 / 0.18215 * latents\n",
            "with torch.no_grad():\n",
            "    image = vae.decode(latents).sample\n",
            "```\n",
            "\n",
            "Lastly, convert the image to a `PIL.Image` to see your generated image!\n",
            "\n",
            "```py\n",
            ">>> image = (image / 2 + 0.5).clamp(0, 1).squeeze()\n",
            ">>> image = (image.permute(1, 2, 0) * 255).to(torch.uint8).cpu().numpy()\n",
            ">>> images = (image * 255).round().astype(\"uint8\")\n",
            ">>> image = Image.fromarray(image)\n",
            ">>> image\n",
            "```\n",
            "\n",
            "<div class=\"flex justify-center\">\n",
            "    <img src=\"https://huggingface.co/blog/assets/98_stable_diffusion/stable_diffusion_k_lms.png\"/>\n",
            "</div>\n",
            "\n",
            "## Next steps\n",
            "\n",
            "From basic to complex pipelines, you've seen that all you really need to write your own diffusion system is a denoising loop. The loop should set the scheduler's timesteps, iterate over them, and alternate between calling the UNet model to predict the noise residual and passing it to the scheduler to compute the previous noisy sample.\n",
            "\n",
            "This is really what ğŸ§¨ Diffusers is designed for: to make it intuitive and easy to write your own diffusion system using models and schedulers.\n",
            "\n",
            "For your next steps, feel free to:\n",
            "\n",
            "* Learn how to [build and contribute a pipeline](../using-diffusers/contribute_pipeline) to ğŸ§¨ Diffusers. We can't wait and see what you'll come up with!\n",
            "* Explore [existing pipelines](../api/pipelines/overview) in the library, and see if you can deconstruct and build a pipeline from scratch using the models and schedulers separately.\n",
            "Document 3------------------------------------------------------------\n",
            "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n",
            "\n",
            "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with\n",
            "the License. You may obtain a copy of the License at\n",
            "\n",
            "http://www.apache.org/licenses/LICENSE-2.0\n",
            "\n",
            "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on\n",
            "an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the\n",
            "specific language governing permissions and limitations under the License.\n",
            "-->\n",
            "\n",
            "# Overview\n",
            "\n",
            "A pipeline is an end-to-end class that provides a quick and easy way to use a diffusion system for inference by bundling independently trained models and schedulers together. Certain combinations of models and schedulers define specific pipeline types, like [`StableDiffusionXLPipeline`] or [`StableDiffusionControlNetPipeline`], with specific capabilities. All pipeline types inherit from the base [`DiffusionPipeline`] class; pass it any checkpoint, and it'll automatically detect the pipeline type and load the necessary components.\n",
            "\n",
            "This section demonstrates how to use specific pipelines such as Stable Diffusion XL, ControlNet, and DiffEdit. You'll also learn how to use a distilled version of the Stable Diffusion model to speed up inference, how to create reproducible pipelines, and how to use and contribute community pipelines.\n",
            "Document 4------------------------------------------------------------\n",
            "!--âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be\n",
            "rendered properly in your Markdown viewer.\n",
            "-->\n",
            "\n",
            "# Using pipelines for a webserver\n",
            "\n",
            "<Tip>\n",
            "Creating an inference engine is a complex topic, and the \"best\" solution \n",
            "will most likely depend on your problem space. Are you on CPU or GPU? Do\n",
            "you want the lowest latency, the highest throughput, support for\n",
            "many models, or just highly optimize 1 specific model?\n",
            "There are many ways to tackle this topic, so what we are going to present is a good default\n",
            "to get started which may not necessarily be the most optimal solution for you.\n",
            "</Tip>\n",
            "\n",
            "\n",
            "The key thing to understand is that we can use an iterator, just like you would [on a\n",
            "dataset](pipeline_tutorial#using-pipelines-on-a-dataset), since a webserver is basically a system that waits for requests and\n",
            "treats them as they come in.\n",
            "\n",
            "Usually webservers are multiplexed (multithreaded, async, etc..) to handle various\n",
            "requests concurrently. Pipelines on the other hand (and mostly the underlying models)\n",
            "are not really great for parallelism; they take up a lot of RAM, so it's best to give them all the available resources when they are running or it's a compute-intensive job.\n",
            "\n",
            "We are going to solve that by having the webserver handle the light load of receiving\n",
            "and sending requests, and having a single thread handling the actual work.\n",
            "This example is going to use `starlette`. The actual framework is not really\n",
            "important, but you might have to tune or change the code if you are using another\n",
            "one to achieve the same effect.\n",
            "\n",
            "Create `server.py`:\n",
            "\n",
            "```py\n",
            "from starlette.applications import Starlette\n",
            "from starlette.responses import JSONResponse\n",
            "from starlette.routing import Route\n",
            "from transformers import pipeline\n",
            "import asyncio\n",
            "\n",
            "\n",
            "async def homepage(request):\n",
            "    payload = await request.body()\n",
            "    string = payload.decode(\"utf-8\")\n",
            "    response_q = asyncio.Queue()\n",
            "    await request.app.model_queue.put((string, response_q))\n",
            "    output = await response_q.get()\n",
            "    return JSONResponse(output)\n",
            "\n",
            "\n",
            "async def server_loop(q):\n",
            "    pipe = pipeline(model=\"bert-base-uncased\")\n",
            "    while True:\n",
            "        (string, response_q) = await q.get()\n",
            "        out = pipe(string)\n",
            "        await response_q.put(out)\n",
            "\n",
            "\n",
            "app = Starlette(\n",
            "    routes=[\n",
            "        Route(\"/\", homepage, methods=[\"POST\"]),\n",
            "    ],\n",
            ")\n",
            "\n",
            "\n",
            "@app.on_event(\"startup\")\n",
            "async def startup_event():\n",
            "    q = asyncio.Queue()\n",
            "    app.model_queue = q\n",
            "    asyncio.create_task(server_loop(q))\n",
            "```\n",
            "\n",
            "Now you can start it with:\n",
            "```bash\n",
            "uvicorn server:app\n",
            "```\n",
            "\n",
            "And you can query it:\n",
            "```bash\n",
            "curl -X POST -d \"test [MASK]\" http://localhost:8000/\n",
            "#[{\"score\":0.7742936015129089,\"token\":1012,\"token_str\":\".\",\"sequence\":\"test.\"},...]\n",
            "```\n",
            "\n",
            "And there you go, now you have a good idea of how to create a webserver!\n",
            "\n",
            "What is really important is that we load the model only **once**, so there are no copies\n",
            "of the model on the webserver. This way, no unnecessary RAM is being used.\n",
            "Then the queuing mechanism allows you to do fancy stuff like maybe accumulating a few\n",
            "items before inferring to use dynamic batching:\n",
            "\n",
            "<Tip warning={true}>\n",
            "\n",
            "The code sample below is intentionally written like pseudo-code for readability.\n",
            "Do not run this without checking if it makes sense for your system resources!\n",
            "\n",
            "</Tip>\n",
            "\n",
            "```py\n",
            "(string, rq) = await q.get()\n",
            "strings = []\n",
            "queues = []\n",
            "while True:\n",
            "    try:\n",
            "        (string, rq) = await asyncio.wait_for(q.get(), timeout=0.001)  # 1ms\n",
            "    except asyncio.exceptions.TimeoutError:\n",
            "        break\n",
            "    strings.append(string)\n",
            "    queues.append(rq)\n",
            "strings\n",
            "outs = pipe(strings, batch_size=len(strings))\n",
            "for rq, out in zip(queues, outs):\n",
            "    await rq.put(out)\n",
            "```\n",
            "\n",
            "Again, the proposed code is optimized for readability, not for being the best code.\n",
            "First of all, there's no batch size limit which is usually not a \n",
            "great idea. Next, the timeout is reset on every queue fetch, meaning you could\n",
            "wait much more than 1ms before running the inference (delaying the first request \n",
            "by that much). \n",
            "\n",
            "It would be better to have a single 1ms deadline.\n",
            "\n",
            "This will always wait for 1ms even if the queue is empty, which might not be the\n",
            "best since you probably want to start doing inference if there's nothing in the queue.\n",
            "But maybe it does make sense if batching is really crucial for your use case.\n",
            "Again, there's really no one best solution.\n",
            "\n",
            "\n",
            "## Few things you might want to consider\n",
            "\n",
            "### Error checking\n",
            "\n",
            "There's a lot that can go wrong in production: out of memory, out of space,\n",
            "loading the model might fail, the query might be wrong, the query might be\n",
            "correct but still fail to run because of a model misconfiguration, and so on.\n",
            "\n",
            "Generally, it's good if the server outputs the errors to the user, so\n",
            "adding a lot of `try..except` statements to show those errors is a good\n",
            "idea. But keep in mind it may also be a security risk to reveal all those errors depending \n",
            "on your security context.\n",
            "\n",
            "### Circuit breaking\n",
            "\n",
            "Webservers usually look better when they do circuit breaking. It means they \n",
            "return proper errors when they're overloaded instead of just waiting for the query indefinitely. Return a 503 error instead of waiting for a super long time or a 504 after a long time.\n",
            "\n",
            "This is relatively easy to implement in the proposed code since there is a single queue.\n",
            "Looking at the queue size is a basic way to start returning errors before your \n",
            "webserver fails under load.\n",
            "\n",
            "### Blocking the main thread\n",
            "\n",
            "Currently PyTorch is not async aware, and computation will block the main\n",
            "thread while running. That means it would be better if PyTorch was forced to run\n",
            "on its own thread/process. This wasn't done here because the code is a lot more\n",
            "complex (mostly because threads and async and queues don't play nice together).\n",
            "But ultimately it does the same thing.\n",
            "\n",
            "This would be important if the inference of single items were long (> 1s) because \n",
            "in this case, it means every query during inference would have to wait for 1s before\n",
            "even receiving an error.\n",
            "\n",
            "### Dynamic batching\n",
            "\n",
            "In general, batching is not necessarily an improvement over passing 1 item at \n",
            "a time (see [batching details](./main_classes/pipelines#pipeline-batching) for more information). But it can be very effective\n",
            "when used in the correct setting. In the API, there is no dynamic\n",
            "batching by default (too much opportunity for a slowdown). But for BLOOM inference -\n",
            "which is a very large model - dynamic batching is **essential** to provide a decent experience for everyone.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"==================================Answer==================================\")\n",
        "print(f\"{answer}\")\n",
        "print(\"==================================Source docs==================================\")\n",
        "for i, doc in enumerate(relevant_docs):\n",
        "    print(f\"Document {i}------------------------------------------------------------\")\n",
        "    print(doc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrvC16VSd_T6",
        "outputId": "cb7ba980-51c7-4eff-cb7a-c40977620ca1"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================Answer==================================\n",
            "To create a pipeline object for named entity recognition (NER) using Hugging Face's Transformers library, follow these steps:\n",
            "\n",
            "1. Install the required dependencies:\n",
            "\n",
            "   ```\n",
            "  !pip install -q gradio torch transformers\n",
            "   ```\n",
            "\n",
            "2. Import the necessary modules:\n",
            "\n",
            "   ```python\n",
            "   from transformers import pipeline\n",
            "   ```\n",
            "\n",
            "3. Create a pipeline object for NER:\n",
            "\n",
            "   ```python\n",
            "   ner_pipeline = pipeline(\"ner\")\n",
            "   ```\n",
            "\n",
            "4. Define a helper function to wrap the pipeline object and display the results:\n",
            "\n",
            "   ```python\n",
            "   def ner(text):\n",
            "       output = ner_pipeline(text)\n",
            "       return {\"text\": text, \"entities\": output}\n",
            "   ```\n",
            "\n",
            "5. Create a Gradio interface to demonstrate the pipeline:\n",
            "\n",
            "   ```python\n",
            "   demo = gr.Interface(ner,\n",
            "                   gr.Textbox(placeholder=\"Enter sentence here...\"),\n",
            "                   gr.HighlightedText(),\n",
            "                   examples=[\"Does Chicago have any stores and does Joe live here?\"])\n",
            "   ```\n",
            "\n",
            "6. Launch the Gradio interface:\n",
            "\n",
            "   ```python\n",
            "   if __name__ == \"__main__\":\n",
            "       demo.launch()\n",
            "   ```\n",
            "\n",
            "This will launch a Gradio interface that demonstrates the NER pipeline. You can enter a sentence into the text box, and the pipeline will extract any named entities from it. The results will be displayed in a highlighted text format.\n",
            "\n",
            "Remember to replace `ner` with the name of the pipeline object you created for your specific use case. Also, replace `examples` with a list of sentences you want to test the pipeline with.\n",
            "\n",
            "Hope this helps you get started with creating a pipeline object for NER using Hugging Face's Transformers library! Let me know if you have any further questions.\n",
            "==================================Source docs==================================\n",
            "Document 0------------------------------------------------------------\n",
            "!--âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be\n",
            "rendered properly in your Markdown viewer.\n",
            "-->\n",
            "\n",
            "# Using pipelines for a webserver\n",
            "\n",
            "<Tip>\n",
            "Creating an inference engine is a complex topic, and the \"best\" solution \n",
            "will most likely depend on your problem space. Are you on CPU or GPU? Do\n",
            "you want the lowest latency, the highest throughput, support for\n",
            "many models, or just highly optimize 1 specific model?\n",
            "There are many ways to tackle this topic, so what we are going to present is a good default\n",
            "to get started which may not necessarily be the most optimal solution for you.\n",
            "</Tip>\n",
            "\n",
            "\n",
            "The key thing to understand is that we can use an iterator, just like you would [on a\n",
            "dataset](pipeline_tutorial#using-pipelines-on-a-dataset), since a webserver is basically a system that waits for requests and\n",
            "treats them as they come in.\n",
            "\n",
            "Usually webservers are multiplexed (multithreaded, async, etc..) to handle various\n",
            "requests concurrently. Pipelines on the other hand (and mostly the underlying models)\n",
            "are not really great for parallelism; they take up a lot of RAM, so it's best to give them all the available resources when they are running or it's a compute-intensive job.\n",
            "\n",
            "We are going to solve that by having the webserver handle the light load of receiving\n",
            "and sending requests, and having a single thread handling the actual work.\n",
            "This example is going to use `starlette`. The actual framework is not really\n",
            "important, but you might have to tune or change the code if you are using another\n",
            "one to achieve the same effect.\n",
            "\n",
            "Create `server.py`:\n",
            "\n",
            "```py\n",
            "from starlette.applications import Starlette\n",
            "from starlette.responses import JSONResponse\n",
            "from starlette.routing import Route\n",
            "from transformers import pipeline\n",
            "import asyncio\n",
            "\n",
            "\n",
            "async def homepage(request):\n",
            "    payload = await request.body()\n",
            "    string = payload.decode(\"utf-8\")\n",
            "    response_q = asyncio.Queue()\n",
            "    await request.app.model_queue.put((string, response_q))\n",
            "    output = await response_q.get()\n",
            "    return JSONResponse(output)\n",
            "\n",
            "\n",
            "async def server_loop(q):\n",
            "    pipe = pipeline(model=\"bert-base-uncased\")\n",
            "    while True:\n",
            "        (string, response_q) = await q.get()\n",
            "        out = pipe(string)\n",
            "        await response_q.put(out)\n",
            "\n",
            "\n",
            "app = Starlette(\n",
            "    routes=[\n",
            "        Route(\"/\", homepage, methods=[\"POST\"]),\n",
            "    ],\n",
            ")\n",
            "\n",
            "\n",
            "@app.on_event(\"startup\")\n",
            "async def startup_event():\n",
            "    q = asyncio.Queue()\n",
            "    app.model_queue = q\n",
            "    asyncio.create_task(server_loop(q))\n",
            "```\n",
            "\n",
            "Now you can start it with:\n",
            "```bash\n",
            "uvicorn server:app\n",
            "```\n",
            "\n",
            "And you can query it:\n",
            "```bash\n",
            "curl -X POST -d \"test [MASK]\" http://localhost:8000/\n",
            "#[{\"score\":0.7742936015129089,\"token\":1012,\"token_str\":\".\",\"sequence\":\"test.\"},...]\n",
            "```\n",
            "\n",
            "And there you go, now you have a good idea of how to create a webserver!\n",
            "\n",
            "What is really important is that we load the model only **once**, so there are no copies\n",
            "of the model on the webserver. This way, no unnecessary RAM is being used.\n",
            "Then the queuing mechanism allows you to do fancy stuff like maybe accumulating a few\n",
            "items before inferring to use dynamic batching:\n",
            "\n",
            "<Tip warning={true}>\n",
            "\n",
            "The code sample below is intentionally written like pseudo-code for readability.\n",
            "Do not run this without checking if it makes sense for your system resources!\n",
            "\n",
            "</Tip>\n",
            "\n",
            "```py\n",
            "(string, rq) = await q.get()\n",
            "strings = []\n",
            "queues = []\n",
            "while True:\n",
            "    try:\n",
            "        (string, rq) = await asyncio.wait_for(q.get(), timeout=0.001)  # 1ms\n",
            "    except asyncio.exceptions.TimeoutError:\n",
            "        break\n",
            "    strings.append(string)\n",
            "    queues.append(rq)\n",
            "strings\n",
            "outs = pipe(strings, batch_size=len(strings))\n",
            "for rq, out in zip(queues, outs):\n",
            "    await rq.put(out)\n",
            "```\n",
            "\n",
            "Again, the proposed code is optimized for readability, not for being the best code.\n",
            "First of all, there's no batch size limit which is usually not a \n",
            "great idea. Next, the timeout is reset on every queue fetch, meaning you could\n",
            "wait much more than 1ms before running the inference (delaying the first request \n",
            "by that much). \n",
            "\n",
            "It would be better to have a single 1ms deadline.\n",
            "\n",
            "This will always wait for 1ms even if the queue is empty, which might not be the\n",
            "best since you probably want to start doing inference if there's nothing in the queue.\n",
            "But maybe it does make sense if batching is really crucial for your use case.\n",
            "Again, there's really no one best solution.\n",
            "\n",
            "\n",
            "## Few things you might want to consider\n",
            "\n",
            "### Error checking\n",
            "\n",
            "There's a lot that can go wrong in production: out of memory, out of space,\n",
            "loading the model might fail, the query might be wrong, the query might be\n",
            "correct but still fail to run because of a model misconfiguration, and so on.\n",
            "\n",
            "Generally, it's good if the server outputs the errors to the user, so\n",
            "adding a lot of `try..except` statements to show those errors is a good\n",
            "idea. But keep in mind it may also be a security risk to reveal all those errors depending \n",
            "on your security context.\n",
            "\n",
            "### Circuit breaking\n",
            "\n",
            "Webservers usually look better when they do circuit breaking. It means they \n",
            "return proper errors when they're overloaded instead of just waiting for the query indefinitely. Return a 503 error instead of waiting for a super long time or a 504 after a long time.\n",
            "\n",
            "This is relatively easy to implement in the proposed code since there is a single queue.\n",
            "Looking at the queue size is a basic way to start returning errors before your \n",
            "webserver fails under load.\n",
            "\n",
            "### Blocking the main thread\n",
            "\n",
            "Currently PyTorch is not async aware, and computation will block the main\n",
            "thread while running. That means it would be better if PyTorch was forced to run\n",
            "on its own thread/process. This wasn't done here because the code is a lot more\n",
            "complex (mostly because threads and async and queues don't play nice together).\n",
            "But ultimately it does the same thing.\n",
            "\n",
            "This would be important if the inference of single items were long (> 1s) because \n",
            "in this case, it means every query during inference would have to wait for 1s before\n",
            "even receiving an error.\n",
            "\n",
            "### Dynamic batching\n",
            "\n",
            "In general, batching is not necessarily an improvement over passing 1 item at \n",
            "a time (see [batching details](./main_classes/pipelines#pipeline-batching) for more information). But it can be very effective\n",
            "when used in the correct setting. In the API, there is no dynamic\n",
            "batching by default (too much opportunity for a slowdown). But for BLOOM inference -\n",
            "which is a very large model - dynamic batching is **essential** to provide a decent experience for everyone.\n",
            "Document 1------------------------------------------------------------\n",
            "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n",
            "\n",
            "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with\n",
            "the License. You may obtain a copy of the License at\n",
            "\n",
            "http://www.apache.org/licenses/LICENSE-2.0\n",
            "\n",
            "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on\n",
            "an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the\n",
            "specific language governing permissions and limitations under the License.\n",
            "-->\n",
            "\n",
            "# Outputs\n",
            "\n",
            "All model outputs are subclasses of [`~utils.BaseOutput`], data structures containing all the information returned by the model. The outputs can also be used as tuples or dictionaries.\n",
            "\n",
            "For example:\n",
            "\n",
            "```python\n",
            "from diffusers import DDIMPipeline\n",
            "\n",
            "pipeline = DDIMPipeline.from_pretrained(\"google/ddpm-cifar10-32\")\n",
            "outputs = pipeline()\n",
            "```\n",
            "\n",
            "The `outputs` object is a [`~pipelines.ImagePipelineOutput`] which means it has an image attribute.\n",
            "\n",
            "You can access each attribute as you normally would or with a keyword lookup, and if that attribute is not returned by the model, you will get `None`:\n",
            "\n",
            "```python\n",
            "outputs.images\n",
            "outputs[\"images\"]\n",
            "```\n",
            "\n",
            "When considering the `outputs` object as a tuple, it only considers the attributes that don't have `None` values.\n",
            "For instance, retrieving an image by indexing into it returns the tuple `(outputs.images)`:\n",
            "\n",
            "```python\n",
            "outputs[:1]\n",
            "```\n",
            "\n",
            "<Tip>\n",
            "\n",
            "To check a specific pipeline or model output, refer to its corresponding API documentation.\n",
            "\n",
            "</Tip>\n",
            "\n",
            "## BaseOutput\n",
            "\n",
            "[[autodoc]] utils.BaseOutput\n",
            "    - to_tuple\n",
            "\n",
            "## ImagePipelineOutput\n",
            "\n",
            "[[autodoc]] pipelines.ImagePipelineOutput\n",
            "\n",
            "## FlaxImagePipelineOutput\n",
            "\n",
            "[[autodoc]] pipelines.pipeline_flax_utils.FlaxImagePipelineOutput\n",
            "\n",
            "## AudioPipelineOutput\n",
            "\n",
            "[[autodoc]] pipelines.AudioPipelineOutput\n",
            "\n",
            "## ImageTextPipelineOutput\n",
            "\n",
            "[[autodoc]] ImageTextPipelineOutput\n",
            "Document 2------------------------------------------------------------\n",
            "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n",
            "\n",
            "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with\n",
            "the License. You may obtain a copy of the License at\n",
            "\n",
            "http://www.apache.org/licenses/LICENSE-2.0\n",
            "\n",
            "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on\n",
            "an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the\n",
            "specific language governing permissions and limitations under the License.\n",
            "-->\n",
            "\n",
            "# Contribute a community pipeline\n",
            "\n",
            "<Tip>\n",
            "\n",
            "ğŸ’¡ Take a look at GitHub Issue [#841](https://github.com/huggingface/diffusers/issues/841) for more context about why we're adding community pipelines to help everyone easily share their work without being slowed down.\n",
            "\n",
            "</Tip>\n",
            "\n",
            "Community pipelines allow you to add any additional features you'd like on top of the [`DiffusionPipeline`]. The main benefit of building on top of the `DiffusionPipeline` is anyone can load and use your pipeline by only adding one more argument, making it super easy for the community to access.\n",
            "\n",
            "This guide will show you how to create a community pipeline and explain how they work. To keep things simple, you'll create a \"one-step\" pipeline where the `UNet` does a single forward pass and calls the scheduler once.\n",
            "\n",
            "## Initialize the pipeline\n",
            "\n",
            "You should start by creating a `one_step_unet.py` file for your community pipeline. In this file, create a pipeline class that inherits from the [`DiffusionPipeline`] to be able to load model weights and the scheduler configuration from the Hub. The one-step pipeline needs a `UNet` and a scheduler, so you'll need to add these as arguments to the `__init__` function:\n",
            "\n",
            "```python\n",
            "from diffusers import DiffusionPipeline\n",
            "import torch\n",
            "\n",
            "class UnetSchedulerOneForwardPipeline(DiffusionPipeline):\n",
            "    def __init__(self, unet, scheduler):\n",
            "        super().__init__()\n",
            "```\n",
            "\n",
            "To ensure your pipeline and its components (`unet` and `scheduler`) can be saved with [`~DiffusionPipeline.save_pretrained`], add them to the `register_modules` function:\n",
            "\n",
            "```diff\n",
            "  from diffusers import DiffusionPipeline\n",
            "  import torch\n",
            "\n",
            "  class UnetSchedulerOneForwardPipeline(DiffusionPipeline):\n",
            "      def __init__(self, unet, scheduler):\n",
            "          super().__init__()\n",
            "\n",
            "+         self.register_modules(unet=unet, scheduler=scheduler)\n",
            "```\n",
            "\n",
            "Cool, the `__init__` step is done and you can move to the forward pass now! ğŸ”¥\n",
            "\n",
            "## Define the forward pass\n",
            "\n",
            "In the forward pass, which we recommend defining as `__call__`, you have complete creative freedom to add whatever feature you'd like. For our amazing one-step pipeline, create a random image and only call the `unet` and `scheduler` once by setting `timestep=1`:\n",
            "\n",
            "```diff\n",
            "  from diffusers import DiffusionPipeline\n",
            "  import torch\n",
            "\n",
            "  class UnetSchedulerOneForwardPipeline(DiffusionPipeline):\n",
            "      def __init__(self, unet, scheduler):\n",
            "          super().__init__()\n",
            "\n",
            "          self.register_modules(unet=unet, scheduler=scheduler)\n",
            "\n",
            "+     def __call__(self):\n",
            "+         image = torch.randn(\n",
            "+             (1, self.unet.config.in_channels, self.unet.config.sample_size, self.unet.config.sample_size),\n",
            "+         )\n",
            "+         timestep = 1\n",
            "\n",
            "+         model_output = self.unet(image, timestep).sample\n",
            "+         scheduler_output = self.scheduler.step(model_output, timestep, image).prev_sample\n",
            "\n",
            "+         return scheduler_output\n",
            "```\n",
            "\n",
            "That's it! ğŸš€ You can now run this pipeline by passing a `unet` and `scheduler` to it:\n",
            "\n",
            "```python\n",
            "from diffusers import DDPMScheduler, UNet2DModel\n",
            "\n",
            "scheduler = DDPMScheduler()\n",
            "unet = UNet2DModel()\n",
            "\n",
            "pipeline = UnetSchedulerOneForwardPipeline(unet=unet, scheduler=scheduler)\n",
            "\n",
            "output = pipeline()\n",
            "```\n",
            "\n",
            "But what's even better is you can load pre-existing weights into the pipeline if the pipeline structure is identical. For example, you can load the [`google/ddpm-cifar10-32`](https://huggingface.co/google/ddpm-cifar10-32) weights into the one-step pipeline:\n",
            "\n",
            "```python\n",
            "pipeline = UnetSchedulerOneForwardPipeline.from_pretrained(\"google/ddpm-cifar10-32\", use_safetensors=True)\n",
            "\n",
            "output = pipeline()\n",
            "```\n",
            "\n",
            "## Share your pipeline\n",
            "\n",
            "Open a Pull Request on the ğŸ§¨ Diffusers [repository](https://github.com/huggingface/diffusers) to add your awesome pipeline in `one_step_unet.py` to the [examples/community](https://github.com/huggingface/diffusers/tree/main/examples/community) subfolder.\n",
            "\n",
            "Once it is merged, anyone with `diffusers >= 0.4.0` installed can use this pipeline magically ğŸª„ by specifying it in the `custom_pipeline` argument:\n",
            "\n",
            "```python\n",
            "from diffusers import DiffusionPipeline\n",
            "\n",
            "pipe = DiffusionPipeline.from_pretrained(\n",
            "    \"google/ddpm-cifar10-32\", custom_pipeline=\"one_step_unet\", use_safetensors=True\n",
            ")\n",
            "pipe()\n",
            "```\n",
            "\n",
            "Another way to share your community pipeline is to upload the `one_step_unet.py` file directly to your preferred [model repository](https://huggingface.co/docs/hub/models-uploading) on the Hub. Instead of specifying the `one_step_unet.py` file, pass the model repository id to the `custom_pipeline` argument:\n",
            "\n",
            "```python\n",
            "from diffusers import DiffusionPipeline\n",
            "\n",
            "pipeline = DiffusionPipeline.from_pretrained(\n",
            "    \"google/ddpm-cifar10-32\", custom_pipeline=\"stevhliu/one_step_unet\", use_safetensors=True\n",
            ")\n",
            "```\n",
            "\n",
            "Take a look at the following table to compare the two sharing workflows to help you decide the best option for you:\n",
            "\n",
            "|                | GitHub community pipeline                                                                                        | HF Hub community pipeline                                                                 |\n",
            "|----------------|------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------|\n",
            "| usage          | same                                                                                                             | same                                                                                      |\n",
            "| review process | open a Pull Request on GitHub and undergo a review process from the Diffusers team before merging; may be slower | upload directly to a Hub repository without any review; this is the fastest workflow      |\n",
            "| visibility     | included in the official Diffusers repository and documentation                                                  | included on your HF Hub profile and relies on your own usage/promotion to gain visibility |\n",
            "\n",
            "<Tip>\n",
            "\n",
            "ğŸ’¡ You can use whatever package you want in your community pipeline file - as long as the user has it installed, everything will work fine. Make sure you have one and only one pipeline class that inherits from `DiffusionPipeline` because this is automatically detected.\n",
            "\n",
            "</Tip>\n",
            "\n",
            "## How do community pipelines work?\n",
            "\n",
            "A community pipeline is a class that inherits from [`DiffusionPipeline`] which means:\n",
            "\n",
            "- It can be loaded with the [`custom_pipeline`] argument.\n",
            "- The model weights and scheduler configuration are loaded from [`pretrained_model_name_or_path`].\n",
            "- The code that implements a feature in the community pipeline is defined in a `pipeline.py` file.\n",
            "\n",
            "Sometimes you can't load all the pipeline components weights from an official repository. In this case, the other components should be passed directly to the pipeline:\n",
            "\n",
            "```python\n",
            "from diffusers import DiffusionPipeline\n",
            "from transformers import CLIPImageProcessor, CLIPModel\n",
            "\n",
            "model_id = \"CompVis/stable-diffusion-v1-4\"\n",
            "clip_model_id = \"laion/CLIP-ViT-B-32-laion2B-s34B-b79K\"\n",
            "\n",
            "feature_extractor = CLIPImageProcessor.from_pretrained(clip_model_id)\n",
            "clip_model = CLIPModel.from_pretrained(clip_model_id, torch_dtype=torch.float16)\n",
            "\n",
            "pipeline = DiffusionPipeline.from_pretrained(\n",
            "    model_id,\n",
            "    custom_pipeline=\"clip_guided_stable_diffusion\",\n",
            "    clip_model=clip_model,\n",
            "    feature_extractor=feature_extractor,\n",
            "    scheduler=scheduler,\n",
            "    torch_dtype=torch.float16,\n",
            "    use_safetensors=True,\n",
            ")\n",
            "```\n",
            "\n",
            "The magic behind community pipelines is contained in the following code. It allows the community pipeline to be loaded from GitHub or the Hub, and it'll be available to all ğŸ§¨ Diffusers packages.\n",
            "\n",
            "```python\n",
            "# 2. Load the pipeline class, if using custom module then load it from the Hub\n",
            "# if we load from explicit class, let's use it\n",
            "if custom_pipeline is not None:\n",
            "    pipeline_class = get_class_from_dynamic_module(\n",
            "        custom_pipeline, module_file=CUSTOM_PIPELINE_FILE_NAME, cache_dir=custom_pipeline\n",
            "    )\n",
            "elif cls != DiffusionPipeline:\n",
            "    pipeline_class = cls\n",
            "else:\n",
            "    diffusers_module = importlib.import_module(cls.__module__.split(\".\")[0])\n",
            "    pipeline_class = getattr(diffusers_module, config_dict[\"_class_name\"])\n",
            "```\n",
            "Document 3------------------------------------------------------------\n",
            "FrameworkSwitchCourse {fw} />\n",
            "\n",
            "# Behind the pipeline[[behind-the-pipeline]]\n",
            "\n",
            "{#if fw === 'pt'}\n",
            "\n",
            "<CourseFloatingBanner chapter={2}\n",
            "  classNames=\"absolute z-10 right-0 top-0\"\n",
            "  notebooks={[\n",
            "    {label: \"Google Colab\", value: \"https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter2/section2_pt.ipynb\"},\n",
            "    {label: \"Aws Studio\", value: \"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/en/chapter2/section2_pt.ipynb\"},\n",
            "]} />\n",
            "\n",
            "{:else}\n",
            "\n",
            "<CourseFloatingBanner chapter={2}\n",
            "  classNames=\"absolute z-10 right-0 top-0\"\n",
            "  notebooks={[\n",
            "    {label: \"Google Colab\", value: \"https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter2/section2_tf.ipynb\"},\n",
            "    {label: \"Aws Studio\", value: \"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/en/chapter2/section2_tf.ipynb\"},\n",
            "]} />\n",
            "\n",
            "{/if}\n",
            "\n",
            "<Tip>\n",
            "This is the first section where the content is slightly different depending on whether you use PyTorch or TensorFlow. Toggle the switch on top of the title to select the platform you prefer!\n",
            "</Tip>\n",
            "\n",
            "{#if fw === 'pt'}\n",
            "<Youtube id=\"1pedAIvTWXk\"/>\n",
            "{:else}\n",
            "<Youtube id=\"wVN12smEvqg\"/>\n",
            "{/if}\n",
            "\n",
            "Let's start with a complete example, taking a look at what happened behind the scenes when we executed the following code in [Chapter 1](/course/chapter1):\n",
            "\n",
            "```python\n",
            "from transformers import pipeline\n",
            "\n",
            "classifier = pipeline(\"sentiment-analysis\")\n",
            "classifier(\n",
            "    [\n",
            "        \"I've been waiting for a HuggingFace course my whole life.\",\n",
            "        \"I hate this so much!\",\n",
            "    ]\n",
            ")\n",
            "```\n",
            "\n",
            "and obtained:\n",
            "\n",
            "```python out\n",
            "[{'label': 'POSITIVE', 'score': 0.9598047137260437},\n",
            " {'label': 'NEGATIVE', 'score': 0.9994558095932007}]\n",
            "```\n",
            "\n",
            "As we saw in [Chapter 1](/course/chapter1), this pipeline groups together three steps: preprocessing, passing the inputs through the model, and postprocessing:\n",
            "\n",
            "<div class=\"flex justify-center\">\n",
            "<img class=\"block dark:hidden\" src=\"https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter2/full_nlp_pipeline.svg\" alt=\"The full NLP pipeline: tokenization of text, conversion to IDs, and inference through the Transformer model and the model head.\"/>\n",
            "<img class=\"hidden dark:block\" src=\"https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter2/full_nlp_pipeline-dark.svg\" alt=\"The full NLP pipeline: tokenization of text, conversion to IDs, and inference through the Transformer model and the model head.\"/>\n",
            "</div>\n",
            "\n",
            "Let's quickly go over each of these.\n",
            "\n",
            "## Preprocessing with a tokenizer[[preprocessing-with-a-tokenizer]]\n",
            "\n",
            "Like other neural networks, Transformer models can't process raw text directly, so the first step of our pipeline is to convert the text inputs into numbers that the model can make sense of. To do this we use a *tokenizer*, which will be responsible for:\n",
            "\n",
            "- Splitting the input into words, subwords, or symbols (like punctuation) that are called *tokens*\n",
            "- Mapping each token to an integer\n",
            "- Adding additional inputs that may be useful to the model\n",
            "\n",
            "All this preprocessing needs to be done in exactly the same way as when the model was pretrained, so we first need to download that information from the [Model Hub](https://huggingface.co/models). To do this, we use the `AutoTokenizer` class and its `from_pretrained()` method. Using the checkpoint name of our model, it will automatically fetch the data associated with the model's tokenizer and cache it (so it's only downloaded the first time you run the code below).\n",
            "\n",
            "Since the default checkpoint of the `sentiment-analysis` pipeline is `distilbert-base-uncased-finetuned-sst-2-english` (you can see its model card [here](https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)), we run the following:\n",
            "\n",
            "```python\n",
            "from transformers import AutoTokenizer\n",
            "\n",
            "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
            "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
            "```\n",
            "\n",
            "Once we have the tokenizer, we can directly pass our sentences to it and we'll get back a dictionary that's ready to feed to our model! The only thing left to do is to convert the list of input IDs to tensors.\n",
            "\n",
            "You can use ğŸ¤— Transformers without having to worry about which ML framework is used as a backend; it might be PyTorch or TensorFlow, or Flax for some models. However, Transformer models only accept *tensors* as input. If this is your first time hearing about tensors, you can think of them as NumPy arrays instead. A NumPy array can be a scalar (0D), a vector (1D), a matrix (2D), or have more dimensions. It's effectively a tensor; other ML frameworks' tensors behave similarly, and are usually as simple to instantiate as NumPy arrays.\n",
            "\n",
            "To specify the type of tensors we want to get back (PyTorch, TensorFlow, or plain NumPy), we use the `return_tensors` argument:\n",
            "\n",
            "{#if fw === 'pt'}\n",
            "```python\n",
            "raw_inputs = [\n",
            "    \"I've been waiting for a HuggingFace course my whole life.\",\n",
            "    \"I hate this so much!\",\n",
            "]\n",
            "inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"pt\")\n",
            "print(inputs)\n",
            "```\n",
            "{:else}\n",
            "```python\n",
            "raw_inputs = [\n",
            "    \"I've been waiting for a HuggingFace course my whole life.\",\n",
            "    \"I hate this so much!\",\n",
            "]\n",
            "inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"tf\")\n",
            "print(inputs)\n",
            "```\n",
            "{/if}\n",
            "\n",
            "Don't worry about padding and truncation just yet; we'll explain those later. The main things to remember here are that you can pass one sentence or a list of sentences, as well as specifying the type of tensors you want to get back (if no type is passed, you will get a list of lists as a result).\n",
            "\n",
            "{#if fw === 'pt'}\n",
            "\n",
            "Here's what the results look like as PyTorch tensors:\n",
            "\n",
            "```python out\n",
            "{\n",
            "    'input_ids': tensor([\n",
            "        [  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172, 2607,  2026,  2878,  2166,  1012,   102],\n",
            "        [  101,  1045,  5223,  2023,  2061,  2172,   999,   102,     0,     0,     0,     0,     0,     0,     0,     0]\n",
            "    ]), \n",
            "    'attention_mask': tensor([\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "    ])\n",
            "}\n",
            "```\n",
            "{:else}\n",
            "\n",
            "Here's what the results look like as TensorFlow tensors:\n",
            "\n",
            "```python out\n",
            "{\n",
            "    'input_ids': <tf.Tensor: shape=(2, 16), dtype=int32, numpy=\n",
            "        array([\n",
            "            [  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,  2607,  2026,  2878,  2166,  1012,   102],\n",
            "            [  101,  1045,  5223,  2023,  2061,  2172,   999,   102,     0,     0,     0,     0,     0,     0,     0,     0]\n",
            "        ], dtype=int32)>, \n",
            "    'attention_mask': <tf.Tensor: shape=(2, 16), dtype=int32, numpy=\n",
            "        array([\n",
            "            [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "            [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "        ], dtype=int32)>\n",
            "}\n",
            "```\n",
            "{/if}\n",
            "\n",
            "The output itself is a dictionary containing two keys, `input_ids` and `attention_mask`. `input_ids` contains two rows of integers (one for each sentence) that are the unique identifiers of the tokens in each sentence. We'll explain what the `attention_mask` is later in this chapter. \n",
            "\n",
            "## Going through the model[[going-through-the-model]]\n",
            "\n",
            "{#if fw === 'pt'}\n",
            "We can download our pretrained model the same way we did with our tokenizer. ğŸ¤— Transformers provides an `AutoModel` class which also has a `from_pretrained()` method:\n",
            "\n",
            "```python\n",
            "from transformers import AutoModel\n",
            "\n",
            "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
            "model = AutoModel.from_pretrained(checkpoint)\n",
            "```\n",
            "{:else}\n",
            "We can download our pretrained model the same way we did with our tokenizer. ğŸ¤— Transformers provides an `TFAutoModel` class which also has a `from_pretrained` method:\n",
            "\n",
            "```python\n",
            "from transformers import TFAutoModel\n",
            "\n",
            "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
            "model = TFAutoModel.from_pretrained(checkpoint)\n",
            "```\n",
            "{/if}\n",
            "\n",
            "In this code snippet, we have downloaded the same checkpoint we used in our pipeline before (it should actually have been cached already) and instantiated a model with it.\n",
            "\n",
            "This architecture contains only the base Transformer module: given some inputs, it outputs what we'll call *hidden states*, also known as *features*. For each model input, we'll retrieve a high-dimensional vector representing the **contextual understanding of that input by the Transformer model**.\n",
            "\n",
            "If this doesn't make sense, don't worry about it. We'll explain it all later.\n",
            "\n",
            "While these hidden states can be useful on their own, they're usually inputs to another part of the model, known as the *head*. In [Chapter 1](/course/chapter1), the different tasks could have been performed with the same architecture, but each of these tasks will have a different head associated with it.\n",
            "\n",
            "### A high-dimensional vector?[[a-high-dimensional-vector]]\n",
            "\n",
            "The vector output by the Transformer module is usually large. It generally has three dimensions:\n",
            "\n",
            "- **Batch size**: The number of sequences processed at a time (2 in our example).\n",
            "- **Sequence length**: The length of the numerical representation of the sequence (16 in our example).\n",
            "- **Hidden size**: The vector dimension of each model input.\n",
            "\n",
            "It is said to be \"high dimensional\" because of the last value. The hidden size can be very large (768 is common for smaller models, and in larger models this can reach 3072 or more).\n",
            "\n",
            "We can see this if we feed the inputs we preprocessed to our model:\n",
            "\n",
            "{#if fw === 'pt'}\n",
            "```python\n",
            "outputs = model(**inputs)\n",
            "print(outputs.last_hidden_state.shape)\n",
            "```\n",
            "\n",
            "```python out\n",
            "torch.Size([2, 16, 768])\n",
            "```\n",
            "{:else}\n",
            "```py\n",
            "outputs = model(inputs)\n",
            "print(outputs.last_hidden_state.shape)\n",
            "```\n",
            "\n",
            "```python out\n",
            "(2, 16, 768)\n",
            "```\n",
            "{/if}\n",
            "\n",
            "Note that the outputs of ğŸ¤— Transformers models behave like `namedtuple`s or dictionaries. You can access the elements by attributes (like we did) or by key (`outputs[\"last_hidden_state\"]`), or even by index if you know exactly where the thing you are looking for is (`outputs[0]`).\n",
            "\n",
            "### Model heads: Making sense out of numbers[[model-heads-making-sense-out-of-numbers]]\n",
            "\n",
            "The model heads take the high-dimensional vector of hidden states as input and project them onto a different dimension. They are usually composed of one or a few linear layers:\n",
            "\n",
            "<div class=\"flex justify-center\">\n",
            "<img class=\"block dark:hidden\" src=\"https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter2/transformer_and_head.svg\" alt=\"A Transformer network alongside its head.\"/>\n",
            "<img class=\"hidden dark:block\" src=\"https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter2/transformer_and_head-dark.svg\" alt=\"A Transformer network alongside its head.\"/>\n",
            "</div>\n",
            "\n",
            "The output of the Transformer model is sent directly to the model head to be processed.\n",
            "\n",
            "In this diagram, the model is represented by its embeddings layer and the subsequent layers. The embeddings layer converts each input ID in the tokenized input into a vector that represents the associated token. The subsequent layers manipulate those vectors using the attention mechanism to produce the final representation of the sentences.\n",
            "\n",
            "There are many different architectures available in ğŸ¤— Transformers, with each one designed around tackling a specific task. Here is a non-exhaustive list:\n",
            "\n",
            "- `*Model` (retrieve the hidden states)\n",
            "- `*ForCausalLM`\n",
            "- `*ForMaskedLM`\n",
            "- `*ForMultipleChoice`\n",
            "- `*ForQuestionAnswering`\n",
            "- `*ForSequenceClassification`\n",
            "- `*ForTokenClassification`\n",
            "- and others ğŸ¤—\n",
            "\n",
            "{#if fw === 'pt'}\n",
            "For our example, we will need a model with a sequence classification head (to be able to classify the sentences as positive or negative). So, we won't actually use the `AutoModel` class, but `AutoModelForSequenceClassification`:\n",
            "\n",
            "```python\n",
            "from transformers import AutoModelForSequenceClassification\n",
            "\n",
            "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
            "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
            "outputs = model(**inputs)\n",
            "```\n",
            "{:else}\n",
            "For our example, we will need a model with a sequence classification head (to be able to classify the sentences as positive or negative). So, we won't actually use the `TFAutoModel` class, but `TFAutoModelForSequenceClassification`:\n",
            "\n",
            "```python\n",
            "from transformers import TFAutoModelForSequenceClassification\n",
            "\n",
            "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
            "model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
            "outputs = model(inputs)\n",
            "```\n",
            "{/if}\n",
            "\n",
            "Now if we look at the shape of our outputs, the dimensionality will be much lower: the model head takes as input the high-dimensional vectors we saw before, and outputs vectors containing two values (one per label):\n",
            "\n",
            "```python\n",
            "print(outputs.logits.shape)\n",
            "```\n",
            "\n",
            "{#if fw === 'pt'}\n",
            "```python out\n",
            "torch.Size([2, 2])\n",
            "```\n",
            "{:else}\n",
            "```python out\n",
            "(2, 2)\n",
            "```\n",
            "{/if}\n",
            "\n",
            "Since we have just two sentences and two labels, the result we get from our model is of shape 2 x 2.\n",
            "\n",
            "## Postprocessing the output[[postprocessing-the-output]]\n",
            "\n",
            "The values we get as output from our model don't necessarily make sense by themselves. Let's take a look:\n",
            "\n",
            "```python\n",
            "print(outputs.logits)\n",
            "```\n",
            "\n",
            "{#if fw === 'pt'}\n",
            "```python out\n",
            "tensor([[-1.5607,  1.6123],\n",
            "        [ 4.1692, -3.3464]], grad_fn=<AddmmBackward>)\n",
            "```\n",
            "{:else}\n",
            "```python out\n",
            "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
            "    array([[-1.5606991,  1.6122842],\n",
            "           [ 4.169231 , -3.3464472]], dtype=float32)>\n",
            "```\n",
            "{/if}\n",
            "\n",
            "Our model predicted `[-1.5607, 1.6123]` for the first sentence and `[ 4.1692, -3.3464]` for the second one. Those are not probabilities but *logits*, the raw, unnormalized scores outputted by the last layer of the model. To be converted to probabilities, they need to go through a [SoftMax](https://en.wikipedia.org/wiki/Softmax_function) layer (all ğŸ¤— Transformers models output the logits, as the loss function for training will generally fuse the last activation function, such as SoftMax, with the actual loss function, such as cross entropy):\n",
            "\n",
            "{#if fw === 'pt'}\n",
            "```py\n",
            "import torch\n",
            "\n",
            "predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
            "print(predictions)\n",
            "```\n",
            "{:else}\n",
            "```py\n",
            "import tensorflow as tf\n",
            "\n",
            "predictions = tf.math.softmax(outputs.logits, axis=-1)\n",
            "print(predictions)\n",
            "```\n",
            "{/if}\n",
            "\n",
            "{#if fw === 'pt'}\n",
            "```python out\n",
            "tensor([[4.0195e-02, 9.5980e-01],\n",
            "        [9.9946e-01, 5.4418e-04]], grad_fn=<SoftmaxBackward>)\n",
            "```\n",
            "{:else}\n",
            "```python out\n",
            "tf.Tensor(\n",
            "[[4.01951671e-02 9.59804833e-01]\n",
            " [9.9945587e-01 5.4418424e-04]], shape=(2, 2), dtype=float32)\n",
            "```\n",
            "{/if}\n",
            "\n",
            "Now we can see that the model predicted `[0.0402, 0.9598]` for the first sentence and `[0.9995,  0.0005]` for the second one. These are recognizable probability scores.\n",
            "\n",
            "To get the labels corresponding to each position, we can inspect the `id2label` attribute of the model config (more on this in the next section):\n",
            "\n",
            "```python\n",
            "model.config.id2label\n",
            "```\n",
            "\n",
            "```python out\n",
            "{0: 'NEGATIVE', 1: 'POSITIVE'}\n",
            "```\n",
            "\n",
            "Now we can conclude that the model predicted the following:\n",
            " \n",
            "- First sentence: NEGATIVE: 0.0402, POSITIVE: 0.9598\n",
            "- Second sentence: NEGATIVE: 0.9995, POSITIVE: 0.0005\n",
            "\n",
            "We have successfully reproduced the three steps of the pipeline: preprocessing with tokenizers, passing the inputs through the model, and postprocessing! Now let's take some time to dive deeper into each of those steps.\n",
            "\n",
            "<Tip>\n",
            "\n",
            "âœï¸ **Try it out!** Choose two (or more) texts of your own and run them through the `sentiment-analysis` pipeline. Then replicate the steps you saw here yourself and check that you obtain the same results!\n",
            "\n",
            "</Tip>\n",
            "Document 4------------------------------------------------------------\n",
            "Gradio Demo: ner_pipeline\n",
            "\n",
            "\n",
            "```\n",
            "!pip install -q gradio torch transformers\n",
            "```\n",
            "\n",
            "\n",
            "```\n",
            "from transformers import pipeline\n",
            "\n",
            "import gradio as gr\n",
            "\n",
            "ner_pipeline = pipeline(\"ner\")\n",
            "\n",
            "examples = [\n",
            "    \"Does Chicago have any stores and does Joe live here?\",\n",
            "]\n",
            "\n",
            "def ner(text):\n",
            "    output = ner_pipeline(text)\n",
            "    return {\"text\": text, \"entities\": output}    \n",
            "\n",
            "demo = gr.Interface(ner,\n",
            "             gr.Textbox(placeholder=\"Enter sentence here...\"), \n",
            "             gr.HighlightedText(),\n",
            "             examples=examples)\n",
            "\n",
            "if __name__ == \"__main__\":\n",
            "    demo.launch()\n",
            "\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"==================================Answer==================================\")\n",
        "print(f\"{answer}\")\n",
        "print(\"==================================Source docs==================================\")\n",
        "for i, doc in enumerate(relevant_docs):\n",
        "    print(f\"Document {i}------------------------------------------------------------\")\n",
        "    print(doc)"
      ],
      "metadata": {
        "id": "rMjT8XForrFK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "381b97f6-28dd-445a-898e-6b118f58fc30"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================Answer==================================\n",
            "To create a pipeline object for named entity recognition (NER) in Hugging Face, follow these steps:\n",
            "\n",
            "1. Install the required libraries:\n",
            "\n",
            "   ```\n",
            "  !pip install -q gradio torch transformers\n",
            "   ```\n",
            "\n",
            "2. Import the `pipeline` function from the `transformers` library:\n",
            "\n",
            "   ```python\n",
            "   from transformers import pipeline\n",
            "   ```\n",
            "\n",
            "3. Create a pipeline object for NER by passing the `ner` task name to the `pipeline` function:\n",
            "\n",
            "   ```python\n",
            "   ner_pipeline = pipeline(\"ner\")\n",
            "   ```\n",
            "\n",
            "4. Define a helper function to wrap the pipeline object and pass it to the Gradio interface:\n",
            "\n",
            "   ```python\n",
            "   def ner(text):\n",
            "       output = ner_pipeline(text)\n",
            "       return {\"text\": text, \"entities\": output}\n",
            "   ```\n",
            "\n",
            "5. Create a Gradio interface with the helper function, a text input widget, a highlighted text output widget, and some examples:\n",
            "\n",
            "   ```python\n",
            "   demo = gr.Interface(ner,\n",
            "                           gr.Textbox(placeholder=\"Enter sentence here...\"),\n",
            "                           gr.HighlightedText(),\n",
            "                           examples=examples)\n",
            "   ```\n",
            "\n",
            "6. Launch the Gradio interface:\n",
            "\n",
            "   ```python\n",
            "   if __name__ == \"__main__\":\n",
            "       demo.launch()\n",
            "   ```\n",
            "\n",
            "This will launch a Gradio interface that lets you test the pipeline object with some examples. You can enter a sentence into the text input widget, and the output will be displayed in the highlighted text output widget. The output will include both the original sentence and the recognized entities, highlighted in different colors.\n",
            "\n",
            "In this example, we created a pipeline object for NER using the `pipeline` function from the `transformers` library. We then defined a helper function that wraps the pipeline object and passes it to the Gradio interface. Finally, we launched the Gradio interface with some examples. When you run this script, you will be able to test the pipeline object with some examples using the Gradio interface. The output will include both the original sentence and the recognized entities, highlighted in different colors.\n",
            "\n",
            "Note that you can replace `ner` with the name of the task you want to perform, as long as it is supported by Hugging Face\n",
            "==================================Source docs==================================\n",
            "Document 0------------------------------------------------------------\n",
            "!--âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be\n",
            "rendered properly in your Markdown viewer.\n",
            "-->\n",
            "\n",
            "# Using pipelines for a webserver\n",
            "\n",
            "<Tip>\n",
            "Creating an inference engine is a complex topic, and the \"best\" solution \n",
            "will most likely depend on your problem space. Are you on CPU or GPU? Do\n",
            "you want the lowest latency, the highest throughput, support for\n",
            "many models, or just highly optimize 1 specific model?\n",
            "There are many ways to tackle this topic, so what we are going to present is a good default\n",
            "to get started which may not necessarily be the most optimal solution for you.\n",
            "</Tip>\n",
            "\n",
            "\n",
            "The key thing to understand is that we can use an iterator, just like you would [on a\n",
            "dataset](pipeline_tutorial#using-pipelines-on-a-dataset), since a webserver is basically a system that waits for requests and\n",
            "treats them as they come in.\n",
            "\n",
            "Usually webservers are multiplexed (multithreaded, async, etc..) to handle various\n",
            "requests concurrently. Pipelines on the other hand (and mostly the underlying models)\n",
            "are not really great for parallelism; they take up a lot of RAM, so it's best to give them all the available resources when they are running or it's a compute-intensive job.\n",
            "\n",
            "We are going to solve that by having the webserver handle the light load of receiving\n",
            "and sending requests, and having a single thread handling the actual work.\n",
            "This example is going to use `starlette`. The actual framework is not really\n",
            "important, but you might have to tune or change the code if you are using another\n",
            "one to achieve the same effect.\n",
            "\n",
            "Create `server.py`:\n",
            "\n",
            "```py\n",
            "from starlette.applications import Starlette\n",
            "from starlette.responses import JSONResponse\n",
            "from starlette.routing import Route\n",
            "from transformers import pipeline\n",
            "import asyncio\n",
            "\n",
            "\n",
            "async def homepage(request):\n",
            "    payload = await request.body()\n",
            "    string = payload.decode(\"utf-8\")\n",
            "    response_q = asyncio.Queue()\n",
            "    await request.app.model_queue.put((string, response_q))\n",
            "    output = await response_q.get()\n",
            "    return JSONResponse(output)\n",
            "\n",
            "\n",
            "async def server_loop(q):\n",
            "    pipe = pipeline(model=\"bert-base-uncased\")\n",
            "    while True:\n",
            "        (string, response_q) = await q.get()\n",
            "        out = pipe(string)\n",
            "        await response_q.put(out)\n",
            "\n",
            "\n",
            "app = Starlette(\n",
            "    routes=[\n",
            "        Route(\"/\", homepage, methods=[\"POST\"]),\n",
            "    ],\n",
            ")\n",
            "\n",
            "\n",
            "@app.on_event(\"startup\")\n",
            "async def startup_event():\n",
            "    q = asyncio.Queue()\n",
            "    app.model_queue = q\n",
            "    asyncio.create_task(server_loop(q))\n",
            "```\n",
            "\n",
            "Now you can start it with:\n",
            "```bash\n",
            "uvicorn server:app\n",
            "```\n",
            "\n",
            "And you can query it:\n",
            "```bash\n",
            "curl -X POST -d \"test [MASK]\" http://localhost:8000/\n",
            "#[{\"score\":0.7742936015129089,\"token\":1012,\"token_str\":\".\",\"sequence\":\"test.\"},...]\n",
            "```\n",
            "\n",
            "And there you go, now you have a good idea of how to create a webserver!\n",
            "\n",
            "What is really important is that we load the model only **once**, so there are no copies\n",
            "of the model on the webserver. This way, no unnecessary RAM is being used.\n",
            "Then the queuing mechanism allows you to do fancy stuff like maybe accumulating a few\n",
            "items before inferring to use dynamic batching:\n",
            "\n",
            "<Tip warning={true}>\n",
            "\n",
            "The code sample below is intentionally written like pseudo-code for readability.\n",
            "Do not run this without checking if it makes sense for your system resources!\n",
            "\n",
            "</Tip>\n",
            "\n",
            "```py\n",
            "(string, rq) = await q.get()\n",
            "strings = []\n",
            "queues = []\n",
            "while True:\n",
            "    try:\n",
            "        (string, rq) = await asyncio.wait_for(q.get(), timeout=0.001)  # 1ms\n",
            "    except asyncio.exceptions.TimeoutError:\n",
            "        break\n",
            "    strings.append(string)\n",
            "    queues.append(rq)\n",
            "strings\n",
            "outs = pipe(strings, batch_size=len(strings))\n",
            "for rq, out in zip(queues, outs):\n",
            "    await rq.put(out)\n",
            "```\n",
            "\n",
            "Again, the proposed code is optimized for readability, not for being the best code.\n",
            "First of all, there's no batch size limit which is usually not a \n",
            "great idea. Next, the timeout is reset on every queue fetch, meaning you could\n",
            "wait much more than 1ms before running the inference (delaying the first request \n",
            "by that much). \n",
            "\n",
            "It would be better to have a single 1ms deadline.\n",
            "\n",
            "This will always wait for 1ms even if the queue is empty, which might not be the\n",
            "best since you probably want to start doing inference if there's nothing in the queue.\n",
            "But maybe it does make sense if batching is really crucial for your use case.\n",
            "Again, there's really no one best solution.\n",
            "\n",
            "\n",
            "## Few things you might want to consider\n",
            "\n",
            "### Error checking\n",
            "\n",
            "There's a lot that can go wrong in production: out of memory, out of space,\n",
            "loading the model might fail, the query might be wrong, the query might be\n",
            "correct but still fail to run because of a model misconfiguration, and so on.\n",
            "\n",
            "Generally, it's good if the server outputs the errors to the user, so\n",
            "adding a lot of `try..except` statements to show those errors is a good\n",
            "idea. But keep in mind it may also be a security risk to reveal all those errors depending \n",
            "on your security context.\n",
            "\n",
            "### Circuit breaking\n",
            "\n",
            "Webservers usually look better when they do circuit breaking. It means they \n",
            "return proper errors when they're overloaded instead of just waiting for the query indefinitely. Return a 503 error instead of waiting for a super long time or a 504 after a long time.\n",
            "\n",
            "This is relatively easy to implement in the proposed code since there is a single queue.\n",
            "Looking at the queue size is a basic way to start returning errors before your \n",
            "webserver fails under load.\n",
            "\n",
            "### Blocking the main thread\n",
            "\n",
            "Currently PyTorch is not async aware, and computation will block the main\n",
            "thread while running. That means it would be better if PyTorch was forced to run\n",
            "on its own thread/process. This wasn't done here because the code is a lot more\n",
            "complex (mostly because threads and async and queues don't play nice together).\n",
            "But ultimately it does the same thing.\n",
            "\n",
            "This would be important if the inference of single items were long (> 1s) because \n",
            "in this case, it means every query during inference would have to wait for 1s before\n",
            "even receiving an error.\n",
            "\n",
            "### Dynamic batching\n",
            "\n",
            "In general, batching is not necessarily an improvement over passing 1 item at \n",
            "a time (see [batching details](./main_classes/pipelines#pipeline-batching) for more information). But it can be very effective\n",
            "when used in the correct setting. In the API, there is no dynamic\n",
            "batching by default (too much opportunity for a slowdown). But for BLOOM inference -\n",
            "which is a very large model - dynamic batching is **essential** to provide a decent experience for everyone.\n",
            "Document 1------------------------------------------------------------\n",
            "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n",
            "\n",
            "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with\n",
            "the License. You may obtain a copy of the License at\n",
            "\n",
            "http://www.apache.org/licenses/LICENSE-2.0\n",
            "\n",
            "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on\n",
            "an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the\n",
            "specific language governing permissions and limitations under the License.\n",
            "-->\n",
            "\n",
            "# Outputs\n",
            "\n",
            "All model outputs are subclasses of [`~utils.BaseOutput`], data structures containing all the information returned by the model. The outputs can also be used as tuples or dictionaries.\n",
            "\n",
            "For example:\n",
            "\n",
            "```python\n",
            "from diffusers import DDIMPipeline\n",
            "\n",
            "pipeline = DDIMPipeline.from_pretrained(\"google/ddpm-cifar10-32\")\n",
            "outputs = pipeline()\n",
            "```\n",
            "\n",
            "The `outputs` object is a [`~pipelines.ImagePipelineOutput`] which means it has an image attribute.\n",
            "\n",
            "You can access each attribute as you normally would or with a keyword lookup, and if that attribute is not returned by the model, you will get `None`:\n",
            "\n",
            "```python\n",
            "outputs.images\n",
            "outputs[\"images\"]\n",
            "```\n",
            "\n",
            "When considering the `outputs` object as a tuple, it only considers the attributes that don't have `None` values.\n",
            "For instance, retrieving an image by indexing into it returns the tuple `(outputs.images)`:\n",
            "\n",
            "```python\n",
            "outputs[:1]\n",
            "```\n",
            "\n",
            "<Tip>\n",
            "\n",
            "To check a specific pipeline or model output, refer to its corresponding API documentation.\n",
            "\n",
            "</Tip>\n",
            "\n",
            "## BaseOutput\n",
            "\n",
            "[[autodoc]] utils.BaseOutput\n",
            "    - to_tuple\n",
            "\n",
            "## ImagePipelineOutput\n",
            "\n",
            "[[autodoc]] pipelines.ImagePipelineOutput\n",
            "\n",
            "## FlaxImagePipelineOutput\n",
            "\n",
            "[[autodoc]] pipelines.pipeline_flax_utils.FlaxImagePipelineOutput\n",
            "\n",
            "## AudioPipelineOutput\n",
            "\n",
            "[[autodoc]] pipelines.AudioPipelineOutput\n",
            "\n",
            "## ImageTextPipelineOutput\n",
            "\n",
            "[[autodoc]] ImageTextPipelineOutput\n",
            "Document 2------------------------------------------------------------\n",
            "!--Copyright 2023 The HuggingFace Team. All rights reserved.\n",
            "\n",
            "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with\n",
            "the License. You may obtain a copy of the License at\n",
            "\n",
            "http://www.apache.org/licenses/LICENSE-2.0\n",
            "\n",
            "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on\n",
            "an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the\n",
            "specific language governing permissions and limitations under the License.\n",
            "-->\n",
            "\n",
            "# Contribute a community pipeline\n",
            "\n",
            "<Tip>\n",
            "\n",
            "ğŸ’¡ Take a look at GitHub Issue [#841](https://github.com/huggingface/diffusers/issues/841) for more context about why we're adding community pipelines to help everyone easily share their work without being slowed down.\n",
            "\n",
            "</Tip>\n",
            "\n",
            "Community pipelines allow you to add any additional features you'd like on top of the [`DiffusionPipeline`]. The main benefit of building on top of the `DiffusionPipeline` is anyone can load and use your pipeline by only adding one more argument, making it super easy for the community to access.\n",
            "\n",
            "This guide will show you how to create a community pipeline and explain how they work. To keep things simple, you'll create a \"one-step\" pipeline where the `UNet` does a single forward pass and calls the scheduler once.\n",
            "\n",
            "## Initialize the pipeline\n",
            "\n",
            "You should start by creating a `one_step_unet.py` file for your community pipeline. In this file, create a pipeline class that inherits from the [`DiffusionPipeline`] to be able to load model weights and the scheduler configuration from the Hub. The one-step pipeline needs a `UNet` and a scheduler, so you'll need to add these as arguments to the `__init__` function:\n",
            "\n",
            "```python\n",
            "from diffusers import DiffusionPipeline\n",
            "import torch\n",
            "\n",
            "class UnetSchedulerOneForwardPipeline(DiffusionPipeline):\n",
            "    def __init__(self, unet, scheduler):\n",
            "        super().__init__()\n",
            "```\n",
            "\n",
            "To ensure your pipeline and its components (`unet` and `scheduler`) can be saved with [`~DiffusionPipeline.save_pretrained`], add them to the `register_modules` function:\n",
            "\n",
            "```diff\n",
            "  from diffusers import DiffusionPipeline\n",
            "  import torch\n",
            "\n",
            "  class UnetSchedulerOneForwardPipeline(DiffusionPipeline):\n",
            "      def __init__(self, unet, scheduler):\n",
            "          super().__init__()\n",
            "\n",
            "+         self.register_modules(unet=unet, scheduler=scheduler)\n",
            "```\n",
            "\n",
            "Cool, the `__init__` step is done and you can move to the forward pass now! ğŸ”¥\n",
            "\n",
            "## Define the forward pass\n",
            "\n",
            "In the forward pass, which we recommend defining as `__call__`, you have complete creative freedom to add whatever feature you'd like. For our amazing one-step pipeline, create a random image and only call the `unet` and `scheduler` once by setting `timestep=1`:\n",
            "\n",
            "```diff\n",
            "  from diffusers import DiffusionPipeline\n",
            "  import torch\n",
            "\n",
            "  class UnetSchedulerOneForwardPipeline(DiffusionPipeline):\n",
            "      def __init__(self, unet, scheduler):\n",
            "          super().__init__()\n",
            "\n",
            "          self.register_modules(unet=unet, scheduler=scheduler)\n",
            "\n",
            "+     def __call__(self):\n",
            "+         image = torch.randn(\n",
            "+             (1, self.unet.config.in_channels, self.unet.config.sample_size, self.unet.config.sample_size),\n",
            "+         )\n",
            "+         timestep = 1\n",
            "\n",
            "+         model_output = self.unet(image, timestep).sample\n",
            "+         scheduler_output = self.scheduler.step(model_output, timestep, image).prev_sample\n",
            "\n",
            "+         return scheduler_output\n",
            "```\n",
            "\n",
            "That's it! ğŸš€ You can now run this pipeline by passing a `unet` and `scheduler` to it:\n",
            "\n",
            "```python\n",
            "from diffusers import DDPMScheduler, UNet2DModel\n",
            "\n",
            "scheduler = DDPMScheduler()\n",
            "unet = UNet2DModel()\n",
            "\n",
            "pipeline = UnetSchedulerOneForwardPipeline(unet=unet, scheduler=scheduler)\n",
            "\n",
            "output = pipeline()\n",
            "```\n",
            "\n",
            "But what's even better is you can load pre-existing weights into the pipeline if the pipeline structure is identical. For example, you can load the [`google/ddpm-cifar10-32`](https://huggingface.co/google/ddpm-cifar10-32) weights into the one-step pipeline:\n",
            "\n",
            "```python\n",
            "pipeline = UnetSchedulerOneForwardPipeline.from_pretrained(\"google/ddpm-cifar10-32\", use_safetensors=True)\n",
            "\n",
            "output = pipeline()\n",
            "```\n",
            "\n",
            "## Share your pipeline\n",
            "\n",
            "Open a Pull Request on the ğŸ§¨ Diffusers [repository](https://github.com/huggingface/diffusers) to add your awesome pipeline in `one_step_unet.py` to the [examples/community](https://github.com/huggingface/diffusers/tree/main/examples/community) subfolder.\n",
            "\n",
            "Once it is merged, anyone with `diffusers >= 0.4.0` installed can use this pipeline magically ğŸª„ by specifying it in the `custom_pipeline` argument:\n",
            "\n",
            "```python\n",
            "from diffusers import DiffusionPipeline\n",
            "\n",
            "pipe = DiffusionPipeline.from_pretrained(\n",
            "    \"google/ddpm-cifar10-32\", custom_pipeline=\"one_step_unet\", use_safetensors=True\n",
            ")\n",
            "pipe()\n",
            "```\n",
            "\n",
            "Another way to share your community pipeline is to upload the `one_step_unet.py` file directly to your preferred [model repository](https://huggingface.co/docs/hub/models-uploading) on the Hub. Instead of specifying the `one_step_unet.py` file, pass the model repository id to the `custom_pipeline` argument:\n",
            "\n",
            "```python\n",
            "from diffusers import DiffusionPipeline\n",
            "\n",
            "pipeline = DiffusionPipeline.from_pretrained(\n",
            "    \"google/ddpm-cifar10-32\", custom_pipeline=\"stevhliu/one_step_unet\", use_safetensors=True\n",
            ")\n",
            "```\n",
            "\n",
            "Take a look at the following table to compare the two sharing workflows to help you decide the best option for you:\n",
            "\n",
            "|                | GitHub community pipeline                                                                                        | HF Hub community pipeline                                                                 |\n",
            "|----------------|------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------|\n",
            "| usage          | same                                                                                                             | same                                                                                      |\n",
            "| review process | open a Pull Request on GitHub and undergo a review process from the Diffusers team before merging; may be slower | upload directly to a Hub repository without any review; this is the fastest workflow      |\n",
            "| visibility     | included in the official Diffusers repository and documentation                                                  | included on your HF Hub profile and relies on your own usage/promotion to gain visibility |\n",
            "\n",
            "<Tip>\n",
            "\n",
            "ğŸ’¡ You can use whatever package you want in your community pipeline file - as long as the user has it installed, everything will work fine. Make sure you have one and only one pipeline class that inherits from `DiffusionPipeline` because this is automatically detected.\n",
            "\n",
            "</Tip>\n",
            "\n",
            "## How do community pipelines work?\n",
            "\n",
            "A community pipeline is a class that inherits from [`DiffusionPipeline`] which means:\n",
            "\n",
            "- It can be loaded with the [`custom_pipeline`] argument.\n",
            "- The model weights and scheduler configuration are loaded from [`pretrained_model_name_or_path`].\n",
            "- The code that implements a feature in the community pipeline is defined in a `pipeline.py` file.\n",
            "\n",
            "Sometimes you can't load all the pipeline components weights from an official repository. In this case, the other components should be passed directly to the pipeline:\n",
            "\n",
            "```python\n",
            "from diffusers import DiffusionPipeline\n",
            "from transformers import CLIPImageProcessor, CLIPModel\n",
            "\n",
            "model_id = \"CompVis/stable-diffusion-v1-4\"\n",
            "clip_model_id = \"laion/CLIP-ViT-B-32-laion2B-s34B-b79K\"\n",
            "\n",
            "feature_extractor = CLIPImageProcessor.from_pretrained(clip_model_id)\n",
            "clip_model = CLIPModel.from_pretrained(clip_model_id, torch_dtype=torch.float16)\n",
            "\n",
            "pipeline = DiffusionPipeline.from_pretrained(\n",
            "    model_id,\n",
            "    custom_pipeline=\"clip_guided_stable_diffusion\",\n",
            "    clip_model=clip_model,\n",
            "    feature_extractor=feature_extractor,\n",
            "    scheduler=scheduler,\n",
            "    torch_dtype=torch.float16,\n",
            "    use_safetensors=True,\n",
            ")\n",
            "```\n",
            "\n",
            "The magic behind community pipelines is contained in the following code. It allows the community pipeline to be loaded from GitHub or the Hub, and it'll be available to all ğŸ§¨ Diffusers packages.\n",
            "\n",
            "```python\n",
            "# 2. Load the pipeline class, if using custom module then load it from the Hub\n",
            "# if we load from explicit class, let's use it\n",
            "if custom_pipeline is not None:\n",
            "    pipeline_class = get_class_from_dynamic_module(\n",
            "        custom_pipeline, module_file=CUSTOM_PIPELINE_FILE_NAME, cache_dir=custom_pipeline\n",
            "    )\n",
            "elif cls != DiffusionPipeline:\n",
            "    pipeline_class = cls\n",
            "else:\n",
            "    diffusers_module = importlib.import_module(cls.__module__.split(\".\")[0])\n",
            "    pipeline_class = getattr(diffusers_module, config_dict[\"_class_name\"])\n",
            "```\n",
            "Document 3------------------------------------------------------------\n",
            "FrameworkSwitchCourse {fw} />\n",
            "\n",
            "# Behind the pipeline[[behind-the-pipeline]]\n",
            "\n",
            "{#if fw === 'pt'}\n",
            "\n",
            "<CourseFloatingBanner chapter={2}\n",
            "  classNames=\"absolute z-10 right-0 top-0\"\n",
            "  notebooks={[\n",
            "    {label: \"Google Colab\", value: \"https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter2/section2_pt.ipynb\"},\n",
            "    {label: \"Aws Studio\", value: \"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/en/chapter2/section2_pt.ipynb\"},\n",
            "]} />\n",
            "\n",
            "{:else}\n",
            "\n",
            "<CourseFloatingBanner chapter={2}\n",
            "  classNames=\"absolute z-10 right-0 top-0\"\n",
            "  notebooks={[\n",
            "    {label: \"Google Colab\", value: \"https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/en/chapter2/section2_tf.ipynb\"},\n",
            "    {label: \"Aws Studio\", value: \"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/master/course/en/chapter2/section2_tf.ipynb\"},\n",
            "]} />\n",
            "\n",
            "{/if}\n",
            "\n",
            "<Tip>\n",
            "This is the first section where the content is slightly different depending on whether you use PyTorch or TensorFlow. Toggle the switch on top of the title to select the platform you prefer!\n",
            "</Tip>\n",
            "\n",
            "{#if fw === 'pt'}\n",
            "<Youtube id=\"1pedAIvTWXk\"/>\n",
            "{:else}\n",
            "<Youtube id=\"wVN12smEvqg\"/>\n",
            "{/if}\n",
            "\n",
            "Let's start with a complete example, taking a look at what happened behind the scenes when we executed the following code in [Chapter 1](/course/chapter1):\n",
            "\n",
            "```python\n",
            "from transformers import pipeline\n",
            "\n",
            "classifier = pipeline(\"sentiment-analysis\")\n",
            "classifier(\n",
            "    [\n",
            "        \"I've been waiting for a HuggingFace course my whole life.\",\n",
            "        \"I hate this so much!\",\n",
            "    ]\n",
            ")\n",
            "```\n",
            "\n",
            "and obtained:\n",
            "\n",
            "```python out\n",
            "[{'label': 'POSITIVE', 'score': 0.9598047137260437},\n",
            " {'label': 'NEGATIVE', 'score': 0.9994558095932007}]\n",
            "```\n",
            "\n",
            "As we saw in [Chapter 1](/course/chapter1), this pipeline groups together three steps: preprocessing, passing the inputs through the model, and postprocessing:\n",
            "\n",
            "<div class=\"flex justify-center\">\n",
            "<img class=\"block dark:hidden\" src=\"https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter2/full_nlp_pipeline.svg\" alt=\"The full NLP pipeline: tokenization of text, conversion to IDs, and inference through the Transformer model and the model head.\"/>\n",
            "<img class=\"hidden dark:block\" src=\"https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter2/full_nlp_pipeline-dark.svg\" alt=\"The full NLP pipeline: tokenization of text, conversion to IDs, and inference through the Transformer model and the model head.\"/>\n",
            "</div>\n",
            "\n",
            "Let's quickly go over each of these.\n",
            "\n",
            "## Preprocessing with a tokenizer[[preprocessing-with-a-tokenizer]]\n",
            "\n",
            "Like other neural networks, Transformer models can't process raw text directly, so the first step of our pipeline is to convert the text inputs into numbers that the model can make sense of. To do this we use a *tokenizer*, which will be responsible for:\n",
            "\n",
            "- Splitting the input into words, subwords, or symbols (like punctuation) that are called *tokens*\n",
            "- Mapping each token to an integer\n",
            "- Adding additional inputs that may be useful to the model\n",
            "\n",
            "All this preprocessing needs to be done in exactly the same way as when the model was pretrained, so we first need to download that information from the [Model Hub](https://huggingface.co/models). To do this, we use the `AutoTokenizer` class and its `from_pretrained()` method. Using the checkpoint name of our model, it will automatically fetch the data associated with the model's tokenizer and cache it (so it's only downloaded the first time you run the code below).\n",
            "\n",
            "Since the default checkpoint of the `sentiment-analysis` pipeline is `distilbert-base-uncased-finetuned-sst-2-english` (you can see its model card [here](https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)), we run the following:\n",
            "\n",
            "```python\n",
            "from transformers import AutoTokenizer\n",
            "\n",
            "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
            "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
            "```\n",
            "\n",
            "Once we have the tokenizer, we can directly pass our sentences to it and we'll get back a dictionary that's ready to feed to our model! The only thing left to do is to convert the list of input IDs to tensors.\n",
            "\n",
            "You can use ğŸ¤— Transformers without having to worry about which ML framework is used as a backend; it might be PyTorch or TensorFlow, or Flax for some models. However, Transformer models only accept *tensors* as input. If this is your first time hearing about tensors, you can think of them as NumPy arrays instead. A NumPy array can be a scalar (0D), a vector (1D), a matrix (2D), or have more dimensions. It's effectively a tensor; other ML frameworks' tensors behave similarly, and are usually as simple to instantiate as NumPy arrays.\n",
            "\n",
            "To specify the type of tensors we want to get back (PyTorch, TensorFlow, or plain NumPy), we use the `return_tensors` argument:\n",
            "\n",
            "{#if fw === 'pt'}\n",
            "```python\n",
            "raw_inputs = [\n",
            "    \"I've been waiting for a HuggingFace course my whole life.\",\n",
            "    \"I hate this so much!\",\n",
            "]\n",
            "inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"pt\")\n",
            "print(inputs)\n",
            "```\n",
            "{:else}\n",
            "```python\n",
            "raw_inputs = [\n",
            "    \"I've been waiting for a HuggingFace course my whole life.\",\n",
            "    \"I hate this so much!\",\n",
            "]\n",
            "inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"tf\")\n",
            "print(inputs)\n",
            "```\n",
            "{/if}\n",
            "\n",
            "Don't worry about padding and truncation just yet; we'll explain those later. The main things to remember here are that you can pass one sentence or a list of sentences, as well as specifying the type of tensors you want to get back (if no type is passed, you will get a list of lists as a result).\n",
            "\n",
            "{#if fw === 'pt'}\n",
            "\n",
            "Here's what the results look like as PyTorch tensors:\n",
            "\n",
            "```python out\n",
            "{\n",
            "    'input_ids': tensor([\n",
            "        [  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172, 2607,  2026,  2878,  2166,  1012,   102],\n",
            "        [  101,  1045,  5223,  2023,  2061,  2172,   999,   102,     0,     0,     0,     0,     0,     0,     0,     0]\n",
            "    ]), \n",
            "    'attention_mask': tensor([\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "    ])\n",
            "}\n",
            "```\n",
            "{:else}\n",
            "\n",
            "Here's what the results look like as TensorFlow tensors:\n",
            "\n",
            "```python out\n",
            "{\n",
            "    'input_ids': <tf.Tensor: shape=(2, 16), dtype=int32, numpy=\n",
            "        array([\n",
            "            [  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,  2607,  2026,  2878,  2166,  1012,   102],\n",
            "            [  101,  1045,  5223,  2023,  2061,  2172,   999,   102,     0,     0,     0,     0,     0,     0,     0,     0]\n",
            "        ], dtype=int32)>, \n",
            "    'attention_mask': <tf.Tensor: shape=(2, 16), dtype=int32, numpy=\n",
            "        array([\n",
            "            [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "            [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "        ], dtype=int32)>\n",
            "}\n",
            "```\n",
            "{/if}\n",
            "\n",
            "The output itself is a dictionary containing two keys, `input_ids` and `attention_mask`. `input_ids` contains two rows of integers (one for each sentence) that are the unique identifiers of the tokens in each sentence. We'll explain what the `attention_mask` is later in this chapter. \n",
            "\n",
            "## Going through the model[[going-through-the-model]]\n",
            "\n",
            "{#if fw === 'pt'}\n",
            "We can download our pretrained model the same way we did with our tokenizer. ğŸ¤— Transformers provides an `AutoModel` class which also has a `from_pretrained()` method:\n",
            "\n",
            "```python\n",
            "from transformers import AutoModel\n",
            "\n",
            "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
            "model = AutoModel.from_pretrained(checkpoint)\n",
            "```\n",
            "{:else}\n",
            "We can download our pretrained model the same way we did with our tokenizer. ğŸ¤— Transformers provides an `TFAutoModel` class which also has a `from_pretrained` method:\n",
            "\n",
            "```python\n",
            "from transformers import TFAutoModel\n",
            "\n",
            "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
            "model = TFAutoModel.from_pretrained(checkpoint)\n",
            "```\n",
            "{/if}\n",
            "\n",
            "In this code snippet, we have downloaded the same checkpoint we used in our pipeline before (it should actually have been cached already) and instantiated a model with it.\n",
            "\n",
            "This architecture contains only the base Transformer module: given some inputs, it outputs what we'll call *hidden states*, also known as *features*. For each model input, we'll retrieve a high-dimensional vector representing the **contextual understanding of that input by the Transformer model**.\n",
            "\n",
            "If this doesn't make sense, don't worry about it. We'll explain it all later.\n",
            "\n",
            "While these hidden states can be useful on their own, they're usually inputs to another part of the model, known as the *head*. In [Chapter 1](/course/chapter1), the different tasks could have been performed with the same architecture, but each of these tasks will have a different head associated with it.\n",
            "\n",
            "### A high-dimensional vector?[[a-high-dimensional-vector]]\n",
            "\n",
            "The vector output by the Transformer module is usually large. It generally has three dimensions:\n",
            "\n",
            "- **Batch size**: The number of sequences processed at a time (2 in our example).\n",
            "- **Sequence length**: The length of the numerical representation of the sequence (16 in our example).\n",
            "- **Hidden size**: The vector dimension of each model input.\n",
            "\n",
            "It is said to be \"high dimensional\" because of the last value. The hidden size can be very large (768 is common for smaller models, and in larger models this can reach 3072 or more).\n",
            "\n",
            "We can see this if we feed the inputs we preprocessed to our model:\n",
            "\n",
            "{#if fw === 'pt'}\n",
            "```python\n",
            "outputs = model(**inputs)\n",
            "print(outputs.last_hidden_state.shape)\n",
            "```\n",
            "\n",
            "```python out\n",
            "torch.Size([2, 16, 768])\n",
            "```\n",
            "{:else}\n",
            "```py\n",
            "outputs = model(inputs)\n",
            "print(outputs.last_hidden_state.shape)\n",
            "```\n",
            "\n",
            "```python out\n",
            "(2, 16, 768)\n",
            "```\n",
            "{/if}\n",
            "\n",
            "Note that the outputs of ğŸ¤— Transformers models behave like `namedtuple`s or dictionaries. You can access the elements by attributes (like we did) or by key (`outputs[\"last_hidden_state\"]`), or even by index if you know exactly where the thing you are looking for is (`outputs[0]`).\n",
            "\n",
            "### Model heads: Making sense out of numbers[[model-heads-making-sense-out-of-numbers]]\n",
            "\n",
            "The model heads take the high-dimensional vector of hidden states as input and project them onto a different dimension. They are usually composed of one or a few linear layers:\n",
            "\n",
            "<div class=\"flex justify-center\">\n",
            "<img class=\"block dark:hidden\" src=\"https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter2/transformer_and_head.svg\" alt=\"A Transformer network alongside its head.\"/>\n",
            "<img class=\"hidden dark:block\" src=\"https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter2/transformer_and_head-dark.svg\" alt=\"A Transformer network alongside its head.\"/>\n",
            "</div>\n",
            "\n",
            "The output of the Transformer model is sent directly to the model head to be processed.\n",
            "\n",
            "In this diagram, the model is represented by its embeddings layer and the subsequent layers. The embeddings layer converts each input ID in the tokenized input into a vector that represents the associated token. The subsequent layers manipulate those vectors using the attention mechanism to produce the final representation of the sentences.\n",
            "\n",
            "There are many different architectures available in ğŸ¤— Transformers, with each one designed around tackling a specific task. Here is a non-exhaustive list:\n",
            "\n",
            "- `*Model` (retrieve the hidden states)\n",
            "- `*ForCausalLM`\n",
            "- `*ForMaskedLM`\n",
            "- `*ForMultipleChoice`\n",
            "- `*ForQuestionAnswering`\n",
            "- `*ForSequenceClassification`\n",
            "- `*ForTokenClassification`\n",
            "- and others ğŸ¤—\n",
            "\n",
            "{#if fw === 'pt'}\n",
            "For our example, we will need a model with a sequence classification head (to be able to classify the sentences as positive or negative). So, we won't actually use the `AutoModel` class, but `AutoModelForSequenceClassification`:\n",
            "\n",
            "```python\n",
            "from transformers import AutoModelForSequenceClassification\n",
            "\n",
            "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
            "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
            "outputs = model(**inputs)\n",
            "```\n",
            "{:else}\n",
            "For our example, we will need a model with a sequence classification head (to be able to classify the sentences as positive or negative). So, we won't actually use the `TFAutoModel` class, but `TFAutoModelForSequenceClassification`:\n",
            "\n",
            "```python\n",
            "from transformers import TFAutoModelForSequenceClassification\n",
            "\n",
            "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
            "model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
            "outputs = model(inputs)\n",
            "```\n",
            "{/if}\n",
            "\n",
            "Now if we look at the shape of our outputs, the dimensionality will be much lower: the model head takes as input the high-dimensional vectors we saw before, and outputs vectors containing two values (one per label):\n",
            "\n",
            "```python\n",
            "print(outputs.logits.shape)\n",
            "```\n",
            "\n",
            "{#if fw === 'pt'}\n",
            "```python out\n",
            "torch.Size([2, 2])\n",
            "```\n",
            "{:else}\n",
            "```python out\n",
            "(2, 2)\n",
            "```\n",
            "{/if}\n",
            "\n",
            "Since we have just two sentences and two labels, the result we get from our model is of shape 2 x 2.\n",
            "\n",
            "## Postprocessing the output[[postprocessing-the-output]]\n",
            "\n",
            "The values we get as output from our model don't necessarily make sense by themselves. Let's take a look:\n",
            "\n",
            "```python\n",
            "print(outputs.logits)\n",
            "```\n",
            "\n",
            "{#if fw === 'pt'}\n",
            "```python out\n",
            "tensor([[-1.5607,  1.6123],\n",
            "        [ 4.1692, -3.3464]], grad_fn=<AddmmBackward>)\n",
            "```\n",
            "{:else}\n",
            "```python out\n",
            "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
            "    array([[-1.5606991,  1.6122842],\n",
            "           [ 4.169231 , -3.3464472]], dtype=float32)>\n",
            "```\n",
            "{/if}\n",
            "\n",
            "Our model predicted `[-1.5607, 1.6123]` for the first sentence and `[ 4.1692, -3.3464]` for the second one. Those are not probabilities but *logits*, the raw, unnormalized scores outputted by the last layer of the model. To be converted to probabilities, they need to go through a [SoftMax](https://en.wikipedia.org/wiki/Softmax_function) layer (all ğŸ¤— Transformers models output the logits, as the loss function for training will generally fuse the last activation function, such as SoftMax, with the actual loss function, such as cross entropy):\n",
            "\n",
            "{#if fw === 'pt'}\n",
            "```py\n",
            "import torch\n",
            "\n",
            "predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
            "print(predictions)\n",
            "```\n",
            "{:else}\n",
            "```py\n",
            "import tensorflow as tf\n",
            "\n",
            "predictions = tf.math.softmax(outputs.logits, axis=-1)\n",
            "print(predictions)\n",
            "```\n",
            "{/if}\n",
            "\n",
            "{#if fw === 'pt'}\n",
            "```python out\n",
            "tensor([[4.0195e-02, 9.5980e-01],\n",
            "        [9.9946e-01, 5.4418e-04]], grad_fn=<SoftmaxBackward>)\n",
            "```\n",
            "{:else}\n",
            "```python out\n",
            "tf.Tensor(\n",
            "[[4.01951671e-02 9.59804833e-01]\n",
            " [9.9945587e-01 5.4418424e-04]], shape=(2, 2), dtype=float32)\n",
            "```\n",
            "{/if}\n",
            "\n",
            "Now we can see that the model predicted `[0.0402, 0.9598]` for the first sentence and `[0.9995,  0.0005]` for the second one. These are recognizable probability scores.\n",
            "\n",
            "To get the labels corresponding to each position, we can inspect the `id2label` attribute of the model config (more on this in the next section):\n",
            "\n",
            "```python\n",
            "model.config.id2label\n",
            "```\n",
            "\n",
            "```python out\n",
            "{0: 'NEGATIVE', 1: 'POSITIVE'}\n",
            "```\n",
            "\n",
            "Now we can conclude that the model predicted the following:\n",
            " \n",
            "- First sentence: NEGATIVE: 0.0402, POSITIVE: 0.9598\n",
            "- Second sentence: NEGATIVE: 0.9995, POSITIVE: 0.0005\n",
            "\n",
            "We have successfully reproduced the three steps of the pipeline: preprocessing with tokenizers, passing the inputs through the model, and postprocessing! Now let's take some time to dive deeper into each of those steps.\n",
            "\n",
            "<Tip>\n",
            "\n",
            "âœï¸ **Try it out!** Choose two (or more) texts of your own and run them through the `sentiment-analysis` pipeline. Then replicate the steps you saw here yourself and check that you obtain the same results!\n",
            "\n",
            "</Tip>\n",
            "Document 4------------------------------------------------------------\n",
            "Gradio Demo: ner_pipeline\n",
            "\n",
            "\n",
            "```\n",
            "!pip install -q gradio torch transformers\n",
            "```\n",
            "\n",
            "\n",
            "```\n",
            "from transformers import pipeline\n",
            "\n",
            "import gradio as gr\n",
            "\n",
            "ner_pipeline = pipeline(\"ner\")\n",
            "\n",
            "examples = [\n",
            "    \"Does Chicago have any stores and does Joe live here?\",\n",
            "]\n",
            "\n",
            "def ner(text):\n",
            "    output = ner_pipeline(text)\n",
            "    return {\"text\": text, \"entities\": output}    \n",
            "\n",
            "demo = gr.Interface(ner,\n",
            "             gr.Textbox(placeholder=\"Enter sentence here...\"), \n",
            "             gr.HighlightedText(),\n",
            "             examples=examples)\n",
            "\n",
            "if __name__ == \"__main__\":\n",
            "    demo.launch()\n",
            "\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ğ’Ñ–Ğ´Ğ¿Ğ¾Ğ²Ñ–Ğ´ÑŒ Ğ¿Ñ–ÑĞ»Ñ Ğ·Ğ¼Ñ–Ğ½Ğ¸ ĞµĞ¼Ğ±ĞµĞ´Ñ–Ğ½Ğ³ Ğ¼Ğ¾Ğ´ĞµĞ»Ñ– Ğ½Ğ° sentence-transformers/bert-base-nli-stsb-mean-tokens"
      ],
      "metadata": {
        "id": "xzj8CFzGe7dS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"==================================Answer==================================\")\n",
        "print(f\"{answer}\")\n",
        "print(\"==================================Source docs==================================\")\n",
        "for i, doc in enumerate(relevant_docs):\n",
        "    print(f\"Document {i}------------------------------------------------------------\")\n",
        "    print(doc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90RSlTOcdeMM",
        "outputId": "d3cc4120-1d5b-4851-ba43-2f79f73ac829"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================Answer==================================\n",
            "Based on the provided context, here's how to create a pipeline object using the `DiffusionPipeline` class from the `diffusers` module in the `Transformers` library:\n",
            "\n",
            "1. First, import the required classes from the `diffusers` and `transformers` modules:\n",
            "\n",
            "   ```python\n",
            "   from diffusers import (\n",
            "       UNet2DConditionModel,\n",
            "       AutoencoderKL,\n",
            "       DDIMScheduler,\n",
            "       StableDiffusionPipeline,\n",
            "   )\n",
            "   from transformers import CLIPTextModel, CLIPTextConfig, CLIPTokenizer\n",
            "   ```\n",
            "\n",
            "2. Initialize the components of your pipeline, such as the diffusion model, autoencoder, scheduler, and text encoder:\n",
            "\n",
            "   ```python\n",
            "   # Initialize diffusion model\n",
            "   diffusion_model = UNet2DConditionModel.from_pretrained(\"CompVis/stable-diffusion-v1-4\")\n",
            "\n",
            "   # Initialize autoencoder\n",
            "   autoencoder = AutoencoderKL.from_pretrained(\"CompVis/stable-diffusion-v1-4\")\n",
            "\n",
            "   # Initialize scheduler\n",
            "   scheduler = DDIMScheduler.from_config(diffusion_model.config.get(\"scheduler\"))\n",
            "\n",
            "   # Initialize text encoder\n",
            "   text_encoder = CLIPTextModel.from_pretrained(\"openai/clip\").to(device)\n",
            "   text_config = CLIPTextConfig.from_pretrained(\"openai/clip\")\n",
            "   text_tokenizer = CLIPTokenizer.from_pretrained(\"openai/clip\")\n",
            "   ```\n",
            "\n",
            "3. Create the pipeline object by passing the initialized components to the `DiffusionPipeline` constructor:\n",
            "\n",
            "   ```python\n",
            "   # Create pipeline object\n",
            "   pipeline = DiffusionPipeline.from_pretrained(\n",
            "       \"CompVis/stable-diffusion-v1-4\",\n",
            "       custom_pipeline=\"my_pipeline\",\n",
            "       revision=\"fp16\",\n",
            "       scheduler=scheduler,\n",
            "       text_encoder=text_encoder,\n",
            "       leapfrog_steps=True,\n",
            "       torch_dtype=torch_dtype,\n",
            "   ).to(device)\n",
            "   ```\n",
            "\n",
            "   In this example, we're creating a pipeline called `my_pipeline`, which uses the `CompVis\n",
            "==================================Source docs==================================\n",
            "Document 0------------------------------------------------------------\n",
            "# Create a pipeline\n",
            ">>> onnx_translation = pipeline(\"translation_en_to_fr\", model=model, tokenizer=tokenizer, device=\"cuda:0\")\n",
            "Document 1------------------------------------------------------------\n",
            "# How to create a custom pipeline?\n",
            "\n",
            "In this guide, we will see how to create a custom pipeline and share it on the [Hub](hf.co/models) or add it to the\n",
            "ğŸ¤— Transformers library.\n",
            "Document 2------------------------------------------------------------\n",
            "```\n",
            "\n",
            "## Pipeline\n",
            "\n",
            "You can also push an entire pipeline with all it's components to the Hub. For example, initialize the components of a [`StableDiffusionPipeline`] with the parameters you want:\n",
            "\n",
            "```py\n",
            "from diffusers import (\n",
            "    UNet2DConditionModel,\n",
            "    AutoencoderKL,\n",
            "    DDIMScheduler,\n",
            "    StableDiffusionPipeline,\n",
            ")\n",
            "from transformers import CLIPTextModel, CLIPTextConfig, CLIPTokenizer\n",
            "Document 3------------------------------------------------------------\n",
            "# initialize pipeline\n",
            "pipeline = DiffusionPipeline.from_pretrained(\n",
            "    pretrained_model_name_or_path=\"CompVis/stable-diffusion-v1-4\",\n",
            "    custom_pipeline=\"edict_pipeline\",\n",
            "    revision=\"fp16\",\n",
            "    scheduler=scheduler,\n",
            "    text_encoder=text_encoder,\n",
            "    leapfrog_steps=True,\n",
            "    torch_dtype=torch_dtype,\n",
            ").to(device)\n",
            "Document 4------------------------------------------------------------\n",
            "## P\n",
            "\n",
            "### pipeline\n",
            "\n",
            "A pipeline in ğŸ¤— Transformers is an abstraction referring to a series of steps that are executed in a specific order to preprocess and transform data and return a prediction from a model. Some example stages found in a pipeline might be data preprocessing, feature extraction, and normalization.\n",
            "\n",
            "For more details, see [Pipelines for inference](https://huggingface.co/docs/transformers/pipeline_tutorial).\n",
            "\n",
            "### PipelineParallel (PP)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ğ’Ñ–Ğ´Ğ¿Ğ¾Ğ²Ñ–Ğ´Ñ– Ğ¿Ñ–ÑĞ»Ñ Ğ·Ğ¼Ñ–Ğ½Ğ¸ ĞµĞ¼Ğ±ĞµĞ´Ñ–Ğ½Ğ³ Ğ¼Ğ¾Ğ´ĞµĞ»Ñ– Ğ½Ğ° \"Mihaiii/gte-micro\""
      ],
      "metadata": {
        "id": "0p79xbj-N5u4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"==================================Answer==================================\")\n",
        "print(f\"{answer}\")\n",
        "print(\"==================================Source docs==================================\")\n",
        "for i, doc in enumerate(relevant_docs):\n",
        "    print(f\"Document {i}------------------------------------------------------------\")\n",
        "    print(doc)"
      ],
      "metadata": {
        "id": "j8NEl101N5Zc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b15821a-18e1-4e9c-ab08-376cf6cf580d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================Answer==================================\n",
            "To create a pipeline object, follow these steps:\n",
            "\n",
            "1. Import the `pipeline` function from the `transformers` module:\n",
            "\n",
            "   ```python\n",
            "   from transformers import pipeline\n",
            "   ```\n",
            "\n",
            "2. Create a new pipeline object by passing the task you want to use as an argument. For example, to create a pipeline for sentiment analysis, use:\n",
            "\n",
            "   ```python\n",
            "   sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
            "   ```\n",
            "\n",
            "3. You can then pass text to the pipeline object to get its sentiment score:\n",
            "\n",
            "   ```python\n",
            "   result = sentiment_pipeline(\"This is a great product!\")\n",
            "   print(result[\"score\"])\n",
            "   ```\n",
            "\n",
            "4. Other tasks, such as classification, question answering, summarization, and translation, can also be performed using pipelines. Refer to the documentation for more details on how to use them.\n",
            "\n",
            "Note that the exact syntax may vary depending on the framework you are using (PyTorch, TensorFlow, etc.). Consult the documentation for your specific framework for more information.\n",
            "\n",
            "Example:\n",
            "\n",
            "```python\n",
            "# Using PyTorch backend\n",
            "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
            "from transformers import pipeline\n",
            "\n",
            "# Load the BERT base model and tokenizer\n",
            "model = AutoModelForSequenceClassification.from_pretrained('bertbase')\n",
            "tokenizer = AutoTokenizer.from_pretrained('bertbase')\n",
            "\n",
            "# Define the pipeline with the loaded model and tokenizer\n",
            "classifier = pipeline(task=\"classification\", model=model, tokenizer=tokenizer)\n",
            "\n",
            "# Use the pipeline to predict the label of a sample text\n",
            "result = classifier(\"This is a sample text.\")\n",
            "print(result['label'])\n",
            "```\n",
            "\n",
            "In this example, we first load the BERT base model and tokenizer using the `AutoModelForSequenceClassification` and `AutoTokenizer` classes respectively. We then define the pipeline with the loaded model and tokenizer, specifying the \"classification\" task. Finally, we use the pipeline to predict the label of a sample text. Note that we need to install the required dependencies before running this code, such as `transformers`, `torch`, and `torchvision`.\n",
            "==================================Source docs==================================\n",
            "Document 0------------------------------------------------------------\n",
            "Start by creating an instance of [`pipeline`] and specifying a task you want to use it for. In this guide, you'll use the [`pipeline`] for sentiment analysis as an example:\n",
            "\n",
            "```py\n",
            ">>> from transformers import pipeline\n",
            "\n",
            ">>> classifier = pipeline(\"sentiment-analysis\")\n",
            "Document 1------------------------------------------------------------\n",
            "classification pipeline is a more general text-classification pipeline: it allows you to provide the labels you want. Here we want to classify our input text along the labels \"education\", \"politics\" and \"business\". The pipeline successfully recognizes it's more about education than the other labels, with a confidence of 84%. Moving on to other tasks, the text generation pipeline will auto-complete a given prompt. The output is generated with a bit of randomness, so it changes each time you call the generator object on a given prompt. Up until now, we have used the pipeline API with the\n",
            "Document 2------------------------------------------------------------\n",
            "text. The grouped_entities=True argument used is to make the pipeline group together the different words linked to the same entity (such as Hugging and Face here). Another task available with the pipeline API is extractive question answering. Providing a context and a question, the model will identify the span of text in the context containing the answer to the question. Getting short summaries of very long articles is also something the Transformers library can help with, with the summarization pipeline. Finally, the last task supported by the pipeline API is translation. Here we use a French/English model found\n",
            "Document 3------------------------------------------------------------\n",
            "```\n",
            "\n",
            "2. Pass a prompt to the pipeline to generate an image:\n",
            "\n",
            "```py\n",
            "image = pipeline(\n",
            "\t\"stained glass of darth vader, backlight, centered composition, masterpiece, photorealistic, 8k\"\n",
            ").images[0]\n",
            "image\n",
            "Document 4------------------------------------------------------------\n",
            "```\n",
            "</tf>\n",
            "</frameworkcontent>\n",
            "\n",
            "## Pipeline\n",
            "\n",
            "<Youtube id=\"tiZFewofSLM\"/>\n",
            "\n",
            "The [`pipeline`] is the easiest and fastest way to use a pretrained model for inference. You can use the [`pipeline`] out-of-the-box for many tasks across different modalities, some of which are shown in the table below:\n",
            "\n",
            "<Tip>\n",
            "\n",
            "For a complete list of available tasks, check out the [pipeline API reference](./main_classes/pipelines).\n",
            "\n",
            "</Tip>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"==================================Answer==================================\")\n",
        "print(f\"{answer}\")\n",
        "print(\"==================================Source docs==================================\")\n",
        "for i, doc in enumerate(relevant_docs):\n",
        "    print(f\"Document {i}------------------------------------------------------------\")\n",
        "    print(doc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnR_6yMRdB0Q",
        "outputId": "8f0f936b-02db-47b4-a106-7ce90a3fe7b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================Answer==================================\n",
            "To create a pipeline object, follow these steps:\n",
            "\n",
            "1. Import the `pipeline` function from the `transformers` module.\n",
            "\n",
            "2. Create a new pipeline object by passing the task you want to use as a string argument to the `pipeline` function. For example, to create a pipeline for sentiment analysis, you would pass'sentiment-analysis' as the argument.\n",
            "\n",
            "Here's an example:\n",
            "\n",
            "```python\n",
            "from transformers import pipeline\n",
            "\n",
            "# Create a pipeline for sentiment analysis\n",
            "classifier = pipeline(\"sentiment-analysis\")\n",
            "```\n",
            "\n",
            "In this case, the `pipeline` function returns an object that can be used to perform inference on text data using the specified task. You can then pass this object to your application to process text inputs.\n",
            "\n",
            "Note: The exact list of available tasks may vary depending on the specific version of the `transformers` library being used. For a complete list of available tasks, refer to the [pipeline API reference](https://huggingface.co/docs/transformers/latest/main_classes/pipelines.html) provided by Hugging Face.\n",
            "==================================Source docs==================================\n",
            "Document 0------------------------------------------------------------\n",
            "Start by creating an instance of [`pipeline`] and specifying a task you want to use it for. In this guide, you'll use the [`pipeline`] for sentiment analysis as an example:\n",
            "\n",
            "```py\n",
            ">>> from transformers import pipeline\n",
            "\n",
            ">>> classifier = pipeline(\"sentiment-analysis\")\n",
            "Document 1------------------------------------------------------------\n",
            "classification pipeline is a more general text-classification pipeline: it allows you to provide the labels you want. Here we want to classify our input text along the labels \"education\", \"politics\" and \"business\". The pipeline successfully recognizes it's more about education than the other labels, with a confidence of 84%. Moving on to other tasks, the text generation pipeline will auto-complete a given prompt. The output is generated with a bit of randomness, so it changes each time you call the generator object on a given prompt. Up until now, we have used the pipeline API with the\n",
            "Document 2------------------------------------------------------------\n",
            "text. The grouped_entities=True argument used is to make the pipeline group together the different words linked to the same entity (such as Hugging and Face here). Another task available with the pipeline API is extractive question answering. Providing a context and a question, the model will identify the span of text in the context containing the answer to the question. Getting short summaries of very long articles is also something the Transformers library can help with, with the summarization pipeline. Finally, the last task supported by the pipeline API is translation. Here we use a French/English model found\n",
            "Document 3------------------------------------------------------------\n",
            "```\n",
            "\n",
            "2. Pass a prompt to the pipeline to generate an image:\n",
            "\n",
            "```py\n",
            "image = pipeline(\n",
            "\t\"stained glass of darth vader, backlight, centered composition, masterpiece, photorealistic, 8k\"\n",
            ").images[0]\n",
            "image\n",
            "Document 4------------------------------------------------------------\n",
            "```\n",
            "</tf>\n",
            "</frameworkcontent>\n",
            "\n",
            "## Pipeline\n",
            "\n",
            "<Youtube id=\"tiZFewofSLM\"/>\n",
            "\n",
            "The [`pipeline`] is the easiest and fastest way to use a pretrained model for inference. You can use the [`pipeline`] out-of-the-box for many tasks across different modalities, some of which are shown in the table below:\n",
            "\n",
            "<Tip>\n",
            "\n",
            "For a complete list of available tasks, check out the [pipeline API reference](./main_classes/pipelines).\n",
            "\n",
            "</Tip>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"==================================Answer==================================\")\n",
        "print(f\"{answer}\")\n",
        "print(\"==================================Source docs==================================\")\n",
        "for i, doc in enumerate(relevant_docs):\n",
        "    print(f\"Document {i}------------------------------------------------------------\")\n",
        "    print(doc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRvsPhmwcD6H",
        "outputId": "336fe8ce-1b32-45dc-e2bb-dfdeb10f53ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================Answer==================================\n",
            "To create a pipeline object, follow these steps:\n",
            "\n",
            "1. Import the `pipeline` function from the `transformers` module.\n",
            "\n",
            "2. Specify the task you want to perform using the pipeline. For example, to perform sentiment analysis, pass'sentiment-analysis' as the argument to the `pipeline` function.\n",
            "\n",
            "   ```python\n",
            "   from transformers import pipeline\n",
            "\n",
            "   nlp = pipeline(\"sentiment-analysis\")\n",
            "   ```\n",
            "\n",
            "3. Similarly, you can create pipelines for other tasks like classification, question answering, summarization, and translation by passing the corresponding task names as arguments to the `pipeline` function.\n",
            "\n",
            "   ```python\n",
            "   # For classification\n",
            "   from transformers import AutoConfig, AutoModelForSequenceClassification\n",
            "\n",
            "   config = AutoConfig.from_pretrained('your_model')\n",
            "   model = AutoModelForSequenceClassification.from_config(config)\n",
            "\n",
            "   classifier = pipeline(model=model, config=config, task=\"classification\")\n",
            "\n",
            "   # For question answering\n",
            "   from transformers import AutoConfig, AutoModelForQuestionAnsweringRegression\n",
            "\n",
            "   config = AutoConfig.from_pretrained('your_model')\n",
            "   model = AutoModelForQuestionAnsweringRegression.from_config(config)\n",
            "\n",
            "   qa = pipeline(model=model, config=config, task=\"question-answering\")\n",
            "\n",
            "   # For summarization\n",
            "   from transformers import AutoConfig, AutoSummarizer\n",
            "\n",
            "   summarizer = AutoSummarizer.from_pretrained('your_model')\n",
            "\n",
            "   summary = summarizer(input_text)\n",
            "\n",
            "   # For translation\n",
            "   from transformers import AutoTokenizer, AutoModelForTranslation\n",
            "\n",
            "   tokenizer = AutoTokenizer.from_pretrained('your_model')\n",
            "   model = AutoModelForTranslation.from_pretrained('your_model')\n",
            "\n",
            "   translator = pipeline(model=model, tokenizer=tokenizer, task=\"translation\")\n",
            "   ```\n",
            "\n",
            "In all cases, replace 'your_model' with the path to your preferred pretrained model.\n",
            "\n",
            "Note that for tasks like classification and question answering, you may need to define the model and its configuration separately before passing them to the `pipeline` function. This is because these tasks require additional layers\n",
            "==================================Source docs==================================\n",
            "Document 0------------------------------------------------------------\n",
            "Start by creating an instance of [`pipeline`] and specifying a task you want to use it for. In this guide, you'll use the [`pipeline`] for sentiment analysis as an example:\n",
            "\n",
            "```py\n",
            ">>> from transformers import pipeline\n",
            "\n",
            ">>> classifier = pipeline(\"sentiment-analysis\")\n",
            "Document 1------------------------------------------------------------\n",
            "classification pipeline is a more general text-classification pipeline: it allows you to provide the labels you want. Here we want to classify our input text along the labels \"education\", \"politics\" and \"business\". The pipeline successfully recognizes it's more about education than the other labels, with a confidence of 84%. Moving on to other tasks, the text generation pipeline will auto-complete a given prompt. The output is generated with a bit of randomness, so it changes each time you call the generator object on a given prompt. Up until now, we have used the pipeline API with the\n",
            "Document 2------------------------------------------------------------\n",
            "text. The grouped_entities=True argument used is to make the pipeline group together the different words linked to the same entity (such as Hugging and Face here). Another task available with the pipeline API is extractive question answering. Providing a context and a question, the model will identify the span of text in the context containing the answer to the question. Getting short summaries of very long articles is also something the Transformers library can help with, with the summarization pipeline. Finally, the last task supported by the pipeline API is translation. Here we use a French/English model found\n",
            "Document 3------------------------------------------------------------\n",
            "```\n",
            "\n",
            "2. Pass a prompt to the pipeline to generate an image:\n",
            "\n",
            "```py\n",
            "image = pipeline(\n",
            "\t\"stained glass of darth vader, backlight, centered composition, masterpiece, photorealistic, 8k\"\n",
            ").images[0]\n",
            "image\n",
            "Document 4------------------------------------------------------------\n",
            "```\n",
            "</tf>\n",
            "</frameworkcontent>\n",
            "\n",
            "## Pipeline\n",
            "\n",
            "<Youtube id=\"tiZFewofSLM\"/>\n",
            "\n",
            "The [`pipeline`] is the easiest and fastest way to use a pretrained model for inference. You can use the [`pipeline`] out-of-the-box for many tasks across different modalities, some of which are shown in the table below:\n",
            "\n",
            "<Tip>\n",
            "\n",
            "For a complete list of available tasks, check out the [pipeline API reference](./main_classes/pipelines).\n",
            "\n",
            "</Tip>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ğ’Ñ–Ğ´Ğ¿Ğ¾Ğ²Ñ–Ğ´Ñ– Ğ¿Ñ–ÑĞ»Ñ Ğ²Ğ¸ĞºĞ¾Ñ€Ğ¸ÑÑ‚Ğ°Ğ½Ğ½Ñ ÑĞµĞ¼Ğ°Ğ½Ñ‚Ğ¸Ñ‡Ğ½Ğ¸Ñ… Ñ‡Ğ°Ğ½ĞºÑ–Ğ²"
      ],
      "metadata": {
        "id": "a26BJG1XsCuM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"==================================Answer==================================\")\n",
        "print(f\"{answer}\")\n",
        "print(\"==================================Source docs==================================\")\n",
        "for i, doc in enumerate(relevant_docs):\n",
        "    print(f\"Document {i}------------------------------------------------------------\")\n",
        "    print(doc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgqlatgSJy93",
        "outputId": "ed45dc10-95d6-4933-e84f-015b0278a442"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================Answer==================================\n",
            "To create a pipeline object, follow these steps:\n",
            "\n",
            "1. Define a custom pipeline class that inherits from the `Pipeline` class provided by the Transformers library. This class should contain methods for preprocessing the input, running the model forward, and postprocessing the output.\n",
            "\n",
            "2. Register the new pipeline on the Hub by adding it to the `PIPELINE_REGISTRY` dictionary and calling the `save_pretrained` method on a repository. This will save the pipeline, as well as the model and tokenizer, to the repository.\n",
            "\n",
            "3. Share the pipeline on the Hub by pushing the repository to the user's account on the Hub.\n",
            "\n",
            "4. Use the shared pipeline by loading it from the Hub and passing input to it. This can be done by providing the pipeline constructor with the necessary options, such as the model name and any additional arguments.\n",
            "\n",
            "Here's an example implementation:\n",
            "\n",
            "```python\n",
            "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Pipeline\n",
            "from transformers.pipelines import PIPELINE_REGISTRY\n",
            "from transformers.utils import logging\n",
            "\n",
            "logging.set_verbosity_error()\n",
            "\n",
            "class CustomPipeline(Pipeline):\n",
            "    def __init__(self, model: str, tokenizer: str):\n",
            "        self.model = AutoModelForSequenceClassification.from_pretrained(model)\n",
            "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer)\n",
            "\n",
            "    def preprocess(self, inputs: Dict[str, Union[str, List[str], np.ndarray]]):\n",
            "        return self.tokenizer(inputs[\"input_ids\"], padding=True, truncation=True, return_tensors=\"tf\")\n",
            "\n",
            "    def _forward(self, model_inputs: Dict[str, Union[int, float, bool, str, List[Any], np.ndarray]]) -> Dict[str, Union[float, int]]:\n",
            "        return self.model(**model_inputs)\n",
            "\n",
            "    def postprocess(self, model_outputs: Dict[str, Union[float, int]]):\n",
            "        logits = model_outputs[\"sequence\"]\n",
            "        probs = tf.nn.softmax(logits)\n",
            "        labels = [\"negative\", \"pos\n",
            "==================================Source docs==================================\n",
            "Document 0------------------------------------------------------------\n",
            "Inference pipelines with the ONNX Runtime accelerator\n",
            "\n",
            "The [`~pipelines.pipeline`] function makes it simple to use models from the [Model Hub](https://huggingface.co/models)\n",
            "for accelerated inference on a variety of tasks such as text classification, question answering and image classification.\n",
            "\n",
            "<Tip>\n",
            "\n",
            "You can also use the\n",
            "[pipeline()](https://huggingface.co/docs/transformers/main/en/main_classes/pipelines#pipelines) function from\n",
            "Transformers and provide your Optimum model class.\n",
            "\n",
            "</Tip>\n",
            "\n",
            "Currently the supported tasks are:\n",
            "\n",
            "* `feature-extraction`\n",
            "* `text-classification`\n",
            "* `token-classification`\n",
            "* `question-answering`\n",
            "* `zero-shot-classification`\n",
            "* `text-generation`\n",
            "* `text2text-generation`\n",
            "* `summarization`\n",
            "* `translation`\n",
            "* `image-classification`\n",
            "* `automatic-speech-recognition`\n",
            "* `image-to-text`\n",
            "\n",
            "## Optimum pipeline usage\n",
            "\n",
            "While each task has an associated pipeline class, it is simpler to use the general [`~pipelines.pipeline`] function which wraps all the task-specific pipelines in one object.\n",
            "The [`~pipelines.pipeline`] function automatically loads a default model and tokenizer/feature-extractor capable of performing inference for your task.\n",
            "\n",
            "1. Start by creating a pipeline by specifying an inference task:\n",
            "\n",
            "```python\n",
            ">>> from optimum.pipelines import pipeline\n",
            "\n",
            ">>> classifier = pipeline(task=\"text-classification\", accelerator=\"ort\")\n",
            "```\n",
            "\n",
            "2. Pass your input text/image to the [`~pipelines.pipeline`] function:\n",
            "\n",
            "```python\n",
            ">>> classifier(\"I like you. I love you.\")  # doctest: +IGNORE_RESULT\n",
            "[{'label': 'POSITIVE', 'score': 0.9998838901519775}]\n",
            "```\n",
            "\n",
            "_Note: The default models used in the [`~pipelines.pipeline`] function are not optimized for inference or quantized, so there won't be a performance improvement compared to their PyTorch counterparts._\n",
            "\n",
            "### Using vanilla Transformers model and converting to ONNX\n",
            "\n",
            "The [`~pipelines.pipeline`] function accepts any supported model from the [Hugging Face Hub](https://huggingface.co/models).\n",
            "There are tags on the Model Hub that allow you to filter for a model you'd like to use for your task.\n",
            "\n",
            "<Tip>\n",
            "\n",
            "To be able to load the model with the ONNX Runtime backend, the export to ONNX needs to be supported for the considered architecture.\n",
            "\n",
            "You can check the list of supported architectures [here](https://huggingface.co/docs/optimum/exporters/onnx/overview#overview).\n",
            "\n",
            "</Tip>\n",
            "\n",
            "Once you have picked an appropriate model, you can create the [`~pipelines.pipeline`] by specifying the model repo:\n",
            "\n",
            "```python\n",
            ">>> from optimum.pipelines import pipeline\n",
            "\n",
            "# The model will be loaded to an ORTModelForQuestionAnswering.\n",
            ">>> onnx_qa = pipeline(\"question-answering\", model=\"deepset/roberta-base-squad2\", accelerator=\"ort\")\n",
            ">>> question = \"What's my name?\"\n",
            ">>> context = \"My name is Philipp and I live in Nuremberg.\"\n",
            "\n",
            ">>> pred = onnx_qa(question=question, context=context)\n",
            "```\n",
            "\n",
            "It is also possible to load it with the `from_pretrained(model_name_or_path, export=True)`\n",
            "method associated with the `ORTModelForXXX` class.\n",
            "\n",
            "For example, here is how you can load the [`~onnxruntime.ORTModelForQuestionAnswering`] class for question answering:\n",
            "\n",
            "```python\n",
            ">>> from transformers import AutoTokenizer\n",
            ">>> from optimum.onnxruntime import ORTModelForQuestionAnswering\n",
            ">>> from optimum.pipelines import pipeline\n",
            "\n",
            ">>> tokenizer = AutoTokenizer.from_pretrained(\"deepset/roberta-base-squad2\")\n",
            "\n",
            ">>> # Loading the PyTorch checkpoint and converting to the ONNX format by providing\n",
            ">>> # export=True\n",
            ">>> model = ORTModelForQuestionAnswering.from_pretrained(\n",
            "...     \"deepset/roberta-base-squad2\",\n",
            "...     export=True\n",
            "... )\n",
            "\n",
            ">>> onnx_qa = pipeline(\"question-answering\", model=model, tokenizer=tokenizer, accelerator=\"ort\")\n",
            ">>> question = \"What's my name?\"\n",
            ">>> context = \"My name is Philipp and I live in Nuremberg.\"\n",
            "\n",
            ">>> pred = onnx_qa(question=question, context=context)\n",
            "```\n",
            "\n",
            "### Using Optimum models\n",
            "\n",
            "The [`~pipelines.pipeline`] function is tightly integrated with the [Hugging Face Hub](https://huggingface.co/models) and can load ONNX models directly.\n",
            "\n",
            "```python\n",
            ">>> from optimum.pipelines import pipeline\n",
            "\n",
            ">>> onnx_qa = pipeline(\"question-answering\", model=\"optimum/roberta-base-squad2\", accelerator=\"ort\")\n",
            ">>> question = \"What's my name?\"\n",
            ">>> context = \"My name is Philipp and I live in Nuremberg.\"\n",
            "\n",
            ">>> pred = onnx_qa(question=question, context=context)\n",
            "```\n",
            "\n",
            "It is also possible to load it with the `from_pretrained(model_name_or_path)`\n",
            "method associated with the `ORTModelForXXX` class.\n",
            "\n",
            "For example, here is how you can load the [`~onnxruntime.ORTModelForQuestionAnswering`] class for question answering:\n",
            "\n",
            "```python\n",
            ">>> from transformers import AutoTokenizer\n",
            ">>> from optimum.onnxruntime import ORTModelForQuestionAnswering\n",
            ">>> from optimum.pipelines import pipeline\n",
            "\n",
            ">>> tokenizer = AutoTokenizer.from_pretrained(\"optimum/roberta-base-squad2\")\n",
            "\n",
            ">>> # Loading directly an ONNX model from a model repo.\n",
            ">>> model = ORTModelForQuestionAnswering.from_pretrained(\"optimum/roberta-base-squad2\")\n",
            "\n",
            ">>> onnx_qa = pipeline(\"question-answering\", model=model, tokenizer=tokenizer, accelerator=\"ort\")\n",
            ">>> question = \"What's my name?\"\n",
            ">>> context = \"My name is Philipp and I live in Nuremberg.\"\n",
            "\n",
            ">>> pred = onnx_qa(question=question, context=context)\n",
            "```\n",
            "\n",
            "\n",
            "## Optimizing and quantizing in pipelines\n",
            "\n",
            "The [`~pipelines.pipeline`] function can not only run inference on vanilla ONNX Runtime checkpoints - you can also use\n",
            "checkpoints optimized with the [`~optimum.onnxruntime.ORTQuantizer`] and the [`~optimum.onnxruntime.ORTOptimizer`].\n",
            "\n",
            "Below you can find two examples of how you could use the [`~optimum.onnxruntime.ORTOptimizer`] and the\n",
            "[`~optimum.onnxruntime.ORTQuantizer`] to optimize/quantize your model and use it for inference afterwards.\n",
            "\n",
            "### Quantizing with the `ORTQuantizer`\n",
            "\n",
            "```python\n",
            ">>> from transformers import AutoTokenizer\n",
            ">>> from optimum.onnxruntime import (\n",
            "...     AutoQuantizationConfig,\n",
            "...     ORTModelForSequenceClassification,\n",
            "...     ORTQuantizer\n",
            "... )\n",
            ">>> from optimum.pipelines import pipeline\n",
            "\n",
            ">>> # Load the tokenizer and export the model to the ONNX format\n",
            ">>> model_id = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
            ">>> save_dir = \"distilbert_quantized\"\n",
            "\n",
            ">>> model = ORTModelForSequenceClassification.from_pretrained(model_id, export=True)\n",
            "\n",
            ">>> # Load the quantization configuration detailing the quantization we wish to apply\n",
            ">>> qconfig = AutoQuantizationConfig.avx512_vnni(is_static=False, per_channel=True)\n",
            ">>> quantizer = ORTQuantizer.from_pretrained(model)\n",
            "\n",
            ">>> # Apply dynamic quantization and save the resulting model\n",
            ">>> quantizer.quantize(save_dir=save_dir, quantization_config=qconfig)  # doctest: +IGNORE_RESULT\n",
            "\n",
            ">>> # Load the quantized model from a local repository\n",
            ">>> model = ORTModelForSequenceClassification.from_pretrained(save_dir)\n",
            "\n",
            ">>> # Create the transformers pipeline\n",
            ">>> onnx_clx = pipeline(\"text-classification\", model=model, accelerator=\"ort\")\n",
            ">>> text = \"I like the new ORT pipeline\"\n",
            ">>> pred = onnx_clx(text)\n",
            ">>> print(pred)  # doctest: +IGNORE_RESULT\n",
            ">>> # [{'label': 'POSITIVE', 'score': 0.9974810481071472}]\n",
            "\n",
            ">>> # Save and push the model to the hub (in practice save_dir could be used here instead)\n",
            ">>> model.save_pretrained(\"new_path_for_directory\")\n",
            ">>> model.push_to_hub(\"new_path_for_directory\", repository_id=\"my-onnx-repo\", use_auth_token=True)  # doctest: +SKIP\n",
            "```\n",
            "\n",
            "### Optimizing with `ORTOptimizer`\n",
            "\n",
            "```python\n",
            ">>> from transformers import AutoTokenizer\n",
            ">>> from optimum.onnxruntime import (\n",
            "...     AutoOptimizationConfig,\n",
            "...     ORTModelForSequenceClassification,\n",
            "...     ORTOptimizer\n",
            "... )\n",
            ">>> from optimum.onnxruntime.configuration import OptimizationConfig\n",
            ">>> from optimum.pipelines import pipeline\n",
            "\n",
            ">>> # Load the tokenizer and export the model to the ONNX format\n",
            ">>> model_id = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
            ">>> save_dir = \"distilbert_optimized\"\n",
            "\n",
            ">>> tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
            ">>> model = ORTModelForSequenceClassification.from_pretrained(model_id, export=True)\n",
            "\n",
            ">>> # Load the optimization configuration detailing the optimization we wish to apply\n",
            ">>> optimization_config = AutoOptimizationConfig.O3()\n",
            ">>> optimizer = ORTOptimizer.from_pretrained(model)\n",
            "\n",
            ">>> optimizer.optimize(save_dir=save_dir, optimization_config=optimization_config)  # doctest: +IGNORE_RESULT\n",
            "\n",
            "# Load the optimized model from a local repository\n",
            ">>> model = ORTModelForSequenceClassification.from_pretrained(save_dir)\n",
            "\n",
            "# Create the transformers pipeline\n",
            ">>> onnx_clx = pipeline(\"text-classification\", model=model, accelerator=\"ort\")\n",
            ">>> text = \"I like the new ORT pipeline\"\n",
            ">>> pred = onnx_clx(text)\n",
            ">>> print(pred)  # doctest: +IGNORE_RESULT\n",
            ">>> # [{'label': 'POSITIVE', 'score': 0.9973127245903015}]\n",
            "\n",
            "# Save and push the model to the hub\n",
            ">>> tokenizer.save_pretrained(\"new_path_for_directory\")  # doctest: +IGNORE_RESULT\n",
            ">>> model.save_pretrained(\"new_path_for_directory\")\n",
            ">>> model.push_to_hub(\"new_path_for_directory\", repository_id=\"my-onnx-repo\", use_auth_token=True)  # doctest: +SKIP\n",
            "```\n",
            "Document 1------------------------------------------------------------\n",
            "he pipeline function. The pipeline function is the most high-level API of the Transformers library. It regroups together all the steps to go from raw texts to usable predictions. The model used is at the core of a pipeline, but the pipeline also include all the necessary pre-processing (since the model does not expect texts, but numbers) as well as some post-processing to make the output of the model human-readable. Let's look at a first example with the sentiment analysis pipeline. This pipeline performs text classification on a given input, and determines if it's positive or negative. Here, it attributed the positive label on the given text, with a confidence of 95%. You can pass multiple texts to the same pipeline, which will be processed and passed through the model together, as a batch. The output is a list of individual results, in the same order as the input texts. Here we find the same label and score for the first text, and the second text is judged positive with a confidence of 99.99%. The zero-shot classification pipeline is a more general text-classification pipeline: it allows you to provide the labels you want. Here we want to classify our input text along the labels \"education\", \"politics\" and \"business\". The pipeline successfully recognizes it's more about education than the other labels, with a confidence of 84%. Moving on to other tasks, the text generation pipeline will auto-complete a given prompt. The output is generated with a bit of randomness, so it changes each time you call the generator object on a given prompt. Up until now, we have used the pipeline API with the default model associated to each task, but you can use it with any model that has been pretrained or fine-tuned on this task. Going on the model hub (huggingface.co/models), you can filter the available models by task. The default model used in our previous example was gpt2, but there are many more models available, and not just in English! Let's go back to the text generation pipeline and load it with another model, distilgpt2. This is a lighter version of gpt2 created by the Hugging Face team. When applying the pipeline to a given prompt, we can specify several arguments, such as the maximum length of the generated texts, or the number of sentences we want to return (since there is some randomness in the generation). Generating text by guessing the next word in a sentence was the pretraining objective of GPT-2, the fill mask pipeline is the pretraining objective of BERT, which is to guess the value of masked word. In this case, we ask the two most likely values for the missing words (according to the model) and get mathematical or computational as possible answers. Another task Transformers model can perform is to classify each word in the sentence instead of the sentence as a whole. One example of this is Named Entity Recognition, which is the task of identifying entities, such as persons, organizations or locations in a sentence. Here, the model correctly finds the person (Sylvain), the organization (Hugging Face) as well as the location (Brooklyn) inside the input text. The grouped_entities=True argument used is to make the pipeline group together the different words linked to the same entity (such as Hugging and Face here). Another task available with the pipeline API is extractive question answering. Providing a context and a question, the model will identify the span of text in the context containing the answer to the question. Getting short summaries of very long articles is also something the Transformers library can help with, with the summarization pipeline. Finally, the last task supported by the pipeline API is translation. Here we use a French/English model found on the model hub to get the English version of our input text. Here is a brief summary of all the tasks we looked into in this video. Try then out through the inference widgets in the model hub!\n",
            "Document 2------------------------------------------------------------\n",
            "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n",
            "\n",
            "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with\n",
            "the License. You may obtain a copy of the License at\n",
            "\n",
            "http://www.apache.org/licenses/LICENSE-2.0\n",
            "\n",
            "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on\n",
            "an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the\n",
            "specific language governing permissions and limitations under the License.\n",
            "\n",
            "âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be\n",
            "rendered properly in your Markdown viewer.\n",
            "\n",
            "-->\n",
            "\n",
            "# Pipelines\n",
            "\n",
            "The pipelines are a great and easy way to use models for inference. These pipelines are objects that abstract most of\n",
            "the complex code from the library, offering a simple API dedicated to several tasks, including Named Entity\n",
            "Recognition, Masked Language Modeling, Sentiment Analysis, Feature Extraction and Question Answering. See the\n",
            "[task summary](../task_summary) for examples of use.\n",
            "\n",
            "There are two categories of pipeline abstractions to be aware about:\n",
            "\n",
            "- The [`pipeline`] which is the most powerful object encapsulating all other pipelines.\n",
            "- Task-specific pipelines are available for [audio](#audio), [computer vision](#computer-vision), [natural language processing](#natural-language-processing), and [multimodal](#multimodal) tasks.\n",
            "\n",
            "## The pipeline abstraction\n",
            "\n",
            "The *pipeline* abstraction is a wrapper around all the other available pipelines. It is instantiated as any other\n",
            "pipeline but can provide additional quality of life.\n",
            "\n",
            "Simple call on one item:\n",
            "\n",
            "```python\n",
            ">>> pipe = pipeline(\"text-classification\")\n",
            ">>> pipe(\"This restaurant is awesome\")\n",
            "[{'label': 'POSITIVE', 'score': 0.9998743534088135}]\n",
            "```\n",
            "\n",
            "If you want to use a specific model from the [hub](https://huggingface.co) you can ignore the task if the model on\n",
            "the hub already defines it:\n",
            "\n",
            "```python\n",
            ">>> pipe = pipeline(model=\"roberta-large-mnli\")\n",
            ">>> pipe(\"This restaurant is awesome\")\n",
            "[{'label': 'NEUTRAL', 'score': 0.7313136458396912}]\n",
            "```\n",
            "\n",
            "To call a pipeline on many items, you can call it with a *list*.\n",
            "\n",
            "```python\n",
            ">>> pipe = pipeline(\"text-classification\")\n",
            ">>> pipe([\"This restaurant is awesome\", \"This restaurant is awful\"])\n",
            "[{'label': 'POSITIVE', 'score': 0.9998743534088135},\n",
            " {'label': 'NEGATIVE', 'score': 0.9996669292449951}]\n",
            "```\n",
            "\n",
            "To iterate over full datasets it is recommended to use a `dataset` directly. This means you don't need to allocate\n",
            "the whole dataset at once, nor do you need to do batching yourself. This should work just as fast as custom loops on\n",
            "GPU. If it doesn't don't hesitate to create an issue.\n",
            "\n",
            "```python\n",
            "import datasets\n",
            "from transformers import pipeline\n",
            "from transformers.pipelines.pt_utils import KeyDataset\n",
            "from tqdm.auto import tqdm\n",
            "\n",
            "pipe = pipeline(\"automatic-speech-recognition\", model=\"facebook/wav2vec2-base-960h\", device=0)\n",
            "dataset = datasets.load_dataset(\"superb\", name=\"asr\", split=\"test\")\n",
            "\n",
            "# KeyDataset (only *pt*) will simply return the item in the dict returned by the dataset item\n",
            "# as we're not interested in the *target* part of the dataset. For sentence pair use KeyPairDataset\n",
            "for out in tqdm(pipe(KeyDataset(dataset, \"file\"))):\n",
            "    print(out)\n",
            "    # {\"text\": \"NUMBER TEN FRESH NELLY IS WAITING ON YOU GOOD NIGHT HUSBAND\"}\n",
            "    # {\"text\": ....}\n",
            "    # ....\n",
            "```\n",
            "\n",
            "For ease of use, a generator is also possible:\n",
            "\n",
            "\n",
            "```python\n",
            "from transformers import pipeline\n",
            "\n",
            "pipe = pipeline(\"text-classification\")\n",
            "\n",
            "\n",
            "def data():\n",
            "    while True:\n",
            "        # This could come from a dataset, a database, a queue or HTTP request\n",
            "        # in a server\n",
            "        # Caveat: because this is iterative, you cannot use `num_workers > 1` variable\n",
            "        # to use multiple threads to preprocess data. You can still have 1 thread that\n",
            "        # does the preprocessing while the main runs the big inference\n",
            "        yield \"This is a test\"\n",
            "\n",
            "\n",
            "for out in pipe(data()):\n",
            "    print(out)\n",
            "    # {\"text\": \"NUMBER TEN FRESH NELLY IS WAITING ON YOU GOOD NIGHT HUSBAND\"}\n",
            "    # {\"text\": ....}\n",
            "    # ....\n",
            "```\n",
            "\n",
            "[[autodoc]] pipeline\n",
            "\n",
            "## Pipeline batching\n",
            "\n",
            "All pipelines can use batching. This will work\n",
            "whenever the pipeline uses its streaming ability (so when passing lists or `Dataset` or `generator`).\n",
            "\n",
            "```python\n",
            "from transformers import pipeline\n",
            "from transformers.pipelines.pt_utils import KeyDataset\n",
            "import datasets\n",
            "\n",
            "dataset = datasets.load_dataset(\"imdb\", name=\"plain_text\", split=\"unsupervised\")\n",
            "pipe = pipeline(\"text-classification\", device=0)\n",
            "for out in pipe(KeyDataset(dataset, \"text\"), batch_size=8, truncation=\"only_first\"):\n",
            "    print(out)\n",
            "    # [{'label': 'POSITIVE', 'score': 0.9998743534088135}]\n",
            "    # Exactly the same output as before, but the content are passed\n",
            "    # as batches to the model\n",
            "```\n",
            "\n",
            "<Tip warning={true}>\n",
            "\n",
            "However, this is not automatically a win for performance. It can be either a 10x speedup or 5x slowdown depending\n",
            "on hardware, data and the actual model being used.\n",
            "\n",
            "Example where it's mostly a speedup:\n",
            "\n",
            "</Tip>\n",
            "\n",
            "```python\n",
            "from transformers import pipeline\n",
            "from torch.utils.data import Dataset\n",
            "from tqdm.auto import tqdm\n",
            "\n",
            "pipe = pipeline(\"text-classification\", device=0)\n",
            "\n",
            "\n",
            "class MyDataset(Dataset):\n",
            "    def __len__(self):\n",
            "        return 5000\n",
            "\n",
            "    def __getitem__(self, i):\n",
            "        return \"This is a test\"\n",
            "\n",
            "\n",
            "dataset = MyDataset()\n",
            "\n",
            "for batch_size in [1, 8, 64, 256]:\n",
            "    print(\"-\" * 30)\n",
            "    print(f\"Streaming batch_size={batch_size}\")\n",
            "    for out in tqdm(pipe(dataset, batch_size=batch_size), total=len(dataset)):\n",
            "        pass\n",
            "```\n",
            "\n",
            "```\n",
            "# On GTX 970\n",
            "------------------------------\n",
            "Streaming no batching\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000 [00:26<00:00, 187.52it/s]\n",
            "------------------------------\n",
            "Streaming batch_size=8\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000 [00:04<00:00, 1205.95it/s]\n",
            "------------------------------\n",
            "Streaming batch_size=64\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000 [00:02<00:00, 2478.24it/s]\n",
            "------------------------------\n",
            "Streaming batch_size=256\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000 [00:01<00:00, 2554.43it/s]\n",
            "(diminishing returns, saturated the GPU)\n",
            "```\n",
            "\n",
            "Example where it's most a slowdown:\n",
            "\n",
            "```python\n",
            "class MyDataset(Dataset):\n",
            "    def __len__(self):\n",
            "        return 5000\n",
            "\n",
            "    def __getitem__(self, i):\n",
            "        if i % 64 == 0:\n",
            "            n = 100\n",
            "        else:\n",
            "            n = 1\n",
            "        return \"This is a test\" * n\n",
            "```\n",
            "\n",
            "This is a occasional very long sentence compared to the other. In that case, the **whole** batch will need to be 400\n",
            "tokens long, so the whole batch will be [64, 400] instead of [64, 4], leading to the high slowdown. Even worse, on\n",
            "bigger batches, the program simply crashes.\n",
            "\n",
            "\n",
            "```\n",
            "------------------------------\n",
            "Streaming no batching\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:05<00:00, 183.69it/s]\n",
            "------------------------------\n",
            "Streaming batch_size=8\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:03<00:00, 265.74it/s]\n",
            "------------------------------\n",
            "Streaming batch_size=64\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:26<00:00, 37.80it/s]\n",
            "------------------------------\n",
            "Streaming batch_size=256\n",
            "  0%|                                                                                 | 0/1000 [00:00<?, ?it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/nicolas/src/transformers/test.py\", line 42, in <module>\n",
            "    for out in tqdm(pipe(dataset, batch_size=256), total=len(dataset)):\n",
            "....\n",
            "    q = q / math.sqrt(dim_per_head)  # (bs, n_heads, q_length, dim_per_head)\n",
            "RuntimeError: CUDA out of memory. Tried to allocate 376.00 MiB (GPU 0; 3.95 GiB total capacity; 1.72 GiB already allocated; 354.88 MiB free; 2.46 GiB reserved in total by PyTorch)\n",
            "```\n",
            "\n",
            "There are no good (general) solutions for this problem, and your mileage may vary depending on your use cases. Rule of\n",
            "thumb:\n",
            "\n",
            "For users, a rule of thumb is:\n",
            "\n",
            "- **Measure performance on your load, with your hardware. Measure, measure, and keep measuring. Real numbers are the\n",
            "  only way to go.**\n",
            "- If you are latency constrained (live product doing inference), don't batch.\n",
            "- If you are using CPU, don't batch.\n",
            "- If you are using throughput (you want to run your model on a bunch of static data), on GPU, then:\n",
            "\n",
            "  - If you have no clue about the size of the sequence_length (\"natural\" data), by default don't batch, measure and\n",
            "    try tentatively to add it, add OOM checks to recover when it will fail (and it will at some point if you don't\n",
            "    control the sequence_length.)\n",
            "  - If your sequence_length is super regular, then batching is more likely to be VERY interesting, measure and push\n",
            "    it until you get OOMs.\n",
            "  - The larger the GPU the more likely batching is going to be more interesting\n",
            "- As soon as you enable batching, make sure you can handle OOMs nicely.\n",
            "\n",
            "## Pipeline chunk batching\n",
            "\n",
            "`zero-shot-classification` and `question-answering` are slightly specific in the sense, that a single input might yield\n",
            "multiple forward pass of a model. Under normal circumstances, this would yield issues with `batch_size` argument.\n",
            "\n",
            "In order to circumvent this issue, both of these pipelines are a bit specific, they are `ChunkPipeline` instead of\n",
            "regular `Pipeline`. In short:\n",
            "\n",
            "\n",
            "```python\n",
            "preprocessed = pipe.preprocess(inputs)\n",
            "model_outputs = pipe.forward(preprocessed)\n",
            "outputs = pipe.postprocess(model_outputs)\n",
            "```\n",
            "\n",
            "Now becomes:\n",
            "\n",
            "\n",
            "```python\n",
            "all_model_outputs = []\n",
            "for preprocessed in pipe.preprocess(inputs):\n",
            "    model_outputs = pipe.forward(preprocessed)\n",
            "    all_model_outputs.append(model_outputs)\n",
            "outputs = pipe.postprocess(all_model_outputs)\n",
            "```\n",
            "\n",
            "This should be very transparent to your code because the pipelines are used in\n",
            "the same way.\n",
            "\n",
            "This is a simplified view, since the pipeline can handle automatically the batch to ! Meaning you don't have to care\n",
            "about how many forward passes you inputs are actually going to trigger, you can optimize the `batch_size`\n",
            "independently of the inputs. The caveats from the previous section still apply.\n",
            "\n",
            "## Pipeline custom code\n",
            "\n",
            "If you want to override a specific pipeline.\n",
            "\n",
            "Don't hesitate to create an issue for your task at hand, the goal of the pipeline is to be easy to use and support most\n",
            "cases, so `transformers` could maybe support your use case.\n",
            "\n",
            "\n",
            "If you want to try simply you can:\n",
            "\n",
            "- Subclass your pipeline of choice\n",
            "\n",
            "```python\n",
            "class MyPipeline(TextClassificationPipeline):\n",
            "    def postprocess():\n",
            "        # Your code goes here\n",
            "        scores = scores * 100\n",
            "        # And here\n",
            "\n",
            "\n",
            "my_pipeline = MyPipeline(model=model, tokenizer=tokenizer, ...)\n",
            "# or if you use *pipeline* function, then:\n",
            "my_pipeline = pipeline(model=\"xxxx\", pipeline_class=MyPipeline)\n",
            "```\n",
            "\n",
            "That should enable you to do all the custom code you want.\n",
            "\n",
            "\n",
            "## Implementing a pipeline\n",
            "\n",
            "[Implementing a new pipeline](../add_new_pipeline)\n",
            "\n",
            "## Audio\n",
            "\n",
            "Pipelines available for audio tasks include the following.\n",
            "\n",
            "### AudioClassificationPipeline\n",
            "\n",
            "[[autodoc]] AudioClassificationPipeline\n",
            "    - __call__\n",
            "    - all\n",
            "\n",
            "### AutomaticSpeechRecognitionPipeline\n",
            "\n",
            "[[autodoc]] AutomaticSpeechRecognitionPipeline\n",
            "    - __call__\n",
            "    - all\n",
            "\n",
            "### TextToAudioPipeline\n",
            "\n",
            "[[autodoc]] TextToAudioPipeline\n",
            "    - __call__\n",
            "    - all\n",
            "\n",
            "\n",
            "### ZeroShotAudioClassificationPipeline\n",
            "\n",
            "[[autodoc]] ZeroShotAudioClassificationPipeline\n",
            "    - __call__\n",
            "    - all\n",
            "\n",
            "## Computer vision\n",
            "\n",
            "Pipelines available for computer vision tasks include the following.\n",
            "\n",
            "### DepthEstimationPipeline\n",
            "[[autodoc]] DepthEstimationPipeline\n",
            "    - __call__\n",
            "    - all\n",
            "\n",
            "### ImageClassificationPipeline\n",
            "\n",
            "[[autodoc]] ImageClassificationPipeline\n",
            "    - __call__\n",
            "    - all\n",
            "\n",
            "### ImageSegmentationPipeline\n",
            "\n",
            "[[autodoc]] ImageSegmentationPipeline\n",
            "    - __call__\n",
            "    - all\n",
            "\n",
            "### ImageToImagePipeline\n",
            "\n",
            "[[autodoc]] ImageToImagePipeline\n",
            "    - __call__\n",
            "    - all\n",
            "\n",
            "### ObjectDetectionPipeline\n",
            "\n",
            "[[autodoc]] ObjectDetectionPipeline\n",
            "    - __call__\n",
            "    - all\n",
            "\n",
            "### VideoClassificationPipeline\n",
            "\n",
            "[[autodoc]] VideoClassificationPipeline\n",
            "    - __call__\n",
            "    - all\n",
            "\n",
            "### ZeroShotImageClassificationPipeline\n",
            "\n",
            "[[autodoc]] ZeroShotImageClassificationPipeline\n",
            "    - __call__\n",
            "    - all\n",
            "\n",
            "### ZeroShotObjectDetectionPipeline\n",
            "\n",
            "[[autodoc]] ZeroShotObjectDetectionPipeline\n",
            "    - __call__\n",
            "    - all\n",
            "\n",
            "## Natural Language Processing\n",
            "\n",
            "Pipelines available for natural language processing tasks include the following.\n",
            "\n",
            "### ConversationalPipeline\n",
            "\n",
            "[[autodoc]] Conversation\n",
            "\n",
            "[[autodoc]] ConversationalPipeline\n",
            "    - __call__\n",
            "    - all\n",
            "\n",
            "### FillMaskPipeline\n",
            "\n",
            "[[autodoc]] FillMaskPipeline\n",
            "    - __call__\n",
            "    - all\n",
            "\n",
            "### QuestionAnsweringPipeline\n",
            "\n",
            "[[autodoc]] QuestionAnsweringPipeline\n",
            "    - __call__\n",
            "    - all\n",
            "\n",
            "### SummarizationPipeline\n",
            "\n",
            "[[autodoc]] SummarizationPipeline\n",
            "    - __call__\n",
            "    - all\n",
            "\n",
            "### TableQuestionAnsweringPipeline\n",
            "\n",
            "[[autodoc]] TableQuestionAnsweringPipeline\n",
            "    - __call__\n",
            "\n",
            "### TextClassificationPipeline\n",
            "\n",
            "[[autodoc]] TextClassificationPipeline\n",
            "    - __call__\n",
            "    - all\n",
            "\n",
            "### TextGenerationPipeline\n",
            "\n",
            "[[autodoc]] TextGenerationPipeline\n",
            "    - __call__\n",
            "    - all\n",
            "\n",
            "### Text2TextGenerationPipeline\n",
            "\n",
            "[[autodoc]] Text2TextGenerationPipeline\n",
            "    - __call__\n",
            "    - all\n",
            "\n",
            "### TokenClassificationPipeline\n",
            "\n",
            "[[autodoc]] TokenClassificationPipeline\n",
            "    - __call__\n",
            "    - all\n",
            "\n",
            "### TranslationPipeline\n",
            "\n",
            "[[autodoc]] TranslationPipeline\n",
            "    - __call__\n",
            "    - all\n",
            "\n",
            "### ZeroShotClassificationPipeline\n",
            "\n",
            "[[autodoc]] ZeroShotClassificationPipeline\n",
            "    - __call__\n",
            "    - all\n",
            "\n",
            "## Multimodal\n",
            "\n",
            "Pipelines available for multimodal tasks include the following.\n",
            "\n",
            "### DocumentQuestionAnsweringPipeline\n",
            "\n",
            "[[autodoc]] DocumentQuestionAnsweringPipeline\n",
            "    - __call__\n",
            "    - all\n",
            "\n",
            "### FeatureExtractionPipeline\n",
            "\n",
            "[[autodoc]] FeatureExtractionPipeline\n",
            "    - __call__\n",
            "    - all\n",
            "\n",
            "### ImageToTextPipeline\n",
            "\n",
            "[[autodoc]] ImageToTextPipeline\n",
            "    - __call__\n",
            "    - all\n",
            "\n",
            "### MaskGenerationPipeline\n",
            "\n",
            "[[autodoc]] MaskGenerationPipeline\n",
            "    - __call__\n",
            "    - all\n",
            "\n",
            "### VisualQuestionAnsweringPipeline\n",
            "\n",
            "[[autodoc]] VisualQuestionAnsweringPipeline\n",
            "    - __call__\n",
            "    - all\n",
            "\n",
            "## Parent class: `Pipeline`\n",
            "\n",
            "[[autodoc]] Pipeline\n",
            "Document 3------------------------------------------------------------\n",
            "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n",
            "\n",
            "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with\n",
            "the License. You may obtain a copy of the License at\n",
            "\n",
            "http://www.apache.org/licenses/LICENSE-2.0\n",
            "\n",
            "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on\n",
            "an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the\n",
            "\n",
            "âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be\n",
            "rendered properly in your Markdown viewer.\n",
            "\n",
            "-->\n",
            "\n",
            "# How to create a custom pipeline?\n",
            "\n",
            "In this guide, we will see how to create a custom pipeline and share it on the [Hub](hf.co/models) or add it to the\n",
            "ğŸ¤— Transformers library.\n",
            "\n",
            "First and foremost, you need to decide the raw entries the pipeline will be able to take. It can be strings, raw bytes,\n",
            "dictionaries or whatever seems to be the most likely desired input. Try to keep these inputs as pure Python as possible\n",
            "as it makes compatibility easier (even through other languages via JSON). Those will be the `inputs` of the\n",
            "pipeline (`preprocess`).\n",
            "\n",
            "Then define the `outputs`. Same policy as the `inputs`. The simpler, the better. Those will be the outputs of\n",
            "`postprocess` method.\n",
            "\n",
            "Start by inheriting the base class `Pipeline` with the 4 methods needed to implement `preprocess`,\n",
            "`_forward`, `postprocess`, and `_sanitize_parameters`.\n",
            "\n",
            "\n",
            "```python\n",
            "from transformers import Pipeline\n",
            "\n",
            "\n",
            "class MyPipeline(Pipeline):\n",
            "    def _sanitize_parameters(self, **kwargs):\n",
            "        preprocess_kwargs = {}\n",
            "        if \"maybe_arg\" in kwargs:\n",
            "            preprocess_kwargs[\"maybe_arg\"] = kwargs[\"maybe_arg\"]\n",
            "        return preprocess_kwargs, {}, {}\n",
            "\n",
            "    def preprocess(self, inputs, maybe_arg=2):\n",
            "        model_input = Tensor(inputs[\"input_ids\"])\n",
            "        return {\"model_input\": model_input}\n",
            "\n",
            "    def _forward(self, model_inputs):\n",
            "        # model_inputs == {\"model_input\": model_input}\n",
            "        outputs = self.model(**model_inputs)\n",
            "        # Maybe {\"logits\": Tensor(...)}\n",
            "        return outputs\n",
            "\n",
            "    def postprocess(self, model_outputs):\n",
            "        best_class = model_outputs[\"logits\"].softmax(-1)\n",
            "        return best_class\n",
            "```\n",
            "\n",
            "The structure of this breakdown is to support relatively seamless support for CPU/GPU, while supporting doing\n",
            "pre/postprocessing on the CPU on different threads\n",
            "\n",
            "`preprocess` will take the originally defined inputs, and turn them into something feedable to the model. It might\n",
            "contain more information and is usually a `Dict`.\n",
            "\n",
            "`_forward` is the implementation detail and is not meant to be called directly. `forward` is the preferred\n",
            "called method as it contains safeguards to make sure everything is working on the expected device. If anything is\n",
            "linked to a real model it belongs in the `_forward` method, anything else is in the preprocess/postprocess.\n",
            "\n",
            "`postprocess` methods will take the output of `_forward` and turn it into the final output that was decided\n",
            "earlier.\n",
            "\n",
            "`_sanitize_parameters` exists to allow users to pass any parameters whenever they wish, be it at initialization\n",
            "time `pipeline(...., maybe_arg=4)` or at call time `pipe = pipeline(...); output = pipe(...., maybe_arg=4)`.\n",
            "\n",
            "The returns of `_sanitize_parameters` are the 3 dicts of kwargs that will be passed directly to `preprocess`,\n",
            "`_forward`, and `postprocess`. Don't fill anything if the caller didn't call with any extra parameter. That\n",
            "allows to keep the default arguments in the function definition which is always more \"natural\".\n",
            "\n",
            "A classic example would be a `top_k` argument in the post processing in classification tasks.\n",
            "\n",
            "```python\n",
            ">>> pipe = pipeline(\"my-new-task\")\n",
            ">>> pipe(\"This is a test\")\n",
            "[{\"label\": \"1-star\", \"score\": 0.8}, {\"label\": \"2-star\", \"score\": 0.1}, {\"label\": \"3-star\", \"score\": 0.05}\n",
            "{\"label\": \"4-star\", \"score\": 0.025}, {\"label\": \"5-star\", \"score\": 0.025}]\n",
            "\n",
            ">>> pipe(\"This is a test\", top_k=2)\n",
            "[{\"label\": \"1-star\", \"score\": 0.8}, {\"label\": \"2-star\", \"score\": 0.1}]\n",
            "```\n",
            "\n",
            "In order to achieve that, we'll update our `postprocess` method with a default parameter to `5`. and edit\n",
            "`_sanitize_parameters` to allow this new parameter.\n",
            "\n",
            "\n",
            "```python\n",
            "def postprocess(self, model_outputs, top_k=5):\n",
            "    best_class = model_outputs[\"logits\"].softmax(-1)\n",
            "    # Add logic to handle top_k\n",
            "    return best_class\n",
            "\n",
            "\n",
            "def _sanitize_parameters(self, **kwargs):\n",
            "    preprocess_kwargs = {}\n",
            "    if \"maybe_arg\" in kwargs:\n",
            "        preprocess_kwargs[\"maybe_arg\"] = kwargs[\"maybe_arg\"]\n",
            "\n",
            "    postprocess_kwargs = {}\n",
            "    if \"top_k\" in kwargs:\n",
            "        postprocess_kwargs[\"top_k\"] = kwargs[\"top_k\"]\n",
            "    return preprocess_kwargs, {}, postprocess_kwargs\n",
            "```\n",
            "\n",
            "Try to keep the inputs/outputs very simple and ideally JSON-serializable as it makes the pipeline usage very easy\n",
            "without requiring users to understand new kinds of objects. It's also relatively common to support many different types\n",
            "of arguments for ease of use (audio files, which can be filenames, URLs or pure bytes)\n",
            "\n",
            "\n",
            "\n",
            "## Adding it to the list of supported tasks\n",
            "\n",
            "To register your `new-task` to the list of supported tasks, you have to add it to the `PIPELINE_REGISTRY`:\n",
            "\n",
            "```python\n",
            "from transformers.pipelines import PIPELINE_REGISTRY\n",
            "\n",
            "PIPELINE_REGISTRY.register_pipeline(\n",
            "    \"new-task\",\n",
            "    pipeline_class=MyPipeline,\n",
            "    pt_model=AutoModelForSequenceClassification,\n",
            ")\n",
            "```\n",
            "\n",
            "You can specify a default model if you want, in which case it should come with a specific revision (which can be the name of a branch or a commit hash, here we took `\"abcdef\"`) as well as the type:\n",
            "\n",
            "```python\n",
            "PIPELINE_REGISTRY.register_pipeline(\n",
            "    \"new-task\",\n",
            "    pipeline_class=MyPipeline,\n",
            "    pt_model=AutoModelForSequenceClassification,\n",
            "    default={\"pt\": (\"user/awesome_model\", \"abcdef\")},\n",
            "    type=\"text\",  # current support type: text, audio, image, multimodal\n",
            ")\n",
            "```\n",
            "\n",
            "## Share your pipeline on the Hub\n",
            "\n",
            "To share your custom pipeline on the Hub, you just have to save the custom code of your `Pipeline` subclass in a\n",
            "python file. For instance, let's say we want to use a custom pipeline for sentence pair classification like this:\n",
            "\n",
            "```py\n",
            "import numpy as np\n",
            "\n",
            "from transformers import Pipeline\n",
            "\n",
            "\n",
            "def softmax(outputs):\n",
            "    maxes = np.max(outputs, axis=-1, keepdims=True)\n",
            "    shifted_exp = np.exp(outputs - maxes)\n",
            "    return shifted_exp / shifted_exp.sum(axis=-1, keepdims=True)\n",
            "\n",
            "\n",
            "class PairClassificationPipeline(Pipeline):\n",
            "    def _sanitize_parameters(self, **kwargs):\n",
            "        preprocess_kwargs = {}\n",
            "        if \"second_text\" in kwargs:\n",
            "            preprocess_kwargs[\"second_text\"] = kwargs[\"second_text\"]\n",
            "        return preprocess_kwargs, {}, {}\n",
            "\n",
            "    def preprocess(self, text, second_text=None):\n",
            "        return self.tokenizer(text, text_pair=second_text, return_tensors=self.framework)\n",
            "\n",
            "    def _forward(self, model_inputs):\n",
            "        return self.model(**model_inputs)\n",
            "\n",
            "    def postprocess(self, model_outputs):\n",
            "        logits = model_outputs.logits[0].numpy()\n",
            "        probabilities = softmax(logits)\n",
            "\n",
            "        best_class = np.argmax(probabilities)\n",
            "        label = self.model.config.id2label[best_class]\n",
            "        score = probabilities[best_class].item()\n",
            "        logits = logits.tolist()\n",
            "        return {\"label\": label, \"score\": score, \"logits\": logits}\n",
            "```\n",
            "\n",
            "The implementation is framework agnostic, and will work for PyTorch and TensorFlow models. If we have saved this in\n",
            "a file named `pair_classification.py`, we can then import it and register it like this:\n",
            "\n",
            "```py\n",
            "from pair_classification import PairClassificationPipeline\n",
            "from transformers.pipelines import PIPELINE_REGISTRY\n",
            "from transformers import AutoModelForSequenceClassification, TFAutoModelForSequenceClassification\n",
            "\n",
            "PIPELINE_REGISTRY.register_pipeline(\n",
            "    \"pair-classification\",\n",
            "    pipeline_class=PairClassificationPipeline,\n",
            "    pt_model=AutoModelForSequenceClassification,\n",
            "    tf_model=TFAutoModelForSequenceClassification,\n",
            ")\n",
            "```\n",
            "\n",
            "Once this is done, we can use it with a pretrained model. For instance `sgugger/finetuned-bert-mrpc` has been\n",
            "fine-tuned on the MRPC dataset, which classifies pairs of sentences as paraphrases or not.\n",
            "\n",
            "```py\n",
            "from transformers import pipeline\n",
            "\n",
            "classifier = pipeline(\"pair-classification\", model=\"sgugger/finetuned-bert-mrpc\")\n",
            "```\n",
            "\n",
            "Then we can share it on the Hub by using the `save_pretrained` method in a `Repository`:\n",
            "\n",
            "```py\n",
            "from huggingface_hub import Repository\n",
            "\n",
            "repo = Repository(\"test-dynamic-pipeline\", clone_from=\"{your_username}/test-dynamic-pipeline\")\n",
            "classifier.save_pretrained(\"test-dynamic-pipeline\")\n",
            "repo.push_to_hub()\n",
            "```\n",
            "\n",
            "This will copy the file where you defined `PairClassificationPipeline` inside the folder `\"test-dynamic-pipeline\"`,\n",
            "along with saving the model and tokenizer of the pipeline, before pushing everything into the repository\n",
            "`{your_username}/test-dynamic-pipeline`. After that, anyone can use it as long as they provide the option\n",
            "`trust_remote_code=True`:\n",
            "\n",
            "```py\n",
            "from transformers import pipeline\n",
            "\n",
            "classifier = pipeline(model=\"{your_username}/test-dynamic-pipeline\", trust_remote_code=True)\n",
            "```\n",
            "\n",
            "## Add the pipeline to ğŸ¤— Transformers\n",
            "\n",
            "If you want to contribute your pipeline to ğŸ¤— Transformers, you will need to add a new module in the `pipelines` submodule\n",
            "with the code of your pipeline, then add it to the list of tasks defined in `pipelines/__init__.py`.\n",
            "\n",
            "Then you will need to add tests. Create a new file `tests/test_pipelines_MY_PIPELINE.py` with examples of the other tests.\n",
            "\n",
            "The `run_pipeline_test` function will be very generic and run on small random models on every possible\n",
            "architecture as defined by `model_mapping` and `tf_model_mapping`.\n",
            "\n",
            "This is very important to test future compatibility, meaning if someone adds a new model for\n",
            "`XXXForQuestionAnswering` then the pipeline test will attempt to run on it. Because the models are random it's\n",
            "impossible to check for actual values, that's why there is a helper `ANY` that will simply attempt to match the\n",
            "output of the pipeline TYPE.\n",
            "\n",
            "You also *need* to implement 2 (ideally 4) tests.\n",
            "\n",
            "- `test_small_model_pt` : Define 1 small model for this pipeline (doesn't matter if the results don't make sense)\n",
            "  and test the pipeline outputs. The results should be the same as `test_small_model_tf`.\n",
            "- `test_small_model_tf` : Define 1 small model for this pipeline (doesn't matter if the results don't make sense)\n",
            "  and test the pipeline outputs. The results should be the same as `test_small_model_pt`.\n",
            "- `test_large_model_pt` (`optional`): Tests the pipeline on a real pipeline where the results are supposed to\n",
            "  make sense. These tests are slow and should be marked as such. Here the goal is to showcase the pipeline and to make\n",
            "  sure there is no drift in future releases.\n",
            "- `test_large_model_tf` (`optional`): Tests the pipeline on a real pipeline where the results are supposed to\n",
            "  make sense. These tests are slow and should be marked as such. Here the goal is to showcase the pipeline and to make\n",
            "  sure there is no drift in future releases.\n",
            "Document 4------------------------------------------------------------\n",
            "hat happens inside the pipeline function? In this video, we will look at what actually happens when we use the pipeline function of the Transformers library. More specifically, we will look at the sentiment analysis pipeline, and how it went from the two following sentences to the positive labels with their respective scores. As we have seen in the pipeline presentation, there are three stages in the pipeline. First, we convert the raw texts to numbers the model can make sense of, using a tokenizer. Then, those numbers go through the model, which outputs logits. Finally, the post-processing steps transforms those logits into labels and scores. Let's look in detail at those three steps, and how to replicate them using the Transformers library, beginning with the first stage, tokenization. The tokenization process has several steps. First, the text is split into small chunks called tokens. They can be words, parts of words or punctuation symbols. Then the tokenizer will had some special tokens (if the model expect them). Here the model uses expects a CLS token at the beginning and a SEP token at the end of the sentence to classify. Lastly, the tokenizer matches each token to its unique ID in the vocabulary of the pretrained model. To load such a tokenizer, the Transformers library provides the AutoTokenizer API. The most important method of this class is from_pretrained, which will download and cache the configuration and the vocabulary associated to a given checkpoint. Here, the checkpoint used by default for the sentiment analysis pipeline is distilbert base uncased finetuned sst2 english. We instantiate a tokenizer associated with that checkpoint, then feed it the two sentences. Since those two sentences are not of the same size, we will need to pad the shortest one to be able to build an array. This is done by the tokenizer with the option padding=True. With truncation=True, we ensure that any sentence longer than the maximum the model can handle is truncated. Lastly, the return_tensors option tells the tokenizer to return a TensorFlow tensor. Looking at the result, we see we have a dictionary with two keys. Input IDs contains the IDs of both sentences, with 0s where the padding is applied. The second key, attention mask, indicates where padding has been applied, so the model does not pay attention to it. This is all what is inside the tokenization step. Now let's have a look at the second step, the model. As for the tokenizer, there is an TFAutoModel API, with a from_pretrained method. It will download and cache the configuration of the model as well as the pretrained weights. However, the TFAutoModel API will only instantiate the body of the model, that is, the part of the model that is left once the pretraining head is removed. It will output a high-dimensional tensor that is a representation of the sentences passed, but which is not directly useful for our classification problem. Here the tensor has two sentences, each of sixteen tokens and the last dimension is the hidden size of our model 768. To get an output linked to our classification problem, we need to use the TFAutoModelForSequenceClassification class. It works exactly as the AutoModel class, except that it will build a model with a classification head. There is one auto class for each common NLP task in the Transformers library. Here, after giving our model the two sentences, we get a tensor of size two by two: one result for each sentence and for each possible label. Those outputs are not probabilities yet (we can see they don't sum to 1). This is because each model of the Transformers library returns logits. To make sense of those logits, we need to dig into the third and last step of the pipeline: post-processing. To convert logits into probabilities, we need to apply a SoftMax layer to them. As we can see, this transforms them into positive numbers that sum up to 1. The last step is to know which of those corresponds to the positive or the negative label. This is given by the id2label field of the model config. The first probabilities (index 0) correspond to the negative label, and the seconds (index 1) correspond to the positive label. This is how our classifier built with the pipeline function picked those labels and computed those scores. Now that you know how each steps works, you can easily tweak them to your needs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"==================================Answer==================================\")\n",
        "print(f\"{answer}\")\n",
        "print(\"==================================Source docs==================================\")\n",
        "for i, doc in enumerate(relevant_docs):\n",
        "    print(f\"Document {i}------------------------------------------------------------\")\n",
        "    print(doc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mn1bVBG9ClIX",
        "outputId": "0d62a306-18df-464f-accb-09b36f701de4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================Answer==================================\n",
            "To create a pipeline object, follow these steps:\n",
            "\n",
            "1. Define a custom pipeline class that inherits from the `Pipeline` class provided by the Transformers library. This class should contain three methods: `_sanitize_parameters`, `preprocess`, and `postprocess`.\n",
            "\n",
            "2. Register the new pipeline on the Hub by adding it to the `PIPELINE_REGISTRY` dictionary. This dictionary maps pipeline names to tuples containing the pipeline class, the model classes, and optional defaults for the pipeline parameters.\n",
            "\n",
            "3. Save the custom pipeline to the Hub by cloning an existing repository and pushing the changes. This will copy the custom pipeline code and the corresponding model and tokenizer to the repository.\n",
            "\n",
            "4. Test the pipeline by creating a new pipeline object and running it on small and large models. The tests should cover at least two small models (one for PyTorch and one for TensorFlow) and two large models (also one for each framework).\n",
            "\n",
            "Here's an example implementation:\n",
            "\n",
            "```python\n",
            "from transformers import Pipeline, AutoModelForSequenceClassification, TFAutoModelForSequenceClassification\n",
            "from transformers.pipelines import PIPELINE_REGISTRY\n",
            "from transformers import AutoTokenizer\n",
            "\n",
            "class CustomPipeline(Pipeline):\n",
            "    def _sanitize_parameters(self, **kwargs):\n",
            "        preprocess_kwargs = {}\n",
            "        if \"second_text\" in kwargs:\n",
            "            preprocess_kwargs[\"second_text\"] = kwargs[\"second_text\"]\n",
            "        return preprocess_kwargs, {}, {}\n",
            "\n",
            "    def preprocess(self, text, second_text=None):\n",
            "        tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
            "        inputs = {\n",
            "            \"input_ids\": tokenizer(text, padding=True, truncation=True, return_tensors=\"tf\"),\n",
            "            \"attention_mask\": tokenizer(text, padding=True, truncation=True, return_tensors=\"tf\").attention_mask,\n",
            "            \"second_input_ids\": tokenizer(second_text, padding=True, truncation=True, return_tensors=\"tf\")\n",
            "            if second_text is not None else None,\n",
            "        }\n",
            "        return inputs\n",
            "\n",
            "    def post\n",
            "==================================Source docs==================================\n",
            "Document 0------------------------------------------------------------\n",
            "Inference pipelines with the ONNX Runtime accelerator\n",
            "\n",
            "The [`~pipelines.pipeline`] function makes it simple to use models from the [Model Hub](https://huggingface.co/models)\n",
            "for accelerated inference on a variety of tasks such as text classification, question answering and image classification.\n",
            "\n",
            "<Tip>\n",
            "\n",
            "You can also use the\n",
            "[pipeline()](https://huggingface.co/docs/transformers/main/en/main_classes/pipelines#pipelines) function from\n",
            "Transformers and provide your Optimum model class.\n",
            "\n",
            "</Tip>\n",
            "\n",
            "Currently the supported tasks are:\n",
            "\n",
            "* `feature-extraction`\n",
            "* `text-classification`\n",
            "* `token-classification`\n",
            "* `question-answering`\n",
            "* `zero-shot-classification`\n",
            "* `text-generation`\n",
            "* `text2text-generation`\n",
            "* `summarization`\n",
            "* `translation`\n",
            "* `image-classification`\n",
            "* `automatic-speech-recognition`\n",
            "* `image-to-text`\n",
            "\n",
            "## Optimum pipeline usage\n",
            "\n",
            "While each task has an associated pipeline class, it is simpler to use the general [`~pipelines.pipeline`] function which wraps all the task-specific pipelines in one object.\n",
            "The [`~pipelines.pipeline`] function automatically loads a default model and tokenizer/feature-extractor capable of performing inference for your task.\n",
            "\n",
            "1. Start by creating a pipeline by specifying an inference task:\n",
            "\n",
            "```python\n",
            ">>> from optimum.pipelines import pipeline\n",
            "\n",
            ">>> classifier = pipeline(task=\"text-classification\", accelerator=\"ort\")\n",
            "```\n",
            "\n",
            "2. Pass your input text/image to the [`~pipelines.pipeline`] function:\n",
            "\n",
            "```python\n",
            ">>> classifier(\"I like you. I love you.\")  # doctest: +IGNORE_RESULT\n",
            "[{'label': 'POSITIVE', 'score': 0.9998838901519775}]\n",
            "```\n",
            "\n",
            "_Note: The default models used in the [`~pipelines.pipeline`] function are not optimized for inference or quantized, so there won't be a performance improvement compared to their PyTorch counterparts._\n",
            "\n",
            "### Using vanilla Transformers model and converting to ONNX\n",
            "\n",
            "The [`~pipelines.pipeline`] function accepts any supported model from the [Hugging Face Hub](https://huggingface.co/models).\n",
            "There are tags on the Model Hub that allow you to filter for a model you'd like to use for your task.\n",
            "\n",
            "<Tip>\n",
            "\n",
            "To be able to load the model with the ONNX Runtime backend, the export to ONNX needs to be supported for the considered architecture.\n",
            "\n",
            "You can check the list of supported architectures [here](https://huggingface.co/docs/optimum/exporters/onnx/overview#overview).\n",
            "\n",
            "</Tip>\n",
            "\n",
            "Once you have picked an appropriate model, you can create the [`~pipelines.pipeline`] by specifying the model repo:\n",
            "\n",
            "```python\n",
            ">>> from optimum.pipelines import pipeline\n",
            "\n",
            "# The model will be loaded to an ORTModelForQuestionAnswering.\n",
            ">>> onnx_qa = pipeline(\"question-answering\", model=\"deepset/roberta-base-squad2\", accelerator=\"ort\")\n",
            ">>> question = \"What's my name?\"\n",
            ">>> context = \"My name is Philipp and I live in Nuremberg.\"\n",
            "\n",
            ">>> pred = onnx_qa(question=question, context=context)\n",
            "```\n",
            "\n",
            "It is also possible to load it with the `from_pretrained(model_name_or_path, export=True)`\n",
            "method associated with the `ORTModelForXXX` class.\n",
            "\n",
            "For example, here is how you can load the [`~onnxruntime.ORTModelForQuestionAnswering`] class for question answering:\n",
            "\n",
            "```python\n",
            ">>> from transformers import AutoTokenizer\n",
            ">>> from optimum.onnxruntime import ORTModelForQuestionAnswering\n",
            ">>> from optimum.pipelines import pipeline\n",
            "\n",
            ">>> tokenizer = AutoTokenizer.from_pretrained(\"deepset/roberta-base-squad2\")\n",
            "\n",
            ">>> # Loading the PyTorch checkpoint and converting to the ONNX format by providing\n",
            ">>> # export=True\n",
            ">>> model = ORTModelForQuestionAnswering.from_pretrained(\n",
            "...     \"deepset/roberta-base-squad2\",\n",
            "...     export=True\n",
            "... )\n",
            "\n",
            ">>> onnx_qa = pipeline(\"question-answering\", model=model, tokenizer=tokenizer, accelerator=\"ort\")\n",
            ">>> question = \"What's my name?\"\n",
            ">>> context = \"My name is Philipp and I live in Nuremberg.\"\n",
            "\n",
            ">>> pred = onnx_qa(question=question, context=context)\n",
            "```\n",
            "\n",
            "### Using Optimum models\n",
            "\n",
            "The [`~pipelines.pipeline`] function is tightly integrated with the [Hugging Face Hub](https://huggingface.co/models) and can load ONNX models directly.\n",
            "\n",
            "```python\n",
            ">>> from optimum.pipelines import pipeline\n",
            "\n",
            ">>> onnx_qa = pipeline(\"question-answering\", model=\"optimum/roberta-base-squad2\", accelerator=\"ort\")\n",
            ">>> question = \"What's my name?\"\n",
            ">>> context = \"My name is Philipp and I live in Nuremberg.\"\n",
            "\n",
            ">>> pred = onnx_qa(question=question, context=context)\n",
            "```\n",
            "\n",
            "It is also possible to load it with the `from_pretrained(model_name_or_path)`\n",
            "method associated with the `ORTModelForXXX` class.\n",
            "\n",
            "For example, here is how you can load the [`~onnxruntime.ORTModelForQuestionAnswering`] class for question answering:\n",
            "\n",
            "```python\n",
            ">>> from transformers import AutoTokenizer\n",
            ">>> from optimum.onnxruntime import ORTModelForQuestionAnswering\n",
            ">>> from optimum.pipelines import pipeline\n",
            "\n",
            ">>> tokenizer = AutoTokenizer.from_pretrained(\"optimum/roberta-base-squad2\")\n",
            "\n",
            ">>> # Loading directly an ONNX model from a model repo.\n",
            ">>> model = ORTModelForQuestionAnswering.from_pretrained(\"optimum/roberta-base-squad2\")\n",
            "\n",
            ">>> onnx_qa = pipeline(\"question-answering\", model=model, tokenizer=tokenizer, accelerator=\"ort\")\n",
            ">>> question = \"What's my name?\"\n",
            ">>> context = \"My name is Philipp and I live in Nuremberg.\"\n",
            "\n",
            ">>> pred = onnx_qa(question=question, context=context)\n",
            "```\n",
            "\n",
            "\n",
            "## Optimizing and quantizing in pipelines\n",
            "\n",
            "The [`~pipelines.pipeline`] function can not only run inference on vanilla ONNX Runtime checkpoints - you can also use\n",
            "checkpoints optimized with the [`~optimum.onnxruntime.ORTQuantizer`] and the [`~optimum.onnxruntime.ORTOptimizer`].\n",
            "\n",
            "Below you can find two examples of how you could use the [`~optimum.onnxruntime.ORTOptimizer`] and the\n",
            "[`~optimum.onnxruntime.ORTQuantizer`] to optimize/quantize your model and use it for inference afterwards.\n",
            "\n",
            "### Quantizing with the `ORTQuantizer`\n",
            "\n",
            "```python\n",
            ">>> from transformers import AutoTokenizer\n",
            ">>> from optimum.onnxruntime import (\n",
            "...     AutoQuantizationConfig,\n",
            "...     ORTModelForSequenceClassification,\n",
            "...     ORTQuantizer\n",
            "... )\n",
            ">>> from optimum.pipelines import pipeline\n",
            "\n",
            ">>> # Load the tokenizer and export the model to the ONNX format\n",
            ">>> model_id = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
            ">>> save_dir = \"distilbert_quantized\"\n",
            "\n",
            ">>> model = ORTModelForSequenceClassification.from_pretrained(model_id, export=True)\n",
            "\n",
            ">>> # Load the quantization configuration detailing the quantization we wish to apply\n",
            ">>> qconfig = AutoQuantizationConfig.avx512_vnni(is_static=False, per_channel=True)\n",
            ">>> quantizer = ORTQuantizer.from_pretrained(model)\n",
            "\n",
            ">>> # Apply dynamic quantization and save the resulting model\n",
            ">>> quantizer.quantize(save_dir=save_dir, quantization_config=qconfig)  # doctest: +IGNORE_RESULT\n",
            "\n",
            ">>> # Load the quantized model from a local repository\n",
            ">>> model = ORTModelForSequenceClassification.from_pretrained(save_dir)\n",
            "\n",
            ">>> # Create the transformers pipeline\n",
            ">>> onnx_clx = pipeline(\"text-classification\", model=model, accelerator=\"ort\")\n",
            ">>> text = \"I like the new ORT pipeline\"\n",
            ">>> pred = onnx_clx(text)\n",
            ">>> print(pred)  # doctest: +IGNORE_RESULT\n",
            ">>> # [{'label': 'POSITIVE', 'score': 0.9974810481071472}]\n",
            "\n",
            ">>> # Save and push the model to the hub (in practice save_dir could be used here instead)\n",
            ">>> model.save_pretrained(\"new_path_for_directory\")\n",
            ">>> model.push_to_hub(\"new_path_for_directory\", repository_id=\"my-onnx-repo\", use_auth_token=True)  # doctest: +SKIP\n",
            "```\n",
            "\n",
            "### Optimizing with `ORTOptimizer`\n",
            "\n",
            "```python\n",
            ">>> from transformers import AutoTokenizer\n",
            ">>> from optimum.onnxruntime import (\n",
            "...     AutoOptimizationConfig,\n",
            "...     ORTModelForSequenceClassification,\n",
            "...     ORTOptimizer\n",
            "... )\n",
            ">>> from optimum.onnxruntime.configuration import OptimizationConfig\n",
            ">>> from optimum.pipelines import pipeline\n",
            "\n",
            ">>> # Load the tokenizer and export the model to the ONNX format\n",
            ">>> model_id = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
            ">>> save_dir = \"distilbert_optimized\"\n",
            "\n",
            ">>> tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
            ">>> model = ORTModelForSequenceClassification.from_pretrained(model_id, export=True)\n",
            "\n",
            ">>> # Load the optimization configuration detailing the optimization we wish to apply\n",
            ">>> optimization_config = AutoOptimizationConfig.O3()\n",
            ">>> optimizer = ORTOptimizer.from_pretrained(model)\n",
            "\n",
            ">>> optimizer.optimize(save_dir=save_dir, optimization_config=optimization_config)  # doctest: +IGNORE_RESULT\n",
            "\n",
            "# Load the optimized model from a local repository\n",
            ">>> model = ORTModelForSequenceClassification.from_pretrained(save_dir)\n",
            "\n",
            "# Create the transformers pipeline\n",
            ">>> onnx_clx = pipeline(\"text-classification\", model=model, accelerator=\"ort\")\n",
            ">>> text = \"I like the new ORT pipeline\"\n",
            ">>> pred = onnx_clx(text)\n",
            ">>> print(pred)  # doctest: +IGNORE_RESULT\n",
            ">>> # [{'label': 'POSITIVE', 'score': 0.9973127245903015}]\n",
            "\n",
            "# Save and push the model to the hub\n",
            ">>> tokenizer.save_pretrained(\"new_path_for_directory\")  # doctest: +IGNORE_RESULT\n",
            ">>> model.save_pretrained(\"new_path_for_directory\")\n",
            ">>> model.push_to_hub(\"new_path_for_directory\", repository_id=\"my-onnx-repo\", use_auth_token=True)  # doctest: +SKIP\n",
            "```\n",
            "Document 1------------------------------------------------------------\n",
            "he pipeline function. The pipeline function is the most high-level API of the Transformers library. It regroups together all the steps to go from raw texts to usable predictions. The model used is at the core of a pipeline, but the pipeline also include all the necessary pre-processing (since the model does not expect texts, but numbers) as well as some post-processing to make the output of the model human-readable. Let's look at a first example with the sentiment analysis pipeline. This pipeline performs text classification on a given input, and determines if it's positive or negative. Here, it attributed the positive label on the given text, with a confidence of 95%. You can pass multiple texts to the same pipeline, which will be processed and passed through the model together, as a batch. The output is a list of individual results, in the same order as the input texts. Here we find the same label and score for the first text, and the second text is judged positive with a confidence of 99.99%. The zero-shot classification pipeline is a more general text-classification pipeline: it allows you to provide the labels you want. Here we want to classify our input text along the labels \"education\", \"politics\" and \"business\". The pipeline successfully recognizes it's more about education than the other labels, with a confidence of 84%. Moving on to other tasks, the text generation pipeline will auto-complete a given prompt. The output is generated with a bit of randomness, so it changes each time you call the generator object on a given prompt. Up until now, we have used the pipeline API with the default model associated to each task, but you can use it with any model that has been pretrained or fine-tuned on this task. Going on the model hub (huggingface.co/models), you can filter the available models by task. The default model used in our previous example was gpt2, but there are many more models available, and not just in English! Let's go back to the text generation pipeline and load it with another model, distilgpt2. This is a lighter version of gpt2 created by the Hugging Face team. When applying the pipeline to a given prompt, we can specify several arguments, such as the maximum length of the generated texts, or the number of sentences we want to return (since there is some randomness in the generation). Generating text by guessing the next word in a sentence was the pretraining objective of GPT-2, the fill mask pipeline is the pretraining objective of BERT, which is to guess the value of masked word. In this case, we ask the two most likely values for the missing words (according to the model) and get mathematical or computational as possible answers. Another task Transformers model can perform is to classify each word in the sentence instead of the sentence as a whole. One example of this is Named Entity Recognition, which is the task of identifying entities, such as persons, organizations or locations in a sentence. Here, the model correctly finds the person (Sylvain), the organization (Hugging Face) as well as the location (Brooklyn) inside the input text. The grouped_entities=True argument used is to make the pipeline group together the different words linked to the same entity (such as Hugging and Face here). Another task available with the pipeline API is extractive question answering. Providing a context and a question, the model will identify the span of text in the context containing the answer to the question. Getting short summaries of very long articles is also something the Transformers library can help with, with the summarization pipeline. Finally, the last task supported by the pipeline API is translation. Here we use a French/English model found on the model hub to get the English version of our input text. Here is a brief summary of all the tasks we looked into in this video. Try then out through the inference widgets in the model hub!\n",
            "Document 2------------------------------------------------------------\n",
            "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n",
            "\n",
            "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with\n",
            "the License. You may obtain a copy of the License at\n",
            "\n",
            "http://www.apache.org/licenses/LICENSE-2.0\n",
            "\n",
            "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on\n",
            "an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the\n",
            "specific language governing permissions and limitations under the License.\n",
            "\n",
            "âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be\n",
            "rendered properly in your Markdown viewer.\n",
            "\n",
            "-->\n",
            "\n",
            "# Pipelines\n",
            "\n",
            "The pipelines are a great and easy way to use models for inference. These pipelines are objects that abstract most of\n",
            "the complex code from the library, offering a simple API dedicated to several tasks, including Named Entity\n",
            "Recognition, Masked Language Modeling, Sentiment Analysis, Feature Extraction and Question Answering. See the\n",
            "[task summary](../task_summary) for examples of use.\n",
            "\n",
            "There are two categories of pipeline abstractions to be aware about:\n",
            "\n",
            "- The [`pipeline`] which is the most powerful object encapsulating all other pipelines.\n",
            "- Task-specific pipelines are available for [audio](#audio), [computer vision](#computer-vision), [natural language processing](#natural-language-processing), and [multimodal](#multimodal) tasks.\n",
            "\n",
            "## The pipeline abstraction\n",
            "\n",
            "The *pipeline* abstraction is a wrapper around all the other available pipelines. It is instantiated as any other\n",
            "pipeline but can provide additional quality of life.\n",
            "\n",
            "Simple call on one item:\n",
            "\n",
            "```python\n",
            ">>> pipe = pipeline(\"text-classification\")\n",
            ">>> pipe(\"This restaurant is awesome\")\n",
            "[{'label': 'POSITIVE', 'score': 0.9998743534088135}]\n",
            "```\n",
            "\n",
            "If you want to use a specific model from the [hub](https://huggingface.co) you can ignore the task if the model on\n",
            "the hub already defines it:\n",
            "\n",
            "```python\n",
            ">>> pipe = pipeline(model=\"roberta-large-mnli\")\n",
            ">>> pipe(\"This restaurant is awesome\")\n",
            "[{'label': 'NEUTRAL', 'score': 0.7313136458396912}]\n",
            "```\n",
            "\n",
            "To call a pipeline on many items, you can call it with a *list*.\n",
            "\n",
            "```python\n",
            ">>> pipe = pipeline(\"text-classification\")\n",
            ">>> pipe([\"This restaurant is awesome\", \"This restaurant is awful\"])\n",
            "[{'label': 'POSITIVE', 'score': 0.9998743534088135},\n",
            " {'label': 'NEGATIVE', 'score': 0.9996669292449951}]\n",
            "```\n",
            "\n",
            "To iterate over full datasets it is recommended to use a `dataset` directly. This means you don't need to allocate\n",
            "the whole dataset at once, nor do you need to do batching yourself. This should work just as fast as custom loops on\n",
            "GPU. If it doesn't don't hesitate to create an issue.\n",
            "\n",
            "```python\n",
            "import datasets\n",
            "from transformers import pipeline\n",
            "from transformers.pipelines.pt_utils import KeyDataset\n",
            "from tqdm.auto import tqdm\n",
            "\n",
            "pipe = pipeline(\"automatic-speech-recognition\", model=\"facebook/wav2vec2-base-960h\", device=0)\n",
            "dataset = datasets.load_dataset(\"superb\", name=\"asr\", split=\"test\")\n",
            "\n",
            "# KeyDataset (only *pt*) will simply return the item in the dict returned by the dataset item\n",
            "# as we're not interested in the *target* part of the dataset. For sentence pair use KeyPairDataset\n",
            "for out in tqdm(pipe(KeyDataset(dataset, \"file\"))):\n",
            "    print(out)\n",
            "    # {\"text\": \"NUMBER TEN FRESH NELLY IS WAITING ON YOU GOOD NIGHT HUSBAND\"}\n",
            "    # {\"text\": ....}\n",
            "    # ....\n",
            "```\n",
            "\n",
            "For ease of use, a generator is also possible:\n",
            "\n",
            "\n",
            "```python\n",
            "from transformers import pipeline\n",
            "\n",
            "pipe = pipeline(\"text-classification\")\n",
            "\n",
            "\n",
            "def data():\n",
            "    while True:\n",
            "        # This could come from a dataset, a database, a queue or HTTP request\n",
            "        # in a server\n",
            "        # Caveat: because this is iterative, you cannot use `num_workers > 1` variable\n",
            "        # to use multiple threads to preprocess data. You can still have 1 thread that\n",
            "        # does the preprocessing while the main runs the big inference\n",
            "        yield \"This is a test\"\n",
            "\n",
            "\n",
            "for out in pipe(data()):\n",
            "    print(out)\n",
            "    # {\"text\": \"NUMBER TEN FRESH NELLY IS WAITING ON YOU GOOD NIGHT HUSBAND\"}\n",
            "    # {\"text\": ....}\n",
            "    # ....\n",
            "```\n",
            "\n",
            "[[autodoc]] pipeline\n",
            "\n",
            "## Pipeline batching\n",
            "\n",
            "All pipelines can use batching. This will work\n",
            "whenever the pipeline uses its streaming ability (so when passing lists or `Dataset` or `generator`).\n",
            "\n",
            "```python\n",
            "from transformers import pipeline\n",
            "from transformers.pipelines.pt_utils import KeyDataset\n",
            "import datasets\n",
            "\n",
            "dataset = datasets.load_dataset(\"imdb\", name=\"plain_text\", split=\"unsupervised\")\n",
            "pipe = pipeline(\"text-classification\", device=0)\n",
            "for out in pipe(KeyDataset(dataset, \"text\"), batch_size=8, truncation=\"only_first\"):\n",
            "    print(out)\n",
            "    # [{'label': 'POSITIVE', 'score': 0.9998743534088135}]\n",
            "    # Exactly the same output as before, but the content are passed\n",
            "    # as batches to the model\n",
            "```\n",
            "\n",
            "<Tip warning={true}>\n",
            "\n",
            "However, this is not automatically a win for performance. It can be either a 10x speedup or 5x slowdown depending\n",
            "on hardware, data and the actual model being used.\n",
            "\n",
            "Example where it's mostly a speedup:\n",
            "\n",
            "</Tip>\n",
            "\n",
            "```python\n",
            "from transformers import pipeline\n",
            "from torch.utils.data import Dataset\n",
            "from tqdm.auto import tqdm\n",
            "\n",
            "pipe = pipeline(\"text-classification\", device=0)\n",
            "\n",
            "\n",
            "class MyDataset(Dataset):\n",
            "    def __len__(self):\n",
            "        return 5000\n",
            "\n",
            "    def __getitem__(self, i):\n",
            "        return \"This is a test\"\n",
            "\n",
            "\n",
            "dataset = MyDataset()\n",
            "\n",
            "for batch_size in [1, 8, 64, 256]:\n",
            "    print(\"-\" * 30)\n",
            "    print(f\"Streaming batch_size={batch_size}\")\n",
            "    for out in tqdm(pipe(dataset, batch_size=batch_size), total=len(dataset)):\n",
            "        pass\n",
            "```\n",
            "\n",
            "```\n",
            "# On GTX 970\n",
            "------------------------------\n",
            "Streaming no batching\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000 [00:26<00:00, 187.52it/s]\n",
            "------------------------------\n",
            "Streaming batch_size=8\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000 [00:04<00:00, 1205.95it/s]\n",
            "------------------------------\n",
            "Streaming batch_size=64\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000 [00:02<00:00, 2478.24it/s]\n",
            "------------------------------\n",
            "Streaming batch_size=256\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000 [00:01<00:00, 2554.43it/s]\n",
            "(diminishing returns, saturated the GPU)\n",
            "```\n",
            "\n",
            "Example where it's most a slowdown:\n",
            "\n",
            "```python\n",
            "class MyDataset(Dataset):\n",
            "    def __len__(self):\n",
            "        return 5000\n",
            "\n",
            "    def __getitem__(self, i):\n",
            "        if i % 64 == 0:\n",
            "            n = 100\n",
            "        else:\n",
            "            n = 1\n",
            "        return \"This is a test\" * n\n",
            "```\n",
            "\n",
            "This is a occasional very long sentence compared to the other. In that case, the **whole** batch will need to be 400\n",
            "tokens long, so the whole batch will be [64, 400] instead of [64, 4], leading to the high slowdown. Even worse, on\n",
            "bigger batches, the program simply crashes.\n",
            "\n",
            "\n",
            "```\n",
            "------------------------------\n",
            "Streaming no batching\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:05<00:00, 183.69it/s]\n",
            "------------------------------\n",
            "Streaming batch_size=8\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:03<00:00, 265.74it/s]\n",
            "------------------------------\n",
            "Streaming batch_size=64\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:26<00:00, 37.80it/s]\n",
            "------------------------------\n",
            "Streaming batch_size=256\n",
            "  0%|                                                                                 | 0/1000 [00:00<?, ?it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/nicolas/src/transformers/test.py\", line 42, in <module>\n",
            "    for out in tqdm(pipe(dataset, batch_size=256), total=len(dataset)):\n",
            "....\n",
            "    q = q / math.sqrt(dim_per_head)  # (bs, n_heads, q_length, dim_per_head)\n",
            "RuntimeError: CUDA out of memory. Tried to allocate 376.00 MiB (GPU 0; 3.95 GiB total capacity; 1.72 GiB already allocated; 354.88 MiB free; 2.46 GiB reserved in total by PyTorch)\n",
            "```\n",
            "\n",
            "There are no good (general) solutions for this problem, and your mileage may vary depending on your use cases. Rule of\n",
            "thumb:\n",
            "\n",
            "For users, a rule of thumb is:\n",
            "\n",
            "- **Measure performance on your load, with your hardware. Measure, measure, and keep measuring. Real numbers are the\n",
            "  only way to go.**\n",
            "- If you are latency constrained (live product doing inference), don't batch.\n",
            "- If you are using CPU, don't batch.\n",
            "- If you are using throughput (you want to run your model on a bunch of static data), on GPU, then:\n",
            "\n",
            "  - If you have no clue about the size of the sequence_length (\"natural\" data), by default don't batch, measure and\n",
            "    try tentatively to add it, add OOM checks to recover when it will fail (and it will at some point if you don't\n",
            "    control the sequence_length.)\n",
            "  - If your sequence_length is super regular, then batching is more likely to be VERY interesting, measure and push\n",
            "    it until you get OOMs.\n",
            "  - The larger the GPU the more likely batching is going to be more interesting\n",
            "- As soon as you enable batching, make sure you can handle OOMs nicely.\n",
            "\n",
            "## Pipeline chunk batching\n",
            "\n",
            "`zero-shot-classification` and `question-answering` are slightly specific in the sense, that a single input might yield\n",
            "multiple forward pass of a model. Under normal circumstances, this would yield issues with `batch_size` argument.\n",
            "\n",
            "In order to circumvent this issue, both of these pipelines are a bit specific, they are `ChunkPipeline` instead of\n",
            "regular `Pipeline`. In short:\n",
            "\n",
            "\n",
            "```python\n",
            "preprocessed = pipe.preprocess(inputs)\n",
            "model_outputs = pipe.forward(preprocessed)\n",
            "outputs = pipe.postprocess(model_outputs)\n",
            "```\n",
            "\n",
            "Now becomes:\n",
            "\n",
            "\n",
            "```python\n",
            "all_model_outputs = []\n",
            "for preprocessed in pipe.preprocess(inputs):\n",
            "    model_outputs = pipe.forward(preprocessed)\n",
            "    all_model_outputs.append(model_outputs)\n",
            "outputs = pipe.postprocess(all_model_outputs)\n",
            "```\n",
            "\n",
            "This should be very transparent to your code because the pipelines are used in\n",
            "the same way.\n",
            "\n",
            "This is a simplified view, since the pipeline can handle automatically the batch to ! Meaning you don't have to care\n",
            "about how many forward passes you inputs are actually going to trigger, you can optimize the `batch_size`\n",
            "independently of the inputs. The caveats from the previous section still apply.\n",
            "\n",
            "## Pipeline custom code\n",
            "\n",
            "If you want to override a specific pipeline.\n",
            "\n",
            "Don't hesitate to create an issue for your task at hand, the goal of the pipeline is to be easy to use and support most\n",
            "cases, so `transformers` could maybe support your use case.\n",
            "\n",
            "\n",
            "If you want to try simply you can:\n",
            "\n",
            "- Subclass your pipeline of choice\n",
            "\n",
            "```python\n",
            "class MyPipeline(TextClassificationPipeline):\n",
            "    def postprocess():\n",
            "        # Your code goes here\n",
            "        scores = scores * 100\n",
            "        # And here\n",
            "\n",
            "\n",
            "my_pipeline = MyPipeline(model=model, tokenizer=tokenizer, ...)\n",
            "# or if you use *pipeline* function, then:\n",
            "my_pipeline = pipeline(model=\"xxxx\", pipeline_class=MyPipeline)\n",
            "```\n",
            "\n",
            "That should enable you to do all the custom code you want.\n",
            "\n",
            "\n",
            "## Implementing a pipeline\n",
            "\n",
            "[Implementing a new pipeline](../add_new_pipeline)\n",
            "\n",
            "## Audio\n",
            "\n",
            "Pipelines available for audio tasks include the following.\n",
            "\n",
            "### AudioClassificationPipeline\n",
            "\n",
            "[[autodoc]] AudioClassificationPipeline\n",
            "    - __call__\n",
            "    - all\n",
            "\n",
            "### AutomaticSpeechRecognitionPipeline\n",
            "\n",
            "[[autodoc]] AutomaticSpeechRecognitionPipeline\n",
            "    - __call__\n",
            "    - all\n",
            "\n",
            "### TextToAudioPipeline\n",
            "\n",
            "[[autodoc]] TextToAudioPipeline\n",
            "    - __call__\n",
            "    - all\n",
            "\n",
            "\n",
            "### ZeroShotAudioClassificationPipeline\n",
            "\n",
            "[[autodoc]] ZeroShotAudioClassificationPipeline\n",
            "    - __call__\n",
            "    - all\n",
            "\n",
            "## Computer vision\n",
            "\n",
            "Pipelines available for computer vision tasks include the following.\n",
            "\n",
            "### DepthEstimationPipeline\n",
            "[[autodoc]] DepthEstimationPipeline\n",
            "    - __call__\n",
            "    - all\n",
            "\n",
            "### ImageClassificationPipeline\n",
            "\n",
            "[[autodoc]] ImageClassificationPipeline\n",
            "    - __call__\n",
            "    - all\n",
            "\n",
            "### ImageSegmentationPipeline\n",
            "\n",
            "[[autodoc]] ImageSegmentationPipeline\n",
            "    - __call__\n",
            "    - all\n",
            "\n",
            "### ImageToImagePipeline\n",
            "\n",
            "[[autodoc]] ImageToImagePipeline\n",
            "    - __call__\n",
            "    - all\n",
            "\n",
            "### ObjectDetectionPipeline\n",
            "\n",
            "[[autodoc]] ObjectDetectionPipeline\n",
            "    - __call__\n",
            "    - all\n",
            "\n",
            "### VideoClassificationPipeline\n",
            "\n",
            "[[autodoc]] VideoClassificationPipeline\n",
            "    - __call__\n",
            "    - all\n",
            "\n",
            "### ZeroShotImageClassificationPipeline\n",
            "\n",
            "[[autodoc]] ZeroShotImageClassificationPipeline\n",
            "    - __call__\n",
            "    - all\n",
            "\n",
            "### ZeroShotObjectDetectionPipeline\n",
            "\n",
            "[[autodoc]] ZeroShotObjectDetectionPipeline\n",
            "    - __call__\n",
            "    - all\n",
            "\n",
            "## Natural Language Processing\n",
            "\n",
            "Pipelines available for natural language processing tasks include the following.\n",
            "\n",
            "### ConversationalPipeline\n",
            "\n",
            "[[autodoc]] Conversation\n",
            "\n",
            "[[autodoc]] ConversationalPipeline\n",
            "    - __call__\n",
            "    - all\n",
            "\n",
            "### FillMaskPipeline\n",
            "\n",
            "[[autodoc]] FillMaskPipeline\n",
            "    - __call__\n",
            "    - all\n",
            "\n",
            "### QuestionAnsweringPipeline\n",
            "\n",
            "[[autodoc]] QuestionAnsweringPipeline\n",
            "    - __call__\n",
            "    - all\n",
            "\n",
            "### SummarizationPipeline\n",
            "\n",
            "[[autodoc]] SummarizationPipeline\n",
            "    - __call__\n",
            "    - all\n",
            "\n",
            "### TableQuestionAnsweringPipeline\n",
            "\n",
            "[[autodoc]] TableQuestionAnsweringPipeline\n",
            "    - __call__\n",
            "\n",
            "### TextClassificationPipeline\n",
            "\n",
            "[[autodoc]] TextClassificationPipeline\n",
            "    - __call__\n",
            "    - all\n",
            "\n",
            "### TextGenerationPipeline\n",
            "\n",
            "[[autodoc]] TextGenerationPipeline\n",
            "    - __call__\n",
            "    - all\n",
            "\n",
            "### Text2TextGenerationPipeline\n",
            "\n",
            "[[autodoc]] Text2TextGenerationPipeline\n",
            "    - __call__\n",
            "    - all\n",
            "\n",
            "### TokenClassificationPipeline\n",
            "\n",
            "[[autodoc]] TokenClassificationPipeline\n",
            "    - __call__\n",
            "    - all\n",
            "\n",
            "### TranslationPipeline\n",
            "\n",
            "[[autodoc]] TranslationPipeline\n",
            "    - __call__\n",
            "    - all\n",
            "\n",
            "### ZeroShotClassificationPipeline\n",
            "\n",
            "[[autodoc]] ZeroShotClassificationPipeline\n",
            "    - __call__\n",
            "    - all\n",
            "\n",
            "## Multimodal\n",
            "\n",
            "Pipelines available for multimodal tasks include the following.\n",
            "\n",
            "### DocumentQuestionAnsweringPipeline\n",
            "\n",
            "[[autodoc]] DocumentQuestionAnsweringPipeline\n",
            "    - __call__\n",
            "    - all\n",
            "\n",
            "### FeatureExtractionPipeline\n",
            "\n",
            "[[autodoc]] FeatureExtractionPipeline\n",
            "    - __call__\n",
            "    - all\n",
            "\n",
            "### ImageToTextPipeline\n",
            "\n",
            "[[autodoc]] ImageToTextPipeline\n",
            "    - __call__\n",
            "    - all\n",
            "\n",
            "### MaskGenerationPipeline\n",
            "\n",
            "[[autodoc]] MaskGenerationPipeline\n",
            "    - __call__\n",
            "    - all\n",
            "\n",
            "### VisualQuestionAnsweringPipeline\n",
            "\n",
            "[[autodoc]] VisualQuestionAnsweringPipeline\n",
            "    - __call__\n",
            "    - all\n",
            "\n",
            "## Parent class: `Pipeline`\n",
            "\n",
            "[[autodoc]] Pipeline\n",
            "Document 3------------------------------------------------------------\n",
            "!--Copyright 2020 The HuggingFace Team. All rights reserved.\n",
            "\n",
            "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with\n",
            "the License. You may obtain a copy of the License at\n",
            "\n",
            "http://www.apache.org/licenses/LICENSE-2.0\n",
            "\n",
            "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on\n",
            "an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the\n",
            "\n",
            "âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be\n",
            "rendered properly in your Markdown viewer.\n",
            "\n",
            "-->\n",
            "\n",
            "# How to create a custom pipeline?\n",
            "\n",
            "In this guide, we will see how to create a custom pipeline and share it on the [Hub](hf.co/models) or add it to the\n",
            "ğŸ¤— Transformers library.\n",
            "\n",
            "First and foremost, you need to decide the raw entries the pipeline will be able to take. It can be strings, raw bytes,\n",
            "dictionaries or whatever seems to be the most likely desired input. Try to keep these inputs as pure Python as possible\n",
            "as it makes compatibility easier (even through other languages via JSON). Those will be the `inputs` of the\n",
            "pipeline (`preprocess`).\n",
            "\n",
            "Then define the `outputs`. Same policy as the `inputs`. The simpler, the better. Those will be the outputs of\n",
            "`postprocess` method.\n",
            "\n",
            "Start by inheriting the base class `Pipeline` with the 4 methods needed to implement `preprocess`,\n",
            "`_forward`, `postprocess`, and `_sanitize_parameters`.\n",
            "\n",
            "\n",
            "```python\n",
            "from transformers import Pipeline\n",
            "\n",
            "\n",
            "class MyPipeline(Pipeline):\n",
            "    def _sanitize_parameters(self, **kwargs):\n",
            "        preprocess_kwargs = {}\n",
            "        if \"maybe_arg\" in kwargs:\n",
            "            preprocess_kwargs[\"maybe_arg\"] = kwargs[\"maybe_arg\"]\n",
            "        return preprocess_kwargs, {}, {}\n",
            "\n",
            "    def preprocess(self, inputs, maybe_arg=2):\n",
            "        model_input = Tensor(inputs[\"input_ids\"])\n",
            "        return {\"model_input\": model_input}\n",
            "\n",
            "    def _forward(self, model_inputs):\n",
            "        # model_inputs == {\"model_input\": model_input}\n",
            "        outputs = self.model(**model_inputs)\n",
            "        # Maybe {\"logits\": Tensor(...)}\n",
            "        return outputs\n",
            "\n",
            "    def postprocess(self, model_outputs):\n",
            "        best_class = model_outputs[\"logits\"].softmax(-1)\n",
            "        return best_class\n",
            "```\n",
            "\n",
            "The structure of this breakdown is to support relatively seamless support for CPU/GPU, while supporting doing\n",
            "pre/postprocessing on the CPU on different threads\n",
            "\n",
            "`preprocess` will take the originally defined inputs, and turn them into something feedable to the model. It might\n",
            "contain more information and is usually a `Dict`.\n",
            "\n",
            "`_forward` is the implementation detail and is not meant to be called directly. `forward` is the preferred\n",
            "called method as it contains safeguards to make sure everything is working on the expected device. If anything is\n",
            "linked to a real model it belongs in the `_forward` method, anything else is in the preprocess/postprocess.\n",
            "\n",
            "`postprocess` methods will take the output of `_forward` and turn it into the final output that was decided\n",
            "earlier.\n",
            "\n",
            "`_sanitize_parameters` exists to allow users to pass any parameters whenever they wish, be it at initialization\n",
            "time `pipeline(...., maybe_arg=4)` or at call time `pipe = pipeline(...); output = pipe(...., maybe_arg=4)`.\n",
            "\n",
            "The returns of `_sanitize_parameters` are the 3 dicts of kwargs that will be passed directly to `preprocess`,\n",
            "`_forward`, and `postprocess`. Don't fill anything if the caller didn't call with any extra parameter. That\n",
            "allows to keep the default arguments in the function definition which is always more \"natural\".\n",
            "\n",
            "A classic example would be a `top_k` argument in the post processing in classification tasks.\n",
            "\n",
            "```python\n",
            ">>> pipe = pipeline(\"my-new-task\")\n",
            ">>> pipe(\"This is a test\")\n",
            "[{\"label\": \"1-star\", \"score\": 0.8}, {\"label\": \"2-star\", \"score\": 0.1}, {\"label\": \"3-star\", \"score\": 0.05}\n",
            "{\"label\": \"4-star\", \"score\": 0.025}, {\"label\": \"5-star\", \"score\": 0.025}]\n",
            "\n",
            ">>> pipe(\"This is a test\", top_k=2)\n",
            "[{\"label\": \"1-star\", \"score\": 0.8}, {\"label\": \"2-star\", \"score\": 0.1}]\n",
            "```\n",
            "\n",
            "In order to achieve that, we'll update our `postprocess` method with a default parameter to `5`. and edit\n",
            "`_sanitize_parameters` to allow this new parameter.\n",
            "\n",
            "\n",
            "```python\n",
            "def postprocess(self, model_outputs, top_k=5):\n",
            "    best_class = model_outputs[\"logits\"].softmax(-1)\n",
            "    # Add logic to handle top_k\n",
            "    return best_class\n",
            "\n",
            "\n",
            "def _sanitize_parameters(self, **kwargs):\n",
            "    preprocess_kwargs = {}\n",
            "    if \"maybe_arg\" in kwargs:\n",
            "        preprocess_kwargs[\"maybe_arg\"] = kwargs[\"maybe_arg\"]\n",
            "\n",
            "    postprocess_kwargs = {}\n",
            "    if \"top_k\" in kwargs:\n",
            "        postprocess_kwargs[\"top_k\"] = kwargs[\"top_k\"]\n",
            "    return preprocess_kwargs, {}, postprocess_kwargs\n",
            "```\n",
            "\n",
            "Try to keep the inputs/outputs very simple and ideally JSON-serializable as it makes the pipeline usage very easy\n",
            "without requiring users to understand new kinds of objects. It's also relatively common to support many different types\n",
            "of arguments for ease of use (audio files, which can be filenames, URLs or pure bytes)\n",
            "\n",
            "\n",
            "\n",
            "## Adding it to the list of supported tasks\n",
            "\n",
            "To register your `new-task` to the list of supported tasks, you have to add it to the `PIPELINE_REGISTRY`:\n",
            "\n",
            "```python\n",
            "from transformers.pipelines import PIPELINE_REGISTRY\n",
            "\n",
            "PIPELINE_REGISTRY.register_pipeline(\n",
            "    \"new-task\",\n",
            "    pipeline_class=MyPipeline,\n",
            "    pt_model=AutoModelForSequenceClassification,\n",
            ")\n",
            "```\n",
            "\n",
            "You can specify a default model if you want, in which case it should come with a specific revision (which can be the name of a branch or a commit hash, here we took `\"abcdef\"`) as well as the type:\n",
            "\n",
            "```python\n",
            "PIPELINE_REGISTRY.register_pipeline(\n",
            "    \"new-task\",\n",
            "    pipeline_class=MyPipeline,\n",
            "    pt_model=AutoModelForSequenceClassification,\n",
            "    default={\"pt\": (\"user/awesome_model\", \"abcdef\")},\n",
            "    type=\"text\",  # current support type: text, audio, image, multimodal\n",
            ")\n",
            "```\n",
            "\n",
            "## Share your pipeline on the Hub\n",
            "\n",
            "To share your custom pipeline on the Hub, you just have to save the custom code of your `Pipeline` subclass in a\n",
            "python file. For instance, let's say we want to use a custom pipeline for sentence pair classification like this:\n",
            "\n",
            "```py\n",
            "import numpy as np\n",
            "\n",
            "from transformers import Pipeline\n",
            "\n",
            "\n",
            "def softmax(outputs):\n",
            "    maxes = np.max(outputs, axis=-1, keepdims=True)\n",
            "    shifted_exp = np.exp(outputs - maxes)\n",
            "    return shifted_exp / shifted_exp.sum(axis=-1, keepdims=True)\n",
            "\n",
            "\n",
            "class PairClassificationPipeline(Pipeline):\n",
            "    def _sanitize_parameters(self, **kwargs):\n",
            "        preprocess_kwargs = {}\n",
            "        if \"second_text\" in kwargs:\n",
            "            preprocess_kwargs[\"second_text\"] = kwargs[\"second_text\"]\n",
            "        return preprocess_kwargs, {}, {}\n",
            "\n",
            "    def preprocess(self, text, second_text=None):\n",
            "        return self.tokenizer(text, text_pair=second_text, return_tensors=self.framework)\n",
            "\n",
            "    def _forward(self, model_inputs):\n",
            "        return self.model(**model_inputs)\n",
            "\n",
            "    def postprocess(self, model_outputs):\n",
            "        logits = model_outputs.logits[0].numpy()\n",
            "        probabilities = softmax(logits)\n",
            "\n",
            "        best_class = np.argmax(probabilities)\n",
            "        label = self.model.config.id2label[best_class]\n",
            "        score = probabilities[best_class].item()\n",
            "        logits = logits.tolist()\n",
            "        return {\"label\": label, \"score\": score, \"logits\": logits}\n",
            "```\n",
            "\n",
            "The implementation is framework agnostic, and will work for PyTorch and TensorFlow models. If we have saved this in\n",
            "a file named `pair_classification.py`, we can then import it and register it like this:\n",
            "\n",
            "```py\n",
            "from pair_classification import PairClassificationPipeline\n",
            "from transformers.pipelines import PIPELINE_REGISTRY\n",
            "from transformers import AutoModelForSequenceClassification, TFAutoModelForSequenceClassification\n",
            "\n",
            "PIPELINE_REGISTRY.register_pipeline(\n",
            "    \"pair-classification\",\n",
            "    pipeline_class=PairClassificationPipeline,\n",
            "    pt_model=AutoModelForSequenceClassification,\n",
            "    tf_model=TFAutoModelForSequenceClassification,\n",
            ")\n",
            "```\n",
            "\n",
            "Once this is done, we can use it with a pretrained model. For instance `sgugger/finetuned-bert-mrpc` has been\n",
            "fine-tuned on the MRPC dataset, which classifies pairs of sentences as paraphrases or not.\n",
            "\n",
            "```py\n",
            "from transformers import pipeline\n",
            "\n",
            "classifier = pipeline(\"pair-classification\", model=\"sgugger/finetuned-bert-mrpc\")\n",
            "```\n",
            "\n",
            "Then we can share it on the Hub by using the `save_pretrained` method in a `Repository`:\n",
            "\n",
            "```py\n",
            "from huggingface_hub import Repository\n",
            "\n",
            "repo = Repository(\"test-dynamic-pipeline\", clone_from=\"{your_username}/test-dynamic-pipeline\")\n",
            "classifier.save_pretrained(\"test-dynamic-pipeline\")\n",
            "repo.push_to_hub()\n",
            "```\n",
            "\n",
            "This will copy the file where you defined `PairClassificationPipeline` inside the folder `\"test-dynamic-pipeline\"`,\n",
            "along with saving the model and tokenizer of the pipeline, before pushing everything into the repository\n",
            "`{your_username}/test-dynamic-pipeline`. After that, anyone can use it as long as they provide the option\n",
            "`trust_remote_code=True`:\n",
            "\n",
            "```py\n",
            "from transformers import pipeline\n",
            "\n",
            "classifier = pipeline(model=\"{your_username}/test-dynamic-pipeline\", trust_remote_code=True)\n",
            "```\n",
            "\n",
            "## Add the pipeline to ğŸ¤— Transformers\n",
            "\n",
            "If you want to contribute your pipeline to ğŸ¤— Transformers, you will need to add a new module in the `pipelines` submodule\n",
            "with the code of your pipeline, then add it to the list of tasks defined in `pipelines/__init__.py`.\n",
            "\n",
            "Then you will need to add tests. Create a new file `tests/test_pipelines_MY_PIPELINE.py` with examples of the other tests.\n",
            "\n",
            "The `run_pipeline_test` function will be very generic and run on small random models on every possible\n",
            "architecture as defined by `model_mapping` and `tf_model_mapping`.\n",
            "\n",
            "This is very important to test future compatibility, meaning if someone adds a new model for\n",
            "`XXXForQuestionAnswering` then the pipeline test will attempt to run on it. Because the models are random it's\n",
            "impossible to check for actual values, that's why there is a helper `ANY` that will simply attempt to match the\n",
            "output of the pipeline TYPE.\n",
            "\n",
            "You also *need* to implement 2 (ideally 4) tests.\n",
            "\n",
            "- `test_small_model_pt` : Define 1 small model for this pipeline (doesn't matter if the results don't make sense)\n",
            "  and test the pipeline outputs. The results should be the same as `test_small_model_tf`.\n",
            "- `test_small_model_tf` : Define 1 small model for this pipeline (doesn't matter if the results don't make sense)\n",
            "  and test the pipeline outputs. The results should be the same as `test_small_model_pt`.\n",
            "- `test_large_model_pt` (`optional`): Tests the pipeline on a real pipeline where the results are supposed to\n",
            "  make sense. These tests are slow and should be marked as such. Here the goal is to showcase the pipeline and to make\n",
            "  sure there is no drift in future releases.\n",
            "- `test_large_model_tf` (`optional`): Tests the pipeline on a real pipeline where the results are supposed to\n",
            "  make sense. These tests are slow and should be marked as such. Here the goal is to showcase the pipeline and to make\n",
            "  sure there is no drift in future releases.\n",
            "Document 4------------------------------------------------------------\n",
            "hat happens inside the pipeline function? In this video, we will look at what actually happens when we use the pipeline function of the Transformers library. More specifically, we will look at the sentiment analysis pipeline, and how it went from the two following sentences to the positive labels with their respective scores. As we have seen in the pipeline presentation, there are three stages in the pipeline. First, we convert the raw texts to numbers the model can make sense of, using a tokenizer. Then, those numbers go through the model, which outputs logits. Finally, the post-processing steps transforms those logits into labels and scores. Let's look in detail at those three steps, and how to replicate them using the Transformers library, beginning with the first stage, tokenization. The tokenization process has several steps. First, the text is split into small chunks called tokens. They can be words, parts of words or punctuation symbols. Then the tokenizer will had some special tokens (if the model expect them). Here the model uses expects a CLS token at the beginning and a SEP token at the end of the sentence to classify. Lastly, the tokenizer matches each token to its unique ID in the vocabulary of the pretrained model. To load such a tokenizer, the Transformers library provides the AutoTokenizer API. The most important method of this class is from_pretrained, which will download and cache the configuration and the vocabulary associated to a given checkpoint. Here, the checkpoint used by default for the sentiment analysis pipeline is distilbert base uncased finetuned sst2 english. We instantiate a tokenizer associated with that checkpoint, then feed it the two sentences. Since those two sentences are not of the same size, we will need to pad the shortest one to be able to build an array. This is done by the tokenizer with the option padding=True. With truncation=True, we ensure that any sentence longer than the maximum the model can handle is truncated. Lastly, the return_tensors option tells the tokenizer to return a TensorFlow tensor. Looking at the result, we see we have a dictionary with two keys. Input IDs contains the IDs of both sentences, with 0s where the padding is applied. The second key, attention mask, indicates where padding has been applied, so the model does not pay attention to it. This is all what is inside the tokenization step. Now let's have a look at the second step, the model. As for the tokenizer, there is an TFAutoModel API, with a from_pretrained method. It will download and cache the configuration of the model as well as the pretrained weights. However, the TFAutoModel API will only instantiate the body of the model, that is, the part of the model that is left once the pretraining head is removed. It will output a high-dimensional tensor that is a representation of the sentences passed, but which is not directly useful for our classification problem. Here the tensor has two sentences, each of sixteen tokens and the last dimension is the hidden size of our model 768. To get an output linked to our classification problem, we need to use the TFAutoModelForSequenceClassification class. It works exactly as the AutoModel class, except that it will build a model with a classification head. There is one auto class for each common NLP task in the Transformers library. Here, after giving our model the two sentences, we get a tensor of size two by two: one result for each sentence and for each possible label. Those outputs are not probabilities yet (we can see they don't sum to 1). This is because each model of the Transformers library returns logits. To make sense of those logits, we need to dig into the third and last step of the pipeline: post-processing. To convert logits into probabilities, we need to apply a SoftMax layer to them. As we can see, this transforms them into positive numbers that sum up to 1. The last step is to know which of those corresponds to the positive or the negative label. This is given by the id2label field of the model config. The first probabilities (index 0) correspond to the negative label, and the seconds (index 1) correspond to the positive label. This is how our classifier built with the pipeline function picked those labels and computed those scores. Now that you know how each steps works, you can easily tweak them to your needs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ğ’Ñ–Ğ´Ğ¿Ğ¾Ğ²Ñ–Ğ´ÑŒ Ğ¿Ñ–ÑĞ»Ñ Ğ·Ğ¼Ñ–Ğ½Ğ¸ Ñ€Ğ¾Ğ·Ğ¼Ñ–Ñ€Ñƒ Ñ‡Ğ°Ğ½ĞºĞ° Ğ· 512 Ğ½Ğ° 348"
      ],
      "metadata": {
        "id": "jYfQpHLEtCq5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"==================================Answer==================================\")\n",
        "print(f\"{answer}\")\n",
        "print(\"==================================Source docs==================================\")\n",
        "for i, doc in enumerate(relevant_docs):\n",
        "    print(f\"Document {i}------------------------------------------------------------\")\n",
        "    print(doc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4lTfzwAsCVG",
        "outputId": "bdd86f1d-7acf-421d-863f-f7dacf3aa8dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================Answer==================================\n",
            "To create a pipeline object in the ğŸ¤— Transformers library, follow these steps:\n",
            "\n",
            "1. Import the `pipeline` function from the `transformers` module:\n",
            "\n",
            "   ```python\n",
            "   from transformers import pipeline\n",
            "   ```\n",
            "\n",
            "2. Specify the inference task for which you want to create the pipeline. You can find a list of supported tasks in the documentation by looking at the `pipeline` documentation or by checking the `PIPELINE_REGISTRY`. For example, to create a pipeline for automatic speech recognition (ASR), use:\n",
            "\n",
            "   ```python\n",
            "   >>> pipeline(task=\"automatic-speech-recognition\")\n",
            "   ```\n",
            "\n",
            "3. Alternatively, you can use the general `pipeline` abstraction that automatically loads a default model and preprocessing class for your task. This approach simplifies the process by requiring fewer lines of code:\n",
            "\n",
            "   ```python\n",
            "   >>> from transformers import pipeline\n",
            "   >>> transcriber = pipeline(task=\"automatic-speech-recognition\")\n",
            "   ```\n",
            "\n",
            "4. To register a new task to the list of supported tasks, you need to add it to the `PIPELINE_REGISTRY`. Here's an example:\n",
            "\n",
            "   ```python\n",
            "   from transformers.pipelines import PIPELINE_REGISTRY\n",
            "\n",
            "   PIPELINE_REGISTRY.register_pipeline(\n",
            "       \"new-task\",\n",
            "       pipeline_class=MyPipeline,\n",
            "       pt_model=AutoModelForSequenceClassification,\n",
            "       default={\"pt\": (\"user/awesome_model\", \"abcdef\")},\n",
            "       type=\"text\",\n",
            "   )\n",
            "   ```\n",
            "\n",
            "In both cases, the pipeline object will contain all the necessary preprocessing, encoding, and decoding steps required for your chosen task. You can then pass input data to the pipeline object to perform inference.\n",
            "==================================Source docs==================================\n",
            "Document 0------------------------------------------------------------\n",
            "<Tip>\n",
            "\n",
            "Take a look at the [`pipeline`] documentation for a complete list of supported tasks and available parameters.\n",
            "\n",
            "</Tip>\n",
            "\n",
            "## Pipeline usage\n",
            "\n",
            "While each task has an associated [`pipeline`], it is simpler to use the general [`pipeline`] abstraction which contains \n",
            "all the task-specific pipelines. The [`pipeline`] automatically loads a default model and a preprocessing class capable \n",
            "of inference for your task. Let's take the example of using the [`pipeline`] for automatic speech recognition (ASR), or\n",
            "speech-to-text.\n",
            "\n",
            "\n",
            "1. Start by creating a [`pipeline`] and specify the inference task:\n",
            "\n",
            "```py\n",
            ">>> from transformers import pipeline\n",
            "\n",
            ">>> transcriber = pipeline(task=\"automatic-speech-recognition\")\n",
            "Document 1------------------------------------------------------------\n",
            "A pipeline is a quick and easy way to run a model for inference, requiring no more than four lines of code to generate an image:\n",
            "\n",
            "```py\n",
            ">>> from diffusers import DDPMPipeline\n",
            "\n",
            ">>> ddpm = DDPMPipeline.from_pretrained(\"google/ddpm-cat-256\", use_safetensors=True).to(\"cuda\")\n",
            ">>> image = ddpm(num_inference_steps=25).images[0]\n",
            ">>> image\n",
            "Document 2------------------------------------------------------------\n",
            "```\n",
            "\n",
            "create `object.txt`, with contents like:\n",
            "\n",
            "```\n",
            "chair\n",
            "sofa\n",
            "bench\n",
            "```\n",
            "\n",
            "```python\n",
            "from diffusers import DiffusionPipeline\n",
            "import torch\n",
            "\n",
            "pipe = DiffusionPipeline.from_pretrained(\n",
            "    \"CompVis/stable-diffusion-v1-4\",\n",
            "    custom_pipeline=\"wildcard_stable_diffusion\",\n",
            "\n",
            "    torch_dtype=torch.float16,\n",
            ")\n",
            "prompt = \"__animal__ sitting on a __object__ wearing a __clothing__\"\n",
            "out = pipe(\n",
            "    prompt,\n",
            "    wildcard_option_dict={\n",
            "        \"clothing\":[\"hat\", \"shirt\", \"scarf\", \"beret\"]\n",
            "    },\n",
            "    wildcard_files=[\"object.txt\", \"animal.txt\"],\n",
            "    num_prompt_samples=1\n",
            ")\n",
            "Document 3------------------------------------------------------------\n",
            "## Working with pipelines[[working-with-pipelines]]\n",
            "\n",
            "<Youtube id=\"tiZFewofSLM\" />\n",
            "\n",
            "The most basic object in the ğŸ¤— Transformers library is the `pipeline()` function. It connects a model with its necessary preprocessing and postprocessing steps, allowing us to directly input any text and get an intelligible answer:\n",
            "\n",
            "```python\n",
            "from transformers import pipeline\n",
            "\n",
            "classifier = pipeline(\"sentiment-analysis\")\n",
            "classifier(\"I've been waiting for a HuggingFace course my whole life.\")\n",
            "Document 4------------------------------------------------------------\n",
            "```\n",
            "\n",
            "Try to keep the inputs/outputs very simple and ideally JSON-serializable as it makes the pipeline usage very easy\n",
            "without requiring users to understand new kinds of objects. It's also relatively common to support many different types\n",
            "of arguments for ease of use (audio files, which can be filenames, URLs or pure bytes)\n",
            "\n",
            "\n",
            "\n",
            "## Adding it to the list of supported tasks\n",
            "\n",
            "To register your `new-task` to the list of supported tasks, you have to add it to the `PIPELINE_REGISTRY`:\n",
            "\n",
            "```python\n",
            "from transformers.pipelines import PIPELINE_REGISTRY\n",
            "\n",
            "PIPELINE_REGISTRY.register_pipeline(\n",
            "    \"new-task\",\n",
            "    pipeline_class=MyPipeline,\n",
            "    pt_model=AutoModelForSequenceClassification,\n",
            ")\n",
            "```\n",
            "\n",
            "You can specify a default model if you want, in which case it should come with a specific revision (which can be the name of a branch or a commit hash, here we took `\"abcdef\"`) as well as the type:\n",
            "\n",
            "```python\n",
            "PIPELINE_REGISTRY.register_pipeline(\n",
            "    \"new-task\",\n",
            "    pipeline_class=MyPipeline,\n",
            "    pt_model=AutoModelForSequenceClassification,\n",
            "    default={\"pt\": (\"user/awesome_model\", \"abcdef\")},\n",
            "    type=\"text\",  # current support type: text, audio, image, multimodal\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Prompt improvements - **2 points total**\n",
        "    1. Find out how to improve prompt to get better results - 1 point\n",
        "    2. Change the ways of how result is represented - 1 point"
      ],
      "metadata": {
        "id": "xMOzwYbeq-Oz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ğ’Ñ–Ğ´Ğ¿Ğ¾Ğ²Ñ–Ğ´ÑŒ Ğ´Ğ¾ Ğ¿Ğ¾ĞºÑ€Ğ°Ñ‰ĞµĞ½Ğ½Ñ prompt\n"
      ],
      "metadata": {
        "id": "FbCBKUPhhkoQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"==================================Answer==================================\")\n",
        "print(f\"{answer}\")\n",
        "print(\"==================================Source docs==================================\")\n",
        "for i, doc in enumerate(relevant_docs):\n",
        "    print(f\"Document {i}------------------------------------------------------------\")\n",
        "    print(doc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qo8hMJi-finn",
        "outputId": "04eb82e9-c0f3-48ef-9160-4e28c8761d2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================Answer==================================\n",
            "To create a pipeline object, follow these steps:\n",
            "\n",
            "1. Import the necessary module, `pipeline`, from the Hugging Face Transformers library.\n",
            "\n",
            "2. Choose the specific task you want to perform with the pipeline, such as object detection, sentiment analysis, or text-to-image generation. Store this choice in a variable.\n",
            "\n",
            "3. Instantiate the pipeline object by passing the chosen task to the `pipeline()` function. You may also pass additional arguments, such as the pretrained model checkpoint to use, the device to run the pipeline on (CPU or GPU), and whether to use half-precision floating point numbers for improved performance.\n",
            "\n",
            "Here's an example:\n",
            "\n",
            "```python\n",
            "from transformers import pipeline\n",
            "\n",
            "# Create a pipeline for object detection\n",
            "object_detector = pipeline(\"object-detection\")\n",
            "\n",
            "# Create a pipeline for sentiment analysis\n",
            "sentiment_analyzer = pipeline(\"sentiment-analysis\")\n",
            "\n",
            "# Create a pipeline for text-to-image generation\n",
            "text_to_image = pipeline(\"text-to-image\")\n",
            "\n",
            "# Create a pipeline for image-to-image generation using the same components from a previously loaded pipeline\n",
            "image_to_image = AutoPipelineForImage2Image.from_pipe(text_to_image)\n",
            "```\n",
            "\n",
            "Note that the exact syntax for creating a pipeline may vary depending on the specific task being performed. Refer to the documentation for each task for more details.\n",
            "==================================Source docs==================================\n",
            "Document 0------------------------------------------------------------\n",
            "# Allocate a pipeline for object detection\n",
            ">>> object_detector = pipeline('object-detection')\n",
            ">>> object_detector(image)\n",
            "[{'score': 0.9982201457023621,\n",
            "  'label': 'remote',\n",
            "  'box': {'xmin': 40, 'ymin': 70, 'xmax': 175, 'ymax': 117}},\n",
            " {'score': 0.9960021376609802,\n",
            "  'label': 'remote',\n",
            "  'box': {'xmin': 333, 'ymin': 72, 'xmax': 368, 'ymax': 187}},\n",
            " {'score': 0.9954745173454285,\n",
            "  'label': 'couch',\n",
            "  'box': {'xmin': 0, 'ymin': 1, 'xmax': 639, 'ymax': 473}},\n",
            " {'score': 0.9988006353378296,\n",
            "  'label': 'cat',\n",
            "  'box': {'xmin': 13, 'ymin': 52, 'xmax': 314, 'ymax': 470}},\n",
            " {'score': 0.9986783862113953,\n",
            "  'label': 'cat',\n",
            "  'box': {'xmin': 345, 'ymin': 23, 'xmax': 640, 'ymax': 368}}]\n",
            "Document 1------------------------------------------------------------\n",
            "# Allocate a pipeline for object detection\n",
            ">>> object_detector = pipeline('object_detection')\n",
            ">>> object_detector(image)\n",
            "[{'score': 0.9982201457023621,\n",
            "  'label': 'remote',\n",
            "  'box': {'xmin': 40, 'ymin': 70, 'xmax': 175, 'ymax': 117}},\n",
            " {'score': 0.9960021376609802,\n",
            "  'label': 'remote',\n",
            "  'box': {'xmin': 333, 'ymin': 72, 'xmax': 368, 'ymax': 187}},\n",
            " {'score': 0.9954745173454285,\n",
            "  'label': 'couch',\n",
            "  'box': {'xmin': 0, 'ymin': 1, 'xmax': 639, 'ymax': 473}},\n",
            " {'score': 0.9988006353378296,\n",
            "  'label': 'cat',\n",
            "  'box': {'xmin': 13, 'ymin': 52, 'xmax': 314, 'ymax': 470}},\n",
            " {'score': 0.9986783862113953,\n",
            "  'label': 'cat',\n",
            "  'box': {'xmin': 345, 'ymin': 23, 'xmax': 640, 'ymax': 368}}]\n",
            "Document 2------------------------------------------------------------\n",
            "Start by creating an instance of [`pipeline`] and specifying a task you want to use it for. In this guide, you'll use the [`pipeline`] for sentiment analysis as an example:\n",
            "\n",
            "```py\n",
            ">>> from transformers import pipeline\n",
            "\n",
            ">>> classifier = pipeline(\"sentiment-analysis\")\n",
            "Document 3------------------------------------------------------------\n",
            "```\n",
            "\n",
            "2. Pass a prompt to the pipeline to generate an image:\n",
            "\n",
            "```py\n",
            "image = pipeline(\n",
            "\t\"stained glass of darth vader, backlight, centered composition, masterpiece, photorealistic, 8k\"\n",
            ").images[0]\n",
            "image\n",
            "Document 4------------------------------------------------------------\n",
            "```\n",
            "\n",
            "## Use multiple pipelines\n",
            "\n",
            "For some workflows or if you're loading many pipelines, it is more memory-efficient to reuse the same components from a checkpoint instead of reloading them which would unnecessarily consume additional memory. For example, if you're using a checkpoint for text-to-image and you want to use it again for image-to-image, use the [`~AutoPipelineForImage2Image.from_pipe`] method. This method creates a new pipeline from the components of a previously loaded pipeline at no additional memory cost.\n",
            "\n",
            "The [`~AutoPipelineForImage2Image.from_pipe`] method detects the original pipeline class and maps it to the new pipeline class corresponding to the task you want to do. For example, if you load a `\"stable-diffusion\"` class pipeline for text-to-image:\n",
            "\n",
            "```py\n",
            "from diffusers import AutoPipelineForText2Image, AutoPipelineForImage2Image\n",
            "import torch\n",
            "\n",
            "pipeline_text2img = AutoPipelineForText2Image.from_pretrained(\n",
            "    \"runwayml/stable-diffusion-v1-5\", torch_dtype=torch.float16, use_safetensors=True\n",
            ")\n",
            "print(type(pipeline_text2img))\n",
            "\"<class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'>\"\n",
            "```\n",
            "\n",
            "Then [`~AutoPipelineForImage2Image.from_pipe`] maps the original `\"stable-diffusion\"` pipeline class to [`StableDiffusionImg2ImgPipeline`]:\n",
            "\n",
            "```py\n",
            "pipeline_img2img = AutoPipelineForImage2Image.from_pipe(pipeline_text2img)\n",
            "print(type(pipeline_img2img))\n",
            "\"<class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion_img2img.StableDiffusionImg2ImgPipeline'>\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ĞŸÑ–ÑĞ»Ñ Ğ·Ğ¼Ñ–Ğ½Ğ¸ prompt"
      ],
      "metadata": {
        "id": "gmN5kZroZW1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"==================================Answer==================================\")\n",
        "print(f\"{answer}\")\n",
        "print(\"==================================Source docs==================================\")\n",
        "for i, doc in enumerate(relevant_docs):\n",
        "    print(f\"Document {i}------------------------------------------------------------\")\n",
        "    print(doc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALX7kh8xhoHZ",
        "outputId": "74d50059-5d09-4e82-bed5-6ac65b1abef5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================Answer==================================\n",
            "To create a pipeline object, follow these steps:\n",
            "\n",
            "1. Import the required module, `pipeline`, from the `transformers` library.\n",
            "\n",
            "2. Choose the task you want to perform with the pipeline, such as object detection, sentiment analysis, or text-to-image generation.\n",
            "\n",
            "3. Create a new pipeline object by passing the chosen task to the `pipeline()` function. For example:\n",
            "\n",
            "   - For object detection:\n",
            "\n",
            "     ```python\n",
            "     >>> from transformers import pipeline\n",
            "     >>> object_detector = pipeline('object-detection')\n",
            "     ```\n",
            "\n",
            "   - For sentiment analysis:\n",
            "\n",
            "     ```python\n",
            "     >>> from transformers import pipeline\n",
            "     >>> classifier = pipeline(\"sentiment-analysis\")\n",
            "     ```\n",
            "\n",
            "   - For text-to-image generation:\n",
            "\n",
            "     ```python\n",
            "     >>> from diffusers import AutoPipelineForText2Image\n",
            "     >>> pipeline_text2img = AutoPipelineForText2Image.from_pretrained(\"runwayml/stable-diffusion-v1-5\")\n",
            "     ```\n",
            "\n",
            "Note that in the case of text-to-image generation, we're using the `AutoPipelineForText2Image` class from the `diffusers` library instead of the `pipeline()` function from the `transformers` library. This is because the `diffusers` library provides specialized classes for certain tasks, like text-to-image generation.\n",
            "\n",
            "In general, the syntax for creating a pipeline object is:\n",
            "\n",
            "```python\n",
            "from [library] import [class]\n",
            "[pipeline_object] = [class].from_pretrained([checkpoint],...)\n",
            "```\n",
            "\n",
            "Replace `[library]` with either `transformers` or `diffusers`, depending on the library you're using. Replace `[class]` with the appropriate class for your chosen task (e.g., `pipeline()` for general tasks, or `AutoPipelineForText2Image` for text-to-image generation). Finally, replace `[checkpoint]` with the path to the pretrained model checkpoint you want to use.\n",
            "\n",
            "If you're loading multiple pipelines, you can reuse the same components from a checkpoint to save memory by using the `from_pipe()` method, as shown in the fourth example above. This method\n",
            "==================================Source docs==================================\n",
            "Document 0------------------------------------------------------------\n",
            "# Allocate a pipeline for object detection\n",
            ">>> object_detector = pipeline('object-detection')\n",
            ">>> object_detector(image)\n",
            "[{'score': 0.9982201457023621,\n",
            "  'label': 'remote',\n",
            "  'box': {'xmin': 40, 'ymin': 70, 'xmax': 175, 'ymax': 117}},\n",
            " {'score': 0.9960021376609802,\n",
            "  'label': 'remote',\n",
            "  'box': {'xmin': 333, 'ymin': 72, 'xmax': 368, 'ymax': 187}},\n",
            " {'score': 0.9954745173454285,\n",
            "  'label': 'couch',\n",
            "  'box': {'xmin': 0, 'ymin': 1, 'xmax': 639, 'ymax': 473}},\n",
            " {'score': 0.9988006353378296,\n",
            "  'label': 'cat',\n",
            "  'box': {'xmin': 13, 'ymin': 52, 'xmax': 314, 'ymax': 470}},\n",
            " {'score': 0.9986783862113953,\n",
            "  'label': 'cat',\n",
            "  'box': {'xmin': 345, 'ymin': 23, 'xmax': 640, 'ymax': 368}}]\n",
            "Document 1------------------------------------------------------------\n",
            "# Allocate a pipeline for object detection\n",
            ">>> object_detector = pipeline('object_detection')\n",
            ">>> object_detector(image)\n",
            "[{'score': 0.9982201457023621,\n",
            "  'label': 'remote',\n",
            "  'box': {'xmin': 40, 'ymin': 70, 'xmax': 175, 'ymax': 117}},\n",
            " {'score': 0.9960021376609802,\n",
            "  'label': 'remote',\n",
            "  'box': {'xmin': 333, 'ymin': 72, 'xmax': 368, 'ymax': 187}},\n",
            " {'score': 0.9954745173454285,\n",
            "  'label': 'couch',\n",
            "  'box': {'xmin': 0, 'ymin': 1, 'xmax': 639, 'ymax': 473}},\n",
            " {'score': 0.9988006353378296,\n",
            "  'label': 'cat',\n",
            "  'box': {'xmin': 13, 'ymin': 52, 'xmax': 314, 'ymax': 470}},\n",
            " {'score': 0.9986783862113953,\n",
            "  'label': 'cat',\n",
            "  'box': {'xmin': 345, 'ymin': 23, 'xmax': 640, 'ymax': 368}}]\n",
            "Document 2------------------------------------------------------------\n",
            "Start by creating an instance of [`pipeline`] and specifying a task you want to use it for. In this guide, you'll use the [`pipeline`] for sentiment analysis as an example:\n",
            "\n",
            "```py\n",
            ">>> from transformers import pipeline\n",
            "\n",
            ">>> classifier = pipeline(\"sentiment-analysis\")\n",
            "Document 3------------------------------------------------------------\n",
            "```\n",
            "\n",
            "2. Pass a prompt to the pipeline to generate an image:\n",
            "\n",
            "```py\n",
            "image = pipeline(\n",
            "\t\"stained glass of darth vader, backlight, centered composition, masterpiece, photorealistic, 8k\"\n",
            ").images[0]\n",
            "image\n",
            "Document 4------------------------------------------------------------\n",
            "```\n",
            "\n",
            "## Use multiple pipelines\n",
            "\n",
            "For some workflows or if you're loading many pipelines, it is more memory-efficient to reuse the same components from a checkpoint instead of reloading them which would unnecessarily consume additional memory. For example, if you're using a checkpoint for text-to-image and you want to use it again for image-to-image, use the [`~AutoPipelineForImage2Image.from_pipe`] method. This method creates a new pipeline from the components of a previously loaded pipeline at no additional memory cost.\n",
            "\n",
            "The [`~AutoPipelineForImage2Image.from_pipe`] method detects the original pipeline class and maps it to the new pipeline class corresponding to the task you want to do. For example, if you load a `\"stable-diffusion\"` class pipeline for text-to-image:\n",
            "\n",
            "```py\n",
            "from diffusers import AutoPipelineForText2Image, AutoPipelineForImage2Image\n",
            "import torch\n",
            "\n",
            "pipeline_text2img = AutoPipelineForText2Image.from_pretrained(\n",
            "    \"runwayml/stable-diffusion-v1-5\", torch_dtype=torch.float16, use_safetensors=True\n",
            ")\n",
            "print(type(pipeline_text2img))\n",
            "\"<class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'>\"\n",
            "```\n",
            "\n",
            "Then [`~AutoPipelineForImage2Image.from_pipe`] maps the original `\"stable-diffusion\"` pipeline class to [`StableDiffusionImg2ImgPipeline`]:\n",
            "\n",
            "```py\n",
            "pipeline_img2img = AutoPipelineForImage2Image.from_pipe(pipeline_text2img)\n",
            "print(type(pipeline_img2img))\n",
            "\"<class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion_img2img.StableDiffusionImg2ImgPipeline'>\"\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2956df5a5ef346d8b00183c8c8e613e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_211e246543704c3fa34ca2fcf079a543",
              "IPY_MODEL_44ba550273f646bbb3ac77c4bdd6a53c",
              "IPY_MODEL_a4d62a370aa041e89a8e99f5151db55b"
            ],
            "layout": "IPY_MODEL_272df92d04944724b223123388d21d41"
          }
        },
        "211e246543704c3fa34ca2fcf079a543": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32de49a189034e288801c60cf75092b4",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_f2dcf3e5aca74b679472e7c3e33d8336",
            "value": "Downloadingâ€‡readme:â€‡100%"
          }
        },
        "44ba550273f646bbb3ac77c4bdd6a53c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7287810c20b5479baa850d372946c472",
            "max": 21,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_90765904443a4778b5d5077093c1bb36",
            "value": 21
          }
        },
        "a4d62a370aa041e89a8e99f5151db55b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b434c8e91f914cbc85e6b90e0c8bfc9c",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_56ed646918894840b56fe8739dae35f6",
            "value": "â€‡21.0/21.0â€‡[00:00&lt;00:00,â€‡1.29kB/s]"
          }
        },
        "272df92d04944724b223123388d21d41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32de49a189034e288801c60cf75092b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2dcf3e5aca74b679472e7c3e33d8336": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7287810c20b5479baa850d372946c472": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90765904443a4778b5d5077093c1bb36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b434c8e91f914cbc85e6b90e0c8bfc9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56ed646918894840b56fe8739dae35f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6760cf877e514c0cb439258fc360182f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7d5a2d1a727e40768d18eecf5dd2d720",
              "IPY_MODEL_d4fa71c5a73f49c6b3e2a42f6fbc3e7d",
              "IPY_MODEL_5a462a5d2963484ba6ae08f20791c2b8"
            ],
            "layout": "IPY_MODEL_b672ad621eeb448cbbb038646d06aee8"
          }
        },
        "7d5a2d1a727e40768d18eecf5dd2d720": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5fd2d7ea2cb4edca35c2ed6d8e25388",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_18e4fb7c01db400db8706f15aa596e85",
            "value": "Downloadingâ€‡data:â€‡100%"
          }
        },
        "d4fa71c5a73f49c6b3e2a42f6fbc3e7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7241e4afcbc8477d82929cd37d3b1909",
            "max": 21954601,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_524e4d1fc823479d8cacd2ffe835edeb",
            "value": 21954601
          }
        },
        "5a462a5d2963484ba6ae08f20791c2b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5009c54c8f5c43db9bcd3c739bb42794",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_51a2ee4a161843e2b900619a8d25ba16",
            "value": "â€‡22.0M/22.0Mâ€‡[00:00&lt;00:00,â€‡32.8MB/s]"
          }
        },
        "b672ad621eeb448cbbb038646d06aee8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5fd2d7ea2cb4edca35c2ed6d8e25388": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18e4fb7c01db400db8706f15aa596e85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7241e4afcbc8477d82929cd37d3b1909": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "524e4d1fc823479d8cacd2ffe835edeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5009c54c8f5c43db9bcd3c739bb42794": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51a2ee4a161843e2b900619a8d25ba16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9175eaa7c9074cf6ad18a6fd3ab5414c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4634fd9ed537423fa40197de02fc85ad",
              "IPY_MODEL_c875b42ce80b4e95a3c416bf0ba60d3f",
              "IPY_MODEL_cb094a58200b415d810814731f45a217"
            ],
            "layout": "IPY_MODEL_002cc319f0a4440bbf065dc4e586e4f8"
          }
        },
        "4634fd9ed537423fa40197de02fc85ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1f2f36cf9c242598a8d8aad3489bb5c",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_cc7b79a6d59d4735a5beaf94dbc14b6e",
            "value": "Generatingâ€‡trainâ€‡split:â€‡100%"
          }
        },
        "c875b42ce80b4e95a3c416bf0ba60d3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f747c9c27f054bc1a51b98ba63f24878",
            "max": 2647,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_db26bed459bb4810929ba91a8a1888a3",
            "value": 2647
          }
        },
        "cb094a58200b415d810814731f45a217": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e2e811f45144bf8b89cd128ae51eb3a",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_95ff6e1ca6db446689aabbb271324d30",
            "value": "â€‡2647/2647â€‡[00:00&lt;00:00,â€‡3732.42â€‡examples/s]"
          }
        },
        "002cc319f0a4440bbf065dc4e586e4f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1f2f36cf9c242598a8d8aad3489bb5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc7b79a6d59d4735a5beaf94dbc14b6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f747c9c27f054bc1a51b98ba63f24878": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db26bed459bb4810929ba91a8a1888a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2e2e811f45144bf8b89cd128ae51eb3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95ff6e1ca6db446689aabbb271324d30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a855d3969d364c6883baa4ea25c9415b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0374af1f2f2141dcbde6dc1ec62f8e04",
              "IPY_MODEL_d635c50fe95241b3aa8d89d628eeb819",
              "IPY_MODEL_6a495551e2d7494093e4b488a00520a5"
            ],
            "layout": "IPY_MODEL_88a30f9f33f1481f9c30f36987f7fc2f"
          }
        },
        "0374af1f2f2141dcbde6dc1ec62f8e04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fbc1a418773042d09d18b21e0649d35d",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_5113b8d55f514315ad7bdc94ca9aa160",
            "value": "100%"
          }
        },
        "d635c50fe95241b3aa8d89d628eeb819": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5fba4a72a9104ef08f28c796100340f4",
            "max": 2647,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_130fe463d7d24d2baf6f8381a1735aaf",
            "value": 2647
          }
        },
        "6a495551e2d7494093e4b488a00520a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1198effa1fd4391ae7dc3e33ce06f0a",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_caa40c25ed824e34afea3274f478cb72",
            "value": "â€‡2647/2647â€‡[00:00&lt;00:00,â€‡8580.41it/s]"
          }
        },
        "88a30f9f33f1481f9c30f36987f7fc2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbc1a418773042d09d18b21e0649d35d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5113b8d55f514315ad7bdc94ca9aa160": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5fba4a72a9104ef08f28c796100340f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "130fe463d7d24d2baf6f8381a1735aaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e1198effa1fd4391ae7dc3e33ce06f0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "caa40c25ed824e34afea3274f478cb72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c52eccde31740f98a2dc73e86b670ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0b12653c943c4d48acf9307e22f4def2",
              "IPY_MODEL_0ff5c7ad45924098bad422f510e6d66f",
              "IPY_MODEL_c4521b0aaa5f4b008a187b8bb9f28ae9"
            ],
            "layout": "IPY_MODEL_fd3b329f856742a4bfffd0a5a58399ee"
          }
        },
        "0b12653c943c4d48acf9307e22f4def2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_921d40fe580b4622a9f3e85de24ebac6",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_761f034edae544e1b8667abe2b706bc1",
            "value": "modules.json:â€‡100%"
          }
        },
        "0ff5c7ad45924098bad422f510e6d66f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad8178beb87d4720963cc257a3af76c5",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cca998bbac2b430ab55ba3607bd97ddf",
            "value": 349
          }
        },
        "c4521b0aaa5f4b008a187b8bb9f28ae9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85082cad860e45c79a3b09901633fe85",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ecb7daff99e141da8e629095e603b30e",
            "value": "â€‡349/349â€‡[00:00&lt;00:00,â€‡8.31kB/s]"
          }
        },
        "fd3b329f856742a4bfffd0a5a58399ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "921d40fe580b4622a9f3e85de24ebac6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "761f034edae544e1b8667abe2b706bc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad8178beb87d4720963cc257a3af76c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cca998bbac2b430ab55ba3607bd97ddf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "85082cad860e45c79a3b09901633fe85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ecb7daff99e141da8e629095e603b30e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d35d0bec01a441b9d7300d905473eed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9215d86a38e64358b57daf0990c54360",
              "IPY_MODEL_4a85071f674f44a19fe7c02e6ae37eb6",
              "IPY_MODEL_3fac0f7cac0f4a959499bb06484a51eb"
            ],
            "layout": "IPY_MODEL_6810fa5182724cc19fdb5f124704c3f8"
          }
        },
        "9215d86a38e64358b57daf0990c54360": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9666cbe1994443b0aa75ce9951fb1ca0",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_c57bcc92bc2e4faa840f5de267794d0b",
            "value": "config_sentence_transformers.json:â€‡100%"
          }
        },
        "4a85071f674f44a19fe7c02e6ae37eb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_893a89883e674cbc85668589602712c0",
            "max": 171,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_536e6e8f5d7b46f78e595a431a99f85e",
            "value": 171
          }
        },
        "3fac0f7cac0f4a959499bb06484a51eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b1d5bc73e70426f99bd3c0078ce5278",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_922a870d16954612ab89a28acb1f59f3",
            "value": "â€‡171/171â€‡[00:00&lt;00:00,â€‡2.25kB/s]"
          }
        },
        "6810fa5182724cc19fdb5f124704c3f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9666cbe1994443b0aa75ce9951fb1ca0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c57bcc92bc2e4faa840f5de267794d0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "893a89883e674cbc85668589602712c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "536e6e8f5d7b46f78e595a431a99f85e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5b1d5bc73e70426f99bd3c0078ce5278": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "922a870d16954612ab89a28acb1f59f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8fb9641e2904464a9b35962da4b5bb54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6d078c09092f4f7db19f5c898f7cce39",
              "IPY_MODEL_9c50416d4a0d4d2ead41f213826cb58f",
              "IPY_MODEL_1922ebb985f444fda4a0f1e9ed01e6f6"
            ],
            "layout": "IPY_MODEL_43f2893792ba497690d1773682385af7"
          }
        },
        "6d078c09092f4f7db19f5c898f7cce39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0289e78f6c49470a9e8bf67dd867e172",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_5318a330754e4c49a6736a9e640f10fb",
            "value": "README.md:â€‡100%"
          }
        },
        "9c50416d4a0d4d2ead41f213826cb58f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97d0264b273549eb9fe1c50cbb166582",
            "max": 14653,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ba7f9b2f0ccd4ccdb6de19bcba0e8e6e",
            "value": 14653
          }
        },
        "1922ebb985f444fda4a0f1e9ed01e6f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6095bceaede048a0825a200a60f8b14c",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_bdc400452f454baabc25b783ed643493",
            "value": "â€‡14.7k/14.7kâ€‡[00:00&lt;00:00,â€‡248kB/s]"
          }
        },
        "43f2893792ba497690d1773682385af7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0289e78f6c49470a9e8bf67dd867e172": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5318a330754e4c49a6736a9e640f10fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "97d0264b273549eb9fe1c50cbb166582": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba7f9b2f0ccd4ccdb6de19bcba0e8e6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6095bceaede048a0825a200a60f8b14c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdc400452f454baabc25b783ed643493": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e378194502d4a1987952f1c961df757": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3ababca1d1e84029b5a3dd40c93bbc53",
              "IPY_MODEL_aae39aec90cd426bbf1be9b82d3eea4d",
              "IPY_MODEL_af1163d0fe4a4aa3bdd4fb9a97046950"
            ],
            "layout": "IPY_MODEL_8661178767ff40c9af81814329bbcc55"
          }
        },
        "3ababca1d1e84029b5a3dd40c93bbc53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76084feac7864b338c4580896805c7a1",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b87a4b3d3af94bc5ae3438431ae3d57d",
            "value": "sentence_bert_config.json:â€‡100%"
          }
        },
        "aae39aec90cd426bbf1be9b82d3eea4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_673e55d54c71465f8e04f2d48f396eaa",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_834ba3c05d8c4a47986535b3bde8dc91",
            "value": 53
          }
        },
        "af1163d0fe4a4aa3bdd4fb9a97046950": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c97da952d464f8f9297b25dffc56850",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_5183c17098c54e32857a712e66e39bee",
            "value": "â€‡53.0/53.0â€‡[00:00&lt;00:00,â€‡1.79kB/s]"
          }
        },
        "8661178767ff40c9af81814329bbcc55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76084feac7864b338c4580896805c7a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b87a4b3d3af94bc5ae3438431ae3d57d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "673e55d54c71465f8e04f2d48f396eaa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "834ba3c05d8c4a47986535b3bde8dc91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5c97da952d464f8f9297b25dffc56850": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5183c17098c54e32857a712e66e39bee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "599008141b7949c2b973ed3912d133d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f2f1c4330ceb42f7ae3dc2fb5e0e6efe",
              "IPY_MODEL_dfdac4ff89764e029f3a10955abd753c",
              "IPY_MODEL_579bbca0ddee4ebfb597a8259212c50f"
            ],
            "layout": "IPY_MODEL_ca415ae913e4404785add23ee7356972"
          }
        },
        "f2f1c4330ceb42f7ae3dc2fb5e0e6efe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fad9772949b946c6965fe5f6b64c822d",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_2583be50cff1449894a9a0ea241b8fb0",
            "value": "config.json:â€‡100%"
          }
        },
        "dfdac4ff89764e029f3a10955abd753c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c16b8b586a1438db9b571571e2c4f11",
            "max": 594,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a97a470947ab4f399239dee50132ae2b",
            "value": 594
          }
        },
        "579bbca0ddee4ebfb597a8259212c50f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c43a33c27534eda8e6c199d3ac9f2c6",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_938145e87a4941af94afd87e619f1ad2",
            "value": "â€‡594/594â€‡[00:00&lt;00:00,â€‡12.2kB/s]"
          }
        },
        "ca415ae913e4404785add23ee7356972": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fad9772949b946c6965fe5f6b64c822d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2583be50cff1449894a9a0ea241b8fb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c16b8b586a1438db9b571571e2c4f11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a97a470947ab4f399239dee50132ae2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5c43a33c27534eda8e6c199d3ac9f2c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "938145e87a4941af94afd87e619f1ad2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "051262e7b15c459580ae5eb9765764c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b0179244d5904679ba73497a3da77845",
              "IPY_MODEL_c28679ef7b02493e81f623b14d09f0f2",
              "IPY_MODEL_0d08cedf90534dfa83407906119c505d"
            ],
            "layout": "IPY_MODEL_c69845eec7ac4b7997f16017d75c20d5"
          }
        },
        "b0179244d5904679ba73497a3da77845": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84fb0aca383c4b098974179757894b62",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_f3c93912ab7945a4aec1209bd3ce442d",
            "value": "model.safetensors:â€‡100%"
          }
        },
        "c28679ef7b02493e81f623b14d09f0f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fa604dad6fe453ca34972fb16c8ff06",
            "max": 69565312,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1d664576d98e4f6c9aec3aece8e197bd",
            "value": 69565312
          }
        },
        "0d08cedf90534dfa83407906119c505d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7bbeee11c9ab4fe799a667fdb9467110",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_063056e902db4514bec9c8d37293016b",
            "value": "â€‡69.6M/69.6Mâ€‡[00:00&lt;00:00,â€‡101MB/s]"
          }
        },
        "c69845eec7ac4b7997f16017d75c20d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84fb0aca383c4b098974179757894b62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3c93912ab7945a4aec1209bd3ce442d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2fa604dad6fe453ca34972fb16c8ff06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d664576d98e4f6c9aec3aece8e197bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7bbeee11c9ab4fe799a667fdb9467110": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "063056e902db4514bec9c8d37293016b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dc63b09dafbf444c9f3af08ac0c7d8b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_098d27ee2dce4f58aa5e3db7617efce4",
              "IPY_MODEL_68d650508812484cadc4ed02c32710e8",
              "IPY_MODEL_253c31ec02b640fc85bdf2339ebb211b"
            ],
            "layout": "IPY_MODEL_1a20a65d8998429f839b39120cad62cd"
          }
        },
        "098d27ee2dce4f58aa5e3db7617efce4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25408a3dd1eb44649f9ec8f81a3ad4a4",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_eac8b023304043b39e0fa1dcf0e0508c",
            "value": "tokenizer_config.json:â€‡100%"
          }
        },
        "68d650508812484cadc4ed02c32710e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ef2ae3251384974b0a6a94c5c9c8162",
            "max": 1461,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c83f0e97952a4e0fb674d00557aea39a",
            "value": 1461
          }
        },
        "253c31ec02b640fc85bdf2339ebb211b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19c0eef7a0f94422addb535444e6584c",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_d694f1f4984b4c8386c6a5867b33dafd",
            "value": "â€‡1.46k/1.46kâ€‡[00:00&lt;00:00,â€‡24.3kB/s]"
          }
        },
        "1a20a65d8998429f839b39120cad62cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25408a3dd1eb44649f9ec8f81a3ad4a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eac8b023304043b39e0fa1dcf0e0508c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ef2ae3251384974b0a6a94c5c9c8162": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c83f0e97952a4e0fb674d00557aea39a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "19c0eef7a0f94422addb535444e6584c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d694f1f4984b4c8386c6a5867b33dafd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "43d1f9c5b9144247aa66920fe71c5bc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0ab16a67dd3143798203378fa8449c6e",
              "IPY_MODEL_1a6d21c92d3b4d949b0782d29dc7eb64",
              "IPY_MODEL_0eca988963174b12be493a6de78c02cf"
            ],
            "layout": "IPY_MODEL_0060493798be456f8d2c2ea9a9c81e16"
          }
        },
        "0ab16a67dd3143798203378fa8449c6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb0cdc2583504f8d925b9f49fee22f12",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_34b002fd67b94cbc9b0dda0b2bf14e19",
            "value": "vocab.txt:â€‡100%"
          }
        },
        "1a6d21c92d3b4d949b0782d29dc7eb64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b659bedc78d4dc881df9bd65822ae73",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3043a09751d2436e954cf4711c5798ab",
            "value": 231508
          }
        },
        "0eca988963174b12be493a6de78c02cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ad450fa1e464e04a656aaf991f9086f",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_42630f1dbfa344cdafa93fc7271bf823",
            "value": "â€‡232k/232kâ€‡[00:00&lt;00:00,â€‡3.32MB/s]"
          }
        },
        "0060493798be456f8d2c2ea9a9c81e16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb0cdc2583504f8d925b9f49fee22f12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34b002fd67b94cbc9b0dda0b2bf14e19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b659bedc78d4dc881df9bd65822ae73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3043a09751d2436e954cf4711c5798ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0ad450fa1e464e04a656aaf991f9086f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42630f1dbfa344cdafa93fc7271bf823": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ebe2e7a8254e435dbe70a49cd6548097": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5850fa89e70b4ca29fdac93dace604a1",
              "IPY_MODEL_2977d8a4e4f242e4aa8eca54de251131",
              "IPY_MODEL_6f153358a883430c936aed4f7ff086fb"
            ],
            "layout": "IPY_MODEL_ee9632f8313d4bc98f028af47c5a1dea"
          }
        },
        "5850fa89e70b4ca29fdac93dace604a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f08b4b1c273433c9539b4eb0d057b20",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_07f6f3f0ee104308b7cf4748c87fd2a1",
            "value": "tokenizer.json:â€‡100%"
          }
        },
        "2977d8a4e4f242e4aa8eca54de251131": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb8b2bdd65a9445abe1ce7ee63f18ca8",
            "max": 711649,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aa4545a9771340d882b98be9a561ffbb",
            "value": 711649
          }
        },
        "6f153358a883430c936aed4f7ff086fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc353ce69f2b438191fcc2c06c36eec2",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_87f88f8cbc144a43bc5674bbb2f4e7ef",
            "value": "â€‡712k/712kâ€‡[00:00&lt;00:00,â€‡18.1MB/s]"
          }
        },
        "ee9632f8313d4bc98f028af47c5a1dea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f08b4b1c273433c9539b4eb0d057b20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07f6f3f0ee104308b7cf4748c87fd2a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fb8b2bdd65a9445abe1ce7ee63f18ca8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa4545a9771340d882b98be9a561ffbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bc353ce69f2b438191fcc2c06c36eec2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87f88f8cbc144a43bc5674bbb2f4e7ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ff43bb3a2394870a0e14c117e49be09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_15aa3e341aef4cd996048e762c39b314",
              "IPY_MODEL_97ed49e9b6304d758c288e610cb425f5",
              "IPY_MODEL_750e807876484cc681060602bd1415eb"
            ],
            "layout": "IPY_MODEL_5ad5d0bffda64009915f56a098ae0e68"
          }
        },
        "15aa3e341aef4cd996048e762c39b314": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb1a5663b21d4a60bee1d78e5a01b6d6",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_3fd7711b603f42508c2918b3ae14bf95",
            "value": "special_tokens_map.json:â€‡100%"
          }
        },
        "97ed49e9b6304d758c288e610cb425f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c5c0616dd3a4ce3beead52965072731",
            "max": 695,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5b57ad2e7f574a809df423d027c4eeb9",
            "value": 695
          }
        },
        "750e807876484cc681060602bd1415eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36a5d5847e8c42428357188f02e08041",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_2e4a148990b6497c9830335610825574",
            "value": "â€‡695/695â€‡[00:00&lt;00:00,â€‡23.5kB/s]"
          }
        },
        "5ad5d0bffda64009915f56a098ae0e68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb1a5663b21d4a60bee1d78e5a01b6d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fd7711b603f42508c2918b3ae14bf95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6c5c0616dd3a4ce3beead52965072731": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b57ad2e7f574a809df423d027c4eeb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "36a5d5847e8c42428357188f02e08041": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e4a148990b6497c9830335610825574": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "314223aab91d4577a76aead5d148c8f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6c6b20ca047c427185d9aa04b19de467",
              "IPY_MODEL_0b2ccef1413147b69b4d05b99c66e691",
              "IPY_MODEL_a5804c8122264d93840c413dd5eff35e"
            ],
            "layout": "IPY_MODEL_3423ba9792774a4cb88c01ae17a17452"
          }
        },
        "6c6b20ca047c427185d9aa04b19de467": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66c89e30c8174259a796d5cd3e40e612",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_6efa18c33f194e9fa43561d0a647ca2c",
            "value": "1_Pooling/config.json:â€‡100%"
          }
        },
        "0b2ccef1413147b69b4d05b99c66e691": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00d4ab26ba62489e9e3059a83071e0b1",
            "max": 296,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5b6efbb15fd94dd7a070db7791b43264",
            "value": 296
          }
        },
        "a5804c8122264d93840c413dd5eff35e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fafacb4028b542aba11886ca03528b8f",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_c0d5da340bda49b6879137e7b7ba3ca3",
            "value": "â€‡296/296â€‡[00:00&lt;00:00,â€‡2.96kB/s]"
          }
        },
        "3423ba9792774a4cb88c01ae17a17452": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66c89e30c8174259a796d5cd3e40e612": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6efa18c33f194e9fa43561d0a647ca2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "00d4ab26ba62489e9e3059a83071e0b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b6efbb15fd94dd7a070db7791b43264": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fafacb4028b542aba11886ca03528b8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0d5da340bda49b6879137e7b7ba3ca3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a602afe293414f4a98ed4bca4cbeaa18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c34d2b27247045518ee1a52d4a213d35",
              "IPY_MODEL_2a83b9d66b9f46c39a46e5115debdff3",
              "IPY_MODEL_a4ddffa6c6e54ac1b781120299ededcf"
            ],
            "layout": "IPY_MODEL_d00bebd6886b4ed59ff0b1b7cc0672af"
          }
        },
        "c34d2b27247045518ee1a52d4a213d35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cab9b7ed1d6f4db2ae3e3a617b08589a",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b02168cb7dd84d5d92c4c16dc6b4fa7e",
            "value": "100%"
          }
        },
        "2a83b9d66b9f46c39a46e5115debdff3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc7dfe551aca46c894e778c1dfaa8737",
            "max": 31085,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2c0c53cc3da645d9ae6ad78021358b9e",
            "value": 31085
          }
        },
        "a4ddffa6c6e54ac1b781120299ededcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c8f1a4b7a2f4627a0b8a6941a9e4e3b",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_bd0cf4e8ff984f718db37137e70a0634",
            "value": "â€‡31085/31085â€‡[00:36&lt;00:00,â€‡1815.97it/s]"
          }
        },
        "d00bebd6886b4ed59ff0b1b7cc0672af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cab9b7ed1d6f4db2ae3e3a617b08589a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b02168cb7dd84d5d92c4c16dc6b4fa7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc7dfe551aca46c894e778c1dfaa8737": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c0c53cc3da645d9ae6ad78021358b9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9c8f1a4b7a2f4627a0b8a6941a9e4e3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd0cf4e8ff984f718db37137e70a0634": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "61aa1a3d641c40759488931c1fa99ea1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_32cc0f5af1f247d6b1b1ec6483dc7f14",
              "IPY_MODEL_8962e85fcceb4692860f9fea1036b545",
              "IPY_MODEL_bbf4422e26c7455bbf42c58fe57240c4"
            ],
            "layout": "IPY_MODEL_9e79cbb5835f495d8bb385d77fa5c4fd"
          }
        },
        "32cc0f5af1f247d6b1b1ec6483dc7f14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_446b11c33f7e490293340ee6a4a2dbfb",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_87faaef4e0e54c31b568e91b42ced923",
            "value": "100%"
          }
        },
        "8962e85fcceb4692860f9fea1036b545": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_364641c148704883bb3c9f7be30c8c10",
            "max": 2647,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7e62eec9dce54917a33bae11b58c3e83",
            "value": 2647
          }
        },
        "bbf4422e26c7455bbf42c58fe57240c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0428c644b4748db954fa3266b071803",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_cb669d9803dd4766a9bddf7488ba46cb",
            "value": "â€‡2647/2647â€‡[01:34&lt;00:00,â€‡45.75it/s]"
          }
        },
        "9e79cbb5835f495d8bb385d77fa5c4fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "446b11c33f7e490293340ee6a4a2dbfb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87faaef4e0e54c31b568e91b42ced923": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "364641c148704883bb3c9f7be30c8c10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e62eec9dce54917a33bae11b58c3e83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e0428c644b4748db954fa3266b071803": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb669d9803dd4766a9bddf7488ba46cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "48f421954105463eb083577cc299b97b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a24015f113a84b36afa1f8716bc1fd01",
              "IPY_MODEL_dec8d95a7d8a4ff189ca322ec7e76f36",
              "IPY_MODEL_02855e587eec4cbdb22a6a0a987498bf"
            ],
            "layout": "IPY_MODEL_01f915bcbd314c51891dbe16f4977952"
          }
        },
        "a24015f113a84b36afa1f8716bc1fd01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26a1b26787b14f1c97fa032a07574065",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_929ab19e75ac44ad8f194b5b6df6bcd8",
            "value": "100%"
          }
        },
        "dec8d95a7d8a4ff189ca322ec7e76f36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1fe3e880aa64b3c9a77bf27e7a25dc6",
            "max": 17995,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0182c114510c4b4eababe3cdbac2a6f6",
            "value": 17995
          }
        },
        "02855e587eec4cbdb22a6a0a987498bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59abc074158046138e049cdcff2cc693",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_bfa7a54b06c947d095ca3d6f20304d93",
            "value": "â€‡17995/17995â€‡[00:18&lt;00:00,â€‡1011.81it/s]"
          }
        },
        "01f915bcbd314c51891dbe16f4977952": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26a1b26787b14f1c97fa032a07574065": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "929ab19e75ac44ad8f194b5b6df6bcd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b1fe3e880aa64b3c9a77bf27e7a25dc6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0182c114510c4b4eababe3cdbac2a6f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "59abc074158046138e049cdcff2cc693": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfa7a54b06c947d095ca3d6f20304d93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee8e030c5fe04bb6952ecfcbe90efcfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_311b84ae2cfe4140ab40a4797ade8220",
              "IPY_MODEL_0759d15312bf4f20ae6fee0e9c584525",
              "IPY_MODEL_d20a0fa248794d38a46cf315ddcc493f"
            ],
            "layout": "IPY_MODEL_4228cdc1d59243bb889c665c9d96b45b"
          }
        },
        "311b84ae2cfe4140ab40a4797ade8220": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d609fd4abfe438d8a59885c7df6ea85",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_47e41defed02436c8d9afaf573e50848",
            "value": "tokenizer_config.json:â€‡100%"
          }
        },
        "0759d15312bf4f20ae6fee0e9c584525": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_abea490afe434d75843f9ac9415c15a6",
            "max": 394,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_04e17b21a41b41bd94d886d46fdc3e2c",
            "value": 394
          }
        },
        "d20a0fa248794d38a46cf315ddcc493f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b372dc78baa4458b19a141a310bc8ef",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_a1700e6effd6479295406beec87d8a00",
            "value": "â€‡394/394â€‡[00:00&lt;00:00,â€‡27.6kB/s]"
          }
        },
        "4228cdc1d59243bb889c665c9d96b45b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d609fd4abfe438d8a59885c7df6ea85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47e41defed02436c8d9afaf573e50848": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "abea490afe434d75843f9ac9415c15a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04e17b21a41b41bd94d886d46fdc3e2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5b372dc78baa4458b19a141a310bc8ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1700e6effd6479295406beec87d8a00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c92b9016f36c40e7b814110f7c2e3b6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_25431821d2da4757ab6d65a04143e7fe",
              "IPY_MODEL_a55e19415bb94990a7964f30be904435",
              "IPY_MODEL_427992f15c11455ab4ab8ffd4ff89492"
            ],
            "layout": "IPY_MODEL_c73a05b066db45c29a818254f65639c2"
          }
        },
        "25431821d2da4757ab6d65a04143e7fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aafdd95536e143febe03a5b8c8701e97",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_50d6e665396242259ac9c9654d7fc0ca",
            "value": "vocab.txt:â€‡100%"
          }
        },
        "a55e19415bb94990a7964f30be904435": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d448855908a64d48aa82a2ca8bf85cc0",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4a6f4649c07e410bb4906c31d1362788",
            "value": 231508
          }
        },
        "427992f15c11455ab4ab8ffd4ff89492": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_950dad6c3ad44418963980327bff066b",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_533ed8b74a7542cda670de9d86ff07b2",
            "value": "â€‡232k/232kâ€‡[00:00&lt;00:00,â€‡10.3MB/s]"
          }
        },
        "c73a05b066db45c29a818254f65639c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aafdd95536e143febe03a5b8c8701e97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50d6e665396242259ac9c9654d7fc0ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d448855908a64d48aa82a2ca8bf85cc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a6f4649c07e410bb4906c31d1362788": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "950dad6c3ad44418963980327bff066b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "533ed8b74a7542cda670de9d86ff07b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6cb4b64dc835485594341b1039826e1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dca089a74a14403e96c99686a19cfd7f",
              "IPY_MODEL_0e3d3a4759da41b2b36df2acb2e49b03",
              "IPY_MODEL_859b6a6997de436b84d9b58c33fbc6de"
            ],
            "layout": "IPY_MODEL_7c72d9b92c8348d2baff4de26d5b804c"
          }
        },
        "dca089a74a14403e96c99686a19cfd7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e0aa61044f94ff3a95ba555fe785fb6",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_9579b0d7de6e4c4fb1f93345279796b4",
            "value": "tokenizer.json:â€‡100%"
          }
        },
        "0e3d3a4759da41b2b36df2acb2e49b03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8479f2ef66df4db19c02f6b9930b4858",
            "max": 711661,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1ee79477267741e59fe8abd47a0495ea",
            "value": 711661
          }
        },
        "859b6a6997de436b84d9b58c33fbc6de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65d7aa6e746048fd8786c3d68fe774dc",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_e357128b85ca4f75889f5bb494064368",
            "value": "â€‡712k/712kâ€‡[00:00&lt;00:00,â€‡7.97MB/s]"
          }
        },
        "7c72d9b92c8348d2baff4de26d5b804c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e0aa61044f94ff3a95ba555fe785fb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9579b0d7de6e4c4fb1f93345279796b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8479f2ef66df4db19c02f6b9930b4858": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ee79477267741e59fe8abd47a0495ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "65d7aa6e746048fd8786c3d68fe774dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e357128b85ca4f75889f5bb494064368": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "be99578799654f108ffb7541acdbfd6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3f3c485bd9654653b841e01bdc9bfaa4",
              "IPY_MODEL_c2002c07fe9e4cf786f477a32b3255cb",
              "IPY_MODEL_d7a7d808b47944f9a3435659de139d67"
            ],
            "layout": "IPY_MODEL_1839d749bc344a83b126a726cc579735"
          }
        },
        "3f3c485bd9654653b841e01bdc9bfaa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82d4471a2e774b11a49ccc2fedfdf501",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ff239f4e8af3409993ca547597172526",
            "value": "special_tokens_map.json:â€‡100%"
          }
        },
        "c2002c07fe9e4cf786f477a32b3255cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51b3a5b1f5b749f09e9b262290289989",
            "max": 125,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_44a9a259896a40f09c5ad9b5d106d2e6",
            "value": 125
          }
        },
        "d7a7d808b47944f9a3435659de139d67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83d8d0336c2a4e14a196373b028cca31",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b8394bfac17e48bf8b8228f8ea119a8a",
            "value": "â€‡125/125â€‡[00:00&lt;00:00,â€‡8.13kB/s]"
          }
        },
        "1839d749bc344a83b126a726cc579735": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82d4471a2e774b11a49ccc2fedfdf501": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff239f4e8af3409993ca547597172526": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51b3a5b1f5b749f09e9b262290289989": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44a9a259896a40f09c5ad9b5d106d2e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "83d8d0336c2a4e14a196373b028cca31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8394bfac17e48bf8b8228f8ea119a8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e9ba3a55e8e8470cadae4ab8f568879b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fb4bc8387c504fdc853744ccd72c8574",
              "IPY_MODEL_19d0de43169f4dec812a3c2cc16117a9",
              "IPY_MODEL_107c93980ef04b0fac47a6bc66438ceb"
            ],
            "layout": "IPY_MODEL_01a384c0be5d4efda260ecc050cdb3ce"
          }
        },
        "fb4bc8387c504fdc853744ccd72c8574": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1753e8f2f7fc46d29b5df827b2bb8884",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_46f9657990dc49aea5f39685b2a4e40f",
            "value": "100%"
          }
        },
        "19d0de43169f4dec812a3c2cc16117a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_848aa6d089fc4b55a829954f8b35d603",
            "max": 26298,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b9f0af68016e421da38f607f4e8df39a",
            "value": 26298
          }
        },
        "107c93980ef04b0fac47a6bc66438ceb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2b35bef5fab4086b3e3e1e8445f4796",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_125423eae7ba44eaaca227df46b8f3fe",
            "value": "â€‡26298/26298â€‡[00:21&lt;00:00,â€‡1269.63it/s]"
          }
        },
        "01a384c0be5d4efda260ecc050cdb3ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1753e8f2f7fc46d29b5df827b2bb8884": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46f9657990dc49aea5f39685b2a4e40f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "848aa6d089fc4b55a829954f8b35d603": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9f0af68016e421da38f607f4e8df39a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c2b35bef5fab4086b3e3e1e8445f4796": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "125423eae7ba44eaaca227df46b8f3fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0355b562bbb640dd82a8a0fd0c8d8e1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3a5ca67cadfa4f488ea872ab43732539",
              "IPY_MODEL_ca3a454d9cb9428a9cbfaf3fc7fccb69",
              "IPY_MODEL_b82bd1b565b94de59ecbecf353365cf0"
            ],
            "layout": "IPY_MODEL_6cfbaebd5ced44489ff622844bef13ae"
          }
        },
        "3a5ca67cadfa4f488ea872ab43732539": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c43b980e9fa1468facd6aad00a0067a7",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_0b3b3ebed04e4dcb871209046ceecadb",
            "value": "tokenizer.json:â€‡100%"
          }
        },
        "ca3a454d9cb9428a9cbfaf3fc7fccb69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f31f3e2131f14f7c99b4c19edcb0c8aa",
            "max": 711661,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5cda11bb426840c980d10113d2655710",
            "value": 711661
          }
        },
        "b82bd1b565b94de59ecbecf353365cf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3306f3ead164f748b49ba66a3d5c161",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_742714df22764075ae1aea1319733cd3",
            "value": "â€‡712k/712kâ€‡[00:00&lt;00:00,â€‡9.91MB/s]"
          }
        },
        "6cfbaebd5ced44489ff622844bef13ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c43b980e9fa1468facd6aad00a0067a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b3b3ebed04e4dcb871209046ceecadb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f31f3e2131f14f7c99b4c19edcb0c8aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cda11bb426840c980d10113d2655710": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f3306f3ead164f748b49ba66a3d5c161": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "742714df22764075ae1aea1319733cd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e638a86a4e94430ab9538feb16a99cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e316a9c6feef495c88a433f5c9fa559b",
              "IPY_MODEL_c39621038fdf4bda8b3b7f944aa1f7ca",
              "IPY_MODEL_5efaadf9602c487cab5dd1bbbd79782d"
            ],
            "layout": "IPY_MODEL_278be15e6ad14a73a5ff27b0856a3c3a"
          }
        },
        "e316a9c6feef495c88a433f5c9fa559b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f06b66eae2f4b6595cf54bbeb65258c",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_71eafa7e4b3643d2810da017d1238252",
            "value": "100%"
          }
        },
        "c39621038fdf4bda8b3b7f944aa1f7ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53d3d3ecff4f4a938de01420755a44b1",
            "max": 2647,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_949efc00a02b43218ed7ee8646dea83f",
            "value": 2647
          }
        },
        "5efaadf9602c487cab5dd1bbbd79782d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dbaad1850f1646c984bdbc49259a3c0c",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_fb80a54ce0164b1a813f16a1831f919e",
            "value": "â€‡2647/2647â€‡[00:49&lt;00:00,â€‡82.67it/s]"
          }
        },
        "278be15e6ad14a73a5ff27b0856a3c3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f06b66eae2f4b6595cf54bbeb65258c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71eafa7e4b3643d2810da017d1238252": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "53d3d3ecff4f4a938de01420755a44b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "949efc00a02b43218ed7ee8646dea83f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dbaad1850f1646c984bdbc49259a3c0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb80a54ce0164b1a813f16a1831f919e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b1ca34935f6f4d868d2937545ad6a205": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d3bfbe39ba2946d388ee5b829bb90b39",
              "IPY_MODEL_5fa0641a56064148982ed03b4367d493",
              "IPY_MODEL_7fb70101db2e4442b45f541163fd9359"
            ],
            "layout": "IPY_MODEL_338e3bbd708649528b58098e91967121"
          }
        },
        "d3bfbe39ba2946d388ee5b829bb90b39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d12a206c14d049fc902886845ebbbac8",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_10d451a0d8a5438c93afd408b4d6c205",
            "value": "tokenizer_config.json:â€‡100%"
          }
        },
        "5fa0641a56064148982ed03b4367d493": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a18a3bbabc084461bef5c6c1a12710a3",
            "max": 394,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7e4b218e9d294ff193cbbce325b88a19",
            "value": 394
          }
        },
        "7fb70101db2e4442b45f541163fd9359": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea0e081ad93747aab02985fe7d73d000",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_61188de0c66f4cb79113b3edfaf54b43",
            "value": "â€‡394/394â€‡[00:00&lt;00:00,â€‡19.6kB/s]"
          }
        },
        "338e3bbd708649528b58098e91967121": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d12a206c14d049fc902886845ebbbac8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10d451a0d8a5438c93afd408b4d6c205": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a18a3bbabc084461bef5c6c1a12710a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e4b218e9d294ff193cbbce325b88a19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ea0e081ad93747aab02985fe7d73d000": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61188de0c66f4cb79113b3edfaf54b43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a718bcb76c3b4aa5a97b7ed23d27633c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8dbe2de7bb2b4cd28b27103ee10bf0fe",
              "IPY_MODEL_dafd2f65eaf2492cbb8924941a89a1e9",
              "IPY_MODEL_f30ed2bb43db40b6be79fbe1784a22b2"
            ],
            "layout": "IPY_MODEL_dc3945c69bb248e0a69d83d13c56733e"
          }
        },
        "8dbe2de7bb2b4cd28b27103ee10bf0fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e96ebc627d7431aa50c93ac97816c72",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_0bfa169fbd3d4941806b55b91a8deb83",
            "value": "vocab.txt:â€‡100%"
          }
        },
        "dafd2f65eaf2492cbb8924941a89a1e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57178a3ae7bb4ab491f2c659c44cdeac",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_95808613a46d4708b49a0050fb76a853",
            "value": 231508
          }
        },
        "f30ed2bb43db40b6be79fbe1784a22b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d12cc4f77ad94379b75a3d3aeccc1e38",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_0131cf1e4491432c906287b921f870da",
            "value": "â€‡232k/232kâ€‡[00:00&lt;00:00,â€‡10.3MB/s]"
          }
        },
        "dc3945c69bb248e0a69d83d13c56733e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e96ebc627d7431aa50c93ac97816c72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bfa169fbd3d4941806b55b91a8deb83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "57178a3ae7bb4ab491f2c659c44cdeac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95808613a46d4708b49a0050fb76a853": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d12cc4f77ad94379b75a3d3aeccc1e38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0131cf1e4491432c906287b921f870da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "013e9f99578042c99092b1a4a73b9a4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5996a751ec8a4946901f63cb3c8408a5",
              "IPY_MODEL_4faeb43ad56f4f5b9448f11dc89008ba",
              "IPY_MODEL_300cac470c754aed865c31792bbaea84"
            ],
            "layout": "IPY_MODEL_98cfcbb4585142008056286f98de426b"
          }
        },
        "5996a751ec8a4946901f63cb3c8408a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3623ce01aaf4adf899d907f6abf5098",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_4bd5be4212bf42dc9fb60e7fedae4ed4",
            "value": "special_tokens_map.json:â€‡100%"
          }
        },
        "4faeb43ad56f4f5b9448f11dc89008ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3e73804ad134994ab770230dfc80dd3",
            "max": 125,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_deeeb5da0c634e2bbdccb3952efb7d56",
            "value": 125
          }
        },
        "300cac470c754aed865c31792bbaea84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13da19098dce427f938e77832af7c1c1",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_605b162479f24735ab4f32d317d88f87",
            "value": "â€‡125/125â€‡[00:00&lt;00:00,â€‡6.68kB/s]"
          }
        },
        "98cfcbb4585142008056286f98de426b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3623ce01aaf4adf899d907f6abf5098": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bd5be4212bf42dc9fb60e7fedae4ed4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a3e73804ad134994ab770230dfc80dd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "deeeb5da0c634e2bbdccb3952efb7d56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "13da19098dce427f938e77832af7c1c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "605b162479f24735ab4f32d317d88f87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "65044b2026b04f0ca921d0db379bd6ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ecbb5cb58cb244399fd23a4fe0f23f4a",
              "IPY_MODEL_946b0d4ab5494b2bb399599f3aeed2ea",
              "IPY_MODEL_53e7c07c73a445b3af8ba7b1700ea65e"
            ],
            "layout": "IPY_MODEL_686a5d216c5e494db23f710fafa9ae66"
          }
        },
        "ecbb5cb58cb244399fd23a4fe0f23f4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2533e146572445b9a07161dbad04629e",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b0772679a9b146ed98b37221e2a73168",
            "value": "100%"
          }
        },
        "946b0d4ab5494b2bb399599f3aeed2ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_815f966f6e554cc3933463c066c06c36",
            "max": 2628,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_141a024723684d5aa3e877b92f5c0e65",
            "value": 2628
          }
        },
        "53e7c07c73a445b3af8ba7b1700ea65e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed0057ac3d0c48d4a5789f568f55b3fb",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b520990dd7a8423abc70f92bfa8f07c5",
            "value": "â€‡2628/2628â€‡[00:18&lt;00:00,â€‡191.10it/s]"
          }
        },
        "686a5d216c5e494db23f710fafa9ae66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2533e146572445b9a07161dbad04629e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0772679a9b146ed98b37221e2a73168": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "815f966f6e554cc3933463c066c06c36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "141a024723684d5aa3e877b92f5c0e65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ed0057ac3d0c48d4a5789f568f55b3fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b520990dd7a8423abc70f92bfa8f07c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d2c0cc488ce4bbc9db96fdf535a0ac8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d61b40127beb4fbe9eb0f827d0ddcadd",
              "IPY_MODEL_c66273058bf54af3a1f2d274223cf2cf",
              "IPY_MODEL_4cba78bf756b4d3299aa51402ea1da9d"
            ],
            "layout": "IPY_MODEL_11743f051fa348bfaa77e43d0ab4cc4d"
          }
        },
        "d61b40127beb4fbe9eb0f827d0ddcadd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1ee2619aeba46d38efdcedcfb01a1a1",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_6563f7b1a03a4dbd82c738acb5f8ae87",
            "value": "config.json:â€‡100%"
          }
        },
        "c66273058bf54af3a1f2d274223cf2cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40aab0eb5e7e4c45a49c65c25f5c7193",
            "max": 638,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_69a8d41a80b04f29b871d8747a8edf0c",
            "value": 638
          }
        },
        "4cba78bf756b4d3299aa51402ea1da9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c48ae09887434d6bbd3aa1cd1a49a715",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_8fd147ccf8ba492488a00563c1218c6e",
            "value": "â€‡638/638â€‡[00:00&lt;00:00,â€‡36.2kB/s]"
          }
        },
        "11743f051fa348bfaa77e43d0ab4cc4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1ee2619aeba46d38efdcedcfb01a1a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6563f7b1a03a4dbd82c738acb5f8ae87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "40aab0eb5e7e4c45a49c65c25f5c7193": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69a8d41a80b04f29b871d8747a8edf0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c48ae09887434d6bbd3aa1cd1a49a715": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fd147ccf8ba492488a00563c1218c6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4dac682e25ac40b1ac5e4143d1f75e5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a0469766185e4454a0ebb5ca8df77a98",
              "IPY_MODEL_c1c206b7373645ffa95dabbb01bf1d19",
              "IPY_MODEL_f4ea43e1fad146bd9eb25185770d1eda"
            ],
            "layout": "IPY_MODEL_4b928c998835416bb40beda4c3994706"
          }
        },
        "a0469766185e4454a0ebb5ca8df77a98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ff092c08cc84953b5212219ae60a4e4",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_bc506cdba1b34b9bac903fbd8e0523bb",
            "value": "model.safetensors.index.json:â€‡100%"
          }
        },
        "c1c206b7373645ffa95dabbb01bf1d19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_210f2e45cb244a41a729f247ffe52b4d",
            "max": 23950,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_330c17b5e2794c8a9adfec05ef47e096",
            "value": 23950
          }
        },
        "f4ea43e1fad146bd9eb25185770d1eda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33f9752b189c4f4b9b1e4fe17b529178",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_628e1a6c7a4d4fc8ba2fa8e477ddbb07",
            "value": "â€‡23.9k/23.9kâ€‡[00:00&lt;00:00,â€‡1.54MB/s]"
          }
        },
        "4b928c998835416bb40beda4c3994706": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ff092c08cc84953b5212219ae60a4e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc506cdba1b34b9bac903fbd8e0523bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "210f2e45cb244a41a729f247ffe52b4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "330c17b5e2794c8a9adfec05ef47e096": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "33f9752b189c4f4b9b1e4fe17b529178": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "628e1a6c7a4d4fc8ba2fa8e477ddbb07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "53e06b2ec3c148f39ac185fd6a69f892": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_98d4a01191c84efeab4ed283e35f0fc8",
              "IPY_MODEL_6fc50a7c50f24232b43be214437cc9d6",
              "IPY_MODEL_b69f92feb3ad471587c799858c7a890b"
            ],
            "layout": "IPY_MODEL_49e25bc0d71c468ca244226c571cb366"
          }
        },
        "98d4a01191c84efeab4ed283e35f0fc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96155b33ab3c49debd3f857ef01c1936",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_3ddc921343c84cdc90855d78719f1174",
            "value": "Downloadingâ€‡shards:â€‡100%"
          }
        },
        "6fc50a7c50f24232b43be214437cc9d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a982c076d79e424babda0c358975bf9b",
            "max": 8,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_52747f0d00164746ba3590b0d19a5db4",
            "value": 8
          }
        },
        "b69f92feb3ad471587c799858c7a890b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7389d222a8164c7b8805fc824ef094bf",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_78e2d9554b8d4a71a9371068ce65e20a",
            "value": "â€‡8/8â€‡[02:34&lt;00:00,â€‡18.35s/it]"
          }
        },
        "49e25bc0d71c468ca244226c571cb366": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96155b33ab3c49debd3f857ef01c1936": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ddc921343c84cdc90855d78719f1174": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a982c076d79e424babda0c358975bf9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52747f0d00164746ba3590b0d19a5db4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7389d222a8164c7b8805fc824ef094bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78e2d9554b8d4a71a9371068ce65e20a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "938556fd9d6e4a4b96c4c4d97d896d62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_76bc342bfbb543b5bbb6963aec6afc91",
              "IPY_MODEL_196ad5e3d4b34c34908998c846661b7c",
              "IPY_MODEL_68b7287f3bff451aabc78414fa694d49"
            ],
            "layout": "IPY_MODEL_14f777e5c7cc4bec9e8dc5a627c3ae70"
          }
        },
        "76bc342bfbb543b5bbb6963aec6afc91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bbbc1411ae5f46e588d758bd6a29628c",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b3958da8cda8406b97d2fd208e14595a",
            "value": "model-00001-of-00008.safetensors:â€‡100%"
          }
        },
        "196ad5e3d4b34c34908998c846661b7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_412c4cbab7a0402fb47d4e67b78bb3ac",
            "max": 1889587040,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a80923a093ec4dd9898f6de07f00b000",
            "value": 1889587040
          }
        },
        "68b7287f3bff451aabc78414fa694d49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eea4493968324a759de6ce68bbfb5d2b",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_730636c37a93486aabe31a71d5b8bb44",
            "value": "â€‡1.89G/1.89Gâ€‡[00:14&lt;00:00,â€‡25.3MB/s]"
          }
        },
        "14f777e5c7cc4bec9e8dc5a627c3ae70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbbc1411ae5f46e588d758bd6a29628c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3958da8cda8406b97d2fd208e14595a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "412c4cbab7a0402fb47d4e67b78bb3ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a80923a093ec4dd9898f6de07f00b000": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eea4493968324a759de6ce68bbfb5d2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "730636c37a93486aabe31a71d5b8bb44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3037531e7a5d43deb6a5874970b8c8f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3f3a1d37f9254e0591040c2e76243ac9",
              "IPY_MODEL_e8dac896ab6849dc85dd5b057a6f9e9e",
              "IPY_MODEL_28b45f7f11604273b2f0ea03b54703f4"
            ],
            "layout": "IPY_MODEL_e2da17e4c3e54e0fb0679498c2ace7c5"
          }
        },
        "3f3a1d37f9254e0591040c2e76243ac9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b7bd24633004c85ae1d5a5004e4fb82",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_22e8341014b748a4b6a2820e7ef49554",
            "value": "model-00002-of-00008.safetensors:â€‡100%"
          }
        },
        "e8dac896ab6849dc85dd5b057a6f9e9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb41e20bad0d431f8db1ac14eba9b9af",
            "max": 1946243936,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f8e1cb2847724331963aed53e7136872",
            "value": 1946243936
          }
        },
        "28b45f7f11604273b2f0ea03b54703f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e771dc5648846e5902a49991e6b1125",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ee987b945c22412b8340a1417052b142",
            "value": "â€‡1.95G/1.95Gâ€‡[00:19&lt;00:00,â€‡172MB/s]"
          }
        },
        "e2da17e4c3e54e0fb0679498c2ace7c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b7bd24633004c85ae1d5a5004e4fb82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22e8341014b748a4b6a2820e7ef49554": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb41e20bad0d431f8db1ac14eba9b9af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8e1cb2847724331963aed53e7136872": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5e771dc5648846e5902a49991e6b1125": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee987b945c22412b8340a1417052b142": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c75868b5a31a4cb9b8399603069f1cd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e847a34eba7a4e8f9e4eca6a293781d3",
              "IPY_MODEL_dd699a9d751743a38764744d7edf3b41",
              "IPY_MODEL_f4b6148491cd4d27803a1c1abd7a3582"
            ],
            "layout": "IPY_MODEL_3d55516482b84be6b0ded94c06c22a56"
          }
        },
        "e847a34eba7a4e8f9e4eca6a293781d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5db928559de4b5083f61b473671edb8",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_7306c79b00ec48079c7853d5e6682210",
            "value": "model-00003-of-00008.safetensors:â€‡100%"
          }
        },
        "dd699a9d751743a38764744d7edf3b41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99985546d33f41799a2aec727c29baeb",
            "max": 1979781432,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3e0e2d03d0034fe89590825eaa5d0641",
            "value": 1979781432
          }
        },
        "f4b6148491cd4d27803a1c1abd7a3582": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6a9d62c017d48e3ab0c93d8b39802d9",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_9c5e43f265714f3d943e6809e1fa2890",
            "value": "â€‡1.98G/1.98Gâ€‡[00:21&lt;00:00,â€‡153MB/s]"
          }
        },
        "3d55516482b84be6b0ded94c06c22a56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5db928559de4b5083f61b473671edb8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7306c79b00ec48079c7853d5e6682210": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "99985546d33f41799a2aec727c29baeb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e0e2d03d0034fe89590825eaa5d0641": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d6a9d62c017d48e3ab0c93d8b39802d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c5e43f265714f3d943e6809e1fa2890": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "809d46f634e047b9b798b1b76d40f193": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fc2af1cfaecc4dd2a6ebc0742522ed00",
              "IPY_MODEL_40ebbb8fa88a45c585a16cbc5c049fac",
              "IPY_MODEL_5b9bc18c3e734709a6026a039e9e0fbb"
            ],
            "layout": "IPY_MODEL_44b1a4adb62049989b2a0891b12beeca"
          }
        },
        "fc2af1cfaecc4dd2a6ebc0742522ed00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa287ca182d2449886767723a5bc5604",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_923fb37db8f948f08dafbd04fedbba41",
            "value": "model-00004-of-00008.safetensors:â€‡100%"
          }
        },
        "40ebbb8fa88a45c585a16cbc5c049fac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cbfb2dfd75d54cde806e867ac63ccf8d",
            "max": 1946243984,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c66a8da3f1784caeb7f4544f759e52cb",
            "value": 1946243984
          }
        },
        "5b9bc18c3e734709a6026a039e9e0fbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98fd3824580a40d0960b42507915e030",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_9d1d13bdcc3a4e73bf7d2a7cfc5fecf8",
            "value": "â€‡1.95G/1.95Gâ€‡[00:19&lt;00:00,â€‡164MB/s]"
          }
        },
        "44b1a4adb62049989b2a0891b12beeca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa287ca182d2449886767723a5bc5604": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "923fb37db8f948f08dafbd04fedbba41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cbfb2dfd75d54cde806e867ac63ccf8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c66a8da3f1784caeb7f4544f759e52cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "98fd3824580a40d0960b42507915e030": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d1d13bdcc3a4e73bf7d2a7cfc5fecf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "67367afabaf94cd1b5af86714a84b4ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4d9efc82f3644539ad1170693d1f76b9",
              "IPY_MODEL_063189ec18154e3f8c8b62ad249e274a",
              "IPY_MODEL_584c9f720e7c4cc58165cd9e7db71c34"
            ],
            "layout": "IPY_MODEL_f32c14df4bdf455ea6a4065af60e38d2"
          }
        },
        "4d9efc82f3644539ad1170693d1f76b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f4031c47a5043549def7e89e96b8e18",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_5a622467285e40308c687cd025ed8b82",
            "value": "model-00005-of-00008.safetensors:â€‡100%"
          }
        },
        "063189ec18154e3f8c8b62ad249e274a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f83d0ad9bccd4536903443429d808bbe",
            "max": 1979781448,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_52001aa42df7424e89f52e562d875b81",
            "value": 1979781448
          }
        },
        "584c9f720e7c4cc58165cd9e7db71c34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c9c457fa40842d09f1f67f388f772c1",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_91fc65efb94746179d34f7bc2fd45c00",
            "value": "â€‡1.98G/1.98Gâ€‡[00:19&lt;00:00,â€‡150MB/s]"
          }
        },
        "f32c14df4bdf455ea6a4065af60e38d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f4031c47a5043549def7e89e96b8e18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a622467285e40308c687cd025ed8b82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f83d0ad9bccd4536903443429d808bbe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52001aa42df7424e89f52e562d875b81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6c9c457fa40842d09f1f67f388f772c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91fc65efb94746179d34f7bc2fd45c00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d1cc04811e347a3a4e192bb1c79112f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_694268d933f14accac63ebba5db9c7d9",
              "IPY_MODEL_2e61f4672a454a19b2ef8b73fa182bd7",
              "IPY_MODEL_c417c66d90034e0eb8ab679086117884"
            ],
            "layout": "IPY_MODEL_d1ec7fc6c8664059a78b4f29144f7d4a"
          }
        },
        "694268d933f14accac63ebba5db9c7d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a3f45e469384587b2fcf37647264bee",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_e1559e2b5fe640df87b5bdb33ad0f61f",
            "value": "model-00006-of-00008.safetensors:â€‡100%"
          }
        },
        "2e61f4672a454a19b2ef8b73fa182bd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_388e7f75628d49e2aa0b4512d522569c",
            "max": 1946243984,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a47fce71b41943f88f842d794924fa48",
            "value": 1946243984
          }
        },
        "c417c66d90034e0eb8ab679086117884": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0783cf548ac640038620a2402b869dbe",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_1b813514418b47cb8fa238b5b52672e1",
            "value": "â€‡1.95G/1.95Gâ€‡[00:24&lt;00:00,â€‡73.3MB/s]"
          }
        },
        "d1ec7fc6c8664059a78b4f29144f7d4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a3f45e469384587b2fcf37647264bee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1559e2b5fe640df87b5bdb33ad0f61f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "388e7f75628d49e2aa0b4512d522569c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a47fce71b41943f88f842d794924fa48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0783cf548ac640038620a2402b869dbe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b813514418b47cb8fa238b5b52672e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0429daca2476425788f98117378e8920": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9706709adc9c4817b264c26a460efec4",
              "IPY_MODEL_99cae34d49b64b8bb881a6f1453276a4",
              "IPY_MODEL_5577d83c43e145a7beeb99daf8f94d1c"
            ],
            "layout": "IPY_MODEL_5fa0827952044472a1a05984a3516515"
          }
        },
        "9706709adc9c4817b264c26a460efec4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b55b51ed02746478edc07593beb30a2",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_0a16eca4a0844fcd92eb6e7cebc4b72c",
            "value": "model-00007-of-00008.safetensors:â€‡100%"
          }
        },
        "99cae34d49b64b8bb881a6f1453276a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d84c61de5664b1dad0f2f5493a3d3ef",
            "max": 1979781448,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4d93a00b62bb4564b57902417653e5fe",
            "value": 1979781448
          }
        },
        "5577d83c43e145a7beeb99daf8f94d1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ecb9a709595467492285ce715b71f8f",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_1495b7636489490db699588ec0ad4612",
            "value": "â€‡1.98G/1.98Gâ€‡[00:23&lt;00:00,â€‡27.0MB/s]"
          }
        },
        "5fa0827952044472a1a05984a3516515": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b55b51ed02746478edc07593beb30a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a16eca4a0844fcd92eb6e7cebc4b72c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d84c61de5664b1dad0f2f5493a3d3ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d93a00b62bb4564b57902417653e5fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2ecb9a709595467492285ce715b71f8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1495b7636489490db699588ec0ad4612": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0af26ce9c2aa4c6aa5cee2879fb02572": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ee0bd4b3cb0a457f91a1cad9c88e2251",
              "IPY_MODEL_2ff8e73a7d034e65b66a0cbf025b5fd1",
              "IPY_MODEL_ddbc700cfcb74a34a76ce8b3e9b5cb20"
            ],
            "layout": "IPY_MODEL_94b26c24c6764de3868b56ff74fadacb"
          }
        },
        "ee0bd4b3cb0a457f91a1cad9c88e2251": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b39fba673d745d099cb9e22c9ccdab4",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b2a47f3bf810469a84d9a51446416bbb",
            "value": "model-00008-of-00008.safetensors:â€‡100%"
          }
        },
        "2ff8e73a7d034e65b66a0cbf025b5fd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0313318522674c4a96f1bf44578bba05",
            "max": 815834680,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6d4a4700840c4038bdf1a1b9b67c0315",
            "value": 815834680
          }
        },
        "ddbc700cfcb74a34a76ce8b3e9b5cb20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98888307619545c5a59b268f12e5f4fc",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_eb04426d2eaf49c1bd8f2dc1217af4fc",
            "value": "â€‡816M/816Mâ€‡[00:10&lt;00:00,â€‡26.4MB/s]"
          }
        },
        "94b26c24c6764de3868b56ff74fadacb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b39fba673d745d099cb9e22c9ccdab4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2a47f3bf810469a84d9a51446416bbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0313318522674c4a96f1bf44578bba05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d4a4700840c4038bdf1a1b9b67c0315": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "98888307619545c5a59b268f12e5f4fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb04426d2eaf49c1bd8f2dc1217af4fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fb605e03c6f64a34b2c7f03d82c6f1eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_baef72b4adb5425ea312be22a4177900",
              "IPY_MODEL_99cd59a7a44047beb9f77a4111ea16e5",
              "IPY_MODEL_006aeef7c58b4b518f5868f59f625e6e"
            ],
            "layout": "IPY_MODEL_b4d0e81ae3f34b7c80604a24bed9e05c"
          }
        },
        "baef72b4adb5425ea312be22a4177900": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d12666709e924965a24031f61d01b6a1",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_28140a19f7ef49a1851d663d81607ce3",
            "value": "Loadingâ€‡checkpointâ€‡shards:â€‡100%"
          }
        },
        "99cd59a7a44047beb9f77a4111ea16e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9180a08ebdc4df6813f7361aa5c666a",
            "max": 8,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fddfc6a30e2b4ba6a5bcf5ab32c6f943",
            "value": 8
          }
        },
        "006aeef7c58b4b518f5868f59f625e6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fcfbc4fcf85d4616b91bb710b13b9293",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_1a335537b8e146d184c28942c627b66b",
            "value": "â€‡8/8â€‡[01:14&lt;00:00,â€‡â€‡8.27s/it]"
          }
        },
        "b4d0e81ae3f34b7c80604a24bed9e05c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d12666709e924965a24031f61d01b6a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28140a19f7ef49a1851d663d81607ce3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c9180a08ebdc4df6813f7361aa5c666a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fddfc6a30e2b4ba6a5bcf5ab32c6f943": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fcfbc4fcf85d4616b91bb710b13b9293": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a335537b8e146d184c28942c627b66b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3589718557884bb784edcc7ae8373d4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_036ed306dcfc482fb22fbc2c88c195c5",
              "IPY_MODEL_8506b289b9c447cca4262869aa924c9d",
              "IPY_MODEL_cde91f23f6d947e290db63458c85e1cf"
            ],
            "layout": "IPY_MODEL_960872bc4fa3476d8fbd2822ec88642f"
          }
        },
        "036ed306dcfc482fb22fbc2c88c195c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8222c3e872a4e3e9f2127d17145de43",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_a94b3d2888114ff7a81e853b8478c64a",
            "value": "generation_config.json:â€‡100%"
          }
        },
        "8506b289b9c447cca4262869aa924c9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bbf1e080955b42f985a5987392fadb8c",
            "max": 111,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aca3a933002841579889196cf378bd5d",
            "value": 111
          }
        },
        "cde91f23f6d947e290db63458c85e1cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f817c541724f46be9200cf12185b1eeb",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b79697abbfae4e9397c921c51dbd3ad8",
            "value": "â€‡111/111â€‡[00:00&lt;00:00,â€‡6.11kB/s]"
          }
        },
        "960872bc4fa3476d8fbd2822ec88642f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8222c3e872a4e3e9f2127d17145de43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a94b3d2888114ff7a81e853b8478c64a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bbf1e080955b42f985a5987392fadb8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aca3a933002841579889196cf378bd5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f817c541724f46be9200cf12185b1eeb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b79697abbfae4e9397c921c51dbd3ad8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "16d2b21ffc7b4390980899157d5a43b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f457c697d65f4f0e970b845ec719a52b",
              "IPY_MODEL_e368db3efdde4e5b934e7a909a2f5e30",
              "IPY_MODEL_03687fe0ce7e41cd93cadc543270165d"
            ],
            "layout": "IPY_MODEL_07eba3f9a247466c98580b2bb390acc3"
          }
        },
        "f457c697d65f4f0e970b845ec719a52b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0939e50659a4bd18524574d28099170",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_588abedffd0b413aab3ea9fc4624e4a3",
            "value": "tokenizer_config.json:â€‡100%"
          }
        },
        "e368db3efdde4e5b934e7a909a2f5e30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3252e04cb6b4e318293eac1075051c4",
            "max": 1431,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a348eb43dddf4e38a778f4b85cbf5e11",
            "value": 1431
          }
        },
        "03687fe0ce7e41cd93cadc543270165d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8599402df210445094594c53f5ca5467",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_dd43d48dd11944e78fd2210e13a75764",
            "value": "â€‡1.43k/1.43kâ€‡[00:00&lt;00:00,â€‡71.1kB/s]"
          }
        },
        "07eba3f9a247466c98580b2bb390acc3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0939e50659a4bd18524574d28099170": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "588abedffd0b413aab3ea9fc4624e4a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e3252e04cb6b4e318293eac1075051c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a348eb43dddf4e38a778f4b85cbf5e11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8599402df210445094594c53f5ca5467": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd43d48dd11944e78fd2210e13a75764": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56cd625f9e884365aecebae7aba82bfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a3aa718eeb0d46169dc90d441ba52c9f",
              "IPY_MODEL_40412be75c784d6b87af16f1d3066243",
              "IPY_MODEL_5f5ae128c39f4da3a814d21f62360943"
            ],
            "layout": "IPY_MODEL_d5a1f3f66e7a428a89dd0a16cdf1018b"
          }
        },
        "a3aa718eeb0d46169dc90d441ba52c9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d39e0b274124d2593ba142274d90294",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_43fb1a3473024c67b42579796574e4b0",
            "value": "tokenizer.model:â€‡100%"
          }
        },
        "40412be75c784d6b87af16f1d3066243": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1016c970819943f8a40c5321310d22f1",
            "max": 493443,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3400d99a2ac745389fbd5aff7caa6f58",
            "value": 493443
          }
        },
        "5f5ae128c39f4da3a814d21f62360943": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10d7a9c2b9784e4b8fefc18525213184",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ffe2019b3311460b808c74acd837ce17",
            "value": "â€‡493k/493kâ€‡[00:00&lt;00:00,â€‡33.4MB/s]"
          }
        },
        "d5a1f3f66e7a428a89dd0a16cdf1018b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d39e0b274124d2593ba142274d90294": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43fb1a3473024c67b42579796574e4b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1016c970819943f8a40c5321310d22f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3400d99a2ac745389fbd5aff7caa6f58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "10d7a9c2b9784e4b8fefc18525213184": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffe2019b3311460b808c74acd837ce17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de391a5d021845f39972a1f67d5ddda0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a2e82011ce09477ab98e83b2a9088cec",
              "IPY_MODEL_cdd61cd6a468464e87c4a61a45bd3257",
              "IPY_MODEL_27bad1cab965434b8d822d768ca64756"
            ],
            "layout": "IPY_MODEL_cd959fabb61e407e98c2a8c098870ac2"
          }
        },
        "a2e82011ce09477ab98e83b2a9088cec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be48478688524ef7978717855dc3bc7e",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_91ab06da42054504bc3b2633dd33b8d2",
            "value": "tokenizer.json:â€‡100%"
          }
        },
        "cdd61cd6a468464e87c4a61a45bd3257": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de53b6104bed4ab489aa0f48eddf999c",
            "max": 1795303,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9fd165d1755c4a6bbc0d6202089e8f9f",
            "value": 1795303
          }
        },
        "27bad1cab965434b8d822d768ca64756": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c7ceabe733d43b9be1df883f400e662",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_507dd012264748ceb18e952911389f39",
            "value": "â€‡1.80M/1.80Mâ€‡[00:00&lt;00:00,â€‡7.11MB/s]"
          }
        },
        "cd959fabb61e407e98c2a8c098870ac2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be48478688524ef7978717855dc3bc7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91ab06da42054504bc3b2633dd33b8d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de53b6104bed4ab489aa0f48eddf999c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9fd165d1755c4a6bbc0d6202089e8f9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3c7ceabe733d43b9be1df883f400e662": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "507dd012264748ceb18e952911389f39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f9138bc4359d4e2cab77b7afd6dd702f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6ad9b918c0594f78a3f6d732aae749aa",
              "IPY_MODEL_9f5f081277ad48fcb4181e804e335256",
              "IPY_MODEL_5b2bc7574f3e44eba2016e915f6f8def"
            ],
            "layout": "IPY_MODEL_df3b1bba00d54cf6809d583cc34be569"
          }
        },
        "6ad9b918c0594f78a3f6d732aae749aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b41593b00124058acf8beedcfc20ae5",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_a10ac0b859f749f589bd9dfe3aa7d2c5",
            "value": "added_tokens.json:â€‡100%"
          }
        },
        "9f5f081277ad48fcb4181e804e335256": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8c72e5a12f247bca25ce1e6add48778",
            "max": 42,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_74d456ceba6c438080d651bab2936b14",
            "value": 42
          }
        },
        "5b2bc7574f3e44eba2016e915f6f8def": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb346ddcf0754712bc66137baa686f26",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_75f3af394a4c4e51a08b677178caa649",
            "value": "â€‡42.0/42.0â€‡[00:00&lt;00:00,â€‡2.73kB/s]"
          }
        },
        "df3b1bba00d54cf6809d583cc34be569": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b41593b00124058acf8beedcfc20ae5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a10ac0b859f749f589bd9dfe3aa7d2c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8c72e5a12f247bca25ce1e6add48778": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74d456ceba6c438080d651bab2936b14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fb346ddcf0754712bc66137baa686f26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75f3af394a4c4e51a08b677178caa649": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "40b266538cde441682b1f3d78acb7fb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f58fbe700b084630bff1a58a95a5c570",
              "IPY_MODEL_db4953a2e7594e18a4a58fa2bc52faa1",
              "IPY_MODEL_660b514e33994687976da66512ff5352"
            ],
            "layout": "IPY_MODEL_bb74dd4eccc24f2791b876f28fdfebec"
          }
        },
        "f58fbe700b084630bff1a58a95a5c570": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48d0fa9e26ef4135a4965b4af1f4f81a",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_fa989e5e176347ab94b4754cabc2550a",
            "value": "special_tokens_map.json:â€‡100%"
          }
        },
        "db4953a2e7594e18a4a58fa2bc52faa1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3b51c03f7c24b338953c9589940415c",
            "max": 168,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9c592408643144e38d3f73bee2f3767f",
            "value": 168
          }
        },
        "660b514e33994687976da66512ff5352": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13714417d40b4f06a47662bd50d8b73d",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_72d4592a87314a7e88c95460c42dd5b1",
            "value": "â€‡168/168â€‡[00:00&lt;00:00,â€‡8.21kB/s]"
          }
        },
        "bb74dd4eccc24f2791b876f28fdfebec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48d0fa9e26ef4135a4965b4af1f4f81a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa989e5e176347ab94b4754cabc2550a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e3b51c03f7c24b338953c9589940415c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c592408643144e38d3f73bee2f3767f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "13714417d40b4f06a47662bd50d8b73d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72d4592a87314a7e88c95460c42dd5b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f431fb8ce0545ad9bb5734725799cd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0abd5ecb830d42b4a06539793b66468f",
              "IPY_MODEL_7be9df84381548318ef3c85afac24326",
              "IPY_MODEL_6cdd4c96d0c04787a134b45cbe89df65"
            ],
            "layout": "IPY_MODEL_05b5ddfc712a4bfba8b3e360dd6ddc25"
          }
        },
        "0abd5ecb830d42b4a06539793b66468f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_666f80e150a349ceae4ac0998dab5291",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_e2eb0d62de1a4bda9b379ac8ed094a8b",
            "value": "artifact.metadata:â€‡100%"
          }
        },
        "7be9df84381548318ef3c85afac24326": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06a598f51b2f4e5fb17db5712975b3f7",
            "max": 1633,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_72ce7eb0b65f424f93488e1091e4c120",
            "value": 1633
          }
        },
        "6cdd4c96d0c04787a134b45cbe89df65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d04ddb575d54f77ac2437b66d8b39c2",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_5dd2f22305bc4fae932587839f3c5bc9",
            "value": "â€‡1.63k/1.63kâ€‡[00:00&lt;00:00,â€‡79.9kB/s]"
          }
        },
        "05b5ddfc712a4bfba8b3e360dd6ddc25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "666f80e150a349ceae4ac0998dab5291": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2eb0d62de1a4bda9b379ac8ed094a8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "06a598f51b2f4e5fb17db5712975b3f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72ce7eb0b65f424f93488e1091e4c120": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9d04ddb575d54f77ac2437b66d8b39c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5dd2f22305bc4fae932587839f3c5bc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cfbe93182fb645bab1d24163a89070c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c79f10c28398429cbdff0062a1f4e416",
              "IPY_MODEL_6c9532ae067249c8a60d58104ea157c6",
              "IPY_MODEL_739a88f13d714070aba2874ab0a1bdbd"
            ],
            "layout": "IPY_MODEL_cb2947fbd6784386a3188923be85be63"
          }
        },
        "c79f10c28398429cbdff0062a1f4e416": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a29b1445e7814070bf56525fc3dfdc01",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_d59c257e88264da1b3c7e957e1faab9a",
            "value": "config.json:â€‡100%"
          }
        },
        "6c9532ae067249c8a60d58104ea157c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e09c23f4fbbd4d05aad639b62b09c65f",
            "max": 743,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dc30fc935928492094a8f9577b3abea7",
            "value": 743
          }
        },
        "739a88f13d714070aba2874ab0a1bdbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60d7e29df2ec47bf8e475fd86f69fb14",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_d24c8190394a4314a4cc5f478493b2bd",
            "value": "â€‡743/743â€‡[00:00&lt;00:00,â€‡52.3kB/s]"
          }
        },
        "cb2947fbd6784386a3188923be85be63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a29b1445e7814070bf56525fc3dfdc01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d59c257e88264da1b3c7e957e1faab9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e09c23f4fbbd4d05aad639b62b09c65f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc30fc935928492094a8f9577b3abea7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "60d7e29df2ec47bf8e475fd86f69fb14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d24c8190394a4314a4cc5f478493b2bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e65be1bb2be844f88c74b967d84c03ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9a38ad70e85944bba5edf61d3d912595",
              "IPY_MODEL_133e5d51f37242f49059d32adb03fbf4",
              "IPY_MODEL_111e98ff4c5c4dbebf96d783ea13ceed"
            ],
            "layout": "IPY_MODEL_9fcd0add1b094f6b9671d9ac8d99840c"
          }
        },
        "9a38ad70e85944bba5edf61d3d912595": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b10e2347160f4e4d97963118f0d8a511",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_94e3a6f9cedb4390a753b185af3c00c4",
            "value": "model.safetensors:â€‡100%"
          }
        },
        "133e5d51f37242f49059d32adb03fbf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c20c0eb50874713b1e924c116d0d4b2",
            "max": 438349816,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4c59436f6bc24c61bdbf968e5b3db5a6",
            "value": 438349816
          }
        },
        "111e98ff4c5c4dbebf96d783ea13ceed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_497592031c084946a3f842bd895203e7",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_7865fa1f9a204029981791871b19e6e2",
            "value": "â€‡438M/438Mâ€‡[00:02&lt;00:00,â€‡182MB/s]"
          }
        },
        "9fcd0add1b094f6b9671d9ac8d99840c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b10e2347160f4e4d97963118f0d8a511": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94e3a6f9cedb4390a753b185af3c00c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c20c0eb50874713b1e924c116d0d4b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c59436f6bc24c61bdbf968e5b3db5a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "497592031c084946a3f842bd895203e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7865fa1f9a204029981791871b19e6e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "93de4aa8a52347e5875a9cef2db1014e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_203d9bf06e2c42249450740c5443a05d",
              "IPY_MODEL_0b31f241559e46d58543b8d7c2ae6fcc",
              "IPY_MODEL_960874129fe347b2bc18dec28b8b60ee"
            ],
            "layout": "IPY_MODEL_28d4aecec3d9491b815556852b4ec66b"
          }
        },
        "203d9bf06e2c42249450740c5443a05d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_214d8f8757b04e91b2e490ecf243b6bf",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_c69568acc9c94d0fb426359d849c0a80",
            "value": "tokenizer_config.json:â€‡100%"
          }
        },
        "0b31f241559e46d58543b8d7c2ae6fcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea0e5d6c95a1493bafad4611ed88cdf4",
            "max": 405,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ee3370325c5a4abfa8efe2501f741539",
            "value": 405
          }
        },
        "960874129fe347b2bc18dec28b8b60ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5f6d68f983e418480d6e12972a664ad",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ec6f7ad19d904f11b76bcdc8a352bce5",
            "value": "â€‡405/405â€‡[00:00&lt;00:00,â€‡28.3kB/s]"
          }
        },
        "28d4aecec3d9491b815556852b4ec66b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "214d8f8757b04e91b2e490ecf243b6bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c69568acc9c94d0fb426359d849c0a80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ea0e5d6c95a1493bafad4611ed88cdf4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee3370325c5a4abfa8efe2501f741539": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f5f6d68f983e418480d6e12972a664ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec6f7ad19d904f11b76bcdc8a352bce5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf2bb0d6c2e34916a6fc2a411134d678": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ef0fcbda6dc841898fd9e93b7aaecbde",
              "IPY_MODEL_b2a85eef467d42108631c4ad5688adb5",
              "IPY_MODEL_eb94037fac7545d7bd8db6dbc4e76a4e"
            ],
            "layout": "IPY_MODEL_e8e88d856f914b2a9ce89bbe3e57994e"
          }
        },
        "ef0fcbda6dc841898fd9e93b7aaecbde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_449968c0d7de4adb843f11e8586363cc",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_5035e42a83f54ee8a1a14f319e04b548",
            "value": "vocab.txt:â€‡100%"
          }
        },
        "b2a85eef467d42108631c4ad5688adb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d8c53f84ab34fea81a861deb84589d9",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0b751780d0d046f19219f1358f9b363e",
            "value": 231508
          }
        },
        "eb94037fac7545d7bd8db6dbc4e76a4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_812794b823034e15bcb1650cf72ae1df",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_c4aaf6ff067742c29614bec5221397e8",
            "value": "â€‡232k/232kâ€‡[00:00&lt;00:00,â€‡9.51MB/s]"
          }
        },
        "e8e88d856f914b2a9ce89bbe3e57994e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "449968c0d7de4adb843f11e8586363cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5035e42a83f54ee8a1a14f319e04b548": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d8c53f84ab34fea81a861deb84589d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b751780d0d046f19219f1358f9b363e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "812794b823034e15bcb1650cf72ae1df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4aaf6ff067742c29614bec5221397e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "573ab7fe33854c709e75be4e52b7d148": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f79cb7a3693249dba13b5043aeb83712",
              "IPY_MODEL_500cd84759b647c8a99ee5a8b9937e66",
              "IPY_MODEL_2d8eaba1e5d6492a8531d899b00e5071"
            ],
            "layout": "IPY_MODEL_e1c14d19874340569f7fba495c76a670"
          }
        },
        "f79cb7a3693249dba13b5043aeb83712": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d12e74a5cc94e3d858e902e35876a34",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_3601dfd92daa42de87fb0842a3095d15",
            "value": "tokenizer.json:â€‡100%"
          }
        },
        "500cd84759b647c8a99ee5a8b9937e66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa4a08fbb5124430b5fff2c25acab6a2",
            "max": 466081,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e1a820f2ef7c4e3faf0d81d88e57a76f",
            "value": 466081
          }
        },
        "2d8eaba1e5d6492a8531d899b00e5071": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a19ccde63e854adca9cbeb446496e065",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_268214273e9d42e69aa2c890171b4cdf",
            "value": "â€‡466k/466kâ€‡[00:00&lt;00:00,â€‡19.8MB/s]"
          }
        },
        "e1c14d19874340569f7fba495c76a670": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d12e74a5cc94e3d858e902e35876a34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3601dfd92daa42de87fb0842a3095d15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa4a08fbb5124430b5fff2c25acab6a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1a820f2ef7c4e3faf0d81d88e57a76f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a19ccde63e854adca9cbeb446496e065": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "268214273e9d42e69aa2c890171b4cdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "14b7777970bb47d29f6e30608a1a64e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_64fc701ad9ac42fa8273409a4fc92e45",
              "IPY_MODEL_b02b396ef7d0439aa51a547b88849f33",
              "IPY_MODEL_22af33aed47c4d30b8050a0235d8d6dd"
            ],
            "layout": "IPY_MODEL_af729fa54b194b7f90be6d3177a4790e"
          }
        },
        "64fc701ad9ac42fa8273409a4fc92e45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e760da3abfa946d084641d3747b25897",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_fa1bd764c6fe4ad6a9d7d7c6dd2de1be",
            "value": "special_tokens_map.json:â€‡100%"
          }
        },
        "b02b396ef7d0439aa51a547b88849f33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_756c798c47634d19beb5f0cfd540658e",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0c99c8741700410bb9fa30b5fba4b244",
            "value": 112
          }
        },
        "22af33aed47c4d30b8050a0235d8d6dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c977ddb3393c498495fcb893865907ae",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_94b4a04a976248fb9b3ddf21bdf3f043",
            "value": "â€‡112/112â€‡[00:00&lt;00:00,â€‡7.03kB/s]"
          }
        },
        "af729fa54b194b7f90be6d3177a4790e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e760da3abfa946d084641d3747b25897": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa1bd764c6fe4ad6a9d7d7c6dd2de1be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "756c798c47634d19beb5f0cfd540658e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c99c8741700410bb9fa30b5fba4b244": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c977ddb3393c498495fcb893865907ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94b4a04a976248fb9b3ddf21bdf3f043": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}